{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1dvL5kuoM5tHLdsE2oonRMJQ7BTMQciwU",
      "authorship_tag": "ABX9TyMMORhH64bico/OwWxfch/q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnastasiyaRahulina/Women-in-Data-Science-Datathon-March-2024/blob/main/WiDS_2024_smote_classifiers_ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpbZU1CZrZ_K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AqtpMTGzy76",
        "outputId": "c3a2b3c9-cdac-4f63-8992-dc7aefd1aeda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.5.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.27)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.10.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.2 alembic-1.13.1 colorlog-6.8.2 optuna-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import optuna"
      ],
      "metadata": {
        "id": "8ymK-_DXzxTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/WinDS/training_modified.csv', index_col=0)\n"
      ],
      "metadata": {
        "id": "qnFWG_sXxsFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('/content/drive/MyDrive/WinDS/test_modified.csv', index_col=0)"
      ],
      "metadata": {
        "id": "fxPnaAnKKCJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.drop(columns=['N02', 'farmer', 'never_married'], inplace = True)\n"
      ],
      "metadata": {
        "id": "q0unONvFr3FQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.drop(columns=['N02', 'farmer', 'never_married'], inplace = True)"
      ],
      "metadata": {
        "id": "XwjjOQtUKGK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data = pd.read_csv('/content/drive/MyDrive/WinDS/csv_sets/data_simple.csv', index_col=0)\n",
        "# test_data = pd.read_csv('/content/drive/MyDrive/WinDS/csv_sets/data_test_simple.csv', index_col=0)"
      ],
      "metadata": {
        "id": "fDTNGADEx7P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data = pd.read_csv('/content/drive/MyDrive/WinDS/csv_sets/data_aug.csv', index_col=0)\n",
        "# test_data = pd.read_csv('/content/drive/MyDrive/WinDS/csv_sets/data_test_aug.csv', index_col=0)"
      ],
      "metadata": {
        "id": "08Y24mV2zf1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "123nDcPJx91K",
        "outputId": "ed581dbe-0b46-44b2-ec2a-6a3e16e1051f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   DiagPeriodL90D  Division_East North Central  Division_East South Central  \\\n",
              "0               1                            0                            0   \n",
              "1               1                            0                            0   \n",
              "2               1                            0                            0   \n",
              "3               0                            0                            0   \n",
              "4               0                            0                            0   \n",
              "\n",
              "   Division_Middle Atlantic  Division_Mountain  Division_New England  \\\n",
              "0                         0                  0                     0   \n",
              "1                         0                  0                     0   \n",
              "2                         0                  0                     0   \n",
              "3                         0                  0                     0   \n",
              "4                         0                  1                     0   \n",
              "\n",
              "   Division_Pacific  Division_South Atlantic  Division_West North Central  \\\n",
              "0                 1                        0                            0   \n",
              "1                 1                        0                            0   \n",
              "2                 0                        0                            0   \n",
              "3                 1                        0                            0   \n",
              "4                 0                        0                            0   \n",
              "\n",
              "   Division_West South Central        N02      Ozone      PM25  \\\n",
              "0                            0  18.606528  52.237210  8.650555   \n",
              "1                            0  20.113179  42.301121  8.487175   \n",
              "2                            1  14.839351  40.108207  7.642753   \n",
              "3                            0  15.894123  42.070075  7.229393   \n",
              "4                            0  11.722197  41.356058  4.110749   \n",
              "\n",
              "   Region_Midwest  Region_Northeast  Region_South  Region_West  age_10_to_19  \\\n",
              "0               0                 0             0            1     15.542857   \n",
              "1               0                 0             0            1     13.354545   \n",
              "2               0                 0             1            0     14.463333   \n",
              "3               0                 0             0            1     12.135714   \n",
              "4               0                 0             0            1     13.976000   \n",
              "\n",
              "     age_20s    age_30s    age_40s    age_50s    age_60s   age_70s  \\\n",
              "0  17.614286  14.014286  11.614286  11.557143   7.571429  4.000000   \n",
              "1  14.230303  13.418182  13.333333  14.060606  10.248485  5.951515   \n",
              "2  12.531667  13.545000  12.860000  12.770000  11.426667  6.565000   \n",
              "3  12.538095  12.464286  12.650000  14.847619  12.280952  8.216667   \n",
              "4   9.492000  10.364000  12.600000  14.992000  14.836000  9.462000   \n",
              "\n",
              "   age_median  age_over_80  age_under_10  \\\n",
              "0   30.642857     2.100000     16.014286   \n",
              "1   38.200000     3.503030     11.878788   \n",
              "2   37.906667     2.811667     13.028333   \n",
              "3   42.871429     4.759524     10.071429   \n",
              "4   43.473469     3.466000     10.824000   \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malig neoplasm quadrant left femal breast  \\\n",
              "0                                                  0                                  \n",
              "1                                                  0                                  \n",
              "2                                                  0                                  \n",
              "3                                                  1                                  \n",
              "4                                                  0                                  \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malig neoplasm quadrant right male breast  \\\n",
              "0                                                  0                                  \n",
              "1                                                  0                                  \n",
              "2                                                  0                                  \n",
              "3                                                  0                                  \n",
              "4                                                  0                                  \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malig neoplasm quadrant unsp femal breast  \\\n",
              "0                                                  0                                  \n",
              "1                                                  0                                  \n",
              "2                                                  0                                  \n",
              "3                                                  0                                  \n",
              "4                                                  0                                  \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malig neoplm quadrant right femal breast  \\\n",
              "0                                                  0                                 \n",
              "1                                                  1                                 \n",
              "2                                                  0                                 \n",
              "3                                                  0                                 \n",
              "4                                                  0                                 \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm axillari tail femal breast  \\\n",
              "0                                                  0                                   \n",
              "1                                                  0                                   \n",
              "2                                                  0                                   \n",
              "3                                                  0                                   \n",
              "4                                                  0                                   \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm axillari tail left femal breast  \\\n",
              "0                                                  0                                        \n",
              "1                                                  0                                        \n",
              "2                                                  0                                        \n",
              "3                                                  0                                        \n",
              "4                                                  0                                        \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm axillari tail right femal breast  \\\n",
              "0                                                  0                                         \n",
              "1                                                  0                                         \n",
              "2                                                  0                                         \n",
              "3                                                  0                                         \n",
              "4                                                  0                                         \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm axillari tail unsp femal breast  \\\n",
              "0                                                  0                                        \n",
              "1                                                  0                                        \n",
              "2                                                  0                                        \n",
              "3                                                  0                                        \n",
              "4                                                  0                                        \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm breast  \\\n",
              "0                                                  0               \n",
              "1                                                  0               \n",
              "2                                                  0               \n",
              "3                                                  0               \n",
              "4                                                  0               \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm breast femal unspecifi  \\\n",
              "0                                                  0                               \n",
              "1                                                  0                               \n",
              "2                                                  0                               \n",
              "3                                                  0                               \n",
              "4                                                  1                               \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm breast unspecifi site  \\\n",
              "0                                                  0                              \n",
              "1                                                  0                              \n",
              "2                                                  0                              \n",
              "3                                                  0                              \n",
              "4                                                  0                              \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm breast unspecifi site femal  \\\n",
              "0                                                  0                                    \n",
              "1                                                  0                                    \n",
              "2                                                  0                                    \n",
              "3                                                  0                                    \n",
              "4                                                  0                                    \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm central portion breast femal  \\\n",
              "0                                                  0                                     \n",
              "1                                                  0                                     \n",
              "2                                                  0                                     \n",
              "3                                                  0                                     \n",
              "4                                                  0                                     \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm central portion femal breast  \\\n",
              "0                                                  0                                     \n",
              "1                                                  0                                     \n",
              "2                                                  0                                     \n",
              "3                                                  0                                     \n",
              "4                                                  0                                     \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm central portion left femal breast  \\\n",
              "0                                                  0                                          \n",
              "1                                                  0                                          \n",
              "2                                                  1                                          \n",
              "3                                                  0                                          \n",
              "4                                                  0                                          \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm central portion right femal breast  \\\n",
              "0                                                  0                                           \n",
              "1                                                  0                                           \n",
              "2                                                  0                                           \n",
              "3                                                  0                                           \n",
              "4                                                  0                                           \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm central portion unsp femal breast  \\\n",
              "0                                                  0                                          \n",
              "1                                                  0                                          \n",
              "2                                                  0                                          \n",
              "3                                                  0                                          \n",
              "4                                                  0                                          \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm nippl areola femal  \\\n",
              "0                                                  0                           \n",
              "1                                                  0                           \n",
              "2                                                  0                           \n",
              "3                                                  0                           \n",
              "4                                                  0                           \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm nippl areola left femal breast  \\\n",
              "0                                                  0                                       \n",
              "1                                                  0                                       \n",
              "2                                                  0                                       \n",
              "3                                                  0                                       \n",
              "4                                                  0                                       \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm nippl areola right femal breast  \\\n",
              "0                                                  0                                        \n",
              "1                                                  0                                        \n",
              "2                                                  0                                        \n",
              "3                                                  0                                        \n",
              "4                                                  0                                        \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm nippl areola unsp femal breast  \\\n",
              "0                                                  0                                       \n",
              "1                                                  0                                       \n",
              "2                                                  0                                       \n",
              "3                                                  0                                       \n",
              "4                                                  0                                       \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm overlap site breast femal  \\\n",
              "0                                                  0                                  \n",
              "1                                                  0                                  \n",
              "2                                                  0                                  \n",
              "3                                                  0                                  \n",
              "4                                                  0                                  \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm ovrlp site left femal breast  \\\n",
              "0                                                  0                                     \n",
              "1                                                  0                                     \n",
              "2                                                  0                                     \n",
              "3                                                  0                                     \n",
              "4                                                  0                                     \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm ovrlp site right femal breast  \\\n",
              "0                                                  0                                      \n",
              "1                                                  0                                      \n",
              "2                                                  0                                      \n",
              "3                                                  0                                      \n",
              "4                                                  0                                      \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm ovrlp site unsp femal breast  \\\n",
              "0                                                  0                                     \n",
              "1                                                  0                                     \n",
              "2                                                  0                                     \n",
              "3                                                  0                                     \n",
              "4                                                  0                                     \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm quadrant breast femal  \\\n",
              "0                                                  0                              \n",
              "1                                                  0                              \n",
              "2                                                  0                              \n",
              "3                                                  0                              \n",
              "4                                                  0                              \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm quadrant femal breast  \\\n",
              "0                                                  0                              \n",
              "1                                                  0                              \n",
              "2                                                  0                              \n",
              "3                                                  0                              \n",
              "4                                                  0                              \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm specifi site femal breast  \\\n",
              "0                                                  0                                  \n",
              "1                                                  0                                  \n",
              "2                                                  0                                  \n",
              "3                                                  0                                  \n",
              "4                                                  0                                  \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm unsp site right femal breast  \\\n",
              "0                                                  0                                     \n",
              "1                                                  0                                     \n",
              "2                                                  0                                     \n",
              "3                                                  0                                     \n",
              "4                                                  0                                     \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm unsp site unspecifi femal breast  \\\n",
              "0                                                  1                                         \n",
              "1                                                  0                                         \n",
              "2                                                  0                                         \n",
              "3                                                  0                                         \n",
              "4                                                  0                                         \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm unsp site unspecifi male breast  \\\n",
              "0                                                  0                                        \n",
              "1                                                  0                                        \n",
              "2                                                  0                                        \n",
              "3                                                  0                                        \n",
              "4                                                  0                                        \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_malign neoplasm unspecifi site left femal breast  \\\n",
              "0                                                  0                                         \n",
              "1                                                  0                                         \n",
              "2                                                  0                                         \n",
              "3                                                  0                                         \n",
              "4                                                  0                                         \n",
              "\n",
              "   breast_cancer_diagnosis_desc_processed_secondari malign neoplasm breast  \\\n",
              "0                                                  0                         \n",
              "1                                                  0                         \n",
              "2                                                  0                         \n",
              "3                                                  0                         \n",
              "4                                                  0                         \n",
              "\n",
              "   commute_time      density   disabled   divorced  education_bachelors  \\\n",
              "0     27.814286  1189.562500  12.871429  11.885714             8.357143   \n",
              "1     30.606061  2295.939394   8.957576   9.827273            23.739394   \n",
              "2     31.394915   626.236667  11.253333  12.330000            19.678333   \n",
              "3     27.561905  1896.220930   8.845238  11.623810            33.285714   \n",
              "4     26.170213   116.886000  15.276000  14.964000            13.978000   \n",
              "\n",
              "   education_college_or_above  education_graduate  education_highschool  \\\n",
              "0                   11.614286            3.257143             29.200000   \n",
              "1                   35.984848           12.245455             19.987879   \n",
              "2                   29.793333           10.115000             27.038333   \n",
              "3                   55.745238           22.459524             12.145238   \n",
              "4                   19.662000            5.684000             29.590000   \n",
              "\n",
              "   education_less_highschool  education_some_college  education_stem_degree  \\\n",
              "0                  33.257143               25.914286              39.557143   \n",
              "1                  14.230303               29.796970              47.918182   \n",
              "2                  10.811667               32.368333              37.308475   \n",
              "3                   5.835714               26.269048              48.938095   \n",
              "4                  11.576000               39.168000              42.332653   \n",
              "\n",
              "   family_dual_income  family_size    farmer     female  health_uninsured  \\\n",
              "0           52.228571     3.928571  0.000000  50.142857         11.200000   \n",
              "1           61.736364     3.622727  0.027273  50.106061          7.018182   \n",
              "2           55.801667     3.260667  3.650847  49.876667         15.066667   \n",
              "3           54.564286     3.098095  0.052381  50.933333          4.404762   \n",
              "4           47.214286     3.352653  6.890909  47.688000         12.088000   \n",
              "\n",
              "    hispanic  home_ownership    home_value  hosp_rating  housing_units  \\\n",
              "0  66.685714       44.585714  2.646343e+05     2.000000    8674.500000   \n",
              "1  37.948485       61.463636  6.776885e+05     2.727273   11725.666670   \n",
              "2  19.370000       72.745000  2.377131e+05     3.470588    7786.583333   \n",
              "3  16.716667       59.221429  1.012474e+06     3.800000   12171.302330   \n",
              "4  13.334000       77.098000  2.498457e+05     3.500000    3768.060000   \n",
              "\n",
              "   income_household_100_to_150  income_household_10_to_15  \\\n",
              "0                    11.571429                   6.157143   \n",
              "1                    19.760606                   2.648485   \n",
              "2                    20.875000                   2.716667   \n",
              "3                    18.850000                   2.180952   \n",
              "4                    13.620000                   3.168000   \n",
              "\n",
              "   income_household_150_over  income_household_15_to_20  \\\n",
              "0                   7.528571                   5.142857   \n",
              "1                  29.596970                   2.178788   \n",
              "2                  18.680000                   2.938333   \n",
              "3                  38.057143                   2.211905   \n",
              "4                   8.606000                   3.240000   \n",
              "\n",
              "   income_household_20_to_25  income_household_25_to_35  \\\n",
              "0                   6.271429                  10.142857   \n",
              "1                   2.409091                   5.163636   \n",
              "2                   2.766667                   6.763333   \n",
              "3                   2.100000                   4.380952   \n",
              "4                   4.778000                  11.462000   \n",
              "\n",
              "   income_household_35_to_50  income_household_50_to_75  \\\n",
              "0                  13.300000                  20.000000   \n",
              "1                   7.972727                  13.936364   \n",
              "2                  12.061667                  15.835000   \n",
              "3                   5.885714                  10.897619   \n",
              "4                  15.656000                  22.432000   \n",
              "\n",
              "   income_household_5_to_10  income_household_75_to_100  \\\n",
              "0                  4.000000                   12.742857   \n",
              "1                  1.536364                   12.469697   \n",
              "2                  1.305000                   13.560000   \n",
              "3                  1.273810                   10.721429   \n",
              "4                  1.960000                   12.480000   \n",
              "\n",
              "   income_household_median  income_household_six_figure  \\\n",
              "0              52996.28571                    19.100000   \n",
              "1             102741.63640                    49.357576   \n",
              "2              85984.74138                    39.555000   \n",
              "3             120533.83330                    56.907143   \n",
              "4              61075.13043                    22.226000   \n",
              "\n",
              "   income_household_under_5  income_individual_median  \\\n",
              "0                  3.142857               24563.57143   \n",
              "1                  2.327273               41287.27273   \n",
              "2                  2.483333               40399.03333   \n",
              "3                  3.435714               55336.28571   \n",
              "4                  2.594000               29073.18367   \n",
              "\n",
              "   labor_force_participation  limited_english       male    married  \\\n",
              "0                  61.528571        10.100000  49.857143  36.571429   \n",
              "1                  65.230303         8.057576  49.893939  50.245455   \n",
              "2                  66.428333         3.356667  50.123333  55.753333   \n",
              "3                  64.430952         5.280952  49.066667  52.604762   \n",
              "4                  57.488000         1.946000  52.312000  57.882000   \n",
              "\n",
              "   metastatic_cancer_category_Other or Unspecified Metastasis  \\\n",
              "0                                                  1            \n",
              "1                                                  1            \n",
              "2                                                  1            \n",
              "3                                                  1            \n",
              "4                                                  1            \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C770  \\\n",
              "0                                      0   \n",
              "1                                      0   \n",
              "2                                      0   \n",
              "3                                      0   \n",
              "4                                      0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C771  \\\n",
              "0                                      0   \n",
              "1                                      0   \n",
              "2                                      0   \n",
              "3                                      0   \n",
              "4                                      0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C772  \\\n",
              "0                                      0   \n",
              "1                                      0   \n",
              "2                                      0   \n",
              "3                                      0   \n",
              "4                                      0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C773  \\\n",
              "0                                      0   \n",
              "1                                      1   \n",
              "2                                      1   \n",
              "3                                      1   \n",
              "4                                      1   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C774  \\\n",
              "0                                      0   \n",
              "1                                      0   \n",
              "2                                      0   \n",
              "3                                      0   \n",
              "4                                      0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C775  \\\n",
              "0                                      0   \n",
              "1                                      0   \n",
              "2                                      0   \n",
              "3                                      0   \n",
              "4                                      0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C778  \\\n",
              "0                                      0   \n",
              "1                                      0   \n",
              "2                                      0   \n",
              "3                                      0   \n",
              "4                                      0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C779  \\\n",
              "0                                      0   \n",
              "1                                      0   \n",
              "2                                      0   \n",
              "3                                      0   \n",
              "4                                      0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7800  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7801  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7802  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C781  \\\n",
              "0                                      0   \n",
              "1                                      0   \n",
              "2                                      0   \n",
              "3                                      0   \n",
              "4                                      0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C782  \\\n",
              "0                                      0   \n",
              "1                                      0   \n",
              "2                                      0   \n",
              "3                                      0   \n",
              "4                                      0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7830  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7839  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C784  \\\n",
              "0                                      0   \n",
              "1                                      0   \n",
              "2                                      0   \n",
              "3                                      0   \n",
              "4                                      0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C785  \\\n",
              "0                                      0   \n",
              "1                                      0   \n",
              "2                                      0   \n",
              "3                                      0   \n",
              "4                                      0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C786  \\\n",
              "0                                      0   \n",
              "1                                      0   \n",
              "2                                      0   \n",
              "3                                      0   \n",
              "4                                      0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C787  \\\n",
              "0                                      0   \n",
              "1                                      0   \n",
              "2                                      0   \n",
              "3                                      0   \n",
              "4                                      0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7880  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7889  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7900  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7901  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7910  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7911  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7919  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C792  \\\n",
              "0                                      0   \n",
              "1                                      0   \n",
              "2                                      0   \n",
              "3                                      0   \n",
              "4                                      0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7931  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7932  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7940  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7949  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7951  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7952  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7960  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7961  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7962  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7970  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7971  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7972  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7981  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7982  \\\n",
              "0                                       0   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C7989  \\\n",
              "0                                       1   \n",
              "1                                       0   \n",
              "2                                       0   \n",
              "3                                       0   \n",
              "4                                       0   \n",
              "\n",
              "   metastatic_cancer_diagnosis_code_C799  \\\n",
              "0                                      0   \n",
              "1                                      0   \n",
              "2                                      0   \n",
              "3                                      0   \n",
              "4                                      0   \n",
              "\n",
              "   metastatic_first_novel_treatment_OLAPARIB  \\\n",
              "0                                          0   \n",
              "1                                          0   \n",
              "2                                          0   \n",
              "3                                          0   \n",
              "4                                          0   \n",
              "\n",
              "   metastatic_first_novel_treatment_PEMBROLIZUMAB  \\\n",
              "0                                               0   \n",
              "1                                               0   \n",
              "2                                               0   \n",
              "3                                               0   \n",
              "4                                               0   \n",
              "\n",
              "   metastatic_first_novel_treatment_Unknown  \\\n",
              "0                                         1   \n",
              "1                                         1   \n",
              "2                                         1   \n",
              "3                                         1   \n",
              "4                                         1   \n",
              "\n",
              "   metastatic_first_novel_treatment_type_Antineoplastics  \\\n",
              "0                                                  0       \n",
              "1                                                  0       \n",
              "2                                                  0       \n",
              "3                                                  0       \n",
              "4                                                  0       \n",
              "\n",
              "   metastatic_first_novel_treatment_type_Unknown  never_married  num_acute  \\\n",
              "0                                              1      47.114286        2.0   \n",
              "1                                              1      35.290909       12.0   \n",
              "2                                              1      27.195000       19.0   \n",
              "3                                              1      31.142857        7.0   \n",
              "4                                              1      21.760000        3.0   \n",
              "\n",
              "   num_children  num_critical  patient_age  patient_id patient_race  \\\n",
              "0           0.0           0.0           84      475714      Unknown   \n",
              "1           0.0           0.0           62      349367        White   \n",
              "2           0.0           0.0           43      138632        White   \n",
              "3           0.0           0.0           45      617843        White   \n",
              "4           0.0           5.0           55      817482      Unknown   \n",
              "\n",
              "   patient_state_AK  patient_state_AL  patient_state_AR  patient_state_AZ  \\\n",
              "0                 0                 0                 0                 0   \n",
              "1                 0                 0                 0                 0   \n",
              "2                 0                 0                 0                 0   \n",
              "3                 0                 0                 0                 0   \n",
              "4                 0                 0                 0                 0   \n",
              "\n",
              "   patient_state_CA  patient_state_CO  patient_state_CT  patient_state_DC  \\\n",
              "0                 1                 0                 0                 0   \n",
              "1                 1                 0                 0                 0   \n",
              "2                 0                 0                 0                 0   \n",
              "3                 1                 0                 0                 0   \n",
              "4                 0                 0                 0                 0   \n",
              "\n",
              "   patient_state_DE  patient_state_FL  patient_state_GA  patient_state_HI  \\\n",
              "0                 0                 0                 0                 0   \n",
              "1                 0                 0                 0                 0   \n",
              "2                 0                 0                 0                 0   \n",
              "3                 0                 0                 0                 0   \n",
              "4                 0                 0                 0                 0   \n",
              "\n",
              "   patient_state_IA  patient_state_ID  patient_state_IL  patient_state_IN  \\\n",
              "0                 0                 0                 0                 0   \n",
              "1                 0                 0                 0                 0   \n",
              "2                 0                 0                 0                 0   \n",
              "3                 0                 0                 0                 0   \n",
              "4                 0                 1                 0                 0   \n",
              "\n",
              "   patient_state_KS  patient_state_KY  patient_state_LA  patient_state_MA  \\\n",
              "0                 0                 0                 0                 0   \n",
              "1                 0                 0                 0                 0   \n",
              "2                 0                 0                 0                 0   \n",
              "3                 0                 0                 0                 0   \n",
              "4                 0                 0                 0                 0   \n",
              "\n",
              "   patient_state_MD  patient_state_MI  patient_state_MN  patient_state_MO  \\\n",
              "0                 0                 0                 0                 0   \n",
              "1                 0                 0                 0                 0   \n",
              "2                 0                 0                 0                 0   \n",
              "3                 0                 0                 0                 0   \n",
              "4                 0                 0                 0                 0   \n",
              "\n",
              "   patient_state_MS  patient_state_MT  patient_state_NC  patient_state_ND  \\\n",
              "0                 0                 0                 0                 0   \n",
              "1                 0                 0                 0                 0   \n",
              "2                 0                 0                 0                 0   \n",
              "3                 0                 0                 0                 0   \n",
              "4                 0                 0                 0                 0   \n",
              "\n",
              "   patient_state_NE  patient_state_NH  patient_state_NJ  patient_state_NM  \\\n",
              "0                 0                 0                 0                 0   \n",
              "1                 0                 0                 0                 0   \n",
              "2                 0                 0                 0                 0   \n",
              "3                 0                 0                 0                 0   \n",
              "4                 0                 0                 0                 0   \n",
              "\n",
              "   patient_state_NV  patient_state_NY  patient_state_OH  patient_state_OK  \\\n",
              "0                 0                 0                 0                 0   \n",
              "1                 0                 0                 0                 0   \n",
              "2                 0                 0                 0                 0   \n",
              "3                 0                 0                 0                 0   \n",
              "4                 0                 0                 0                 0   \n",
              "\n",
              "   patient_state_OR  patient_state_PA  patient_state_RI  patient_state_SC  \\\n",
              "0                 0                 0                 0                 0   \n",
              "1                 0                 0                 0                 0   \n",
              "2                 0                 0                 0                 0   \n",
              "3                 0                 0                 0                 0   \n",
              "4                 0                 0                 0                 0   \n",
              "\n",
              "   patient_state_SD  patient_state_TN  patient_state_TX  patient_state_UT  \\\n",
              "0                 0                 0                 0                 0   \n",
              "1                 0                 0                 0                 0   \n",
              "2                 0                 0                 1                 0   \n",
              "3                 0                 0                 0                 0   \n",
              "4                 0                 0                 0                 0   \n",
              "\n",
              "   patient_state_VA  patient_state_WA  patient_state_WI  patient_state_WV  \\\n",
              "0                 0                 0                 0                 0   \n",
              "1                 0                 0                 0                 0   \n",
              "2                 0                 0                 0                 0   \n",
              "3                 0                 0                 0                 0   \n",
              "4                 0                 0                 0                 0   \n",
              "\n",
              "   patient_state_WY  payer_type_COMMERCIAL  payer_type_MEDICAID  \\\n",
              "0                 0                      0                    1   \n",
              "1                 0                      1                    0   \n",
              "2                 0                      1                    0   \n",
              "3                 0                      1                    0   \n",
              "4                 0                      1                    0   \n",
              "\n",
              "   payer_type_MEDICARE ADVANTAGE  payer_type_Unknown   population    poverty  \\\n",
              "0                              0                   0  31437.75000  22.542857   \n",
              "1                              0                   0  39121.87879  10.109091   \n",
              "2                              0                   0  21996.68333   9.663333   \n",
              "3                              0                   0  32795.32558   8.688095   \n",
              "4                              0                   0  10886.26000  11.224000   \n",
              "\n",
              "   race_asian  race_black  race_multiple  race_native  race_other  \\\n",
              "0    5.100000   13.100000       8.757143     1.485714   27.114286   \n",
              "1   20.827273    2.527273      10.081818     0.587879   11.645455   \n",
              "2    3.618333    9.231667       6.898333     0.463333    3.816667   \n",
              "3   18.845238    1.438095       8.611905     0.430952    5.428571   \n",
              "4    0.656000    0.426000       6.258000     0.760000    5.080000   \n",
              "\n",
              "   race_pacific  race_white  rent_burden  rent_median  self_employed  \\\n",
              "0      0.342857   44.100000    37.442857  1165.000000      13.428571   \n",
              "1      0.300000   54.030303    34.753125  2003.125000      15.224242   \n",
              "2      0.146667   75.820000    29.358491  1235.907407      13.722034   \n",
              "3      0.252381   65.014286    32.030952  2354.738095      18.502381   \n",
              "4      0.108000   86.712000    27.029730   919.743590      13.029545   \n",
              "\n",
              "   unemployment_rate    veteran   widowed  \n",
              "0           8.471429   3.500000  4.442857  \n",
              "1           5.103030   4.103030  4.651515  \n",
              "2           4.560000   7.446667  4.710000  \n",
              "3           5.264286   4.809524  4.623810  \n",
              "4           4.258000  13.106000  5.406000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21a9c6d0-c6c4-47a1-b2e4-c8e56194dc64\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DiagPeriodL90D</th>\n",
              "      <th>Division_East North Central</th>\n",
              "      <th>Division_East South Central</th>\n",
              "      <th>Division_Middle Atlantic</th>\n",
              "      <th>Division_Mountain</th>\n",
              "      <th>Division_New England</th>\n",
              "      <th>Division_Pacific</th>\n",
              "      <th>Division_South Atlantic</th>\n",
              "      <th>Division_West North Central</th>\n",
              "      <th>Division_West South Central</th>\n",
              "      <th>N02</th>\n",
              "      <th>Ozone</th>\n",
              "      <th>PM25</th>\n",
              "      <th>Region_Midwest</th>\n",
              "      <th>Region_Northeast</th>\n",
              "      <th>Region_South</th>\n",
              "      <th>Region_West</th>\n",
              "      <th>age_10_to_19</th>\n",
              "      <th>age_20s</th>\n",
              "      <th>age_30s</th>\n",
              "      <th>age_40s</th>\n",
              "      <th>age_50s</th>\n",
              "      <th>age_60s</th>\n",
              "      <th>age_70s</th>\n",
              "      <th>age_median</th>\n",
              "      <th>age_over_80</th>\n",
              "      <th>age_under_10</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malig neoplasm quadrant left femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malig neoplasm quadrant right male breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malig neoplasm quadrant unsp femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malig neoplm quadrant right femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm axillari tail femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm axillari tail left femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm axillari tail right femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm axillari tail unsp femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm breast femal unspecifi</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm breast unspecifi site</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm breast unspecifi site femal</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm central portion breast femal</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm central portion femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm central portion left femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm central portion right femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm central portion unsp femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm nippl areola femal</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm nippl areola left femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm nippl areola right femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm nippl areola unsp femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm overlap site breast femal</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm ovrlp site left femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm ovrlp site right femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm ovrlp site unsp femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm quadrant breast femal</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm quadrant femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm specifi site femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm unsp site right femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm unsp site unspecifi femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm unsp site unspecifi male breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_malign neoplasm unspecifi site left femal breast</th>\n",
              "      <th>breast_cancer_diagnosis_desc_processed_secondari malign neoplasm breast</th>\n",
              "      <th>commute_time</th>\n",
              "      <th>density</th>\n",
              "      <th>disabled</th>\n",
              "      <th>divorced</th>\n",
              "      <th>education_bachelors</th>\n",
              "      <th>education_college_or_above</th>\n",
              "      <th>education_graduate</th>\n",
              "      <th>education_highschool</th>\n",
              "      <th>education_less_highschool</th>\n",
              "      <th>education_some_college</th>\n",
              "      <th>education_stem_degree</th>\n",
              "      <th>family_dual_income</th>\n",
              "      <th>family_size</th>\n",
              "      <th>farmer</th>\n",
              "      <th>female</th>\n",
              "      <th>health_uninsured</th>\n",
              "      <th>hispanic</th>\n",
              "      <th>home_ownership</th>\n",
              "      <th>home_value</th>\n",
              "      <th>hosp_rating</th>\n",
              "      <th>housing_units</th>\n",
              "      <th>income_household_100_to_150</th>\n",
              "      <th>income_household_10_to_15</th>\n",
              "      <th>income_household_150_over</th>\n",
              "      <th>income_household_15_to_20</th>\n",
              "      <th>income_household_20_to_25</th>\n",
              "      <th>income_household_25_to_35</th>\n",
              "      <th>income_household_35_to_50</th>\n",
              "      <th>income_household_50_to_75</th>\n",
              "      <th>income_household_5_to_10</th>\n",
              "      <th>income_household_75_to_100</th>\n",
              "      <th>income_household_median</th>\n",
              "      <th>income_household_six_figure</th>\n",
              "      <th>income_household_under_5</th>\n",
              "      <th>income_individual_median</th>\n",
              "      <th>labor_force_participation</th>\n",
              "      <th>limited_english</th>\n",
              "      <th>male</th>\n",
              "      <th>married</th>\n",
              "      <th>metastatic_cancer_category_Other or Unspecified Metastasis</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C770</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C771</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C772</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C773</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C774</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C775</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C778</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C779</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7800</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7801</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7802</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C781</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C782</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7830</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7839</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C784</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C785</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C786</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C787</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7880</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7889</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7900</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7901</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7910</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7911</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7919</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C792</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7931</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7932</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7940</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7949</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7951</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7952</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7960</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7961</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7962</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7970</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7971</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7972</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7981</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7982</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C7989</th>\n",
              "      <th>metastatic_cancer_diagnosis_code_C799</th>\n",
              "      <th>metastatic_first_novel_treatment_OLAPARIB</th>\n",
              "      <th>metastatic_first_novel_treatment_PEMBROLIZUMAB</th>\n",
              "      <th>metastatic_first_novel_treatment_Unknown</th>\n",
              "      <th>metastatic_first_novel_treatment_type_Antineoplastics</th>\n",
              "      <th>metastatic_first_novel_treatment_type_Unknown</th>\n",
              "      <th>never_married</th>\n",
              "      <th>num_acute</th>\n",
              "      <th>num_children</th>\n",
              "      <th>num_critical</th>\n",
              "      <th>patient_age</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>patient_race</th>\n",
              "      <th>patient_state_AK</th>\n",
              "      <th>patient_state_AL</th>\n",
              "      <th>patient_state_AR</th>\n",
              "      <th>patient_state_AZ</th>\n",
              "      <th>patient_state_CA</th>\n",
              "      <th>patient_state_CO</th>\n",
              "      <th>patient_state_CT</th>\n",
              "      <th>patient_state_DC</th>\n",
              "      <th>patient_state_DE</th>\n",
              "      <th>patient_state_FL</th>\n",
              "      <th>patient_state_GA</th>\n",
              "      <th>patient_state_HI</th>\n",
              "      <th>patient_state_IA</th>\n",
              "      <th>patient_state_ID</th>\n",
              "      <th>patient_state_IL</th>\n",
              "      <th>patient_state_IN</th>\n",
              "      <th>patient_state_KS</th>\n",
              "      <th>patient_state_KY</th>\n",
              "      <th>patient_state_LA</th>\n",
              "      <th>patient_state_MA</th>\n",
              "      <th>patient_state_MD</th>\n",
              "      <th>patient_state_MI</th>\n",
              "      <th>patient_state_MN</th>\n",
              "      <th>patient_state_MO</th>\n",
              "      <th>patient_state_MS</th>\n",
              "      <th>patient_state_MT</th>\n",
              "      <th>patient_state_NC</th>\n",
              "      <th>patient_state_ND</th>\n",
              "      <th>patient_state_NE</th>\n",
              "      <th>patient_state_NH</th>\n",
              "      <th>patient_state_NJ</th>\n",
              "      <th>patient_state_NM</th>\n",
              "      <th>patient_state_NV</th>\n",
              "      <th>patient_state_NY</th>\n",
              "      <th>patient_state_OH</th>\n",
              "      <th>patient_state_OK</th>\n",
              "      <th>patient_state_OR</th>\n",
              "      <th>patient_state_PA</th>\n",
              "      <th>patient_state_RI</th>\n",
              "      <th>patient_state_SC</th>\n",
              "      <th>patient_state_SD</th>\n",
              "      <th>patient_state_TN</th>\n",
              "      <th>patient_state_TX</th>\n",
              "      <th>patient_state_UT</th>\n",
              "      <th>patient_state_VA</th>\n",
              "      <th>patient_state_WA</th>\n",
              "      <th>patient_state_WI</th>\n",
              "      <th>patient_state_WV</th>\n",
              "      <th>patient_state_WY</th>\n",
              "      <th>payer_type_COMMERCIAL</th>\n",
              "      <th>payer_type_MEDICAID</th>\n",
              "      <th>payer_type_MEDICARE ADVANTAGE</th>\n",
              "      <th>payer_type_Unknown</th>\n",
              "      <th>population</th>\n",
              "      <th>poverty</th>\n",
              "      <th>race_asian</th>\n",
              "      <th>race_black</th>\n",
              "      <th>race_multiple</th>\n",
              "      <th>race_native</th>\n",
              "      <th>race_other</th>\n",
              "      <th>race_pacific</th>\n",
              "      <th>race_white</th>\n",
              "      <th>rent_burden</th>\n",
              "      <th>rent_median</th>\n",
              "      <th>self_employed</th>\n",
              "      <th>unemployment_rate</th>\n",
              "      <th>veteran</th>\n",
              "      <th>widowed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18.606528</td>\n",
              "      <td>52.237210</td>\n",
              "      <td>8.650555</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15.542857</td>\n",
              "      <td>17.614286</td>\n",
              "      <td>14.014286</td>\n",
              "      <td>11.614286</td>\n",
              "      <td>11.557143</td>\n",
              "      <td>7.571429</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>30.642857</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>16.014286</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>27.814286</td>\n",
              "      <td>1189.562500</td>\n",
              "      <td>12.871429</td>\n",
              "      <td>11.885714</td>\n",
              "      <td>8.357143</td>\n",
              "      <td>11.614286</td>\n",
              "      <td>3.257143</td>\n",
              "      <td>29.200000</td>\n",
              "      <td>33.257143</td>\n",
              "      <td>25.914286</td>\n",
              "      <td>39.557143</td>\n",
              "      <td>52.228571</td>\n",
              "      <td>3.928571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.142857</td>\n",
              "      <td>11.200000</td>\n",
              "      <td>66.685714</td>\n",
              "      <td>44.585714</td>\n",
              "      <td>2.646343e+05</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>8674.500000</td>\n",
              "      <td>11.571429</td>\n",
              "      <td>6.157143</td>\n",
              "      <td>7.528571</td>\n",
              "      <td>5.142857</td>\n",
              "      <td>6.271429</td>\n",
              "      <td>10.142857</td>\n",
              "      <td>13.300000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>12.742857</td>\n",
              "      <td>52996.28571</td>\n",
              "      <td>19.100000</td>\n",
              "      <td>3.142857</td>\n",
              "      <td>24563.57143</td>\n",
              "      <td>61.528571</td>\n",
              "      <td>10.100000</td>\n",
              "      <td>49.857143</td>\n",
              "      <td>36.571429</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>47.114286</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>84</td>\n",
              "      <td>475714</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31437.75000</td>\n",
              "      <td>22.542857</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>13.100000</td>\n",
              "      <td>8.757143</td>\n",
              "      <td>1.485714</td>\n",
              "      <td>27.114286</td>\n",
              "      <td>0.342857</td>\n",
              "      <td>44.100000</td>\n",
              "      <td>37.442857</td>\n",
              "      <td>1165.000000</td>\n",
              "      <td>13.428571</td>\n",
              "      <td>8.471429</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>4.442857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20.113179</td>\n",
              "      <td>42.301121</td>\n",
              "      <td>8.487175</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>13.354545</td>\n",
              "      <td>14.230303</td>\n",
              "      <td>13.418182</td>\n",
              "      <td>13.333333</td>\n",
              "      <td>14.060606</td>\n",
              "      <td>10.248485</td>\n",
              "      <td>5.951515</td>\n",
              "      <td>38.200000</td>\n",
              "      <td>3.503030</td>\n",
              "      <td>11.878788</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.606061</td>\n",
              "      <td>2295.939394</td>\n",
              "      <td>8.957576</td>\n",
              "      <td>9.827273</td>\n",
              "      <td>23.739394</td>\n",
              "      <td>35.984848</td>\n",
              "      <td>12.245455</td>\n",
              "      <td>19.987879</td>\n",
              "      <td>14.230303</td>\n",
              "      <td>29.796970</td>\n",
              "      <td>47.918182</td>\n",
              "      <td>61.736364</td>\n",
              "      <td>3.622727</td>\n",
              "      <td>0.027273</td>\n",
              "      <td>50.106061</td>\n",
              "      <td>7.018182</td>\n",
              "      <td>37.948485</td>\n",
              "      <td>61.463636</td>\n",
              "      <td>6.776885e+05</td>\n",
              "      <td>2.727273</td>\n",
              "      <td>11725.666670</td>\n",
              "      <td>19.760606</td>\n",
              "      <td>2.648485</td>\n",
              "      <td>29.596970</td>\n",
              "      <td>2.178788</td>\n",
              "      <td>2.409091</td>\n",
              "      <td>5.163636</td>\n",
              "      <td>7.972727</td>\n",
              "      <td>13.936364</td>\n",
              "      <td>1.536364</td>\n",
              "      <td>12.469697</td>\n",
              "      <td>102741.63640</td>\n",
              "      <td>49.357576</td>\n",
              "      <td>2.327273</td>\n",
              "      <td>41287.27273</td>\n",
              "      <td>65.230303</td>\n",
              "      <td>8.057576</td>\n",
              "      <td>49.893939</td>\n",
              "      <td>50.245455</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>35.290909</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>62</td>\n",
              "      <td>349367</td>\n",
              "      <td>White</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39121.87879</td>\n",
              "      <td>10.109091</td>\n",
              "      <td>20.827273</td>\n",
              "      <td>2.527273</td>\n",
              "      <td>10.081818</td>\n",
              "      <td>0.587879</td>\n",
              "      <td>11.645455</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>54.030303</td>\n",
              "      <td>34.753125</td>\n",
              "      <td>2003.125000</td>\n",
              "      <td>15.224242</td>\n",
              "      <td>5.103030</td>\n",
              "      <td>4.103030</td>\n",
              "      <td>4.651515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>14.839351</td>\n",
              "      <td>40.108207</td>\n",
              "      <td>7.642753</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>14.463333</td>\n",
              "      <td>12.531667</td>\n",
              "      <td>13.545000</td>\n",
              "      <td>12.860000</td>\n",
              "      <td>12.770000</td>\n",
              "      <td>11.426667</td>\n",
              "      <td>6.565000</td>\n",
              "      <td>37.906667</td>\n",
              "      <td>2.811667</td>\n",
              "      <td>13.028333</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31.394915</td>\n",
              "      <td>626.236667</td>\n",
              "      <td>11.253333</td>\n",
              "      <td>12.330000</td>\n",
              "      <td>19.678333</td>\n",
              "      <td>29.793333</td>\n",
              "      <td>10.115000</td>\n",
              "      <td>27.038333</td>\n",
              "      <td>10.811667</td>\n",
              "      <td>32.368333</td>\n",
              "      <td>37.308475</td>\n",
              "      <td>55.801667</td>\n",
              "      <td>3.260667</td>\n",
              "      <td>3.650847</td>\n",
              "      <td>49.876667</td>\n",
              "      <td>15.066667</td>\n",
              "      <td>19.370000</td>\n",
              "      <td>72.745000</td>\n",
              "      <td>2.377131e+05</td>\n",
              "      <td>3.470588</td>\n",
              "      <td>7786.583333</td>\n",
              "      <td>20.875000</td>\n",
              "      <td>2.716667</td>\n",
              "      <td>18.680000</td>\n",
              "      <td>2.938333</td>\n",
              "      <td>2.766667</td>\n",
              "      <td>6.763333</td>\n",
              "      <td>12.061667</td>\n",
              "      <td>15.835000</td>\n",
              "      <td>1.305000</td>\n",
              "      <td>13.560000</td>\n",
              "      <td>85984.74138</td>\n",
              "      <td>39.555000</td>\n",
              "      <td>2.483333</td>\n",
              "      <td>40399.03333</td>\n",
              "      <td>66.428333</td>\n",
              "      <td>3.356667</td>\n",
              "      <td>50.123333</td>\n",
              "      <td>55.753333</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>27.195000</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43</td>\n",
              "      <td>138632</td>\n",
              "      <td>White</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>21996.68333</td>\n",
              "      <td>9.663333</td>\n",
              "      <td>3.618333</td>\n",
              "      <td>9.231667</td>\n",
              "      <td>6.898333</td>\n",
              "      <td>0.463333</td>\n",
              "      <td>3.816667</td>\n",
              "      <td>0.146667</td>\n",
              "      <td>75.820000</td>\n",
              "      <td>29.358491</td>\n",
              "      <td>1235.907407</td>\n",
              "      <td>13.722034</td>\n",
              "      <td>4.560000</td>\n",
              "      <td>7.446667</td>\n",
              "      <td>4.710000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15.894123</td>\n",
              "      <td>42.070075</td>\n",
              "      <td>7.229393</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>12.135714</td>\n",
              "      <td>12.538095</td>\n",
              "      <td>12.464286</td>\n",
              "      <td>12.650000</td>\n",
              "      <td>14.847619</td>\n",
              "      <td>12.280952</td>\n",
              "      <td>8.216667</td>\n",
              "      <td>42.871429</td>\n",
              "      <td>4.759524</td>\n",
              "      <td>10.071429</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>27.561905</td>\n",
              "      <td>1896.220930</td>\n",
              "      <td>8.845238</td>\n",
              "      <td>11.623810</td>\n",
              "      <td>33.285714</td>\n",
              "      <td>55.745238</td>\n",
              "      <td>22.459524</td>\n",
              "      <td>12.145238</td>\n",
              "      <td>5.835714</td>\n",
              "      <td>26.269048</td>\n",
              "      <td>48.938095</td>\n",
              "      <td>54.564286</td>\n",
              "      <td>3.098095</td>\n",
              "      <td>0.052381</td>\n",
              "      <td>50.933333</td>\n",
              "      <td>4.404762</td>\n",
              "      <td>16.716667</td>\n",
              "      <td>59.221429</td>\n",
              "      <td>1.012474e+06</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>12171.302330</td>\n",
              "      <td>18.850000</td>\n",
              "      <td>2.180952</td>\n",
              "      <td>38.057143</td>\n",
              "      <td>2.211905</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>4.380952</td>\n",
              "      <td>5.885714</td>\n",
              "      <td>10.897619</td>\n",
              "      <td>1.273810</td>\n",
              "      <td>10.721429</td>\n",
              "      <td>120533.83330</td>\n",
              "      <td>56.907143</td>\n",
              "      <td>3.435714</td>\n",
              "      <td>55336.28571</td>\n",
              "      <td>64.430952</td>\n",
              "      <td>5.280952</td>\n",
              "      <td>49.066667</td>\n",
              "      <td>52.604762</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>31.142857</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>45</td>\n",
              "      <td>617843</td>\n",
              "      <td>White</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32795.32558</td>\n",
              "      <td>8.688095</td>\n",
              "      <td>18.845238</td>\n",
              "      <td>1.438095</td>\n",
              "      <td>8.611905</td>\n",
              "      <td>0.430952</td>\n",
              "      <td>5.428571</td>\n",
              "      <td>0.252381</td>\n",
              "      <td>65.014286</td>\n",
              "      <td>32.030952</td>\n",
              "      <td>2354.738095</td>\n",
              "      <td>18.502381</td>\n",
              "      <td>5.264286</td>\n",
              "      <td>4.809524</td>\n",
              "      <td>4.623810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11.722197</td>\n",
              "      <td>41.356058</td>\n",
              "      <td>4.110749</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>13.976000</td>\n",
              "      <td>9.492000</td>\n",
              "      <td>10.364000</td>\n",
              "      <td>12.600000</td>\n",
              "      <td>14.992000</td>\n",
              "      <td>14.836000</td>\n",
              "      <td>9.462000</td>\n",
              "      <td>43.473469</td>\n",
              "      <td>3.466000</td>\n",
              "      <td>10.824000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26.170213</td>\n",
              "      <td>116.886000</td>\n",
              "      <td>15.276000</td>\n",
              "      <td>14.964000</td>\n",
              "      <td>13.978000</td>\n",
              "      <td>19.662000</td>\n",
              "      <td>5.684000</td>\n",
              "      <td>29.590000</td>\n",
              "      <td>11.576000</td>\n",
              "      <td>39.168000</td>\n",
              "      <td>42.332653</td>\n",
              "      <td>47.214286</td>\n",
              "      <td>3.352653</td>\n",
              "      <td>6.890909</td>\n",
              "      <td>47.688000</td>\n",
              "      <td>12.088000</td>\n",
              "      <td>13.334000</td>\n",
              "      <td>77.098000</td>\n",
              "      <td>2.498457e+05</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3768.060000</td>\n",
              "      <td>13.620000</td>\n",
              "      <td>3.168000</td>\n",
              "      <td>8.606000</td>\n",
              "      <td>3.240000</td>\n",
              "      <td>4.778000</td>\n",
              "      <td>11.462000</td>\n",
              "      <td>15.656000</td>\n",
              "      <td>22.432000</td>\n",
              "      <td>1.960000</td>\n",
              "      <td>12.480000</td>\n",
              "      <td>61075.13043</td>\n",
              "      <td>22.226000</td>\n",
              "      <td>2.594000</td>\n",
              "      <td>29073.18367</td>\n",
              "      <td>57.488000</td>\n",
              "      <td>1.946000</td>\n",
              "      <td>52.312000</td>\n",
              "      <td>57.882000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>21.760000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>55</td>\n",
              "      <td>817482</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10886.26000</td>\n",
              "      <td>11.224000</td>\n",
              "      <td>0.656000</td>\n",
              "      <td>0.426000</td>\n",
              "      <td>6.258000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>5.080000</td>\n",
              "      <td>0.108000</td>\n",
              "      <td>86.712000</td>\n",
              "      <td>27.029730</td>\n",
              "      <td>919.743590</td>\n",
              "      <td>13.029545</td>\n",
              "      <td>4.258000</td>\n",
              "      <td>13.106000</td>\n",
              "      <td>5.406000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21a9c6d0-c6c4-47a1-b2e4-c8e56194dc64')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-21a9c6d0-c6c4-47a1-b2e4-c8e56194dc64 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-21a9c6d0-c6c4-47a1-b2e4-c8e56194dc64');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-572db84f-a691-43bc-ae3c-fea922cb1744\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-572db84f-a691-43bc-ae3c-fea922cb1744')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-572db84f-a691-43bc-ae3c-fea922cb1744 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data"
            }
          },
          "metadata": {},
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " pd.set_option('display.max_rows', None)"
      ],
      "metadata": {
        "id": "kdCaMabStKwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.isnull().sum()"
      ],
      "metadata": {
        "id": "8tl7o1bxsJ0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape, test_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOSYlqvDyDLF",
        "outputId": "82a00f09-819b-4059-ec50-ed2021b4343e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12906, 220), (5792, 219))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.get_dummies(train_data, columns=['patient_race'])\n",
        "test_data = pd.get_dummies(test_data, columns=['patient_race'])\n",
        "train_data.shape, test_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52SeY-9A6zfP",
        "outputId": "550a01c0-8239-4976-9e39-2e765f9350a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12906, 225), (5792, 224))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_data = pd.get_dummies(test_data, columns=['patient_race'])\n"
      ],
      "metadata": {
        "id": "pfkZclMxKKAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_data.dtypes"
      ],
      "metadata": {
        "id": "wNRlQI52cmPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YKVBdmZk_eX",
        "outputId": "a7815ab3-b64c-4338-cd6a-d6652d6438da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DiagPeriodL90D                                                                               0\n",
              "Division_East North Central                                                                  0\n",
              "Division_East South Central                                                                  0\n",
              "Division_Middle Atlantic                                                                     0\n",
              "Division_Mountain                                                                            0\n",
              "Division_New England                                                                         0\n",
              "Division_Pacific                                                                             0\n",
              "Division_South Atlantic                                                                      0\n",
              "Division_West North Central                                                                  0\n",
              "Division_West South Central                                                                  0\n",
              "Ozone                                                                                        0\n",
              "PM25                                                                                         0\n",
              "Region_Midwest                                                                               0\n",
              "Region_Northeast                                                                             0\n",
              "Region_South                                                                                 0\n",
              "Region_West                                                                                  0\n",
              "age_10_to_19                                                                                 0\n",
              "age_20s                                                                                      0\n",
              "age_30s                                                                                      0\n",
              "age_40s                                                                                      0\n",
              "age_50s                                                                                      0\n",
              "age_60s                                                                                      0\n",
              "age_70s                                                                                      0\n",
              "age_median                                                                                   0\n",
              "age_over_80                                                                                  0\n",
              "age_under_10                                                                                 0\n",
              "breast_cancer_diagnosis_desc_processed_malig neoplasm quadrant left femal breast             0\n",
              "breast_cancer_diagnosis_desc_processed_malig neoplasm quadrant right male breast             0\n",
              "breast_cancer_diagnosis_desc_processed_malig neoplasm quadrant unsp femal breast             0\n",
              "breast_cancer_diagnosis_desc_processed_malig neoplm quadrant right femal breast              0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm axillari tail femal breast            0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm axillari tail left femal breast       0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm axillari tail right femal breast      0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm axillari tail unsp femal breast       0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm breast                                0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm breast femal unspecifi                0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm breast unspecifi site                 0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm breast unspecifi site femal           0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm central portion breast femal          0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm central portion femal breast          0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm central portion left femal breast     0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm central portion right femal breast    0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm central portion unsp femal breast     0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm nippl areola femal                    0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm nippl areola left femal breast        0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm nippl areola right femal breast       0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm nippl areola unsp femal breast        0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm overlap site breast femal             0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm ovrlp site left femal breast          0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm ovrlp site right femal breast         0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm ovrlp site unsp femal breast          0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm quadrant breast femal                 0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm quadrant femal breast                 0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm specifi site femal breast             0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm unsp site right femal breast          0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm unsp site unspecifi femal breast      0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm unsp site unspecifi male breast       0\n",
              "breast_cancer_diagnosis_desc_processed_malign neoplasm unspecifi site left femal breast      0\n",
              "breast_cancer_diagnosis_desc_processed_secondari malign neoplasm breast                      0\n",
              "commute_time                                                                                 0\n",
              "density                                                                                      0\n",
              "disabled                                                                                     0\n",
              "divorced                                                                                     0\n",
              "education_bachelors                                                                          0\n",
              "education_college_or_above                                                                   0\n",
              "education_graduate                                                                           0\n",
              "education_highschool                                                                         0\n",
              "education_less_highschool                                                                    0\n",
              "education_some_college                                                                       0\n",
              "education_stem_degree                                                                        0\n",
              "family_dual_income                                                                           0\n",
              "family_size                                                                                  0\n",
              "female                                                                                       0\n",
              "health_uninsured                                                                             0\n",
              "hispanic                                                                                     0\n",
              "home_ownership                                                                               0\n",
              "home_value                                                                                   0\n",
              "hosp_rating                                                                                  0\n",
              "housing_units                                                                                0\n",
              "income_household_100_to_150                                                                  0\n",
              "income_household_10_to_15                                                                    0\n",
              "income_household_150_over                                                                    0\n",
              "income_household_15_to_20                                                                    0\n",
              "income_household_20_to_25                                                                    0\n",
              "income_household_25_to_35                                                                    0\n",
              "income_household_35_to_50                                                                    0\n",
              "income_household_50_to_75                                                                    0\n",
              "income_household_5_to_10                                                                     0\n",
              "income_household_75_to_100                                                                   0\n",
              "income_household_median                                                                      0\n",
              "income_household_six_figure                                                                  0\n",
              "income_household_under_5                                                                     0\n",
              "income_individual_median                                                                     0\n",
              "labor_force_participation                                                                    0\n",
              "limited_english                                                                              0\n",
              "male                                                                                         0\n",
              "married                                                                                      0\n",
              "metastatic_cancer_category_Other or Unspecified Metastasis                                   0\n",
              "metastatic_cancer_diagnosis_code_C770                                                        0\n",
              "metastatic_cancer_diagnosis_code_C771                                                        0\n",
              "metastatic_cancer_diagnosis_code_C772                                                        0\n",
              "metastatic_cancer_diagnosis_code_C773                                                        0\n",
              "metastatic_cancer_diagnosis_code_C774                                                        0\n",
              "metastatic_cancer_diagnosis_code_C775                                                        0\n",
              "metastatic_cancer_diagnosis_code_C778                                                        0\n",
              "metastatic_cancer_diagnosis_code_C779                                                        0\n",
              "metastatic_cancer_diagnosis_code_C7800                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7801                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7802                                                       0\n",
              "metastatic_cancer_diagnosis_code_C781                                                        0\n",
              "metastatic_cancer_diagnosis_code_C782                                                        0\n",
              "metastatic_cancer_diagnosis_code_C7830                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7839                                                       0\n",
              "metastatic_cancer_diagnosis_code_C784                                                        0\n",
              "metastatic_cancer_diagnosis_code_C785                                                        0\n",
              "metastatic_cancer_diagnosis_code_C786                                                        0\n",
              "metastatic_cancer_diagnosis_code_C787                                                        0\n",
              "metastatic_cancer_diagnosis_code_C7880                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7889                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7900                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7901                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7910                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7911                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7919                                                       0\n",
              "metastatic_cancer_diagnosis_code_C792                                                        0\n",
              "metastatic_cancer_diagnosis_code_C7931                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7932                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7940                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7949                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7951                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7952                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7960                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7961                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7962                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7970                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7971                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7972                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7981                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7982                                                       0\n",
              "metastatic_cancer_diagnosis_code_C7989                                                       0\n",
              "metastatic_cancer_diagnosis_code_C799                                                        0\n",
              "metastatic_first_novel_treatment_OLAPARIB                                                    0\n",
              "metastatic_first_novel_treatment_PEMBROLIZUMAB                                               0\n",
              "metastatic_first_novel_treatment_Unknown                                                     0\n",
              "metastatic_first_novel_treatment_type_Antineoplastics                                        0\n",
              "metastatic_first_novel_treatment_type_Unknown                                                0\n",
              "num_acute                                                                                    0\n",
              "num_children                                                                                 0\n",
              "num_critical                                                                                 0\n",
              "patient_age                                                                                  0\n",
              "patient_id                                                                                   0\n",
              "patient_state_AK                                                                             0\n",
              "patient_state_AL                                                                             0\n",
              "patient_state_AR                                                                             0\n",
              "patient_state_AZ                                                                             0\n",
              "patient_state_CA                                                                             0\n",
              "patient_state_CO                                                                             0\n",
              "patient_state_CT                                                                             0\n",
              "patient_state_DC                                                                             0\n",
              "patient_state_DE                                                                             0\n",
              "patient_state_FL                                                                             0\n",
              "patient_state_GA                                                                             0\n",
              "patient_state_HI                                                                             0\n",
              "patient_state_IA                                                                             0\n",
              "patient_state_ID                                                                             0\n",
              "patient_state_IL                                                                             0\n",
              "patient_state_IN                                                                             0\n",
              "patient_state_KS                                                                             0\n",
              "patient_state_KY                                                                             0\n",
              "patient_state_LA                                                                             0\n",
              "patient_state_MA                                                                             0\n",
              "patient_state_MD                                                                             0\n",
              "patient_state_MI                                                                             0\n",
              "patient_state_MN                                                                             0\n",
              "patient_state_MO                                                                             0\n",
              "patient_state_MS                                                                             0\n",
              "patient_state_MT                                                                             0\n",
              "patient_state_NC                                                                             0\n",
              "patient_state_ND                                                                             0\n",
              "patient_state_NE                                                                             0\n",
              "patient_state_NH                                                                             0\n",
              "patient_state_NJ                                                                             0\n",
              "patient_state_NM                                                                             0\n",
              "patient_state_NV                                                                             0\n",
              "patient_state_NY                                                                             0\n",
              "patient_state_OH                                                                             0\n",
              "patient_state_OK                                                                             0\n",
              "patient_state_OR                                                                             0\n",
              "patient_state_PA                                                                             0\n",
              "patient_state_RI                                                                             0\n",
              "patient_state_SC                                                                             0\n",
              "patient_state_SD                                                                             0\n",
              "patient_state_TN                                                                             0\n",
              "patient_state_TX                                                                             0\n",
              "patient_state_UT                                                                             0\n",
              "patient_state_VA                                                                             0\n",
              "patient_state_WA                                                                             0\n",
              "patient_state_WI                                                                             0\n",
              "patient_state_WV                                                                             0\n",
              "patient_state_WY                                                                             0\n",
              "payer_type_COMMERCIAL                                                                        0\n",
              "payer_type_MEDICAID                                                                          0\n",
              "payer_type_MEDICARE ADVANTAGE                                                                0\n",
              "payer_type_Unknown                                                                           0\n",
              "population                                                                                   0\n",
              "poverty                                                                                      0\n",
              "race_asian                                                                                   0\n",
              "race_black                                                                                   0\n",
              "race_multiple                                                                                0\n",
              "race_native                                                                                  0\n",
              "race_other                                                                                   0\n",
              "race_pacific                                                                                 0\n",
              "race_white                                                                                   0\n",
              "rent_burden                                                                                  0\n",
              "rent_median                                                                                  0\n",
              "self_employed                                                                                0\n",
              "unemployment_rate                                                                            0\n",
              "veteran                                                                                      0\n",
              "widowed                                                                                      0\n",
              "patient_race_Asian                                                                           0\n",
              "patient_race_Black                                                                           0\n",
              "patient_race_Hispanic                                                                        0\n",
              "patient_race_Other                                                                           0\n",
              "patient_race_Unknown                                                                         0\n",
              "patient_race_White                                                                           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data['Hospital Ownership'].fillna('Unknown', inplace=True)\n",
        "# test_data['Hospital Ownership'].fillna('Unknown', inplace=True)\n"
      ],
      "metadata": {
        "id": "-AUZOHTF0lEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# types_dict = train_data.dtypes.to_dict()\n",
        "# test_dtypes = test_data.dtypes.to_dict()\n",
        "\n",
        "# for key in types_dict:\n",
        "#     if types_dict[key]=='O':\n",
        "#         train_data[key] = train_data[key].astype('category')\n",
        "\n",
        "# for key in test_dtypes:\n",
        "#     if test_dtypes[key]=='O':\n",
        "#         test_data[key] = test_data[key].astype('category')"
      ],
      "metadata": {
        "id": "MTcMJaTgdU3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data['Hospital Ownership'] = train_data['Hospital Ownership'].astype('category')\n",
        "# test_data['Hospital Ownership'] = test_data['Hospital Ownership'].astype('category')"
      ],
      "metadata": {
        "id": "6sxYW-9fz3D8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_data.drop(['patient_id','DiagPeriodL90D'], axis=1)\n",
        "y = train_data['DiagPeriodL90D']"
      ],
      "metadata": {
        "id": "ghJVApFYyGZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8g2VaFS0sDX",
        "outputId": "73380849-0f35-482c-cecd-5c688670eecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10324, 223), (2582, 223))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SMOTE"
      ],
      "metadata": {
        "id": "NLhScXQFmloN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cats = train_data.select_dtypes(exclude=np.number).columns.tolist()\n",
        "# cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuCapGwHUnvv",
        "outputId": "c01c2c8e-eecf-4461-b83e-d051832edd0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cats_idx = [X.columns.get_loc(col) for col in cats]\n",
        "# cats_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFVVk4EDa7xp",
        "outputId": "3ae0bfd1-55d1-4269-fc03-ae3f9be3e8a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 78, 79, 80]"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imblearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXiD6RZGMil2",
        "outputId": "55d6ea76-6407-4b0e-dff3-cc8768b2ec6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imblearn\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (from imblearn) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.4.1.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (3.3.0)\n",
            "Installing collected packages: imblearn\n",
            "Successfully installed imblearn-0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "VOR3tz5yMeot",
        "outputId": "5f0493b0-32cb-4179-b8da-189156b7ae13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-0b052d41b57a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# process, as it may not be compiled yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     from . import (\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mcombine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mensemble\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/combine/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_smote_enn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTEENN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_smote_tomek\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTETomek\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/combine/_smote_enn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseOverSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_sampling_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/utils/_param_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_valid_param\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m     from sklearn.utils._param_validation import (\n\u001b[0m\u001b[1;32m    909\u001b[0m         \u001b[0mHasMethods\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0mHidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "# from imblearn.over_sampling import SMOTENC\n",
        "\n",
        "# smote_nc = SMOTENC(categorical_features=cats_idx, random_state=10)\n",
        "# X_new,y_new = smote_nc.fit_resample(X, y)\n",
        "\n",
        "smote = SMOTE(random_state=10)\n",
        "X_new,y_new = smote.fit_resample(X, y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2, random_state=10)\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "RbuMH6pCmzCz",
        "outputId": "ca21ce29-83ec-467b-b8a3-91cd8af5bc2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-15adcac64491>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# from imblearn.over_sampling import SMOTENC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# smote_nc = SMOTENC(categorical_features=cats_idx, random_state=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# X_new,y_new = smote_nc.fit_resample(X, y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# process, as it may not be compiled yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     from . import (\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mcombine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mensemble\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/combine/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_smote_enn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTEENN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_smote_tomek\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTETomek\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/combine/_smote_enn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseOverSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_sampling_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/imblearn/utils/_param_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenerate_valid_param\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m     from sklearn.utils._param_validation import (\n\u001b[0m\u001b[1;32m    909\u001b[0m         \u001b[0mHasMethods\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0mHidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "se = StandardScaler()\n",
        "scaled_X_train = se.fit_transform(X_train)\n",
        "scaled_X_test = se.transform(X_test)"
      ],
      "metadata": {
        "id": "InDLsmbRM_2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Forest Classifier"
      ],
      "metadata": {
        "id": "qbTnli2YAaKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters_rf = {'max_depth':10, 'min_samples_split':50, 'n_estimators':187}\n"
      ],
      "metadata": {
        "id": "4nSsLSYqoElO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(**parameters_rf)\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "auc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9LLoXXa0Fhb",
        "outputId": "a3e28299-b0c9-495d-924f-f370e7141e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8605255683786143"
            ]
          },
          "metadata": {},
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##tuning"
      ],
      "metadata": {
        "id": "qOwsBKJaG7kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def objective_rf(trial):\n",
        "#     params = {'n_estimators': trial.suggest_int('n_estimators', low=100, high=500, step=100),\n",
        "#               'max_features': trial.suggest_categorical('max_features', choices=['auto', 'sqrt']),\n",
        "#               'max_depth': trial.suggest_int('max_depth', low=10, high=110, step=20),\n",
        "#               'min_samples_split': trial.suggest_int('min_samples_split', low=2, high=10, step=2),\n",
        "#               'min_samples_leaf': trial.suggest_int('min_samples_leaf', low=1, high=4, step=1)}\n",
        "\n",
        "#     model = RandomForestClassifier(random_state=10, **params)\n",
        "\n",
        "#     model.fit(X_train, y_train)\n",
        "#     y_pred = model.predict_proba(X_test)[:, 1]\n",
        "#     auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "#     return auc\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    # Number of trees in random forest\n",
        "    n_estimators = trial.suggest_int(name=\"n_estimators\", low=100, high=500, step=100)\n",
        "\n",
        "    # Maximum number of levels in tree\n",
        "    max_depth = trial.suggest_int(name=\"max_depth\", low=10, high=110, step=20)\n",
        "\n",
        "    # Minimum number of samples required to split a node\n",
        "    min_samples_split = trial.suggest_int(name=\"min_samples_split\", low=2, high=10, step=2)\n",
        "\n",
        "    # Minimum number of samples required at each leaf node\n",
        "    min_samples_leaf = trial.suggest_int(name=\"min_samples_leaf\", low=1, high=4, step=1)\n",
        "\n",
        "    params = {\n",
        "        \"n_estimators\": n_estimators,\n",
        "        \"max_depth\": max_depth,\n",
        "        \"min_samples_split\": min_samples_split,\n",
        "        \"min_samples_leaf\": min_samples_leaf\n",
        "    }\n",
        "    model = RandomForestClassifier(random_state=10, **params)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict_proba(X_test)[:, 1]\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "    return auc\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hr9n597EyPf",
        "outputId": "a74469e4-0f7d-4884-c2b7-b4e0cd3f150f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-28 17:01:22,821] A new study created in memory with name: no-name-deb56130-ad66-4fa5-9804-6c891699fada\n",
            "[I 2024-02-28 17:01:54,309] Trial 0 finished with value: 0.8620439770878263 and parameters: {'n_estimators': 500, 'max_depth': 90, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8620439770878263.\n",
            "[I 2024-02-28 17:02:06,777] Trial 1 finished with value: 0.8618888842707405 and parameters: {'n_estimators': 200, 'max_depth': 50, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 0 with value: 0.8620439770878263.\n",
            "[I 2024-02-28 17:02:32,214] Trial 2 finished with value: 0.8628009685796577 and parameters: {'n_estimators': 400, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.8628009685796577.\n",
            "[I 2024-02-28 17:03:00,330] Trial 3 finished with value: 0.8623276083687005 and parameters: {'n_estimators': 400, 'max_depth': 70, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8628009685796577.\n",
            "[I 2024-02-28 17:03:07,405] Trial 4 finished with value: 0.8600466279050077 and parameters: {'n_estimators': 100, 'max_depth': 70, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8628009685796577.\n",
            "[I 2024-02-28 17:03:20,386] Trial 5 finished with value: 0.8619493050456349 and parameters: {'n_estimators': 200, 'max_depth': 30, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.8628009685796577.\n",
            "[I 2024-02-28 17:03:38,120] Trial 6 finished with value: 0.8631531023951258 and parameters: {'n_estimators': 300, 'max_depth': 90, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.8631531023951258.\n",
            "[I 2024-02-28 17:04:10,808] Trial 7 finished with value: 0.8622464059260081 and parameters: {'n_estimators': 500, 'max_depth': 30, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.8631531023951258.\n",
            "[I 2024-02-28 17:04:41,291] Trial 8 finished with value: 0.8624234349479919 and parameters: {'n_estimators': 500, 'max_depth': 110, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.8631531023951258.\n",
            "[I 2024-02-28 17:04:59,941] Trial 9 finished with value: 0.8626039275812756 and parameters: {'n_estimators': 300, 'max_depth': 90, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 6 with value: 0.8631531023951258.\n",
            "[I 2024-02-28 17:05:18,857] Trial 10 finished with value: 0.8629229646665467 and parameters: {'n_estimators': 300, 'max_depth': 110, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.8631531023951258.\n",
            "[I 2024-02-28 17:05:36,540] Trial 11 finished with value: 0.8629229646665467 and parameters: {'n_estimators': 300, 'max_depth': 110, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 6 with value: 0.8631531023951258.\n",
            "[I 2024-02-28 17:05:48,809] Trial 12 finished with value: 0.8631904324280223 and parameters: {'n_estimators': 200, 'max_depth': 90, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.8631904324280223.\n",
            "[I 2024-02-28 17:05:55,339] Trial 13 finished with value: 0.8617395641391541 and parameters: {'n_estimators': 100, 'max_depth': 90, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.8631904324280223.\n",
            "[I 2024-02-28 17:06:07,554] Trial 14 finished with value: 0.8631904324280223 and parameters: {'n_estimators': 200, 'max_depth': 70, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.8631904324280223.\n",
            "[I 2024-02-28 17:06:19,757] Trial 15 finished with value: 0.8631904324280223 and parameters: {'n_estimators': 200, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.8631904324280223.\n",
            "[I 2024-02-28 17:06:27,039] Trial 16 finished with value: 0.8597828161776817 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.8631904324280223.\n",
            "[I 2024-02-28 17:06:33,294] Trial 17 finished with value: 0.8610291389770184 and parameters: {'n_estimators': 100, 'max_depth': 70, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 12 with value: 0.8631904324280223.\n",
            "[I 2024-02-28 17:06:45,563] Trial 18 finished with value: 0.8631904324280223 and parameters: {'n_estimators': 200, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.8631904324280223.\n",
            "[I 2024-02-28 17:07:10,652] Trial 19 finished with value: 0.8628790922567505 and parameters: {'n_estimators': 400, 'max_depth': 70, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.8631904324280223.\n",
            "[I 2024-02-28 17:07:16,264] Trial 20 finished with value: 0.8618811873567412 and parameters: {'n_estimators': 100, 'max_depth': 90, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.8631904324280223.\n",
            "[I 2024-02-28 17:07:28,570] Trial 21 finished with value: 0.8631904324280223 and parameters: {'n_estimators': 200, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.8631904324280223.\n",
            "[I 2024-02-28 17:07:40,868] Trial 22 finished with value: 0.8631904324280223 and parameters: {'n_estimators': 200, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.8631904324280223.\n",
            "[I 2024-02-28 17:07:53,527] Trial 23 finished with value: 0.8627347751192639 and parameters: {'n_estimators': 200, 'max_depth': 70, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.8631904324280223.\n",
            "[I 2024-02-28 17:08:11,189] Trial 24 finished with value: 0.8629229646665467 and parameters: {'n_estimators': 300, 'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.8631904324280223.\n",
            "[I 2024-02-28 17:08:15,310] Trial 25 finished with value: 0.8582059109220749 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 12 with value: 0.8631904324280223.\n",
            "[I 2024-02-28 17:08:27,889] Trial 26 finished with value: 0.8619962562210307 and parameters: {'n_estimators': 200, 'max_depth': 70, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 12 with value: 0.8631904324280223.\n",
            "[I 2024-02-28 17:08:45,517] Trial 27 finished with value: 0.8635968294871854 and parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 27 with value: 0.8635968294871854.\n",
            "[I 2024-02-28 17:09:03,645] Trial 28 finished with value: 0.8625042525449848 and parameters: {'n_estimators': 300, 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 27 with value: 0.8635968294871854.\n",
            "[I 2024-02-28 17:09:16,959] Trial 29 finished with value: 0.8593539056450705 and parameters: {'n_estimators': 400, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 27 with value: 0.8635968294871854.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_rf_params = study.best_params"
      ],
      "metadata": {
        "id": "zwz7g63NHxSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_tuned = RandomForestClassifier(**best_rf_params)\n",
        "\n",
        "rf_tuned.fit(X_train, y_train)\n",
        "y_pred = rf_tuned.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "auc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "PZl8o7wdH6vb",
        "outputId": "818cf020-a9cd-40fe-dc41-735769042884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "RandomForestClassifier.__init__() got an unexpected keyword argument 'learning_rate'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-272-2664fb6dd14c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrf_tuned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbest_rf_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrf_tuned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_tuned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: RandomForestClassifier.__init__() got an unexpected keyword argument 'learning_rate'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#XGBoost Classifier"
      ],
      "metadata": {
        "id": "ZMCTUGSnAVsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "se = StandardScaler()\n",
        "scaled_X_train = se.fit_transform(X_train)\n",
        "scaled_X_test = se.transform(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "awOMsk_QMz_X",
        "outputId": "dc126147-285e-4348-dced-88d68303c4cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'StandardScaler' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-34828e53d512>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscaled_X_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscaled_X_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_params = {'n_estimators': 200,\n",
        "        'learning_rate': 0.01,\n",
        "        'max_depth': 5,\n",
        "        'subsample': 0.3,\n",
        "        'colsample_bytree': 0.3,\n",
        "        'gamma': 1e-6}"
      ],
      "metadata": {
        "id": "GZj4nSmf2fIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = XGBClassifier(random_state=42, **xgb_params, enable_categorical=True)\n",
        "\n",
        "xgb_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "9zTtfuaj2Af0",
        "outputId": "7097a798-2c5a-4109-bc33-3e43b7c89a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.3, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
              "              gamma=1e-06, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=42, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.3, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
              "              gamma=1e-06, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.3, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
              "              gamma=1e-06, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=200, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
        "auc_xgb = roc_auc_score(y_test, y_pred_xgb)\n",
        "auc_xgb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGbiNFyq2nCO",
        "outputId": "ef91c5d3-ffa5-436b-a1aa-83bb6d0f1039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8589296132608591"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##tuning"
      ],
      "metadata": {
        "id": "fqTFFpbyE8Cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 200, 300),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
        "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n",
        "        'gamma': trial.suggest_float('gamma', 1e-8, 1.0, log=True),\n",
        "        'random_state': 10\n",
        "    }\n",
        "\n",
        "    xgb_model = XGBClassifier(**params, enable_categorical=True)\n",
        "\n",
        "    xgb_model.fit(X_train, y_train)\n",
        "    y_pred = xgb_model.predict_proba(X_test)[:, 1]\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "    return auc"
      ],
      "metadata": {
        "id": "B5kSueP_auqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize')"
      ],
      "metadata": {
        "id": "hauGext2bpov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b734f5b-f735-4541-b352-a8eb1eb397d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-01 06:37:15,092] A new study created in memory with name: no-name-fccfe82e-68ad-403f-904e-f300386dd8c3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.optimize(objective, n_trials=30)"
      ],
      "metadata": {
        "id": "D32_0A9-bjEY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "f5f1238a-984b-49d0-fdeb-8fbfebd3e12a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-03-01 06:37:21,883] Trial 0 finished with value: 0.8493350251150302 and parameters: {'n_estimators': 207, 'learning_rate': 0.01661169306619972, 'max_depth': 3, 'subsample': 0.8695036559818463, 'colsample_bytree': 0.5041731701944661, 'gamma': 0.08718333738279883}. Best is trial 0 with value: 0.8493350251150302.\n",
            "[I 2024-03-01 06:37:24,015] Trial 1 finished with value: 0.8502270974475494 and parameters: {'n_estimators': 236, 'learning_rate': 0.01581791709722112, 'max_depth': 3, 'subsample': 0.7820267593491408, 'colsample_bytree': 0.9699904377772403, 'gamma': 9.148493251241553e-05}. Best is trial 1 with value: 0.8502270974475494.\n",
            "[I 2024-03-01 06:37:37,447] Trial 2 finished with value: 0.8625535127945801 and parameters: {'n_estimators': 205, 'learning_rate': 0.004105892557959294, 'max_depth': 9, 'subsample': 0.7367445791289681, 'colsample_bytree': 0.8531975274362495, 'gamma': 3.4867146955224075e-05}. Best is trial 2 with value: 0.8625535127945801.\n",
            "[I 2024-03-01 06:37:45,191] Trial 3 finished with value: 0.8593340860915224 and parameters: {'n_estimators': 248, 'learning_rate': 0.007572791765420991, 'max_depth': 6, 'subsample': 0.7490905899748306, 'colsample_bytree': 0.7705102456032562, 'gamma': 3.326186003387549e-06}. Best is trial 2 with value: 0.8625535127945801.\n",
            "[I 2024-03-01 06:37:47,002] Trial 4 finished with value: 0.8612839068303955 and parameters: {'n_estimators': 215, 'learning_rate': 0.043924662475548014, 'max_depth': 3, 'subsample': 0.5071785896111713, 'colsample_bytree': 0.6794240793977374, 'gamma': 1.2069297855114677e-07}. Best is trial 2 with value: 0.8625535127945801.\n",
            "[I 2024-03-01 06:37:52,123] Trial 5 finished with value: 0.8267674808462295 and parameters: {'n_estimators': 231, 'learning_rate': 0.00121991524200438, 'max_depth': 6, 'subsample': 0.8033923732359416, 'colsample_bytree': 0.9996137701051117, 'gamma': 9.779844991393403e-05}. Best is trial 2 with value: 0.8625535127945801.\n",
            "[W 2024-03-01 06:38:05,239] Trial 6 failed with parameters: {'n_estimators': 284, 'learning_rate': 0.0021712256337599995, 'max_depth': 9, 'subsample': 0.6948259068208924, 'colsample_bytree': 0.9264457880298662, 'gamma': 8.787716358714065e-06} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-29-6ba4e7465939>\", line 14, in objective\n",
            "    xgb_model.fit(X_train, y_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 730, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 1519, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 730, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/training.py\", line 181, in train\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 2051, in update\n",
            "    _LIB.XGBoosterUpdateOneIter(\n",
            "KeyboardInterrupt\n",
            "[W 2024-03-01 06:38:05,245] Trial 6 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-2e8fb90be33b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-6ba4e7465939>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mxgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_categorical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1517\u001b[0m             )\n\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1519\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1520\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m             _check_call(\n\u001b[0;32m-> 2051\u001b[0;31m                 _LIB.XGBoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   2052\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2053\u001b[0m                 )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = study.best_params"
      ],
      "metadata": {
        "id": "xAHpCMA-epqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PH8HnjHgGHD",
        "outputId": "016e0fca-b39a-4781-fd11-8d95e71deb0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_estimators': 217,\n",
              " 'learning_rate': 0.041509965338468416,\n",
              " 'max_depth': 9,\n",
              " 'subsample': 0.9927497897645347,\n",
              " 'colsample_bytree': 0.7202038200230569,\n",
              " 'gamma': 0.14508007721449825}"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters_xgb ={'n_estimators': 232,\n",
        " 'learning_rate': 0.09330039417706945,\n",
        " 'max_depth': 4,\n",
        " 'subsample': 0.8180910137459942,\n",
        " 'colsample_bytree': 0.7309531744186701,\n",
        " 'gamma': 3.7710013857451275e-05}\n",
        "\n"
      ],
      "metadata": {
        "id": "EFPpEeJjEORp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model_tuned = XGBClassifier(**parameters_xgb, random_state=10)\n",
        "\n",
        "xgb_model_tuned.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "ttlkrac8exF6",
        "outputId": "45514b19-deec-4edf-9d1b-037a3b8167b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.7309531744186701, device=None,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric=None, feature_types=None,\n",
              "              gamma=3.7710013857451275e-05, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.09330039417706945, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=232, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=10, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.7309531744186701, device=None,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric=None, feature_types=None,\n",
              "              gamma=3.7710013857451275e-05, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.09330039417706945, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=232, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=10, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.7309531744186701, device=None,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eval_metric=None, feature_types=None,\n",
              "              gamma=3.7710013857451275e-05, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.09330039417706945, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=232, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=10, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_xgb_tuned = xgb_model_tuned.predict_proba(X_test)[:, 1]\n",
        "auc_xgb_tuned = roc_auc_score(y_test, y_pred_xgb_tuned)\n",
        "auc_xgb_tuned"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BtuEfPJgPky",
        "outputId": "1a8fe01b-e02a-459f-b6e5-396fc1c2a187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8754414180178599"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gradient Boosting"
      ],
      "metadata": {
        "id": "pTunxKs9EKjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "9clkYMTtEO4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb_clf = GradientBoostingClassifier()"
      ],
      "metadata": {
        "id": "0wb0oYW_EQSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb_clf.fit(X_train, y_train)\n",
        "y_pred_gb = gb_clf.predict_proba(X_test)[:, 1]\n",
        "auc_gb = roc_auc_score(y_test, y_pred_gb)\n",
        "auc_gb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPm19AHdEU-3",
        "outputId": "277e0480-1e26-4134-cd97-877dc6060448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.86222485456681"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##tuning"
      ],
      "metadata": {
        "id": "2i8exteaIX2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate"
      ],
      "metadata": {
        "id": "qWL3jAFZO5fL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "  params = {\n",
        "    \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500, step = 100),\n",
        "    \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.3, log = True),\n",
        "    \"max_depth\": trial.suggest_int(\"max_depth\", 3, 9),\n",
        "    \"subsample\": trial.suggest_float(\"subsample\", 0.5, 0.9, step = 0.1),\n",
        "    \"random_state\": 42,\n",
        "    }\n",
        "  # Perform cross validation\n",
        "  gb_class = GradientBoostingClassifier(**params)\n",
        "\n",
        "  gb_class.fit(X_train, y_train)\n",
        "  y_pred = gb_class.predict_proba(X_test)[:, 1]\n",
        "  auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "  return auc"
      ],
      "metadata": {
        "id": "iODx4vQbIaqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "46W2aAuRIaqs",
        "outputId": "726f6064-26a5-4d13-c5c5-72d6f2005632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-02-28 10:53:12,179] A new study created in memory with name: no-name-5ecf6964-d413-42b6-9a22-61ad1db3327e\n",
            "[W 2024-02-28 11:04:42,589] Trial 0 failed with parameters: {'n_estimators': 3700, 'learning_rate': 0.009135368085344906, 'max_depth': 9, 'subsample': 0.9} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-108-53e643c5f313>\", line 12, in objective\n",
            "    gb_class.fit(X_train, y_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\", line 538, in fit\n",
            "    n_stages = self._fit_stages(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\", line 615, in _fit_stages\n",
            "    raw_predictions = self._fit_stage(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\", line 257, in _fit_stage\n",
            "    tree.fit(X, residual, sample_weight=sample_weight, check_input=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
            "    super().fit(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\", line 379, in fit\n",
            "    builder.build(self.tree_, X, y, sample_weight)\n",
            "KeyboardInterrupt\n",
            "[W 2024-02-28 11:04:42,593] Trial 0 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-da5b7e186295>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-108-53e643c5f313>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mgb_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mgb_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgb_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         n_stages = self._fit_stages(\n\u001b[0m\u001b[1;32m    539\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[1;32m    616\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_gb_params = study.best_params"
      ],
      "metadata": {
        "id": "IMpwTpDoIaqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gb_tuned = GradientBoostingClassifier(**best_gb_params)\n",
        "\n",
        "gb_tuned.fit(X_train, y_train)\n",
        "y_pred = gb_tuned.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "auc"
      ],
      "metadata": {
        "id": "DqL9wAwCIaqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-3xcpqILIZuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Catboost Classifier"
      ],
      "metadata": {
        "id": "8r1qK4KV19FS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "M7Ji9t-R2FU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier"
      ],
      "metadata": {
        "id": "2RXnLY4Z1_vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_catboost = CatBoostClassifier()\n",
        "model_catboost.fit(X_train, y_train)\n",
        "\n",
        "y_pred_catboost = model_catboost.predict_proba(X_test)[:, 1]\n",
        "auc_catboost = roc_auc_score(y_test, y_pred_catboost)\n",
        "auc_catboost\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2bhTBBQ2IFl",
        "outputId": "f3222f52-67d1-4c2c-8dfd-7faeecc80baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.030697\n",
            "0:\tlearn: 0.6838248\ttotal: 43.8ms\tremaining: 43.7s\n",
            "1:\tlearn: 0.6744519\ttotal: 70.4ms\tremaining: 35.1s\n",
            "2:\tlearn: 0.6649391\ttotal: 96.9ms\tremaining: 32.2s\n",
            "3:\tlearn: 0.6568457\ttotal: 122ms\tremaining: 30.5s\n",
            "4:\tlearn: 0.6492528\ttotal: 151ms\tremaining: 30s\n",
            "5:\tlearn: 0.6411575\ttotal: 175ms\tremaining: 29s\n",
            "6:\tlearn: 0.6345487\ttotal: 204ms\tremaining: 28.9s\n",
            "7:\tlearn: 0.6282876\ttotal: 228ms\tremaining: 28.2s\n",
            "8:\tlearn: 0.6225933\ttotal: 253ms\tremaining: 27.8s\n",
            "9:\tlearn: 0.6171454\ttotal: 277ms\tremaining: 27.5s\n",
            "10:\tlearn: 0.6116584\ttotal: 315ms\tremaining: 28.3s\n",
            "11:\tlearn: 0.6054502\ttotal: 343ms\tremaining: 28.2s\n",
            "12:\tlearn: 0.5993917\ttotal: 367ms\tremaining: 27.9s\n",
            "13:\tlearn: 0.5952382\ttotal: 392ms\tremaining: 27.6s\n",
            "14:\tlearn: 0.5909584\ttotal: 421ms\tremaining: 27.6s\n",
            "15:\tlearn: 0.5869634\ttotal: 447ms\tremaining: 27.5s\n",
            "16:\tlearn: 0.5833210\ttotal: 472ms\tremaining: 27.3s\n",
            "17:\tlearn: 0.5785082\ttotal: 497ms\tremaining: 27.1s\n",
            "18:\tlearn: 0.5749503\ttotal: 523ms\tremaining: 27s\n",
            "19:\tlearn: 0.5716837\ttotal: 546ms\tremaining: 26.8s\n",
            "20:\tlearn: 0.5685334\ttotal: 571ms\tremaining: 26.6s\n",
            "21:\tlearn: 0.5646153\ttotal: 597ms\tremaining: 26.5s\n",
            "22:\tlearn: 0.5613529\ttotal: 625ms\tremaining: 26.6s\n",
            "23:\tlearn: 0.5566559\ttotal: 650ms\tremaining: 26.4s\n",
            "24:\tlearn: 0.5533694\ttotal: 675ms\tremaining: 26.3s\n",
            "25:\tlearn: 0.5485675\ttotal: 698ms\tremaining: 26.1s\n",
            "26:\tlearn: 0.5443952\ttotal: 722ms\tremaining: 26s\n",
            "27:\tlearn: 0.5410496\ttotal: 747ms\tremaining: 25.9s\n",
            "28:\tlearn: 0.5366167\ttotal: 772ms\tremaining: 25.8s\n",
            "29:\tlearn: 0.5338163\ttotal: 795ms\tremaining: 25.7s\n",
            "30:\tlearn: 0.5307606\ttotal: 818ms\tremaining: 25.6s\n",
            "31:\tlearn: 0.5289461\ttotal: 848ms\tremaining: 25.6s\n",
            "32:\tlearn: 0.5252388\ttotal: 871ms\tremaining: 25.5s\n",
            "33:\tlearn: 0.5228635\ttotal: 895ms\tremaining: 25.4s\n",
            "34:\tlearn: 0.5203597\ttotal: 918ms\tremaining: 25.3s\n",
            "35:\tlearn: 0.5171776\ttotal: 941ms\tremaining: 25.2s\n",
            "36:\tlearn: 0.5157468\ttotal: 966ms\tremaining: 25.1s\n",
            "37:\tlearn: 0.5139551\ttotal: 989ms\tremaining: 25s\n",
            "38:\tlearn: 0.5125221\ttotal: 1.01s\tremaining: 25s\n",
            "39:\tlearn: 0.5112106\ttotal: 1.04s\tremaining: 24.9s\n",
            "40:\tlearn: 0.5089160\ttotal: 1.07s\tremaining: 24.9s\n",
            "41:\tlearn: 0.5062212\ttotal: 1.1s\tremaining: 25s\n",
            "42:\tlearn: 0.5043148\ttotal: 1.12s\tremaining: 25s\n",
            "43:\tlearn: 0.5032124\ttotal: 1.15s\tremaining: 25s\n",
            "44:\tlearn: 0.5022512\ttotal: 1.17s\tremaining: 24.9s\n",
            "45:\tlearn: 0.5003378\ttotal: 1.19s\tremaining: 24.8s\n",
            "46:\tlearn: 0.4985173\ttotal: 1.22s\tremaining: 24.7s\n",
            "47:\tlearn: 0.4968343\ttotal: 1.24s\tremaining: 24.6s\n",
            "48:\tlearn: 0.4957302\ttotal: 1.27s\tremaining: 24.6s\n",
            "49:\tlearn: 0.4950103\ttotal: 1.29s\tremaining: 24.6s\n",
            "50:\tlearn: 0.4941118\ttotal: 1.34s\tremaining: 25s\n",
            "51:\tlearn: 0.4920366\ttotal: 1.37s\tremaining: 24.9s\n",
            "52:\tlearn: 0.4910585\ttotal: 1.39s\tremaining: 24.9s\n",
            "53:\tlearn: 0.4901817\ttotal: 1.42s\tremaining: 24.8s\n",
            "54:\tlearn: 0.4893895\ttotal: 1.44s\tremaining: 24.8s\n",
            "55:\tlearn: 0.4884774\ttotal: 1.47s\tremaining: 24.7s\n",
            "56:\tlearn: 0.4870982\ttotal: 1.5s\tremaining: 24.7s\n",
            "57:\tlearn: 0.4862138\ttotal: 1.52s\tremaining: 24.7s\n",
            "58:\tlearn: 0.4845057\ttotal: 1.54s\tremaining: 24.6s\n",
            "59:\tlearn: 0.4837617\ttotal: 1.57s\tremaining: 24.6s\n",
            "60:\tlearn: 0.4821399\ttotal: 1.59s\tremaining: 24.5s\n",
            "61:\tlearn: 0.4813741\ttotal: 1.61s\tremaining: 24.4s\n",
            "62:\tlearn: 0.4805824\ttotal: 1.64s\tremaining: 24.4s\n",
            "63:\tlearn: 0.4799436\ttotal: 1.66s\tremaining: 24.3s\n",
            "64:\tlearn: 0.4790425\ttotal: 1.69s\tremaining: 24.3s\n",
            "65:\tlearn: 0.4782102\ttotal: 1.72s\tremaining: 24.3s\n",
            "66:\tlearn: 0.4776093\ttotal: 1.74s\tremaining: 24.3s\n",
            "67:\tlearn: 0.4771367\ttotal: 1.77s\tremaining: 24.2s\n",
            "68:\tlearn: 0.4755252\ttotal: 1.79s\tremaining: 24.2s\n",
            "69:\tlearn: 0.4749149\ttotal: 1.82s\tremaining: 24.1s\n",
            "70:\tlearn: 0.4739046\ttotal: 1.84s\tremaining: 24.1s\n",
            "71:\tlearn: 0.4733696\ttotal: 1.86s\tremaining: 24s\n",
            "72:\tlearn: 0.4723036\ttotal: 1.89s\tremaining: 24s\n",
            "73:\tlearn: 0.4717119\ttotal: 1.92s\tremaining: 24s\n",
            "74:\tlearn: 0.4708692\ttotal: 1.94s\tremaining: 24s\n",
            "75:\tlearn: 0.4703099\ttotal: 1.97s\tremaining: 23.9s\n",
            "76:\tlearn: 0.4699164\ttotal: 1.99s\tremaining: 23.9s\n",
            "77:\tlearn: 0.4642376\ttotal: 2.02s\tremaining: 23.9s\n",
            "78:\tlearn: 0.4636291\ttotal: 2.04s\tremaining: 23.8s\n",
            "79:\tlearn: 0.4631037\ttotal: 2.07s\tremaining: 23.8s\n",
            "80:\tlearn: 0.4625833\ttotal: 2.1s\tremaining: 23.8s\n",
            "81:\tlearn: 0.4620625\ttotal: 2.13s\tremaining: 23.8s\n",
            "82:\tlearn: 0.4612148\ttotal: 2.15s\tremaining: 23.8s\n",
            "83:\tlearn: 0.4608141\ttotal: 2.17s\tremaining: 23.7s\n",
            "84:\tlearn: 0.4604098\ttotal: 2.2s\tremaining: 23.7s\n",
            "85:\tlearn: 0.4599840\ttotal: 2.24s\tremaining: 23.8s\n",
            "86:\tlearn: 0.4596073\ttotal: 2.27s\tremaining: 23.8s\n",
            "87:\tlearn: 0.4592193\ttotal: 2.29s\tremaining: 23.7s\n",
            "88:\tlearn: 0.4586414\ttotal: 2.33s\tremaining: 23.9s\n",
            "89:\tlearn: 0.4580294\ttotal: 2.36s\tremaining: 23.9s\n",
            "90:\tlearn: 0.4576768\ttotal: 2.39s\tremaining: 23.9s\n",
            "91:\tlearn: 0.4572628\ttotal: 2.41s\tremaining: 23.8s\n",
            "92:\tlearn: 0.4569889\ttotal: 2.44s\tremaining: 23.8s\n",
            "93:\tlearn: 0.4565484\ttotal: 2.46s\tremaining: 23.7s\n",
            "94:\tlearn: 0.4561379\ttotal: 2.49s\tremaining: 23.7s\n",
            "95:\tlearn: 0.4557806\ttotal: 2.51s\tremaining: 23.7s\n",
            "96:\tlearn: 0.4554265\ttotal: 2.54s\tremaining: 23.7s\n",
            "97:\tlearn: 0.4551097\ttotal: 2.57s\tremaining: 23.6s\n",
            "98:\tlearn: 0.4548165\ttotal: 2.59s\tremaining: 23.6s\n",
            "99:\tlearn: 0.4544642\ttotal: 2.62s\tremaining: 23.5s\n",
            "100:\tlearn: 0.4540270\ttotal: 2.64s\tremaining: 23.5s\n",
            "101:\tlearn: 0.4534669\ttotal: 2.66s\tremaining: 23.4s\n",
            "102:\tlearn: 0.4531361\ttotal: 2.69s\tremaining: 23.4s\n",
            "103:\tlearn: 0.4528476\ttotal: 2.71s\tremaining: 23.4s\n",
            "104:\tlearn: 0.4525280\ttotal: 2.74s\tremaining: 23.4s\n",
            "105:\tlearn: 0.4521599\ttotal: 2.77s\tremaining: 23.4s\n",
            "106:\tlearn: 0.4517296\ttotal: 2.8s\tremaining: 23.4s\n",
            "107:\tlearn: 0.4513087\ttotal: 2.82s\tremaining: 23.3s\n",
            "108:\tlearn: 0.4509644\ttotal: 2.85s\tremaining: 23.3s\n",
            "109:\tlearn: 0.4505675\ttotal: 2.87s\tremaining: 23.2s\n",
            "110:\tlearn: 0.4501689\ttotal: 2.9s\tremaining: 23.2s\n",
            "111:\tlearn: 0.4498398\ttotal: 2.92s\tremaining: 23.2s\n",
            "112:\tlearn: 0.4494474\ttotal: 2.95s\tremaining: 23.2s\n",
            "113:\tlearn: 0.4490637\ttotal: 2.98s\tremaining: 23.1s\n",
            "114:\tlearn: 0.4485447\ttotal: 3s\tremaining: 23.1s\n",
            "115:\tlearn: 0.4482781\ttotal: 3.02s\tremaining: 23.1s\n",
            "116:\tlearn: 0.4478506\ttotal: 3.05s\tremaining: 23s\n",
            "117:\tlearn: 0.4475806\ttotal: 3.08s\tremaining: 23s\n",
            "118:\tlearn: 0.4471905\ttotal: 3.11s\tremaining: 23s\n",
            "119:\tlearn: 0.4468898\ttotal: 3.13s\tremaining: 23s\n",
            "120:\tlearn: 0.4466426\ttotal: 3.16s\tremaining: 23s\n",
            "121:\tlearn: 0.4463591\ttotal: 3.19s\tremaining: 22.9s\n",
            "122:\tlearn: 0.4461216\ttotal: 3.21s\tremaining: 22.9s\n",
            "123:\tlearn: 0.4457254\ttotal: 3.24s\tremaining: 22.9s\n",
            "124:\tlearn: 0.4414813\ttotal: 3.26s\tremaining: 22.8s\n",
            "125:\tlearn: 0.4411108\ttotal: 3.29s\tremaining: 22.8s\n",
            "126:\tlearn: 0.4407800\ttotal: 3.31s\tremaining: 22.8s\n",
            "127:\tlearn: 0.4402658\ttotal: 3.34s\tremaining: 22.8s\n",
            "128:\tlearn: 0.4399931\ttotal: 3.38s\tremaining: 22.8s\n",
            "129:\tlearn: 0.4397126\ttotal: 3.4s\tremaining: 22.8s\n",
            "130:\tlearn: 0.4393748\ttotal: 3.43s\tremaining: 22.8s\n",
            "131:\tlearn: 0.4391110\ttotal: 3.46s\tremaining: 22.8s\n",
            "132:\tlearn: 0.4389004\ttotal: 3.48s\tremaining: 22.7s\n",
            "133:\tlearn: 0.4385353\ttotal: 3.51s\tremaining: 22.7s\n",
            "134:\tlearn: 0.4382729\ttotal: 3.53s\tremaining: 22.6s\n",
            "135:\tlearn: 0.4379328\ttotal: 3.56s\tremaining: 22.6s\n",
            "136:\tlearn: 0.4376033\ttotal: 3.59s\tremaining: 22.6s\n",
            "137:\tlearn: 0.4373175\ttotal: 3.62s\tremaining: 22.6s\n",
            "138:\tlearn: 0.4370260\ttotal: 3.64s\tremaining: 22.6s\n",
            "139:\tlearn: 0.4368024\ttotal: 3.67s\tremaining: 22.5s\n",
            "140:\tlearn: 0.4365881\ttotal: 3.7s\tremaining: 22.5s\n",
            "141:\tlearn: 0.4362713\ttotal: 3.72s\tremaining: 22.5s\n",
            "142:\tlearn: 0.4359427\ttotal: 3.75s\tremaining: 22.5s\n",
            "143:\tlearn: 0.4356038\ttotal: 3.77s\tremaining: 22.4s\n",
            "144:\tlearn: 0.4353653\ttotal: 3.8s\tremaining: 22.4s\n",
            "145:\tlearn: 0.4351248\ttotal: 3.83s\tremaining: 22.4s\n",
            "146:\tlearn: 0.4348007\ttotal: 3.85s\tremaining: 22.4s\n",
            "147:\tlearn: 0.4345278\ttotal: 3.88s\tremaining: 22.3s\n",
            "148:\tlearn: 0.4341881\ttotal: 3.91s\tremaining: 22.3s\n",
            "149:\tlearn: 0.4338990\ttotal: 3.93s\tremaining: 22.3s\n",
            "150:\tlearn: 0.4335588\ttotal: 3.96s\tremaining: 22.2s\n",
            "151:\tlearn: 0.4332305\ttotal: 3.98s\tremaining: 22.2s\n",
            "152:\tlearn: 0.4330407\ttotal: 4.01s\tremaining: 22.2s\n",
            "153:\tlearn: 0.4325722\ttotal: 4.04s\tremaining: 22.2s\n",
            "154:\tlearn: 0.4322938\ttotal: 4.06s\tremaining: 22.1s\n",
            "155:\tlearn: 0.4320320\ttotal: 4.09s\tremaining: 22.1s\n",
            "156:\tlearn: 0.4317275\ttotal: 4.11s\tremaining: 22.1s\n",
            "157:\tlearn: 0.4314789\ttotal: 4.14s\tremaining: 22.1s\n",
            "158:\tlearn: 0.4312067\ttotal: 4.16s\tremaining: 22s\n",
            "159:\tlearn: 0.4309687\ttotal: 4.19s\tremaining: 22s\n",
            "160:\tlearn: 0.4307061\ttotal: 4.22s\tremaining: 22s\n",
            "161:\tlearn: 0.4301447\ttotal: 4.24s\tremaining: 21.9s\n",
            "162:\tlearn: 0.4299190\ttotal: 4.27s\tremaining: 21.9s\n",
            "163:\tlearn: 0.4297240\ttotal: 4.29s\tremaining: 21.9s\n",
            "164:\tlearn: 0.4294904\ttotal: 4.32s\tremaining: 21.9s\n",
            "165:\tlearn: 0.4291901\ttotal: 4.34s\tremaining: 21.8s\n",
            "166:\tlearn: 0.4288662\ttotal: 4.38s\tremaining: 21.9s\n",
            "167:\tlearn: 0.4284942\ttotal: 4.41s\tremaining: 21.8s\n",
            "168:\tlearn: 0.4282656\ttotal: 4.44s\tremaining: 21.8s\n",
            "169:\tlearn: 0.4279030\ttotal: 4.47s\tremaining: 21.8s\n",
            "170:\tlearn: 0.4275394\ttotal: 4.49s\tremaining: 21.8s\n",
            "171:\tlearn: 0.4274104\ttotal: 4.52s\tremaining: 21.7s\n",
            "172:\tlearn: 0.4270916\ttotal: 4.55s\tremaining: 21.8s\n",
            "173:\tlearn: 0.4267391\ttotal: 4.58s\tremaining: 21.7s\n",
            "174:\tlearn: 0.4265071\ttotal: 4.6s\tremaining: 21.7s\n",
            "175:\tlearn: 0.4262735\ttotal: 4.63s\tremaining: 21.7s\n",
            "176:\tlearn: 0.4260477\ttotal: 4.66s\tremaining: 21.7s\n",
            "177:\tlearn: 0.4258423\ttotal: 4.68s\tremaining: 21.6s\n",
            "178:\tlearn: 0.4254792\ttotal: 4.71s\tremaining: 21.6s\n",
            "179:\tlearn: 0.4252934\ttotal: 4.73s\tremaining: 21.6s\n",
            "180:\tlearn: 0.4250059\ttotal: 4.75s\tremaining: 21.5s\n",
            "181:\tlearn: 0.4247336\ttotal: 4.78s\tremaining: 21.5s\n",
            "182:\tlearn: 0.4245634\ttotal: 4.8s\tremaining: 21.4s\n",
            "183:\tlearn: 0.4243699\ttotal: 4.83s\tremaining: 21.4s\n",
            "184:\tlearn: 0.4241348\ttotal: 4.85s\tremaining: 21.4s\n",
            "185:\tlearn: 0.4239370\ttotal: 4.89s\tremaining: 21.4s\n",
            "186:\tlearn: 0.4235085\ttotal: 4.91s\tremaining: 21.4s\n",
            "187:\tlearn: 0.4233358\ttotal: 4.94s\tremaining: 21.3s\n",
            "188:\tlearn: 0.4231258\ttotal: 4.96s\tremaining: 21.3s\n",
            "189:\tlearn: 0.4228430\ttotal: 4.99s\tremaining: 21.3s\n",
            "190:\tlearn: 0.4226404\ttotal: 5.01s\tremaining: 21.2s\n",
            "191:\tlearn: 0.4224284\ttotal: 5.04s\tremaining: 21.2s\n",
            "192:\tlearn: 0.4221539\ttotal: 5.06s\tremaining: 21.2s\n",
            "193:\tlearn: 0.4218352\ttotal: 5.09s\tremaining: 21.1s\n",
            "194:\tlearn: 0.4215982\ttotal: 5.12s\tremaining: 21.1s\n",
            "195:\tlearn: 0.4213520\ttotal: 5.14s\tremaining: 21.1s\n",
            "196:\tlearn: 0.4210925\ttotal: 5.17s\tremaining: 21.1s\n",
            "197:\tlearn: 0.4207768\ttotal: 5.19s\tremaining: 21s\n",
            "198:\tlearn: 0.4205428\ttotal: 5.22s\tremaining: 21s\n",
            "199:\tlearn: 0.4203068\ttotal: 5.24s\tremaining: 21s\n",
            "200:\tlearn: 0.4200606\ttotal: 5.27s\tremaining: 20.9s\n",
            "201:\tlearn: 0.4198293\ttotal: 5.29s\tremaining: 20.9s\n",
            "202:\tlearn: 0.4195707\ttotal: 5.32s\tremaining: 20.9s\n",
            "203:\tlearn: 0.4193263\ttotal: 5.34s\tremaining: 20.9s\n",
            "204:\tlearn: 0.4190873\ttotal: 5.38s\tremaining: 20.9s\n",
            "205:\tlearn: 0.4188297\ttotal: 5.42s\tremaining: 20.9s\n",
            "206:\tlearn: 0.4185849\ttotal: 5.44s\tremaining: 20.9s\n",
            "207:\tlearn: 0.4183310\ttotal: 5.47s\tremaining: 20.8s\n",
            "208:\tlearn: 0.4180592\ttotal: 5.49s\tremaining: 20.8s\n",
            "209:\tlearn: 0.4178009\ttotal: 5.52s\tremaining: 20.8s\n",
            "210:\tlearn: 0.4175352\ttotal: 5.54s\tremaining: 20.7s\n",
            "211:\tlearn: 0.4173894\ttotal: 5.57s\tremaining: 20.7s\n",
            "212:\tlearn: 0.4171167\ttotal: 5.59s\tremaining: 20.7s\n",
            "213:\tlearn: 0.4168910\ttotal: 5.62s\tremaining: 20.6s\n",
            "214:\tlearn: 0.4167256\ttotal: 5.65s\tremaining: 20.6s\n",
            "215:\tlearn: 0.4164336\ttotal: 5.67s\tremaining: 20.6s\n",
            "216:\tlearn: 0.4162183\ttotal: 5.7s\tremaining: 20.6s\n",
            "217:\tlearn: 0.4159957\ttotal: 5.73s\tremaining: 20.5s\n",
            "218:\tlearn: 0.4158120\ttotal: 5.75s\tremaining: 20.5s\n",
            "219:\tlearn: 0.4156482\ttotal: 5.78s\tremaining: 20.5s\n",
            "220:\tlearn: 0.4154007\ttotal: 5.81s\tremaining: 20.5s\n",
            "221:\tlearn: 0.4150862\ttotal: 5.83s\tremaining: 20.4s\n",
            "222:\tlearn: 0.4148285\ttotal: 5.86s\tremaining: 20.4s\n",
            "223:\tlearn: 0.4145995\ttotal: 5.88s\tremaining: 20.4s\n",
            "224:\tlearn: 0.4144014\ttotal: 5.91s\tremaining: 20.4s\n",
            "225:\tlearn: 0.4141120\ttotal: 5.94s\tremaining: 20.3s\n",
            "226:\tlearn: 0.4139599\ttotal: 5.96s\tremaining: 20.3s\n",
            "227:\tlearn: 0.4137640\ttotal: 5.99s\tremaining: 20.3s\n",
            "228:\tlearn: 0.4134776\ttotal: 6.01s\tremaining: 20.2s\n",
            "229:\tlearn: 0.4131951\ttotal: 6.04s\tremaining: 20.2s\n",
            "230:\tlearn: 0.4129844\ttotal: 6.07s\tremaining: 20.2s\n",
            "231:\tlearn: 0.4128421\ttotal: 6.09s\tremaining: 20.2s\n",
            "232:\tlearn: 0.4126776\ttotal: 6.12s\tremaining: 20.1s\n",
            "233:\tlearn: 0.4125478\ttotal: 6.14s\tremaining: 20.1s\n",
            "234:\tlearn: 0.4123321\ttotal: 6.17s\tremaining: 20.1s\n",
            "235:\tlearn: 0.4121889\ttotal: 6.19s\tremaining: 20.1s\n",
            "236:\tlearn: 0.4119277\ttotal: 6.22s\tremaining: 20s\n",
            "237:\tlearn: 0.4116435\ttotal: 6.24s\tremaining: 20s\n",
            "238:\tlearn: 0.4113785\ttotal: 6.26s\tremaining: 19.9s\n",
            "239:\tlearn: 0.4112198\ttotal: 6.29s\tremaining: 19.9s\n",
            "240:\tlearn: 0.4110024\ttotal: 6.31s\tremaining: 19.9s\n",
            "241:\tlearn: 0.4108304\ttotal: 6.35s\tremaining: 19.9s\n",
            "242:\tlearn: 0.4106463\ttotal: 6.39s\tremaining: 19.9s\n",
            "243:\tlearn: 0.4105074\ttotal: 6.42s\tremaining: 19.9s\n",
            "244:\tlearn: 0.4104464\ttotal: 6.45s\tremaining: 19.9s\n",
            "245:\tlearn: 0.4102510\ttotal: 6.47s\tremaining: 19.8s\n",
            "246:\tlearn: 0.4100607\ttotal: 6.49s\tremaining: 19.8s\n",
            "247:\tlearn: 0.4098850\ttotal: 6.52s\tremaining: 19.8s\n",
            "248:\tlearn: 0.4096327\ttotal: 6.54s\tremaining: 19.7s\n",
            "249:\tlearn: 0.4093888\ttotal: 6.58s\tremaining: 19.7s\n",
            "250:\tlearn: 0.4091997\ttotal: 6.6s\tremaining: 19.7s\n",
            "251:\tlearn: 0.4089575\ttotal: 6.63s\tremaining: 19.7s\n",
            "252:\tlearn: 0.4087792\ttotal: 6.65s\tremaining: 19.6s\n",
            "253:\tlearn: 0.4085182\ttotal: 6.68s\tremaining: 19.6s\n",
            "254:\tlearn: 0.4082701\ttotal: 6.71s\tremaining: 19.6s\n",
            "255:\tlearn: 0.4080886\ttotal: 6.73s\tremaining: 19.6s\n",
            "256:\tlearn: 0.4078951\ttotal: 6.75s\tremaining: 19.5s\n",
            "257:\tlearn: 0.4076857\ttotal: 6.78s\tremaining: 19.5s\n",
            "258:\tlearn: 0.4074646\ttotal: 6.81s\tremaining: 19.5s\n",
            "259:\tlearn: 0.4072948\ttotal: 6.83s\tremaining: 19.5s\n",
            "260:\tlearn: 0.4070066\ttotal: 6.86s\tremaining: 19.4s\n",
            "261:\tlearn: 0.4067930\ttotal: 6.88s\tremaining: 19.4s\n",
            "262:\tlearn: 0.4065953\ttotal: 6.91s\tremaining: 19.4s\n",
            "263:\tlearn: 0.4064146\ttotal: 6.94s\tremaining: 19.3s\n",
            "264:\tlearn: 0.4062364\ttotal: 6.96s\tremaining: 19.3s\n",
            "265:\tlearn: 0.4060204\ttotal: 6.99s\tremaining: 19.3s\n",
            "266:\tlearn: 0.4057636\ttotal: 7.02s\tremaining: 19.3s\n",
            "267:\tlearn: 0.4056166\ttotal: 7.04s\tremaining: 19.2s\n",
            "268:\tlearn: 0.4054262\ttotal: 7.07s\tremaining: 19.2s\n",
            "269:\tlearn: 0.4052053\ttotal: 7.09s\tremaining: 19.2s\n",
            "270:\tlearn: 0.4049939\ttotal: 7.12s\tremaining: 19.1s\n",
            "271:\tlearn: 0.4047476\ttotal: 7.14s\tremaining: 19.1s\n",
            "272:\tlearn: 0.4045333\ttotal: 7.17s\tremaining: 19.1s\n",
            "273:\tlearn: 0.4043989\ttotal: 7.19s\tremaining: 19.1s\n",
            "274:\tlearn: 0.4042010\ttotal: 7.22s\tremaining: 19s\n",
            "275:\tlearn: 0.4040598\ttotal: 7.24s\tremaining: 19s\n",
            "276:\tlearn: 0.4039125\ttotal: 7.27s\tremaining: 19s\n",
            "277:\tlearn: 0.4037150\ttotal: 7.29s\tremaining: 18.9s\n",
            "278:\tlearn: 0.4035204\ttotal: 7.32s\tremaining: 18.9s\n",
            "279:\tlearn: 0.4012249\ttotal: 7.34s\tremaining: 18.9s\n",
            "280:\tlearn: 0.4010522\ttotal: 7.37s\tremaining: 18.9s\n",
            "281:\tlearn: 0.4008023\ttotal: 7.41s\tremaining: 18.9s\n",
            "282:\tlearn: 0.4005666\ttotal: 7.44s\tremaining: 18.9s\n",
            "283:\tlearn: 0.4003456\ttotal: 7.46s\tremaining: 18.8s\n",
            "284:\tlearn: 0.4001474\ttotal: 7.49s\tremaining: 18.8s\n",
            "285:\tlearn: 0.3998547\ttotal: 7.52s\tremaining: 18.8s\n",
            "286:\tlearn: 0.3996610\ttotal: 7.54s\tremaining: 18.7s\n",
            "287:\tlearn: 0.3994438\ttotal: 7.56s\tremaining: 18.7s\n",
            "288:\tlearn: 0.3992228\ttotal: 7.59s\tremaining: 18.7s\n",
            "289:\tlearn: 0.3989895\ttotal: 7.62s\tremaining: 18.7s\n",
            "290:\tlearn: 0.3988039\ttotal: 7.65s\tremaining: 18.6s\n",
            "291:\tlearn: 0.3985485\ttotal: 7.67s\tremaining: 18.6s\n",
            "292:\tlearn: 0.3983234\ttotal: 7.7s\tremaining: 18.6s\n",
            "293:\tlearn: 0.3980582\ttotal: 7.72s\tremaining: 18.5s\n",
            "294:\tlearn: 0.3978577\ttotal: 7.75s\tremaining: 18.5s\n",
            "295:\tlearn: 0.3976584\ttotal: 7.77s\tremaining: 18.5s\n",
            "296:\tlearn: 0.3974224\ttotal: 7.8s\tremaining: 18.5s\n",
            "297:\tlearn: 0.3971884\ttotal: 7.83s\tremaining: 18.4s\n",
            "298:\tlearn: 0.3970594\ttotal: 7.85s\tremaining: 18.4s\n",
            "299:\tlearn: 0.3968819\ttotal: 7.88s\tremaining: 18.4s\n",
            "300:\tlearn: 0.3947648\ttotal: 7.9s\tremaining: 18.4s\n",
            "301:\tlearn: 0.3945785\ttotal: 7.93s\tremaining: 18.3s\n",
            "302:\tlearn: 0.3943793\ttotal: 7.95s\tremaining: 18.3s\n",
            "303:\tlearn: 0.3941926\ttotal: 7.97s\tremaining: 18.3s\n",
            "304:\tlearn: 0.3940224\ttotal: 8s\tremaining: 18.2s\n",
            "305:\tlearn: 0.3937935\ttotal: 8.03s\tremaining: 18.2s\n",
            "306:\tlearn: 0.3934158\ttotal: 8.06s\tremaining: 18.2s\n",
            "307:\tlearn: 0.3932450\ttotal: 8.08s\tremaining: 18.2s\n",
            "308:\tlearn: 0.3931000\ttotal: 8.11s\tremaining: 18.1s\n",
            "309:\tlearn: 0.3929190\ttotal: 8.13s\tremaining: 18.1s\n",
            "310:\tlearn: 0.3927026\ttotal: 8.16s\tremaining: 18.1s\n",
            "311:\tlearn: 0.3925689\ttotal: 8.2s\tremaining: 18.1s\n",
            "312:\tlearn: 0.3924080\ttotal: 8.22s\tremaining: 18s\n",
            "313:\tlearn: 0.3921865\ttotal: 8.24s\tremaining: 18s\n",
            "314:\tlearn: 0.3920029\ttotal: 8.29s\tremaining: 18s\n",
            "315:\tlearn: 0.3918062\ttotal: 8.32s\tremaining: 18s\n",
            "316:\tlearn: 0.3916467\ttotal: 8.35s\tremaining: 18s\n",
            "317:\tlearn: 0.3914515\ttotal: 8.37s\tremaining: 17.9s\n",
            "318:\tlearn: 0.3911797\ttotal: 8.4s\tremaining: 17.9s\n",
            "319:\tlearn: 0.3910289\ttotal: 8.44s\tremaining: 17.9s\n",
            "320:\tlearn: 0.3908338\ttotal: 8.46s\tremaining: 17.9s\n",
            "321:\tlearn: 0.3906853\ttotal: 8.49s\tremaining: 17.9s\n",
            "322:\tlearn: 0.3905253\ttotal: 8.52s\tremaining: 17.8s\n",
            "323:\tlearn: 0.3903467\ttotal: 8.54s\tremaining: 17.8s\n",
            "324:\tlearn: 0.3902028\ttotal: 8.56s\tremaining: 17.8s\n",
            "325:\tlearn: 0.3900088\ttotal: 8.59s\tremaining: 17.8s\n",
            "326:\tlearn: 0.3898222\ttotal: 8.62s\tremaining: 17.7s\n",
            "327:\tlearn: 0.3896611\ttotal: 8.64s\tremaining: 17.7s\n",
            "328:\tlearn: 0.3894764\ttotal: 8.66s\tremaining: 17.7s\n",
            "329:\tlearn: 0.3892838\ttotal: 8.69s\tremaining: 17.6s\n",
            "330:\tlearn: 0.3890818\ttotal: 8.71s\tremaining: 17.6s\n",
            "331:\tlearn: 0.3888613\ttotal: 8.74s\tremaining: 17.6s\n",
            "332:\tlearn: 0.3887124\ttotal: 8.77s\tremaining: 17.6s\n",
            "333:\tlearn: 0.3885382\ttotal: 8.79s\tremaining: 17.5s\n",
            "334:\tlearn: 0.3883460\ttotal: 8.82s\tremaining: 17.5s\n",
            "335:\tlearn: 0.3881914\ttotal: 8.84s\tremaining: 17.5s\n",
            "336:\tlearn: 0.3880177\ttotal: 8.87s\tremaining: 17.5s\n",
            "337:\tlearn: 0.3878406\ttotal: 8.9s\tremaining: 17.4s\n",
            "338:\tlearn: 0.3875936\ttotal: 8.92s\tremaining: 17.4s\n",
            "339:\tlearn: 0.3874345\ttotal: 8.95s\tremaining: 17.4s\n",
            "340:\tlearn: 0.3871938\ttotal: 8.98s\tremaining: 17.4s\n",
            "341:\tlearn: 0.3869688\ttotal: 9s\tremaining: 17.3s\n",
            "342:\tlearn: 0.3868336\ttotal: 9.03s\tremaining: 17.3s\n",
            "343:\tlearn: 0.3866778\ttotal: 9.06s\tremaining: 17.3s\n",
            "344:\tlearn: 0.3864433\ttotal: 9.08s\tremaining: 17.2s\n",
            "345:\tlearn: 0.3862341\ttotal: 9.11s\tremaining: 17.2s\n",
            "346:\tlearn: 0.3860547\ttotal: 9.13s\tremaining: 17.2s\n",
            "347:\tlearn: 0.3857724\ttotal: 9.18s\tremaining: 17.2s\n",
            "348:\tlearn: 0.3855603\ttotal: 9.23s\tremaining: 17.2s\n",
            "349:\tlearn: 0.3853622\ttotal: 9.28s\tremaining: 17.2s\n",
            "350:\tlearn: 0.3851284\ttotal: 9.33s\tremaining: 17.2s\n",
            "351:\tlearn: 0.3849151\ttotal: 9.38s\tremaining: 17.3s\n",
            "352:\tlearn: 0.3846774\ttotal: 9.45s\tremaining: 17.3s\n",
            "353:\tlearn: 0.3845255\ttotal: 9.5s\tremaining: 17.3s\n",
            "354:\tlearn: 0.3843627\ttotal: 9.54s\tremaining: 17.3s\n",
            "355:\tlearn: 0.3841644\ttotal: 9.58s\tremaining: 17.3s\n",
            "356:\tlearn: 0.3839780\ttotal: 9.63s\tremaining: 17.3s\n",
            "357:\tlearn: 0.3837877\ttotal: 9.69s\tremaining: 17.4s\n",
            "358:\tlearn: 0.3836079\ttotal: 9.74s\tremaining: 17.4s\n",
            "359:\tlearn: 0.3834362\ttotal: 9.79s\tremaining: 17.4s\n",
            "360:\tlearn: 0.3831380\ttotal: 9.84s\tremaining: 17.4s\n",
            "361:\tlearn: 0.3830131\ttotal: 9.9s\tremaining: 17.5s\n",
            "362:\tlearn: 0.3827910\ttotal: 9.94s\tremaining: 17.4s\n",
            "363:\tlearn: 0.3825868\ttotal: 9.98s\tremaining: 17.4s\n",
            "364:\tlearn: 0.3823793\ttotal: 10s\tremaining: 17.5s\n",
            "365:\tlearn: 0.3822627\ttotal: 10.1s\tremaining: 17.5s\n",
            "366:\tlearn: 0.3820762\ttotal: 10.1s\tremaining: 17.5s\n",
            "367:\tlearn: 0.3818982\ttotal: 10.2s\tremaining: 17.5s\n",
            "368:\tlearn: 0.3817177\ttotal: 10.2s\tremaining: 17.5s\n",
            "369:\tlearn: 0.3815218\ttotal: 10.3s\tremaining: 17.5s\n",
            "370:\tlearn: 0.3813617\ttotal: 10.3s\tremaining: 17.5s\n",
            "371:\tlearn: 0.3811501\ttotal: 10.4s\tremaining: 17.5s\n",
            "372:\tlearn: 0.3809746\ttotal: 10.4s\tremaining: 17.5s\n",
            "373:\tlearn: 0.3807837\ttotal: 10.5s\tremaining: 17.5s\n",
            "374:\tlearn: 0.3805027\ttotal: 10.5s\tremaining: 17.5s\n",
            "375:\tlearn: 0.3803254\ttotal: 10.6s\tremaining: 17.6s\n",
            "376:\tlearn: 0.3801495\ttotal: 10.6s\tremaining: 17.6s\n",
            "377:\tlearn: 0.3799926\ttotal: 10.7s\tremaining: 17.6s\n",
            "378:\tlearn: 0.3798017\ttotal: 10.7s\tremaining: 17.6s\n",
            "379:\tlearn: 0.3796875\ttotal: 10.8s\tremaining: 17.6s\n",
            "380:\tlearn: 0.3795311\ttotal: 10.8s\tremaining: 17.6s\n",
            "381:\tlearn: 0.3793899\ttotal: 10.9s\tremaining: 17.6s\n",
            "382:\tlearn: 0.3791703\ttotal: 10.9s\tremaining: 17.6s\n",
            "383:\tlearn: 0.3789897\ttotal: 11s\tremaining: 17.6s\n",
            "384:\tlearn: 0.3787548\ttotal: 11s\tremaining: 17.6s\n",
            "385:\tlearn: 0.3785702\ttotal: 11.1s\tremaining: 17.7s\n",
            "386:\tlearn: 0.3783761\ttotal: 11.2s\tremaining: 17.7s\n",
            "387:\tlearn: 0.3781337\ttotal: 11.2s\tremaining: 17.7s\n",
            "388:\tlearn: 0.3779195\ttotal: 11.3s\tremaining: 17.7s\n",
            "389:\tlearn: 0.3777343\ttotal: 11.3s\tremaining: 17.7s\n",
            "390:\tlearn: 0.3775818\ttotal: 11.4s\tremaining: 17.7s\n",
            "391:\tlearn: 0.3773452\ttotal: 11.4s\tremaining: 17.7s\n",
            "392:\tlearn: 0.3771779\ttotal: 11.5s\tremaining: 17.7s\n",
            "393:\tlearn: 0.3769840\ttotal: 11.5s\tremaining: 17.7s\n",
            "394:\tlearn: 0.3767784\ttotal: 11.6s\tremaining: 17.7s\n",
            "395:\tlearn: 0.3765729\ttotal: 11.6s\tremaining: 17.7s\n",
            "396:\tlearn: 0.3764360\ttotal: 11.7s\tremaining: 17.7s\n",
            "397:\tlearn: 0.3762812\ttotal: 11.7s\tremaining: 17.7s\n",
            "398:\tlearn: 0.3760804\ttotal: 11.8s\tremaining: 17.7s\n",
            "399:\tlearn: 0.3758563\ttotal: 11.8s\tremaining: 17.7s\n",
            "400:\tlearn: 0.3757035\ttotal: 11.9s\tremaining: 17.7s\n",
            "401:\tlearn: 0.3755491\ttotal: 11.9s\tremaining: 17.7s\n",
            "402:\tlearn: 0.3753245\ttotal: 12s\tremaining: 17.7s\n",
            "403:\tlearn: 0.3751415\ttotal: 12s\tremaining: 17.8s\n",
            "404:\tlearn: 0.3749126\ttotal: 12.1s\tremaining: 17.8s\n",
            "405:\tlearn: 0.3747716\ttotal: 12.1s\tremaining: 17.8s\n",
            "406:\tlearn: 0.3746685\ttotal: 12.2s\tremaining: 17.8s\n",
            "407:\tlearn: 0.3744962\ttotal: 12.2s\tremaining: 17.8s\n",
            "408:\tlearn: 0.3742903\ttotal: 12.3s\tremaining: 17.8s\n",
            "409:\tlearn: 0.3740256\ttotal: 12.3s\tremaining: 17.8s\n",
            "410:\tlearn: 0.3738667\ttotal: 12.4s\tremaining: 17.8s\n",
            "411:\tlearn: 0.3737183\ttotal: 12.5s\tremaining: 17.8s\n",
            "412:\tlearn: 0.3735780\ttotal: 12.5s\tremaining: 17.8s\n",
            "413:\tlearn: 0.3734068\ttotal: 12.5s\tremaining: 17.7s\n",
            "414:\tlearn: 0.3731804\ttotal: 12.6s\tremaining: 17.8s\n",
            "415:\tlearn: 0.3729671\ttotal: 12.6s\tremaining: 17.7s\n",
            "416:\tlearn: 0.3727606\ttotal: 12.7s\tremaining: 17.7s\n",
            "417:\tlearn: 0.3726050\ttotal: 12.8s\tremaining: 17.8s\n",
            "418:\tlearn: 0.3724017\ttotal: 12.8s\tremaining: 17.8s\n",
            "419:\tlearn: 0.3722497\ttotal: 12.9s\tremaining: 17.7s\n",
            "420:\tlearn: 0.3721522\ttotal: 12.9s\tremaining: 17.7s\n",
            "421:\tlearn: 0.3719909\ttotal: 13s\tremaining: 17.7s\n",
            "422:\tlearn: 0.3718144\ttotal: 13s\tremaining: 17.7s\n",
            "423:\tlearn: 0.3715452\ttotal: 13s\tremaining: 17.7s\n",
            "424:\tlearn: 0.3713141\ttotal: 13s\tremaining: 17.6s\n",
            "425:\tlearn: 0.3711548\ttotal: 13.1s\tremaining: 17.6s\n",
            "426:\tlearn: 0.3709538\ttotal: 13.1s\tremaining: 17.6s\n",
            "427:\tlearn: 0.3707253\ttotal: 13.1s\tremaining: 17.5s\n",
            "428:\tlearn: 0.3705845\ttotal: 13.1s\tremaining: 17.5s\n",
            "429:\tlearn: 0.3704021\ttotal: 13.2s\tremaining: 17.4s\n",
            "430:\tlearn: 0.3702024\ttotal: 13.2s\tremaining: 17.4s\n",
            "431:\tlearn: 0.3701200\ttotal: 13.2s\tremaining: 17.4s\n",
            "432:\tlearn: 0.3699237\ttotal: 13.2s\tremaining: 17.3s\n",
            "433:\tlearn: 0.3697447\ttotal: 13.3s\tremaining: 17.3s\n",
            "434:\tlearn: 0.3695662\ttotal: 13.3s\tremaining: 17.3s\n",
            "435:\tlearn: 0.3694107\ttotal: 13.3s\tremaining: 17.2s\n",
            "436:\tlearn: 0.3692252\ttotal: 13.3s\tremaining: 17.2s\n",
            "437:\tlearn: 0.3690339\ttotal: 13.4s\tremaining: 17.1s\n",
            "438:\tlearn: 0.3688239\ttotal: 13.4s\tremaining: 17.1s\n",
            "439:\tlearn: 0.3686465\ttotal: 13.4s\tremaining: 17.1s\n",
            "440:\tlearn: 0.3684648\ttotal: 13.4s\tremaining: 17s\n",
            "441:\tlearn: 0.3683693\ttotal: 13.5s\tremaining: 17s\n",
            "442:\tlearn: 0.3681557\ttotal: 13.5s\tremaining: 17s\n",
            "443:\tlearn: 0.3679537\ttotal: 13.5s\tremaining: 16.9s\n",
            "444:\tlearn: 0.3678004\ttotal: 13.5s\tremaining: 16.9s\n",
            "445:\tlearn: 0.3676355\ttotal: 13.6s\tremaining: 16.9s\n",
            "446:\tlearn: 0.3675037\ttotal: 13.6s\tremaining: 16.8s\n",
            "447:\tlearn: 0.3673418\ttotal: 13.6s\tremaining: 16.8s\n",
            "448:\tlearn: 0.3671199\ttotal: 13.7s\tremaining: 16.8s\n",
            "449:\tlearn: 0.3669746\ttotal: 13.7s\tremaining: 16.7s\n",
            "450:\tlearn: 0.3667508\ttotal: 13.7s\tremaining: 16.7s\n",
            "451:\tlearn: 0.3665634\ttotal: 13.7s\tremaining: 16.7s\n",
            "452:\tlearn: 0.3663693\ttotal: 13.8s\tremaining: 16.6s\n",
            "453:\tlearn: 0.3662127\ttotal: 13.8s\tremaining: 16.6s\n",
            "454:\tlearn: 0.3660568\ttotal: 13.8s\tremaining: 16.5s\n",
            "455:\tlearn: 0.3658070\ttotal: 13.8s\tremaining: 16.5s\n",
            "456:\tlearn: 0.3656233\ttotal: 13.9s\tremaining: 16.5s\n",
            "457:\tlearn: 0.3654672\ttotal: 13.9s\tremaining: 16.4s\n",
            "458:\tlearn: 0.3652602\ttotal: 13.9s\tremaining: 16.4s\n",
            "459:\tlearn: 0.3651887\ttotal: 13.9s\tremaining: 16.4s\n",
            "460:\tlearn: 0.3649672\ttotal: 14s\tremaining: 16.3s\n",
            "461:\tlearn: 0.3647590\ttotal: 14s\tremaining: 16.3s\n",
            "462:\tlearn: 0.3646310\ttotal: 14s\tremaining: 16.3s\n",
            "463:\tlearn: 0.3644726\ttotal: 14.1s\tremaining: 16.2s\n",
            "464:\tlearn: 0.3643120\ttotal: 14.1s\tremaining: 16.2s\n",
            "465:\tlearn: 0.3640885\ttotal: 14.1s\tremaining: 16.2s\n",
            "466:\tlearn: 0.3638787\ttotal: 14.1s\tremaining: 16.1s\n",
            "467:\tlearn: 0.3637417\ttotal: 14.2s\tremaining: 16.1s\n",
            "468:\tlearn: 0.3635470\ttotal: 14.2s\tremaining: 16.1s\n",
            "469:\tlearn: 0.3633663\ttotal: 14.2s\tremaining: 16s\n",
            "470:\tlearn: 0.3631688\ttotal: 14.2s\tremaining: 16s\n",
            "471:\tlearn: 0.3629828\ttotal: 14.3s\tremaining: 15.9s\n",
            "472:\tlearn: 0.3628120\ttotal: 14.3s\tremaining: 15.9s\n",
            "473:\tlearn: 0.3625977\ttotal: 14.3s\tremaining: 15.9s\n",
            "474:\tlearn: 0.3624007\ttotal: 14.3s\tremaining: 15.8s\n",
            "475:\tlearn: 0.3622577\ttotal: 14.4s\tremaining: 15.8s\n",
            "476:\tlearn: 0.3620870\ttotal: 14.4s\tremaining: 15.8s\n",
            "477:\tlearn: 0.3619063\ttotal: 14.4s\tremaining: 15.7s\n",
            "478:\tlearn: 0.3617384\ttotal: 14.4s\tremaining: 15.7s\n",
            "479:\tlearn: 0.3616645\ttotal: 14.5s\tremaining: 15.7s\n",
            "480:\tlearn: 0.3614986\ttotal: 14.5s\tremaining: 15.6s\n",
            "481:\tlearn: 0.3613062\ttotal: 14.5s\tremaining: 15.6s\n",
            "482:\tlearn: 0.3611207\ttotal: 14.5s\tremaining: 15.6s\n",
            "483:\tlearn: 0.3609473\ttotal: 14.6s\tremaining: 15.5s\n",
            "484:\tlearn: 0.3607675\ttotal: 14.6s\tremaining: 15.5s\n",
            "485:\tlearn: 0.3605823\ttotal: 14.6s\tremaining: 15.5s\n",
            "486:\tlearn: 0.3604428\ttotal: 14.7s\tremaining: 15.4s\n",
            "487:\tlearn: 0.3602584\ttotal: 14.7s\tremaining: 15.4s\n",
            "488:\tlearn: 0.3600669\ttotal: 14.7s\tremaining: 15.4s\n",
            "489:\tlearn: 0.3598936\ttotal: 14.7s\tremaining: 15.3s\n",
            "490:\tlearn: 0.3596615\ttotal: 14.8s\tremaining: 15.3s\n",
            "491:\tlearn: 0.3595939\ttotal: 14.8s\tremaining: 15.3s\n",
            "492:\tlearn: 0.3594377\ttotal: 14.8s\tremaining: 15.2s\n",
            "493:\tlearn: 0.3592776\ttotal: 14.9s\tremaining: 15.2s\n",
            "494:\tlearn: 0.3591410\ttotal: 14.9s\tremaining: 15.2s\n",
            "495:\tlearn: 0.3589677\ttotal: 14.9s\tremaining: 15.2s\n",
            "496:\tlearn: 0.3588057\ttotal: 15s\tremaining: 15.2s\n",
            "497:\tlearn: 0.3585953\ttotal: 15.1s\tremaining: 15.2s\n",
            "498:\tlearn: 0.3584427\ttotal: 15.1s\tremaining: 15.2s\n",
            "499:\tlearn: 0.3582426\ttotal: 15.1s\tremaining: 15.1s\n",
            "500:\tlearn: 0.3580592\ttotal: 15.2s\tremaining: 15.1s\n",
            "501:\tlearn: 0.3579222\ttotal: 15.2s\tremaining: 15.1s\n",
            "502:\tlearn: 0.3578546\ttotal: 15.2s\tremaining: 15s\n",
            "503:\tlearn: 0.3576753\ttotal: 15.2s\tremaining: 15s\n",
            "504:\tlearn: 0.3574605\ttotal: 15.3s\tremaining: 15s\n",
            "505:\tlearn: 0.3572874\ttotal: 15.3s\tremaining: 14.9s\n",
            "506:\tlearn: 0.3570293\ttotal: 15.3s\tremaining: 14.9s\n",
            "507:\tlearn: 0.3568548\ttotal: 15.3s\tremaining: 14.9s\n",
            "508:\tlearn: 0.3566346\ttotal: 15.4s\tremaining: 14.8s\n",
            "509:\tlearn: 0.3564039\ttotal: 15.4s\tremaining: 14.8s\n",
            "510:\tlearn: 0.3562327\ttotal: 15.5s\tremaining: 14.8s\n",
            "511:\tlearn: 0.3560761\ttotal: 15.5s\tremaining: 14.8s\n",
            "512:\tlearn: 0.3559282\ttotal: 15.6s\tremaining: 14.8s\n",
            "513:\tlearn: 0.3557965\ttotal: 15.6s\tremaining: 14.8s\n",
            "514:\tlearn: 0.3556223\ttotal: 15.7s\tremaining: 14.7s\n",
            "515:\tlearn: 0.3554560\ttotal: 15.7s\tremaining: 14.7s\n",
            "516:\tlearn: 0.3553092\ttotal: 15.8s\tremaining: 14.7s\n",
            "517:\tlearn: 0.3551406\ttotal: 15.8s\tremaining: 14.7s\n",
            "518:\tlearn: 0.3549719\ttotal: 15.9s\tremaining: 14.7s\n",
            "519:\tlearn: 0.3548094\ttotal: 15.9s\tremaining: 14.7s\n",
            "520:\tlearn: 0.3546371\ttotal: 15.9s\tremaining: 14.7s\n",
            "521:\tlearn: 0.3544509\ttotal: 16s\tremaining: 14.6s\n",
            "522:\tlearn: 0.3542890\ttotal: 16s\tremaining: 14.6s\n",
            "523:\tlearn: 0.3542257\ttotal: 16s\tremaining: 14.5s\n",
            "524:\tlearn: 0.3540189\ttotal: 16s\tremaining: 14.5s\n",
            "525:\tlearn: 0.3538740\ttotal: 16.1s\tremaining: 14.5s\n",
            "526:\tlearn: 0.3536993\ttotal: 16.1s\tremaining: 14.4s\n",
            "527:\tlearn: 0.3534505\ttotal: 16.1s\tremaining: 14.4s\n",
            "528:\tlearn: 0.3532810\ttotal: 16.2s\tremaining: 14.4s\n",
            "529:\tlearn: 0.3530949\ttotal: 16.2s\tremaining: 14.4s\n",
            "530:\tlearn: 0.3529342\ttotal: 16.2s\tremaining: 14.3s\n",
            "531:\tlearn: 0.3527981\ttotal: 16.3s\tremaining: 14.3s\n",
            "532:\tlearn: 0.3526213\ttotal: 16.3s\tremaining: 14.3s\n",
            "533:\tlearn: 0.3524821\ttotal: 16.3s\tremaining: 14.2s\n",
            "534:\tlearn: 0.3522700\ttotal: 16.3s\tremaining: 14.2s\n",
            "535:\tlearn: 0.3521192\ttotal: 16.4s\tremaining: 14.2s\n",
            "536:\tlearn: 0.3519295\ttotal: 16.4s\tremaining: 14.1s\n",
            "537:\tlearn: 0.3518543\ttotal: 16.4s\tremaining: 14.1s\n",
            "538:\tlearn: 0.3516818\ttotal: 16.5s\tremaining: 14.1s\n",
            "539:\tlearn: 0.3515438\ttotal: 16.5s\tremaining: 14.1s\n",
            "540:\tlearn: 0.3513877\ttotal: 16.6s\tremaining: 14s\n",
            "541:\tlearn: 0.3512228\ttotal: 16.6s\tremaining: 14s\n",
            "542:\tlearn: 0.3510903\ttotal: 16.6s\tremaining: 14s\n",
            "543:\tlearn: 0.3509436\ttotal: 16.6s\tremaining: 14s\n",
            "544:\tlearn: 0.3507795\ttotal: 16.7s\tremaining: 13.9s\n",
            "545:\tlearn: 0.3506556\ttotal: 16.7s\tremaining: 13.9s\n",
            "546:\tlearn: 0.3504972\ttotal: 16.7s\tremaining: 13.9s\n",
            "547:\tlearn: 0.3503461\ttotal: 16.8s\tremaining: 13.8s\n",
            "548:\tlearn: 0.3501329\ttotal: 16.8s\tremaining: 13.8s\n",
            "549:\tlearn: 0.3499861\ttotal: 16.9s\tremaining: 13.8s\n",
            "550:\tlearn: 0.3498369\ttotal: 16.9s\tremaining: 13.8s\n",
            "551:\tlearn: 0.3496757\ttotal: 16.9s\tremaining: 13.7s\n",
            "552:\tlearn: 0.3494871\ttotal: 16.9s\tremaining: 13.7s\n",
            "553:\tlearn: 0.3493344\ttotal: 17s\tremaining: 13.7s\n",
            "554:\tlearn: 0.3491703\ttotal: 17s\tremaining: 13.6s\n",
            "555:\tlearn: 0.3491118\ttotal: 17s\tremaining: 13.6s\n",
            "556:\tlearn: 0.3489570\ttotal: 17s\tremaining: 13.6s\n",
            "557:\tlearn: 0.3487721\ttotal: 17.1s\tremaining: 13.5s\n",
            "558:\tlearn: 0.3486456\ttotal: 17.1s\tremaining: 13.5s\n",
            "559:\tlearn: 0.3485574\ttotal: 17.2s\tremaining: 13.5s\n",
            "560:\tlearn: 0.3483692\ttotal: 17.2s\tremaining: 13.5s\n",
            "561:\tlearn: 0.3482092\ttotal: 17.3s\tremaining: 13.5s\n",
            "562:\tlearn: 0.3480412\ttotal: 17.3s\tremaining: 13.4s\n",
            "563:\tlearn: 0.3478021\ttotal: 17.4s\tremaining: 13.4s\n",
            "564:\tlearn: 0.3475476\ttotal: 17.4s\tremaining: 13.4s\n",
            "565:\tlearn: 0.3474114\ttotal: 17.5s\tremaining: 13.4s\n",
            "566:\tlearn: 0.3472316\ttotal: 17.6s\tremaining: 13.4s\n",
            "567:\tlearn: 0.3470528\ttotal: 17.6s\tremaining: 13.4s\n",
            "568:\tlearn: 0.3468855\ttotal: 17.7s\tremaining: 13.4s\n",
            "569:\tlearn: 0.3468256\ttotal: 17.7s\tremaining: 13.4s\n",
            "570:\tlearn: 0.3467191\ttotal: 17.8s\tremaining: 13.3s\n",
            "571:\tlearn: 0.3465668\ttotal: 17.8s\tremaining: 13.3s\n",
            "572:\tlearn: 0.3464427\ttotal: 17.9s\tremaining: 13.3s\n",
            "573:\tlearn: 0.3463448\ttotal: 17.9s\tremaining: 13.3s\n",
            "574:\tlearn: 0.3462121\ttotal: 18s\tremaining: 13.3s\n",
            "575:\tlearn: 0.3460371\ttotal: 18.1s\tremaining: 13.3s\n",
            "576:\tlearn: 0.3458492\ttotal: 18.1s\tremaining: 13.3s\n",
            "577:\tlearn: 0.3457196\ttotal: 18.1s\tremaining: 13.2s\n",
            "578:\tlearn: 0.3455755\ttotal: 18.2s\tremaining: 13.2s\n",
            "579:\tlearn: 0.3454296\ttotal: 18.2s\tremaining: 13.2s\n",
            "580:\tlearn: 0.3452745\ttotal: 18.3s\tremaining: 13.2s\n",
            "581:\tlearn: 0.3450971\ttotal: 18.3s\tremaining: 13.2s\n",
            "582:\tlearn: 0.3449358\ttotal: 18.4s\tremaining: 13.2s\n",
            "583:\tlearn: 0.3447602\ttotal: 18.5s\tremaining: 13.1s\n",
            "584:\tlearn: 0.3446034\ttotal: 18.5s\tremaining: 13.1s\n",
            "585:\tlearn: 0.3443654\ttotal: 18.6s\tremaining: 13.1s\n",
            "586:\tlearn: 0.3442313\ttotal: 18.6s\tremaining: 13.1s\n",
            "587:\tlearn: 0.3441032\ttotal: 18.7s\tremaining: 13.1s\n",
            "588:\tlearn: 0.3439235\ttotal: 18.7s\tremaining: 13.1s\n",
            "589:\tlearn: 0.3437690\ttotal: 18.8s\tremaining: 13s\n",
            "590:\tlearn: 0.3436175\ttotal: 18.8s\tremaining: 13s\n",
            "591:\tlearn: 0.3434377\ttotal: 18.8s\tremaining: 13s\n",
            "592:\tlearn: 0.3432680\ttotal: 18.9s\tremaining: 13s\n",
            "593:\tlearn: 0.3431184\ttotal: 19s\tremaining: 13s\n",
            "594:\tlearn: 0.3429228\ttotal: 19s\tremaining: 12.9s\n",
            "595:\tlearn: 0.3427421\ttotal: 19.1s\tremaining: 12.9s\n",
            "596:\tlearn: 0.3425958\ttotal: 19.1s\tremaining: 12.9s\n",
            "597:\tlearn: 0.3423574\ttotal: 19.2s\tremaining: 12.9s\n",
            "598:\tlearn: 0.3422743\ttotal: 19.2s\tremaining: 12.9s\n",
            "599:\tlearn: 0.3420714\ttotal: 19.3s\tremaining: 12.9s\n",
            "600:\tlearn: 0.3419425\ttotal: 19.3s\tremaining: 12.8s\n",
            "601:\tlearn: 0.3418143\ttotal: 19.4s\tremaining: 12.8s\n",
            "602:\tlearn: 0.3417077\ttotal: 19.4s\tremaining: 12.8s\n",
            "603:\tlearn: 0.3414733\ttotal: 19.5s\tremaining: 12.8s\n",
            "604:\tlearn: 0.3413456\ttotal: 19.5s\tremaining: 12.7s\n",
            "605:\tlearn: 0.3411616\ttotal: 19.6s\tremaining: 12.7s\n",
            "606:\tlearn: 0.3409860\ttotal: 19.6s\tremaining: 12.7s\n",
            "607:\tlearn: 0.3408458\ttotal: 19.7s\tremaining: 12.7s\n",
            "608:\tlearn: 0.3406972\ttotal: 19.8s\tremaining: 12.7s\n",
            "609:\tlearn: 0.3405129\ttotal: 19.8s\tremaining: 12.7s\n",
            "610:\tlearn: 0.3403333\ttotal: 19.8s\tremaining: 12.6s\n",
            "611:\tlearn: 0.3402032\ttotal: 19.9s\tremaining: 12.6s\n",
            "612:\tlearn: 0.3401036\ttotal: 19.9s\tremaining: 12.6s\n",
            "613:\tlearn: 0.3400406\ttotal: 20s\tremaining: 12.5s\n",
            "614:\tlearn: 0.3399018\ttotal: 20s\tremaining: 12.5s\n",
            "615:\tlearn: 0.3397524\ttotal: 20.1s\tremaining: 12.5s\n",
            "616:\tlearn: 0.3396343\ttotal: 20.1s\tremaining: 12.5s\n",
            "617:\tlearn: 0.3395293\ttotal: 20.2s\tremaining: 12.5s\n",
            "618:\tlearn: 0.3394029\ttotal: 20.2s\tremaining: 12.4s\n",
            "619:\tlearn: 0.3392642\ttotal: 20.2s\tremaining: 12.4s\n",
            "620:\tlearn: 0.3391418\ttotal: 20.3s\tremaining: 12.4s\n",
            "621:\tlearn: 0.3390177\ttotal: 20.3s\tremaining: 12.4s\n",
            "622:\tlearn: 0.3388525\ttotal: 20.4s\tremaining: 12.3s\n",
            "623:\tlearn: 0.3386776\ttotal: 20.5s\tremaining: 12.3s\n",
            "624:\tlearn: 0.3385629\ttotal: 20.6s\tremaining: 12.3s\n",
            "625:\tlearn: 0.3385108\ttotal: 20.7s\tremaining: 12.3s\n",
            "626:\tlearn: 0.3383048\ttotal: 20.8s\tremaining: 12.3s\n",
            "627:\tlearn: 0.3381429\ttotal: 20.8s\tremaining: 12.3s\n",
            "628:\tlearn: 0.3379509\ttotal: 20.9s\tremaining: 12.3s\n",
            "629:\tlearn: 0.3377877\ttotal: 21s\tremaining: 12.3s\n",
            "630:\tlearn: 0.3376399\ttotal: 21s\tremaining: 12.3s\n",
            "631:\tlearn: 0.3374864\ttotal: 21.1s\tremaining: 12.3s\n",
            "632:\tlearn: 0.3373104\ttotal: 21.1s\tremaining: 12.3s\n",
            "633:\tlearn: 0.3371721\ttotal: 21.2s\tremaining: 12.2s\n",
            "634:\tlearn: 0.3370293\ttotal: 21.3s\tremaining: 12.2s\n",
            "635:\tlearn: 0.3368919\ttotal: 21.3s\tremaining: 12.2s\n",
            "636:\tlearn: 0.3368494\ttotal: 21.4s\tremaining: 12.2s\n",
            "637:\tlearn: 0.3366992\ttotal: 21.4s\tremaining: 12.2s\n",
            "638:\tlearn: 0.3365805\ttotal: 21.5s\tremaining: 12.1s\n",
            "639:\tlearn: 0.3364404\ttotal: 21.5s\tremaining: 12.1s\n",
            "640:\tlearn: 0.3363128\ttotal: 21.6s\tremaining: 12.1s\n",
            "641:\tlearn: 0.3361626\ttotal: 21.6s\tremaining: 12s\n",
            "642:\tlearn: 0.3360211\ttotal: 21.7s\tremaining: 12s\n",
            "643:\tlearn: 0.3358863\ttotal: 21.7s\tremaining: 12s\n",
            "644:\tlearn: 0.3357848\ttotal: 21.8s\tremaining: 12s\n",
            "645:\tlearn: 0.3356653\ttotal: 21.8s\tremaining: 12s\n",
            "646:\tlearn: 0.3354908\ttotal: 21.9s\tremaining: 11.9s\n",
            "647:\tlearn: 0.3353713\ttotal: 21.9s\tremaining: 11.9s\n",
            "648:\tlearn: 0.3352548\ttotal: 22s\tremaining: 11.9s\n",
            "649:\tlearn: 0.3351095\ttotal: 22s\tremaining: 11.9s\n",
            "650:\tlearn: 0.3349631\ttotal: 22.1s\tremaining: 11.8s\n",
            "651:\tlearn: 0.3347818\ttotal: 22.1s\tremaining: 11.8s\n",
            "652:\tlearn: 0.3346465\ttotal: 22.2s\tremaining: 11.8s\n",
            "653:\tlearn: 0.3344870\ttotal: 22.2s\tremaining: 11.7s\n",
            "654:\tlearn: 0.3343584\ttotal: 22.2s\tremaining: 11.7s\n",
            "655:\tlearn: 0.3341898\ttotal: 22.3s\tremaining: 11.7s\n",
            "656:\tlearn: 0.3340560\ttotal: 22.3s\tremaining: 11.6s\n",
            "657:\tlearn: 0.3339009\ttotal: 22.3s\tremaining: 11.6s\n",
            "658:\tlearn: 0.3337841\ttotal: 22.3s\tremaining: 11.6s\n",
            "659:\tlearn: 0.3336284\ttotal: 22.4s\tremaining: 11.5s\n",
            "660:\tlearn: 0.3334642\ttotal: 22.4s\tremaining: 11.5s\n",
            "661:\tlearn: 0.3333307\ttotal: 22.4s\tremaining: 11.4s\n",
            "662:\tlearn: 0.3331648\ttotal: 22.4s\tremaining: 11.4s\n",
            "663:\tlearn: 0.3330523\ttotal: 22.5s\tremaining: 11.4s\n",
            "664:\tlearn: 0.3329146\ttotal: 22.5s\tremaining: 11.3s\n",
            "665:\tlearn: 0.3327684\ttotal: 22.5s\tremaining: 11.3s\n",
            "666:\tlearn: 0.3326404\ttotal: 22.5s\tremaining: 11.2s\n",
            "667:\tlearn: 0.3325962\ttotal: 22.6s\tremaining: 11.2s\n",
            "668:\tlearn: 0.3324641\ttotal: 22.6s\tremaining: 11.2s\n",
            "669:\tlearn: 0.3323583\ttotal: 22.6s\tremaining: 11.1s\n",
            "670:\tlearn: 0.3322343\ttotal: 22.6s\tremaining: 11.1s\n",
            "671:\tlearn: 0.3320453\ttotal: 22.7s\tremaining: 11.1s\n",
            "672:\tlearn: 0.3319040\ttotal: 22.7s\tremaining: 11s\n",
            "673:\tlearn: 0.3317582\ttotal: 22.7s\tremaining: 11s\n",
            "674:\tlearn: 0.3316309\ttotal: 22.7s\tremaining: 10.9s\n",
            "675:\tlearn: 0.3315049\ttotal: 22.8s\tremaining: 10.9s\n",
            "676:\tlearn: 0.3313605\ttotal: 22.8s\tremaining: 10.9s\n",
            "677:\tlearn: 0.3312137\ttotal: 22.8s\tremaining: 10.8s\n",
            "678:\tlearn: 0.3310856\ttotal: 22.9s\tremaining: 10.8s\n",
            "679:\tlearn: 0.3309386\ttotal: 22.9s\tremaining: 10.8s\n",
            "680:\tlearn: 0.3307780\ttotal: 23s\tremaining: 10.8s\n",
            "681:\tlearn: 0.3306559\ttotal: 23s\tremaining: 10.7s\n",
            "682:\tlearn: 0.3305584\ttotal: 23.1s\tremaining: 10.7s\n",
            "683:\tlearn: 0.3304159\ttotal: 23.1s\tremaining: 10.7s\n",
            "684:\tlearn: 0.3302694\ttotal: 23.2s\tremaining: 10.6s\n",
            "685:\tlearn: 0.3301552\ttotal: 23.2s\tremaining: 10.6s\n",
            "686:\tlearn: 0.3300388\ttotal: 23.3s\tremaining: 10.6s\n",
            "687:\tlearn: 0.3298216\ttotal: 23.3s\tremaining: 10.6s\n",
            "688:\tlearn: 0.3296983\ttotal: 23.4s\tremaining: 10.5s\n",
            "689:\tlearn: 0.3295490\ttotal: 23.4s\tremaining: 10.5s\n",
            "690:\tlearn: 0.3293170\ttotal: 23.5s\tremaining: 10.5s\n",
            "691:\tlearn: 0.3291269\ttotal: 23.5s\tremaining: 10.5s\n",
            "692:\tlearn: 0.3290171\ttotal: 23.5s\tremaining: 10.4s\n",
            "693:\tlearn: 0.3289207\ttotal: 23.6s\tremaining: 10.4s\n",
            "694:\tlearn: 0.3287819\ttotal: 23.6s\tremaining: 10.4s\n",
            "695:\tlearn: 0.3286258\ttotal: 23.7s\tremaining: 10.3s\n",
            "696:\tlearn: 0.3284278\ttotal: 23.7s\tremaining: 10.3s\n",
            "697:\tlearn: 0.3282732\ttotal: 23.8s\tremaining: 10.3s\n",
            "698:\tlearn: 0.3282375\ttotal: 23.8s\tremaining: 10.3s\n",
            "699:\tlearn: 0.3280625\ttotal: 23.9s\tremaining: 10.2s\n",
            "700:\tlearn: 0.3279279\ttotal: 23.9s\tremaining: 10.2s\n",
            "701:\tlearn: 0.3277876\ttotal: 24s\tremaining: 10.2s\n",
            "702:\tlearn: 0.3276610\ttotal: 24.1s\tremaining: 10.2s\n",
            "703:\tlearn: 0.3275472\ttotal: 24.1s\tremaining: 10.1s\n",
            "704:\tlearn: 0.3274414\ttotal: 24.2s\tremaining: 10.1s\n",
            "705:\tlearn: 0.3272672\ttotal: 24.2s\tremaining: 10.1s\n",
            "706:\tlearn: 0.3272473\ttotal: 24.2s\tremaining: 10s\n",
            "707:\tlearn: 0.3271162\ttotal: 24.3s\tremaining: 10s\n",
            "708:\tlearn: 0.3269872\ttotal: 24.3s\tremaining: 9.98s\n",
            "709:\tlearn: 0.3268740\ttotal: 24.4s\tremaining: 9.95s\n",
            "710:\tlearn: 0.3267674\ttotal: 24.4s\tremaining: 9.92s\n",
            "711:\tlearn: 0.3266561\ttotal: 24.5s\tremaining: 9.89s\n",
            "712:\tlearn: 0.3264876\ttotal: 24.5s\tremaining: 9.86s\n",
            "713:\tlearn: 0.3263565\ttotal: 24.5s\tremaining: 9.83s\n",
            "714:\tlearn: 0.3262168\ttotal: 24.6s\tremaining: 9.8s\n",
            "715:\tlearn: 0.3260232\ttotal: 24.6s\tremaining: 9.78s\n",
            "716:\tlearn: 0.3259313\ttotal: 24.7s\tremaining: 9.75s\n",
            "717:\tlearn: 0.3258196\ttotal: 24.8s\tremaining: 9.72s\n",
            "718:\tlearn: 0.3258073\ttotal: 24.8s\tremaining: 9.69s\n",
            "719:\tlearn: 0.3256344\ttotal: 24.9s\tremaining: 9.66s\n",
            "720:\tlearn: 0.3255173\ttotal: 24.9s\tremaining: 9.64s\n",
            "721:\tlearn: 0.3254417\ttotal: 25s\tremaining: 9.61s\n",
            "722:\tlearn: 0.3253604\ttotal: 25s\tremaining: 9.58s\n",
            "723:\tlearn: 0.3251718\ttotal: 25.1s\tremaining: 9.55s\n",
            "724:\tlearn: 0.3250929\ttotal: 25.1s\tremaining: 9.52s\n",
            "725:\tlearn: 0.3249827\ttotal: 25.2s\tremaining: 9.49s\n",
            "726:\tlearn: 0.3249637\ttotal: 25.2s\tremaining: 9.46s\n",
            "727:\tlearn: 0.3248353\ttotal: 25.3s\tremaining: 9.44s\n",
            "728:\tlearn: 0.3246307\ttotal: 25.3s\tremaining: 9.41s\n",
            "729:\tlearn: 0.3244934\ttotal: 25.4s\tremaining: 9.38s\n",
            "730:\tlearn: 0.3243762\ttotal: 25.4s\tremaining: 9.35s\n",
            "731:\tlearn: 0.3241718\ttotal: 25.5s\tremaining: 9.32s\n",
            "732:\tlearn: 0.3240630\ttotal: 25.5s\tremaining: 9.29s\n",
            "733:\tlearn: 0.3238600\ttotal: 25.5s\tremaining: 9.26s\n",
            "734:\tlearn: 0.3237301\ttotal: 25.6s\tremaining: 9.23s\n",
            "735:\tlearn: 0.3235761\ttotal: 25.7s\tremaining: 9.2s\n",
            "736:\tlearn: 0.3233640\ttotal: 25.7s\tremaining: 9.17s\n",
            "737:\tlearn: 0.3231859\ttotal: 25.8s\tremaining: 9.14s\n",
            "738:\tlearn: 0.3230815\ttotal: 25.8s\tremaining: 9.12s\n",
            "739:\tlearn: 0.3229172\ttotal: 25.9s\tremaining: 9.09s\n",
            "740:\tlearn: 0.3227871\ttotal: 25.9s\tremaining: 9.05s\n",
            "741:\tlearn: 0.3226727\ttotal: 26s\tremaining: 9.03s\n",
            "742:\tlearn: 0.3226001\ttotal: 26s\tremaining: 9s\n",
            "743:\tlearn: 0.3225123\ttotal: 26s\tremaining: 8.96s\n",
            "744:\tlearn: 0.3223601\ttotal: 26.1s\tremaining: 8.94s\n",
            "745:\tlearn: 0.3222262\ttotal: 26.2s\tremaining: 8.91s\n",
            "746:\tlearn: 0.3221530\ttotal: 26.2s\tremaining: 8.88s\n",
            "747:\tlearn: 0.3219902\ttotal: 26.3s\tremaining: 8.85s\n",
            "748:\tlearn: 0.3218663\ttotal: 26.3s\tremaining: 8.82s\n",
            "749:\tlearn: 0.3217446\ttotal: 26.4s\tremaining: 8.79s\n",
            "750:\tlearn: 0.3216177\ttotal: 26.4s\tremaining: 8.76s\n",
            "751:\tlearn: 0.3214686\ttotal: 26.5s\tremaining: 8.73s\n",
            "752:\tlearn: 0.3213451\ttotal: 26.5s\tremaining: 8.69s\n",
            "753:\tlearn: 0.3212314\ttotal: 26.5s\tremaining: 8.65s\n",
            "754:\tlearn: 0.3212135\ttotal: 26.5s\tremaining: 8.61s\n",
            "755:\tlearn: 0.3211032\ttotal: 26.6s\tremaining: 8.57s\n",
            "756:\tlearn: 0.3209381\ttotal: 26.6s\tremaining: 8.53s\n",
            "757:\tlearn: 0.3208017\ttotal: 26.6s\tremaining: 8.49s\n",
            "758:\tlearn: 0.3206887\ttotal: 26.6s\tremaining: 8.46s\n",
            "759:\tlearn: 0.3205564\ttotal: 26.7s\tremaining: 8.42s\n",
            "760:\tlearn: 0.3204067\ttotal: 26.7s\tremaining: 8.38s\n",
            "761:\tlearn: 0.3202703\ttotal: 26.7s\tremaining: 8.34s\n",
            "762:\tlearn: 0.3201872\ttotal: 26.7s\tremaining: 8.3s\n",
            "763:\tlearn: 0.3200980\ttotal: 26.7s\tremaining: 8.26s\n",
            "764:\tlearn: 0.3200119\ttotal: 26.8s\tremaining: 8.22s\n",
            "765:\tlearn: 0.3198934\ttotal: 26.8s\tremaining: 8.18s\n",
            "766:\tlearn: 0.3197307\ttotal: 26.8s\tremaining: 8.15s\n",
            "767:\tlearn: 0.3195250\ttotal: 26.8s\tremaining: 8.11s\n",
            "768:\tlearn: 0.3193826\ttotal: 26.9s\tremaining: 8.07s\n",
            "769:\tlearn: 0.3192393\ttotal: 26.9s\tremaining: 8.03s\n",
            "770:\tlearn: 0.3191160\ttotal: 26.9s\tremaining: 7.99s\n",
            "771:\tlearn: 0.3189791\ttotal: 26.9s\tremaining: 7.96s\n",
            "772:\tlearn: 0.3188728\ttotal: 27s\tremaining: 7.92s\n",
            "773:\tlearn: 0.3187899\ttotal: 27s\tremaining: 7.88s\n",
            "774:\tlearn: 0.3187128\ttotal: 27s\tremaining: 7.85s\n",
            "775:\tlearn: 0.3185979\ttotal: 27.1s\tremaining: 7.81s\n",
            "776:\tlearn: 0.3184526\ttotal: 27.1s\tremaining: 7.77s\n",
            "777:\tlearn: 0.3183026\ttotal: 27.1s\tremaining: 7.73s\n",
            "778:\tlearn: 0.3181764\ttotal: 27.1s\tremaining: 7.7s\n",
            "779:\tlearn: 0.3180489\ttotal: 27.2s\tremaining: 7.66s\n",
            "780:\tlearn: 0.3179394\ttotal: 27.2s\tremaining: 7.62s\n",
            "781:\tlearn: 0.3177989\ttotal: 27.2s\tremaining: 7.58s\n",
            "782:\tlearn: 0.3177270\ttotal: 27.2s\tremaining: 7.54s\n",
            "783:\tlearn: 0.3176320\ttotal: 27.2s\tremaining: 7.51s\n",
            "784:\tlearn: 0.3175229\ttotal: 27.3s\tremaining: 7.47s\n",
            "785:\tlearn: 0.3174138\ttotal: 27.3s\tremaining: 7.43s\n",
            "786:\tlearn: 0.3173058\ttotal: 27.3s\tremaining: 7.39s\n",
            "787:\tlearn: 0.3171942\ttotal: 27.3s\tremaining: 7.36s\n",
            "788:\tlearn: 0.3170751\ttotal: 27.4s\tremaining: 7.32s\n",
            "789:\tlearn: 0.3169484\ttotal: 27.4s\tremaining: 7.28s\n",
            "790:\tlearn: 0.3167907\ttotal: 27.4s\tremaining: 7.24s\n",
            "791:\tlearn: 0.3166656\ttotal: 27.4s\tremaining: 7.21s\n",
            "792:\tlearn: 0.3166235\ttotal: 27.5s\tremaining: 7.17s\n",
            "793:\tlearn: 0.3165269\ttotal: 27.5s\tremaining: 7.13s\n",
            "794:\tlearn: 0.3164186\ttotal: 27.5s\tremaining: 7.09s\n",
            "795:\tlearn: 0.3163234\ttotal: 27.5s\tremaining: 7.05s\n",
            "796:\tlearn: 0.3161444\ttotal: 27.6s\tremaining: 7.02s\n",
            "797:\tlearn: 0.3159848\ttotal: 27.6s\tremaining: 6.98s\n",
            "798:\tlearn: 0.3158804\ttotal: 27.6s\tremaining: 6.94s\n",
            "799:\tlearn: 0.3158699\ttotal: 27.6s\tremaining: 6.91s\n",
            "800:\tlearn: 0.3157310\ttotal: 27.6s\tremaining: 6.87s\n",
            "801:\tlearn: 0.3156327\ttotal: 27.7s\tremaining: 6.83s\n",
            "802:\tlearn: 0.3155492\ttotal: 27.7s\tremaining: 6.79s\n",
            "803:\tlearn: 0.3154267\ttotal: 27.7s\tremaining: 6.76s\n",
            "804:\tlearn: 0.3153197\ttotal: 27.7s\tremaining: 6.72s\n",
            "805:\tlearn: 0.3152134\ttotal: 27.8s\tremaining: 6.68s\n",
            "806:\tlearn: 0.3151081\ttotal: 27.8s\tremaining: 6.64s\n",
            "807:\tlearn: 0.3149621\ttotal: 27.8s\tremaining: 6.61s\n",
            "808:\tlearn: 0.3148656\ttotal: 27.8s\tremaining: 6.57s\n",
            "809:\tlearn: 0.3147461\ttotal: 27.9s\tremaining: 6.54s\n",
            "810:\tlearn: 0.3146144\ttotal: 27.9s\tremaining: 6.5s\n",
            "811:\tlearn: 0.3145316\ttotal: 27.9s\tremaining: 6.46s\n",
            "812:\tlearn: 0.3143890\ttotal: 27.9s\tremaining: 6.42s\n",
            "813:\tlearn: 0.3142969\ttotal: 28s\tremaining: 6.39s\n",
            "814:\tlearn: 0.3141818\ttotal: 28s\tremaining: 6.35s\n",
            "815:\tlearn: 0.3140774\ttotal: 28s\tremaining: 6.32s\n",
            "816:\tlearn: 0.3140608\ttotal: 28s\tremaining: 6.28s\n",
            "817:\tlearn: 0.3139328\ttotal: 28.1s\tremaining: 6.25s\n",
            "818:\tlearn: 0.3138332\ttotal: 28.1s\tremaining: 6.21s\n",
            "819:\tlearn: 0.3136287\ttotal: 28.1s\tremaining: 6.17s\n",
            "820:\tlearn: 0.3135425\ttotal: 28.1s\tremaining: 6.14s\n",
            "821:\tlearn: 0.3134076\ttotal: 28.2s\tremaining: 6.1s\n",
            "822:\tlearn: 0.3133175\ttotal: 28.2s\tremaining: 6.06s\n",
            "823:\tlearn: 0.3132714\ttotal: 28.2s\tremaining: 6.03s\n",
            "824:\tlearn: 0.3131484\ttotal: 28.2s\tremaining: 5.99s\n",
            "825:\tlearn: 0.3130301\ttotal: 28.3s\tremaining: 5.96s\n",
            "826:\tlearn: 0.3128632\ttotal: 28.3s\tremaining: 5.92s\n",
            "827:\tlearn: 0.3127630\ttotal: 28.3s\tremaining: 5.88s\n",
            "828:\tlearn: 0.3126341\ttotal: 28.3s\tremaining: 5.85s\n",
            "829:\tlearn: 0.3125196\ttotal: 28.4s\tremaining: 5.81s\n",
            "830:\tlearn: 0.3124068\ttotal: 28.4s\tremaining: 5.77s\n",
            "831:\tlearn: 0.3122922\ttotal: 28.4s\tremaining: 5.74s\n",
            "832:\tlearn: 0.3121345\ttotal: 28.4s\tremaining: 5.7s\n",
            "833:\tlearn: 0.3120128\ttotal: 28.5s\tremaining: 5.67s\n",
            "834:\tlearn: 0.3119324\ttotal: 28.5s\tremaining: 5.63s\n",
            "835:\tlearn: 0.3118395\ttotal: 28.5s\tremaining: 5.59s\n",
            "836:\tlearn: 0.3117268\ttotal: 28.5s\tremaining: 5.56s\n",
            "837:\tlearn: 0.3116280\ttotal: 28.6s\tremaining: 5.52s\n",
            "838:\tlearn: 0.3115434\ttotal: 28.6s\tremaining: 5.49s\n",
            "839:\tlearn: 0.3115330\ttotal: 28.6s\tremaining: 5.45s\n",
            "840:\tlearn: 0.3114410\ttotal: 28.6s\tremaining: 5.41s\n",
            "841:\tlearn: 0.3113103\ttotal: 28.7s\tremaining: 5.38s\n",
            "842:\tlearn: 0.3111764\ttotal: 28.7s\tremaining: 5.34s\n",
            "843:\tlearn: 0.3110677\ttotal: 28.7s\tremaining: 5.31s\n",
            "844:\tlearn: 0.3109678\ttotal: 28.7s\tremaining: 5.27s\n",
            "845:\tlearn: 0.3108367\ttotal: 28.8s\tremaining: 5.24s\n",
            "846:\tlearn: 0.3107981\ttotal: 28.8s\tremaining: 5.2s\n",
            "847:\tlearn: 0.3106397\ttotal: 28.8s\tremaining: 5.17s\n",
            "848:\tlearn: 0.3105410\ttotal: 28.8s\tremaining: 5.13s\n",
            "849:\tlearn: 0.3104423\ttotal: 28.9s\tremaining: 5.09s\n",
            "850:\tlearn: 0.3102692\ttotal: 28.9s\tremaining: 5.06s\n",
            "851:\tlearn: 0.3101539\ttotal: 28.9s\tremaining: 5.02s\n",
            "852:\tlearn: 0.3100416\ttotal: 28.9s\tremaining: 4.99s\n",
            "853:\tlearn: 0.3098745\ttotal: 29s\tremaining: 4.95s\n",
            "854:\tlearn: 0.3098106\ttotal: 29s\tremaining: 4.92s\n",
            "855:\tlearn: 0.3097195\ttotal: 29s\tremaining: 4.88s\n",
            "856:\tlearn: 0.3095247\ttotal: 29s\tremaining: 4.85s\n",
            "857:\tlearn: 0.3093931\ttotal: 29.1s\tremaining: 4.81s\n",
            "858:\tlearn: 0.3093064\ttotal: 29.1s\tremaining: 4.78s\n",
            "859:\tlearn: 0.3092109\ttotal: 29.1s\tremaining: 4.74s\n",
            "860:\tlearn: 0.3091015\ttotal: 29.1s\tremaining: 4.71s\n",
            "861:\tlearn: 0.3090860\ttotal: 29.2s\tremaining: 4.67s\n",
            "862:\tlearn: 0.3089140\ttotal: 29.2s\tremaining: 4.63s\n",
            "863:\tlearn: 0.3088361\ttotal: 29.2s\tremaining: 4.6s\n",
            "864:\tlearn: 0.3087273\ttotal: 29.2s\tremaining: 4.56s\n",
            "865:\tlearn: 0.3085748\ttotal: 29.3s\tremaining: 4.53s\n",
            "866:\tlearn: 0.3084448\ttotal: 29.3s\tremaining: 4.49s\n",
            "867:\tlearn: 0.3083684\ttotal: 29.3s\tremaining: 4.46s\n",
            "868:\tlearn: 0.3082742\ttotal: 29.3s\tremaining: 4.42s\n",
            "869:\tlearn: 0.3081379\ttotal: 29.4s\tremaining: 4.39s\n",
            "870:\tlearn: 0.3080183\ttotal: 29.4s\tremaining: 4.35s\n",
            "871:\tlearn: 0.3078977\ttotal: 29.4s\tremaining: 4.32s\n",
            "872:\tlearn: 0.3077734\ttotal: 29.4s\tremaining: 4.28s\n",
            "873:\tlearn: 0.3077610\ttotal: 29.5s\tremaining: 4.25s\n",
            "874:\tlearn: 0.3076340\ttotal: 29.5s\tremaining: 4.21s\n",
            "875:\tlearn: 0.3076242\ttotal: 29.5s\tremaining: 4.18s\n",
            "876:\tlearn: 0.3075497\ttotal: 29.5s\tremaining: 4.14s\n",
            "877:\tlearn: 0.3074704\ttotal: 29.6s\tremaining: 4.11s\n",
            "878:\tlearn: 0.3073607\ttotal: 29.6s\tremaining: 4.07s\n",
            "879:\tlearn: 0.3072047\ttotal: 29.6s\tremaining: 4.04s\n",
            "880:\tlearn: 0.3071056\ttotal: 29.6s\tremaining: 4s\n",
            "881:\tlearn: 0.3070138\ttotal: 29.7s\tremaining: 3.97s\n",
            "882:\tlearn: 0.3068940\ttotal: 29.7s\tremaining: 3.93s\n",
            "883:\tlearn: 0.3067750\ttotal: 29.7s\tremaining: 3.9s\n",
            "884:\tlearn: 0.3066675\ttotal: 29.7s\tremaining: 3.86s\n",
            "885:\tlearn: 0.3065485\ttotal: 29.7s\tremaining: 3.83s\n",
            "886:\tlearn: 0.3064407\ttotal: 29.8s\tremaining: 3.79s\n",
            "887:\tlearn: 0.3063105\ttotal: 29.8s\tremaining: 3.76s\n",
            "888:\tlearn: 0.3062009\ttotal: 29.8s\tremaining: 3.72s\n",
            "889:\tlearn: 0.3061311\ttotal: 29.9s\tremaining: 3.69s\n",
            "890:\tlearn: 0.3060312\ttotal: 29.9s\tremaining: 3.65s\n",
            "891:\tlearn: 0.3059711\ttotal: 29.9s\tremaining: 3.62s\n",
            "892:\tlearn: 0.3058827\ttotal: 29.9s\tremaining: 3.58s\n",
            "893:\tlearn: 0.3057559\ttotal: 29.9s\tremaining: 3.55s\n",
            "894:\tlearn: 0.3056361\ttotal: 30s\tremaining: 3.52s\n",
            "895:\tlearn: 0.3054889\ttotal: 30s\tremaining: 3.48s\n",
            "896:\tlearn: 0.3054006\ttotal: 30s\tremaining: 3.45s\n",
            "897:\tlearn: 0.3052975\ttotal: 30.1s\tremaining: 3.41s\n",
            "898:\tlearn: 0.3052361\ttotal: 30.1s\tremaining: 3.38s\n",
            "899:\tlearn: 0.3051362\ttotal: 30.1s\tremaining: 3.35s\n",
            "900:\tlearn: 0.3051220\ttotal: 30.1s\tremaining: 3.31s\n",
            "901:\tlearn: 0.3049672\ttotal: 30.2s\tremaining: 3.27s\n",
            "902:\tlearn: 0.3048759\ttotal: 30.2s\tremaining: 3.24s\n",
            "903:\tlearn: 0.3048042\ttotal: 30.2s\tremaining: 3.21s\n",
            "904:\tlearn: 0.3046566\ttotal: 30.2s\tremaining: 3.17s\n",
            "905:\tlearn: 0.3045264\ttotal: 30.3s\tremaining: 3.14s\n",
            "906:\tlearn: 0.3043996\ttotal: 30.3s\tremaining: 3.1s\n",
            "907:\tlearn: 0.3042780\ttotal: 30.3s\tremaining: 3.07s\n",
            "908:\tlearn: 0.3041572\ttotal: 30.3s\tremaining: 3.04s\n",
            "909:\tlearn: 0.3040680\ttotal: 30.3s\tremaining: 3s\n",
            "910:\tlearn: 0.3039443\ttotal: 30.4s\tremaining: 2.97s\n",
            "911:\tlearn: 0.3038905\ttotal: 30.4s\tremaining: 2.93s\n",
            "912:\tlearn: 0.3037360\ttotal: 30.4s\tremaining: 2.9s\n",
            "913:\tlearn: 0.3036388\ttotal: 30.4s\tremaining: 2.86s\n",
            "914:\tlearn: 0.3035027\ttotal: 30.5s\tremaining: 2.83s\n",
            "915:\tlearn: 0.3033690\ttotal: 30.5s\tremaining: 2.8s\n",
            "916:\tlearn: 0.3033598\ttotal: 30.5s\tremaining: 2.76s\n",
            "917:\tlearn: 0.3032343\ttotal: 30.5s\tremaining: 2.73s\n",
            "918:\tlearn: 0.3030579\ttotal: 30.6s\tremaining: 2.69s\n",
            "919:\tlearn: 0.3029434\ttotal: 30.6s\tremaining: 2.66s\n",
            "920:\tlearn: 0.3028197\ttotal: 30.6s\tremaining: 2.63s\n",
            "921:\tlearn: 0.3027366\ttotal: 30.6s\tremaining: 2.59s\n",
            "922:\tlearn: 0.3026284\ttotal: 30.7s\tremaining: 2.56s\n",
            "923:\tlearn: 0.3024707\ttotal: 30.7s\tremaining: 2.52s\n",
            "924:\tlearn: 0.3022864\ttotal: 30.7s\tremaining: 2.49s\n",
            "925:\tlearn: 0.3021644\ttotal: 30.7s\tremaining: 2.46s\n",
            "926:\tlearn: 0.3020662\ttotal: 30.8s\tremaining: 2.42s\n",
            "927:\tlearn: 0.3020153\ttotal: 30.8s\tremaining: 2.39s\n",
            "928:\tlearn: 0.3019195\ttotal: 30.8s\tremaining: 2.35s\n",
            "929:\tlearn: 0.3017991\ttotal: 30.8s\tremaining: 2.32s\n",
            "930:\tlearn: 0.3017279\ttotal: 30.9s\tremaining: 2.29s\n",
            "931:\tlearn: 0.3016423\ttotal: 30.9s\tremaining: 2.25s\n",
            "932:\tlearn: 0.3014945\ttotal: 30.9s\tremaining: 2.22s\n",
            "933:\tlearn: 0.3013961\ttotal: 30.9s\tremaining: 2.19s\n",
            "934:\tlearn: 0.3012530\ttotal: 31s\tremaining: 2.15s\n",
            "935:\tlearn: 0.3011014\ttotal: 31s\tremaining: 2.12s\n",
            "936:\tlearn: 0.3010038\ttotal: 31s\tremaining: 2.08s\n",
            "937:\tlearn: 0.3009041\ttotal: 31s\tremaining: 2.05s\n",
            "938:\tlearn: 0.3008025\ttotal: 31.1s\tremaining: 2.02s\n",
            "939:\tlearn: 0.3006946\ttotal: 31.1s\tremaining: 1.99s\n",
            "940:\tlearn: 0.3005763\ttotal: 31.1s\tremaining: 1.95s\n",
            "941:\tlearn: 0.3004981\ttotal: 31.1s\tremaining: 1.92s\n",
            "942:\tlearn: 0.3004086\ttotal: 31.2s\tremaining: 1.88s\n",
            "943:\tlearn: 0.3002790\ttotal: 31.2s\tremaining: 1.85s\n",
            "944:\tlearn: 0.3001518\ttotal: 31.2s\tremaining: 1.82s\n",
            "945:\tlearn: 0.3000606\ttotal: 31.2s\tremaining: 1.78s\n",
            "946:\tlearn: 0.2999261\ttotal: 31.3s\tremaining: 1.75s\n",
            "947:\tlearn: 0.2997870\ttotal: 31.3s\tremaining: 1.72s\n",
            "948:\tlearn: 0.2996939\ttotal: 31.3s\tremaining: 1.68s\n",
            "949:\tlearn: 0.2996537\ttotal: 31.3s\tremaining: 1.65s\n",
            "950:\tlearn: 0.2995562\ttotal: 31.4s\tremaining: 1.61s\n",
            "951:\tlearn: 0.2994414\ttotal: 31.4s\tremaining: 1.58s\n",
            "952:\tlearn: 0.2993625\ttotal: 31.4s\tremaining: 1.55s\n",
            "953:\tlearn: 0.2992105\ttotal: 31.4s\tremaining: 1.51s\n",
            "954:\tlearn: 0.2990807\ttotal: 31.5s\tremaining: 1.48s\n",
            "955:\tlearn: 0.2990042\ttotal: 31.5s\tremaining: 1.45s\n",
            "956:\tlearn: 0.2989055\ttotal: 31.5s\tremaining: 1.42s\n",
            "957:\tlearn: 0.2988023\ttotal: 31.5s\tremaining: 1.38s\n",
            "958:\tlearn: 0.2987119\ttotal: 31.6s\tremaining: 1.35s\n",
            "959:\tlearn: 0.2986161\ttotal: 31.6s\tremaining: 1.31s\n",
            "960:\tlearn: 0.2984984\ttotal: 31.6s\tremaining: 1.28s\n",
            "961:\tlearn: 0.2983802\ttotal: 31.6s\tremaining: 1.25s\n",
            "962:\tlearn: 0.2982521\ttotal: 31.6s\tremaining: 1.22s\n",
            "963:\tlearn: 0.2982098\ttotal: 31.7s\tremaining: 1.18s\n",
            "964:\tlearn: 0.2981482\ttotal: 31.7s\tremaining: 1.15s\n",
            "965:\tlearn: 0.2980753\ttotal: 31.7s\tremaining: 1.12s\n",
            "966:\tlearn: 0.2979381\ttotal: 31.7s\tremaining: 1.08s\n",
            "967:\tlearn: 0.2978256\ttotal: 31.8s\tremaining: 1.05s\n",
            "968:\tlearn: 0.2977394\ttotal: 31.8s\tremaining: 1.02s\n",
            "969:\tlearn: 0.2976540\ttotal: 31.8s\tremaining: 984ms\n",
            "970:\tlearn: 0.2975610\ttotal: 31.8s\tremaining: 951ms\n",
            "971:\tlearn: 0.2974194\ttotal: 31.9s\tremaining: 918ms\n",
            "972:\tlearn: 0.2973184\ttotal: 31.9s\tremaining: 885ms\n",
            "973:\tlearn: 0.2971843\ttotal: 31.9s\tremaining: 852ms\n",
            "974:\tlearn: 0.2970827\ttotal: 31.9s\tremaining: 819ms\n",
            "975:\tlearn: 0.2969294\ttotal: 32s\tremaining: 786ms\n",
            "976:\tlearn: 0.2968396\ttotal: 32s\tremaining: 753ms\n",
            "977:\tlearn: 0.2967125\ttotal: 32s\tremaining: 720ms\n",
            "978:\tlearn: 0.2965833\ttotal: 32s\tremaining: 687ms\n",
            "979:\tlearn: 0.2964880\ttotal: 32.1s\tremaining: 655ms\n",
            "980:\tlearn: 0.2963212\ttotal: 32.1s\tremaining: 622ms\n",
            "981:\tlearn: 0.2961885\ttotal: 32.1s\tremaining: 589ms\n",
            "982:\tlearn: 0.2960393\ttotal: 32.2s\tremaining: 556ms\n",
            "983:\tlearn: 0.2958741\ttotal: 32.2s\tremaining: 523ms\n",
            "984:\tlearn: 0.2957902\ttotal: 32.2s\tremaining: 490ms\n",
            "985:\tlearn: 0.2956451\ttotal: 32.2s\tremaining: 458ms\n",
            "986:\tlearn: 0.2955521\ttotal: 32.3s\tremaining: 425ms\n",
            "987:\tlearn: 0.2954729\ttotal: 32.3s\tremaining: 392ms\n",
            "988:\tlearn: 0.2953591\ttotal: 32.3s\tremaining: 359ms\n",
            "989:\tlearn: 0.2952885\ttotal: 32.3s\tremaining: 326ms\n",
            "990:\tlearn: 0.2951371\ttotal: 32.4s\tremaining: 294ms\n",
            "991:\tlearn: 0.2950511\ttotal: 32.4s\tremaining: 261ms\n",
            "992:\tlearn: 0.2949491\ttotal: 32.4s\tremaining: 228ms\n",
            "993:\tlearn: 0.2948773\ttotal: 32.4s\tremaining: 196ms\n",
            "994:\tlearn: 0.2948026\ttotal: 32.4s\tremaining: 163ms\n",
            "995:\tlearn: 0.2947264\ttotal: 32.5s\tremaining: 130ms\n",
            "996:\tlearn: 0.2945787\ttotal: 32.5s\tremaining: 97.8ms\n",
            "997:\tlearn: 0.2944509\ttotal: 32.5s\tremaining: 65.2ms\n",
            "998:\tlearn: 0.2943289\ttotal: 32.5s\tremaining: 32.6ms\n",
            "999:\tlearn: 0.2942174\ttotal: 32.6s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8760481272638548"
            ]
          },
          "metadata": {},
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EARLY_STOPPING_ROUND = 100"
      ],
      "metadata": {
        "id": "XiPJYLJ55PvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        \"iterations\": 1000,\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True),\n",
        "        \"depth\": trial.suggest_int(\"depth\", 1, 10),\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
        "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
        "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
        "    }\n",
        "\n",
        "    model = CatBoostClassifier(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict_proba(X_test)[:, 1]\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "    return auc"
      ],
      "metadata": {
        "id": "CvAV-T3h2hAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=30, n_jobs=-1)"
      ],
      "metadata": {
        "id": "L7cDTzMN5XiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters_catboost = {'learning_rate': 0.04, 'depth': 6, 'subsample': 0.6, 'colsample_bylevel': 0.5, 'min_data_in_leaf': 80}\n"
      ],
      "metadata": {
        "id": "hmLEudsvEl_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_catboost_tuned = CatBoostClassifier(**parameters_catboost)\n",
        "model_catboost_tuned.fit(X_train, y_train)\n",
        "\n",
        "y_pred_catboost_tuned = model_catboost_tuned.predict_proba(X_test)[:, 1]\n",
        "auc_catboost_tuned = roc_auc_score(y_test, y_pred_catboost_tuned)\n",
        "auc_catboost_tuned"
      ],
      "metadata": {
        "id": "0B942b_LF3MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM Classifier"
      ],
      "metadata": {
        "id": "9ERQXY2NAgFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "2RqRMu4mAjbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uik55K7B_HPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsSqRS-q8c7I"
      },
      "outputs": [],
      "source": [
        "se = StandardScaler()\n",
        "scaled_X_train = se.fit_transform(X_train)\n",
        "scaled_X_test = se.transform(X_test)\n",
        "\n",
        "parameters_catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-phvWnR8c7J",
        "outputId": "e8659b5f-f5a3-4697-8750-e13b2bac7694",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8671135494934661"
            ]
          },
          "metadata": {},
          "execution_count": 264
        }
      ],
      "source": [
        "svm = SVC(probability=True)\n",
        "\n",
        "svm.fit(scaled_X_train, y_train)\n",
        "y_pred = svm.predict_proba(scaled_X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "auc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKzCVdOE8c7Q",
        "outputId": "18ddae98-031f-40e3-9e06-dff64b6aa5b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7945729289397336"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = svm.predict_proba(scaled_X_val)[:, 1]\n",
        "auc = roc_auc_score(y_val, y_pred)\n",
        "auc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MLPClassifier"
      ],
      "metadata": {
        "id": "2WiiQgE4B_z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n"
      ],
      "metadata": {
        "id": "hMJmMPwpB_RN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier(hidden_layer_sizes=(15),\n",
        "\tmax_iter=3000)"
      ],
      "metadata": {
        "id": "gm-kwLpSCjNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "yJIign2pCqf_",
        "outputId": "a98eec92-1288-443a-c740-04b4445b61d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=15, max_iter=3000)"
            ],
            "text/html": [
              "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=15, max_iter=3000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=15, max_iter=3000)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_mlp = mlp.predict_proba(X_test)[:, 1]\n",
        "auc_mlp = roc_auc_score(y_test, y_pred_mlp)\n",
        "auc_mlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ_85v7jCvfx",
        "outputId": "b5bd09cf-5ea4-4859-cfb4-1c989c448e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5001249932242193"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Voting Classifier"
      ],
      "metadata": {
        "id": "PciX-1nBAEwo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0h8NGM8IY-Vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier"
      ],
      "metadata": {
        "id": "eg2O0AcB6BVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimators = [('XGBClassifier', xgb_model_tuned), ('CatBoostClassifier', model_catboost_tuned)]"
      ],
      "metadata": {
        "id": "Ay41g0ofARpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VC_soft = VotingClassifier(estimators = estimators, voting ='soft')\n",
        "VC_soft.fit(X_train, y_train)\n",
        "# y_pred_soft = VC_soft.predict(X_test)\n",
        "# auc_soft = roc_auc_score(y_test, y_pred_soft)\n",
        "# auc_soft"
      ],
      "metadata": {
        "id": "4kNjK5xQ6SFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stacking Classifier"
      ],
      "metadata": {
        "id": "MS4Nan0UAJwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import StackingClassifier"
      ],
      "metadata": {
        "id": "ioRn4fMXAOW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimators = [('Random Forest', RandomForestClassifier(**parameters_rf)),\n",
        "              ('XGBoost', XGBClassifier(**parameters_xgb)),\n",
        "              ('CatBoost', CatBoostClassifier(**parameters_catboost)),\n",
        "              ('Support Vector', SVC(probability=True))]"
      ],
      "metadata": {
        "id": "fCDb_XGWXNML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XGB = XGBClassifier(**parameters_xgb)"
      ],
      "metadata": {
        "id": "VpSZQ5KtXWya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SC = StackingClassifier(estimators=estimators, final_estimator=XGB,cv=6)\n",
        "SC.fit(scaled_X_train, y_train)\n",
        "y_pred = SC.predict(scaled_X_test)\n",
        "auc_stack = roc_auc_score(y_test, y_pred)\n",
        "auc_stack"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcsDuLWiXOrg",
        "outputId": "f9de0422-6c6d-4bb8-e440-3225fc7ec763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n",
            "0:\tlearn: 0.6808990\ttotal: 22.1ms\tremaining: 22.1s\n",
            "1:\tlearn: 0.6697780\ttotal: 43.3ms\tremaining: 21.6s\n",
            "2:\tlearn: 0.6579013\ttotal: 64.6ms\tremaining: 21.5s\n",
            "3:\tlearn: 0.6480993\ttotal: 84.4ms\tremaining: 21s\n",
            "4:\tlearn: 0.6378790\ttotal: 107ms\tremaining: 21.3s\n",
            "5:\tlearn: 0.6295992\ttotal: 127ms\tremaining: 21s\n",
            "6:\tlearn: 0.6212975\ttotal: 150ms\tremaining: 21.2s\n",
            "7:\tlearn: 0.6140941\ttotal: 168ms\tremaining: 20.9s\n",
            "8:\tlearn: 0.6072154\ttotal: 194ms\tremaining: 21.3s\n",
            "9:\tlearn: 0.6013918\ttotal: 213ms\tremaining: 21.1s\n",
            "10:\tlearn: 0.5956237\ttotal: 240ms\tremaining: 21.5s\n",
            "11:\tlearn: 0.5898155\ttotal: 260ms\tremaining: 21.4s\n",
            "12:\tlearn: 0.5839134\ttotal: 282ms\tremaining: 21.4s\n",
            "13:\tlearn: 0.5781732\ttotal: 302ms\tremaining: 21.3s\n",
            "14:\tlearn: 0.5706049\ttotal: 324ms\tremaining: 21.3s\n",
            "15:\tlearn: 0.5645611\ttotal: 343ms\tremaining: 21.1s\n",
            "16:\tlearn: 0.5599752\ttotal: 367ms\tremaining: 21.2s\n",
            "17:\tlearn: 0.5544013\ttotal: 387ms\tremaining: 21.1s\n",
            "18:\tlearn: 0.5503641\ttotal: 410ms\tremaining: 21.2s\n",
            "19:\tlearn: 0.5471805\ttotal: 448ms\tremaining: 22s\n",
            "20:\tlearn: 0.5442167\ttotal: 473ms\tremaining: 22.1s\n",
            "21:\tlearn: 0.5415113\ttotal: 495ms\tremaining: 22s\n",
            "22:\tlearn: 0.5384456\ttotal: 523ms\tremaining: 22.2s\n",
            "23:\tlearn: 0.5356558\ttotal: 545ms\tremaining: 22.2s\n",
            "24:\tlearn: 0.5330644\ttotal: 570ms\tremaining: 22.2s\n",
            "25:\tlearn: 0.5281726\ttotal: 590ms\tremaining: 22.1s\n",
            "26:\tlearn: 0.5261982\ttotal: 610ms\tremaining: 22s\n",
            "27:\tlearn: 0.5233533\ttotal: 632ms\tremaining: 21.9s\n",
            "28:\tlearn: 0.5211274\ttotal: 656ms\tremaining: 21.9s\n",
            "29:\tlearn: 0.5180336\ttotal: 678ms\tremaining: 21.9s\n",
            "30:\tlearn: 0.5158591\ttotal: 699ms\tremaining: 21.9s\n",
            "31:\tlearn: 0.5059850\ttotal: 723ms\tremaining: 21.9s\n",
            "32:\tlearn: 0.5043862\ttotal: 742ms\tremaining: 21.7s\n",
            "33:\tlearn: 0.5028036\ttotal: 763ms\tremaining: 21.7s\n",
            "34:\tlearn: 0.5014262\ttotal: 786ms\tremaining: 21.7s\n",
            "35:\tlearn: 0.5002982\ttotal: 807ms\tremaining: 21.6s\n",
            "36:\tlearn: 0.4987708\ttotal: 831ms\tremaining: 21.6s\n",
            "37:\tlearn: 0.4970701\ttotal: 855ms\tremaining: 21.7s\n",
            "38:\tlearn: 0.4960030\ttotal: 883ms\tremaining: 21.8s\n",
            "39:\tlearn: 0.4946388\ttotal: 907ms\tremaining: 21.8s\n",
            "40:\tlearn: 0.4933075\ttotal: 936ms\tremaining: 21.9s\n",
            "41:\tlearn: 0.4923678\ttotal: 955ms\tremaining: 21.8s\n",
            "42:\tlearn: 0.4907309\ttotal: 977ms\tremaining: 21.7s\n",
            "43:\tlearn: 0.4895196\ttotal: 995ms\tremaining: 21.6s\n",
            "44:\tlearn: 0.4883308\ttotal: 1.02s\tremaining: 21.6s\n",
            "45:\tlearn: 0.4866529\ttotal: 1.04s\tremaining: 21.5s\n",
            "46:\tlearn: 0.4849288\ttotal: 1.06s\tremaining: 21.5s\n",
            "47:\tlearn: 0.4773432\ttotal: 1.08s\tremaining: 21.5s\n",
            "48:\tlearn: 0.4762563\ttotal: 1.11s\tremaining: 21.5s\n",
            "49:\tlearn: 0.4755188\ttotal: 1.13s\tremaining: 21.4s\n",
            "50:\tlearn: 0.4747374\ttotal: 1.15s\tremaining: 21.4s\n",
            "51:\tlearn: 0.4736759\ttotal: 1.17s\tremaining: 21.3s\n",
            "52:\tlearn: 0.4727165\ttotal: 1.19s\tremaining: 21.3s\n",
            "53:\tlearn: 0.4715940\ttotal: 1.21s\tremaining: 21.3s\n",
            "54:\tlearn: 0.4707258\ttotal: 1.23s\tremaining: 21.2s\n",
            "55:\tlearn: 0.4700598\ttotal: 1.25s\tremaining: 21.1s\n",
            "56:\tlearn: 0.4695127\ttotal: 1.28s\tremaining: 21.2s\n",
            "57:\tlearn: 0.4689898\ttotal: 1.3s\tremaining: 21.1s\n",
            "58:\tlearn: 0.4681150\ttotal: 1.32s\tremaining: 21.1s\n",
            "59:\tlearn: 0.4675186\ttotal: 1.34s\tremaining: 21.1s\n",
            "60:\tlearn: 0.4670756\ttotal: 1.36s\tremaining: 21s\n",
            "61:\tlearn: 0.4666594\ttotal: 1.39s\tremaining: 21s\n",
            "62:\tlearn: 0.4659945\ttotal: 1.41s\tremaining: 20.9s\n",
            "63:\tlearn: 0.4653049\ttotal: 1.43s\tremaining: 21s\n",
            "64:\tlearn: 0.4637876\ttotal: 1.47s\tremaining: 21.1s\n",
            "65:\tlearn: 0.4630939\ttotal: 1.5s\tremaining: 21.2s\n",
            "66:\tlearn: 0.4625835\ttotal: 1.52s\tremaining: 21.2s\n",
            "67:\tlearn: 0.4614102\ttotal: 1.54s\tremaining: 21.2s\n",
            "68:\tlearn: 0.4607743\ttotal: 1.56s\tremaining: 21.1s\n",
            "69:\tlearn: 0.4600768\ttotal: 1.59s\tremaining: 21.1s\n",
            "70:\tlearn: 0.4595147\ttotal: 1.61s\tremaining: 21s\n",
            "71:\tlearn: 0.4588045\ttotal: 1.63s\tremaining: 21s\n",
            "72:\tlearn: 0.4582556\ttotal: 1.65s\tremaining: 21s\n",
            "73:\tlearn: 0.4576719\ttotal: 1.67s\tremaining: 20.9s\n",
            "74:\tlearn: 0.4568269\ttotal: 1.69s\tremaining: 20.9s\n",
            "75:\tlearn: 0.4563630\ttotal: 1.72s\tremaining: 20.9s\n",
            "76:\tlearn: 0.4553197\ttotal: 1.74s\tremaining: 20.9s\n",
            "77:\tlearn: 0.4546965\ttotal: 1.76s\tremaining: 20.8s\n",
            "78:\tlearn: 0.4540719\ttotal: 1.78s\tremaining: 20.8s\n",
            "79:\tlearn: 0.4536264\ttotal: 1.8s\tremaining: 20.7s\n",
            "80:\tlearn: 0.4530841\ttotal: 1.82s\tremaining: 20.7s\n",
            "81:\tlearn: 0.4524023\ttotal: 1.84s\tremaining: 20.6s\n",
            "82:\tlearn: 0.4517797\ttotal: 1.87s\tremaining: 20.6s\n",
            "83:\tlearn: 0.4509533\ttotal: 1.89s\tremaining: 20.6s\n",
            "84:\tlearn: 0.4505033\ttotal: 1.91s\tremaining: 20.5s\n",
            "85:\tlearn: 0.4500203\ttotal: 1.93s\tremaining: 20.6s\n",
            "86:\tlearn: 0.4493758\ttotal: 1.96s\tremaining: 20.5s\n",
            "87:\tlearn: 0.4488888\ttotal: 1.98s\tremaining: 20.5s\n",
            "88:\tlearn: 0.4484025\ttotal: 2s\tremaining: 20.4s\n",
            "89:\tlearn: 0.4478225\ttotal: 2.02s\tremaining: 20.4s\n",
            "90:\tlearn: 0.4473466\ttotal: 2.04s\tremaining: 20.4s\n",
            "91:\tlearn: 0.4470101\ttotal: 2.06s\tremaining: 20.4s\n",
            "92:\tlearn: 0.4466723\ttotal: 2.08s\tremaining: 20.3s\n",
            "93:\tlearn: 0.4462798\ttotal: 2.11s\tremaining: 20.3s\n",
            "94:\tlearn: 0.4458321\ttotal: 2.13s\tremaining: 20.3s\n",
            "95:\tlearn: 0.4453545\ttotal: 2.15s\tremaining: 20.3s\n",
            "96:\tlearn: 0.4448187\ttotal: 2.18s\tremaining: 20.3s\n",
            "97:\tlearn: 0.4441446\ttotal: 2.2s\tremaining: 20.2s\n",
            "98:\tlearn: 0.4436334\ttotal: 2.22s\tremaining: 20.2s\n",
            "99:\tlearn: 0.4430444\ttotal: 2.24s\tremaining: 20.2s\n",
            "100:\tlearn: 0.4424544\ttotal: 2.27s\tremaining: 20.2s\n",
            "101:\tlearn: 0.4421130\ttotal: 2.29s\tremaining: 20.1s\n",
            "102:\tlearn: 0.4416418\ttotal: 2.31s\tremaining: 20.1s\n",
            "103:\tlearn: 0.4407725\ttotal: 2.33s\tremaining: 20.1s\n",
            "104:\tlearn: 0.4404318\ttotal: 2.35s\tremaining: 20s\n",
            "105:\tlearn: 0.4400311\ttotal: 2.38s\tremaining: 20.1s\n",
            "106:\tlearn: 0.4396829\ttotal: 2.4s\tremaining: 20.1s\n",
            "107:\tlearn: 0.4392068\ttotal: 2.42s\tremaining: 20s\n",
            "108:\tlearn: 0.4385732\ttotal: 2.45s\tremaining: 20.1s\n",
            "109:\tlearn: 0.4381434\ttotal: 2.48s\tremaining: 20.1s\n",
            "110:\tlearn: 0.4376812\ttotal: 2.51s\tremaining: 20.1s\n",
            "111:\tlearn: 0.4371026\ttotal: 2.52s\tremaining: 20s\n",
            "112:\tlearn: 0.4367806\ttotal: 2.55s\tremaining: 20s\n",
            "113:\tlearn: 0.4364411\ttotal: 2.57s\tremaining: 20s\n",
            "114:\tlearn: 0.4360541\ttotal: 2.6s\tremaining: 20s\n",
            "115:\tlearn: 0.4357245\ttotal: 2.62s\tremaining: 20s\n",
            "116:\tlearn: 0.4353013\ttotal: 2.65s\tremaining: 20s\n",
            "117:\tlearn: 0.4348923\ttotal: 2.66s\tremaining: 19.9s\n",
            "118:\tlearn: 0.4345910\ttotal: 2.68s\tremaining: 19.9s\n",
            "119:\tlearn: 0.4342310\ttotal: 2.72s\tremaining: 19.9s\n",
            "120:\tlearn: 0.4337482\ttotal: 2.74s\tremaining: 19.9s\n",
            "121:\tlearn: 0.4332704\ttotal: 2.76s\tremaining: 19.8s\n",
            "122:\tlearn: 0.4329050\ttotal: 2.78s\tremaining: 19.8s\n",
            "123:\tlearn: 0.4324433\ttotal: 2.8s\tremaining: 19.8s\n",
            "124:\tlearn: 0.4319844\ttotal: 2.83s\tremaining: 19.8s\n",
            "125:\tlearn: 0.4314671\ttotal: 2.85s\tremaining: 19.8s\n",
            "126:\tlearn: 0.4311546\ttotal: 2.87s\tremaining: 19.7s\n",
            "127:\tlearn: 0.4307839\ttotal: 2.89s\tremaining: 19.7s\n",
            "128:\tlearn: 0.4303559\ttotal: 2.91s\tremaining: 19.6s\n",
            "129:\tlearn: 0.4297909\ttotal: 2.93s\tremaining: 19.6s\n",
            "130:\tlearn: 0.4293205\ttotal: 2.95s\tremaining: 19.6s\n",
            "131:\tlearn: 0.4290224\ttotal: 2.97s\tremaining: 19.6s\n",
            "132:\tlearn: 0.4287474\ttotal: 2.99s\tremaining: 19.5s\n",
            "133:\tlearn: 0.4282973\ttotal: 3.02s\tremaining: 19.5s\n",
            "134:\tlearn: 0.4280160\ttotal: 3.04s\tremaining: 19.5s\n",
            "135:\tlearn: 0.4277034\ttotal: 3.06s\tremaining: 19.5s\n",
            "136:\tlearn: 0.4273849\ttotal: 3.09s\tremaining: 19.4s\n",
            "137:\tlearn: 0.4270188\ttotal: 3.11s\tremaining: 19.4s\n",
            "138:\tlearn: 0.4266763\ttotal: 3.13s\tremaining: 19.4s\n",
            "139:\tlearn: 0.4262899\ttotal: 3.15s\tremaining: 19.4s\n",
            "140:\tlearn: 0.4259190\ttotal: 3.17s\tremaining: 19.3s\n",
            "141:\tlearn: 0.4255734\ttotal: 3.19s\tremaining: 19.3s\n",
            "142:\tlearn: 0.4253552\ttotal: 3.21s\tremaining: 19.3s\n",
            "143:\tlearn: 0.4250475\ttotal: 3.25s\tremaining: 19.3s\n",
            "144:\tlearn: 0.4248354\ttotal: 3.27s\tremaining: 19.3s\n",
            "145:\tlearn: 0.4244538\ttotal: 3.29s\tremaining: 19.3s\n",
            "146:\tlearn: 0.4240618\ttotal: 3.31s\tremaining: 19.2s\n",
            "147:\tlearn: 0.4236918\ttotal: 3.34s\tremaining: 19.2s\n",
            "148:\tlearn: 0.4234272\ttotal: 3.36s\tremaining: 19.2s\n",
            "149:\tlearn: 0.4230705\ttotal: 3.38s\tremaining: 19.1s\n",
            "150:\tlearn: 0.4227683\ttotal: 3.4s\tremaining: 19.1s\n",
            "151:\tlearn: 0.4224656\ttotal: 3.42s\tremaining: 19.1s\n",
            "152:\tlearn: 0.4221617\ttotal: 3.44s\tremaining: 19.1s\n",
            "153:\tlearn: 0.4219112\ttotal: 3.48s\tremaining: 19.1s\n",
            "154:\tlearn: 0.4214434\ttotal: 3.51s\tremaining: 19.1s\n",
            "155:\tlearn: 0.4211574\ttotal: 3.53s\tremaining: 19.1s\n",
            "156:\tlearn: 0.4208019\ttotal: 3.55s\tremaining: 19.1s\n",
            "157:\tlearn: 0.4203890\ttotal: 3.57s\tremaining: 19s\n",
            "158:\tlearn: 0.4202001\ttotal: 3.59s\tremaining: 19s\n",
            "159:\tlearn: 0.4199028\ttotal: 3.61s\tremaining: 19s\n",
            "160:\tlearn: 0.4194697\ttotal: 3.63s\tremaining: 18.9s\n",
            "161:\tlearn: 0.4191004\ttotal: 3.65s\tremaining: 18.9s\n",
            "162:\tlearn: 0.4187692\ttotal: 3.67s\tremaining: 18.9s\n",
            "163:\tlearn: 0.4184130\ttotal: 3.7s\tremaining: 18.9s\n",
            "164:\tlearn: 0.4182874\ttotal: 3.72s\tremaining: 18.8s\n",
            "165:\tlearn: 0.4180476\ttotal: 3.75s\tremaining: 18.8s\n",
            "166:\tlearn: 0.4177885\ttotal: 3.77s\tremaining: 18.8s\n",
            "167:\tlearn: 0.4173227\ttotal: 3.79s\tremaining: 18.8s\n",
            "168:\tlearn: 0.4169730\ttotal: 3.81s\tremaining: 18.8s\n",
            "169:\tlearn: 0.4166472\ttotal: 3.83s\tremaining: 18.7s\n",
            "170:\tlearn: 0.4163752\ttotal: 3.86s\tremaining: 18.7s\n",
            "171:\tlearn: 0.4160344\ttotal: 3.88s\tremaining: 18.7s\n",
            "172:\tlearn: 0.4157272\ttotal: 3.9s\tremaining: 18.7s\n",
            "173:\tlearn: 0.4154085\ttotal: 3.93s\tremaining: 18.6s\n",
            "174:\tlearn: 0.4151380\ttotal: 3.95s\tremaining: 18.6s\n",
            "175:\tlearn: 0.4149078\ttotal: 3.97s\tremaining: 18.6s\n",
            "176:\tlearn: 0.4145850\ttotal: 3.99s\tremaining: 18.6s\n",
            "177:\tlearn: 0.4141241\ttotal: 4.01s\tremaining: 18.5s\n",
            "178:\tlearn: 0.4138792\ttotal: 4.04s\tremaining: 18.5s\n",
            "179:\tlearn: 0.4136569\ttotal: 4.05s\tremaining: 18.5s\n",
            "180:\tlearn: 0.4133518\ttotal: 4.08s\tremaining: 18.5s\n",
            "181:\tlearn: 0.4130265\ttotal: 4.1s\tremaining: 18.4s\n",
            "182:\tlearn: 0.4126001\ttotal: 4.13s\tremaining: 18.4s\n",
            "183:\tlearn: 0.4122116\ttotal: 4.15s\tremaining: 18.4s\n",
            "184:\tlearn: 0.4120037\ttotal: 4.17s\tremaining: 18.4s\n",
            "185:\tlearn: 0.4117312\ttotal: 4.19s\tremaining: 18.3s\n",
            "186:\tlearn: 0.4114784\ttotal: 4.21s\tremaining: 18.3s\n",
            "187:\tlearn: 0.4112211\ttotal: 4.23s\tremaining: 18.3s\n",
            "188:\tlearn: 0.4110040\ttotal: 4.25s\tremaining: 18.3s\n",
            "189:\tlearn: 0.4107551\ttotal: 4.27s\tremaining: 18.2s\n",
            "190:\tlearn: 0.4104410\ttotal: 4.3s\tremaining: 18.2s\n",
            "191:\tlearn: 0.4101129\ttotal: 4.32s\tremaining: 18.2s\n",
            "192:\tlearn: 0.4097718\ttotal: 4.35s\tremaining: 18.2s\n",
            "193:\tlearn: 0.4094812\ttotal: 4.37s\tremaining: 18.1s\n",
            "194:\tlearn: 0.4091902\ttotal: 4.39s\tremaining: 18.1s\n",
            "195:\tlearn: 0.4088876\ttotal: 4.41s\tremaining: 18.1s\n",
            "196:\tlearn: 0.4085797\ttotal: 4.44s\tremaining: 18.1s\n",
            "197:\tlearn: 0.4082965\ttotal: 4.46s\tremaining: 18.1s\n",
            "198:\tlearn: 0.4080172\ttotal: 4.49s\tremaining: 18.1s\n",
            "199:\tlearn: 0.4076770\ttotal: 4.52s\tremaining: 18.1s\n",
            "200:\tlearn: 0.4074197\ttotal: 4.54s\tremaining: 18.1s\n",
            "201:\tlearn: 0.4070034\ttotal: 4.57s\tremaining: 18s\n",
            "202:\tlearn: 0.4067027\ttotal: 4.59s\tremaining: 18s\n",
            "203:\tlearn: 0.4064380\ttotal: 4.6s\tremaining: 18s\n",
            "204:\tlearn: 0.4061968\ttotal: 4.63s\tremaining: 18s\n",
            "205:\tlearn: 0.4059288\ttotal: 4.65s\tremaining: 17.9s\n",
            "206:\tlearn: 0.4056055\ttotal: 4.67s\tremaining: 17.9s\n",
            "207:\tlearn: 0.4052844\ttotal: 4.69s\tremaining: 17.9s\n",
            "208:\tlearn: 0.4049264\ttotal: 4.71s\tremaining: 17.8s\n",
            "209:\tlearn: 0.4046465\ttotal: 4.74s\tremaining: 17.8s\n",
            "210:\tlearn: 0.4043684\ttotal: 4.77s\tremaining: 17.8s\n",
            "211:\tlearn: 0.4014866\ttotal: 4.79s\tremaining: 17.8s\n",
            "212:\tlearn: 0.4012275\ttotal: 4.81s\tremaining: 17.8s\n",
            "213:\tlearn: 0.4009712\ttotal: 4.83s\tremaining: 17.8s\n",
            "214:\tlearn: 0.4006665\ttotal: 4.85s\tremaining: 17.7s\n",
            "215:\tlearn: 0.4003843\ttotal: 4.88s\tremaining: 17.7s\n",
            "216:\tlearn: 0.4000671\ttotal: 4.9s\tremaining: 17.7s\n",
            "217:\tlearn: 0.3998110\ttotal: 4.92s\tremaining: 17.6s\n",
            "218:\tlearn: 0.3994756\ttotal: 4.94s\tremaining: 17.6s\n",
            "219:\tlearn: 0.3992640\ttotal: 4.96s\tremaining: 17.6s\n",
            "220:\tlearn: 0.3989982\ttotal: 4.99s\tremaining: 17.6s\n",
            "221:\tlearn: 0.3986543\ttotal: 5.01s\tremaining: 17.6s\n",
            "222:\tlearn: 0.3983613\ttotal: 5.04s\tremaining: 17.5s\n",
            "223:\tlearn: 0.3980249\ttotal: 5.05s\tremaining: 17.5s\n",
            "224:\tlearn: 0.3977484\ttotal: 5.08s\tremaining: 17.5s\n",
            "225:\tlearn: 0.3975486\ttotal: 5.1s\tremaining: 17.5s\n",
            "226:\tlearn: 0.3972243\ttotal: 5.12s\tremaining: 17.4s\n",
            "227:\tlearn: 0.3970310\ttotal: 5.14s\tremaining: 17.4s\n",
            "228:\tlearn: 0.3967889\ttotal: 5.16s\tremaining: 17.4s\n",
            "229:\tlearn: 0.3964678\ttotal: 5.18s\tremaining: 17.3s\n",
            "230:\tlearn: 0.3961658\ttotal: 5.21s\tremaining: 17.3s\n",
            "231:\tlearn: 0.3960258\ttotal: 5.23s\tremaining: 17.3s\n",
            "232:\tlearn: 0.3957386\ttotal: 5.25s\tremaining: 17.3s\n",
            "233:\tlearn: 0.3955035\ttotal: 5.27s\tremaining: 17.2s\n",
            "234:\tlearn: 0.3952787\ttotal: 5.29s\tremaining: 17.2s\n",
            "235:\tlearn: 0.3949201\ttotal: 5.32s\tremaining: 17.2s\n",
            "236:\tlearn: 0.3946287\ttotal: 5.34s\tremaining: 17.2s\n",
            "237:\tlearn: 0.3942648\ttotal: 5.36s\tremaining: 17.2s\n",
            "238:\tlearn: 0.3939516\ttotal: 5.38s\tremaining: 17.1s\n",
            "239:\tlearn: 0.3936738\ttotal: 5.4s\tremaining: 17.1s\n",
            "240:\tlearn: 0.3933869\ttotal: 5.43s\tremaining: 17.1s\n",
            "241:\tlearn: 0.3930716\ttotal: 5.46s\tremaining: 17.1s\n",
            "242:\tlearn: 0.3927809\ttotal: 5.47s\tremaining: 17.1s\n",
            "243:\tlearn: 0.3926047\ttotal: 5.5s\tremaining: 17s\n",
            "244:\tlearn: 0.3923665\ttotal: 5.53s\tremaining: 17s\n",
            "245:\tlearn: 0.3920699\ttotal: 5.55s\tremaining: 17s\n",
            "246:\tlearn: 0.3917298\ttotal: 5.57s\tremaining: 17s\n",
            "247:\tlearn: 0.3915056\ttotal: 5.59s\tremaining: 16.9s\n",
            "248:\tlearn: 0.3912537\ttotal: 5.61s\tremaining: 16.9s\n",
            "249:\tlearn: 0.3908606\ttotal: 5.64s\tremaining: 16.9s\n",
            "250:\tlearn: 0.3903797\ttotal: 5.66s\tremaining: 16.9s\n",
            "251:\tlearn: 0.3900992\ttotal: 5.68s\tremaining: 16.9s\n",
            "252:\tlearn: 0.3898010\ttotal: 5.71s\tremaining: 16.8s\n",
            "253:\tlearn: 0.3894990\ttotal: 5.73s\tremaining: 16.8s\n",
            "254:\tlearn: 0.3891109\ttotal: 5.74s\tremaining: 16.8s\n",
            "255:\tlearn: 0.3888871\ttotal: 5.77s\tremaining: 16.8s\n",
            "256:\tlearn: 0.3885468\ttotal: 5.79s\tremaining: 16.7s\n",
            "257:\tlearn: 0.3882400\ttotal: 5.81s\tremaining: 16.7s\n",
            "258:\tlearn: 0.3880290\ttotal: 5.83s\tremaining: 16.7s\n",
            "259:\tlearn: 0.3878083\ttotal: 5.86s\tremaining: 16.7s\n",
            "260:\tlearn: 0.3875130\ttotal: 5.87s\tremaining: 16.6s\n",
            "261:\tlearn: 0.3872434\ttotal: 5.89s\tremaining: 16.6s\n",
            "262:\tlearn: 0.3868420\ttotal: 5.91s\tremaining: 16.6s\n",
            "263:\tlearn: 0.3865649\ttotal: 5.93s\tremaining: 16.5s\n",
            "264:\tlearn: 0.3863874\ttotal: 5.95s\tremaining: 16.5s\n",
            "265:\tlearn: 0.3860571\ttotal: 5.98s\tremaining: 16.5s\n",
            "266:\tlearn: 0.3856795\ttotal: 6s\tremaining: 16.5s\n",
            "267:\tlearn: 0.3854123\ttotal: 6.02s\tremaining: 16.4s\n",
            "268:\tlearn: 0.3851392\ttotal: 6.04s\tremaining: 16.4s\n",
            "269:\tlearn: 0.3848852\ttotal: 6.06s\tremaining: 16.4s\n",
            "270:\tlearn: 0.3846736\ttotal: 6.08s\tremaining: 16.4s\n",
            "271:\tlearn: 0.3843603\ttotal: 6.11s\tremaining: 16.3s\n",
            "272:\tlearn: 0.3841308\ttotal: 6.13s\tremaining: 16.3s\n",
            "273:\tlearn: 0.3839019\ttotal: 6.15s\tremaining: 16.3s\n",
            "274:\tlearn: 0.3835938\ttotal: 6.17s\tremaining: 16.3s\n",
            "275:\tlearn: 0.3833329\ttotal: 6.19s\tremaining: 16.2s\n",
            "276:\tlearn: 0.3830702\ttotal: 6.21s\tremaining: 16.2s\n",
            "277:\tlearn: 0.3828980\ttotal: 6.23s\tremaining: 16.2s\n",
            "278:\tlearn: 0.3825147\ttotal: 6.25s\tremaining: 16.2s\n",
            "279:\tlearn: 0.3822739\ttotal: 6.27s\tremaining: 16.1s\n",
            "280:\tlearn: 0.3820431\ttotal: 6.3s\tremaining: 16.1s\n",
            "281:\tlearn: 0.3816644\ttotal: 6.32s\tremaining: 16.1s\n",
            "282:\tlearn: 0.3813714\ttotal: 6.34s\tremaining: 16.1s\n",
            "283:\tlearn: 0.3811914\ttotal: 6.36s\tremaining: 16s\n",
            "284:\tlearn: 0.3808789\ttotal: 6.38s\tremaining: 16s\n",
            "285:\tlearn: 0.3805932\ttotal: 6.4s\tremaining: 16s\n",
            "286:\tlearn: 0.3804095\ttotal: 6.42s\tremaining: 16s\n",
            "287:\tlearn: 0.3801538\ttotal: 6.45s\tremaining: 15.9s\n",
            "288:\tlearn: 0.3798764\ttotal: 6.47s\tremaining: 15.9s\n",
            "289:\tlearn: 0.3796533\ttotal: 6.5s\tremaining: 15.9s\n",
            "290:\tlearn: 0.3794270\ttotal: 6.53s\tremaining: 15.9s\n",
            "291:\tlearn: 0.3791119\ttotal: 6.56s\tremaining: 15.9s\n",
            "292:\tlearn: 0.3789110\ttotal: 6.58s\tremaining: 15.9s\n",
            "293:\tlearn: 0.3786828\ttotal: 6.6s\tremaining: 15.9s\n",
            "294:\tlearn: 0.3783941\ttotal: 6.62s\tremaining: 15.8s\n",
            "295:\tlearn: 0.3780944\ttotal: 6.64s\tremaining: 15.8s\n",
            "296:\tlearn: 0.3777905\ttotal: 6.66s\tremaining: 15.8s\n",
            "297:\tlearn: 0.3775427\ttotal: 6.68s\tremaining: 15.7s\n",
            "298:\tlearn: 0.3772647\ttotal: 6.71s\tremaining: 15.7s\n",
            "299:\tlearn: 0.3770499\ttotal: 6.73s\tremaining: 15.7s\n",
            "300:\tlearn: 0.3767649\ttotal: 6.75s\tremaining: 15.7s\n",
            "301:\tlearn: 0.3765909\ttotal: 6.78s\tremaining: 15.7s\n",
            "302:\tlearn: 0.3763050\ttotal: 6.8s\tremaining: 15.6s\n",
            "303:\tlearn: 0.3760588\ttotal: 6.82s\tremaining: 15.6s\n",
            "304:\tlearn: 0.3758179\ttotal: 6.84s\tremaining: 15.6s\n",
            "305:\tlearn: 0.3755944\ttotal: 6.87s\tremaining: 15.6s\n",
            "306:\tlearn: 0.3753605\ttotal: 6.89s\tremaining: 15.5s\n",
            "307:\tlearn: 0.3751567\ttotal: 6.91s\tremaining: 15.5s\n",
            "308:\tlearn: 0.3749114\ttotal: 6.93s\tremaining: 15.5s\n",
            "309:\tlearn: 0.3746442\ttotal: 6.95s\tremaining: 15.5s\n",
            "310:\tlearn: 0.3743309\ttotal: 6.97s\tremaining: 15.4s\n",
            "311:\tlearn: 0.3740071\ttotal: 6.99s\tremaining: 15.4s\n",
            "312:\tlearn: 0.3738162\ttotal: 7.01s\tremaining: 15.4s\n",
            "313:\tlearn: 0.3736298\ttotal: 7.04s\tremaining: 15.4s\n",
            "314:\tlearn: 0.3734001\ttotal: 7.05s\tremaining: 15.3s\n",
            "315:\tlearn: 0.3732032\ttotal: 7.08s\tremaining: 15.3s\n",
            "316:\tlearn: 0.3730365\ttotal: 7.1s\tremaining: 15.3s\n",
            "317:\tlearn: 0.3727643\ttotal: 7.12s\tremaining: 15.3s\n",
            "318:\tlearn: 0.3725639\ttotal: 7.14s\tremaining: 15.2s\n",
            "319:\tlearn: 0.3723340\ttotal: 7.17s\tremaining: 15.2s\n",
            "320:\tlearn: 0.3720536\ttotal: 7.18s\tremaining: 15.2s\n",
            "321:\tlearn: 0.3718123\ttotal: 7.21s\tremaining: 15.2s\n",
            "322:\tlearn: 0.3715803\ttotal: 7.23s\tremaining: 15.2s\n",
            "323:\tlearn: 0.3712892\ttotal: 7.25s\tremaining: 15.1s\n",
            "324:\tlearn: 0.3710932\ttotal: 7.27s\tremaining: 15.1s\n",
            "325:\tlearn: 0.3709561\ttotal: 7.29s\tremaining: 15.1s\n",
            "326:\tlearn: 0.3707085\ttotal: 7.31s\tremaining: 15.1s\n",
            "327:\tlearn: 0.3704384\ttotal: 7.34s\tremaining: 15s\n",
            "328:\tlearn: 0.3701830\ttotal: 7.36s\tremaining: 15s\n",
            "329:\tlearn: 0.3699727\ttotal: 7.38s\tremaining: 15s\n",
            "330:\tlearn: 0.3697551\ttotal: 7.41s\tremaining: 15s\n",
            "331:\tlearn: 0.3695126\ttotal: 7.43s\tremaining: 15s\n",
            "332:\tlearn: 0.3693032\ttotal: 7.45s\tremaining: 14.9s\n",
            "333:\tlearn: 0.3690945\ttotal: 7.47s\tremaining: 14.9s\n",
            "334:\tlearn: 0.3688156\ttotal: 7.49s\tremaining: 14.9s\n",
            "335:\tlearn: 0.3685898\ttotal: 7.51s\tremaining: 14.8s\n",
            "336:\tlearn: 0.3684298\ttotal: 7.54s\tremaining: 14.8s\n",
            "337:\tlearn: 0.3682113\ttotal: 7.57s\tremaining: 14.8s\n",
            "338:\tlearn: 0.3679823\ttotal: 7.59s\tremaining: 14.8s\n",
            "339:\tlearn: 0.3677678\ttotal: 7.62s\tremaining: 14.8s\n",
            "340:\tlearn: 0.3675561\ttotal: 7.63s\tremaining: 14.8s\n",
            "341:\tlearn: 0.3673981\ttotal: 7.66s\tremaining: 14.7s\n",
            "342:\tlearn: 0.3672022\ttotal: 7.67s\tremaining: 14.7s\n",
            "343:\tlearn: 0.3669813\ttotal: 7.7s\tremaining: 14.7s\n",
            "344:\tlearn: 0.3666570\ttotal: 7.72s\tremaining: 14.7s\n",
            "345:\tlearn: 0.3664036\ttotal: 7.75s\tremaining: 14.7s\n",
            "346:\tlearn: 0.3661546\ttotal: 7.77s\tremaining: 14.6s\n",
            "347:\tlearn: 0.3659675\ttotal: 7.79s\tremaining: 14.6s\n",
            "348:\tlearn: 0.3657921\ttotal: 7.81s\tremaining: 14.6s\n",
            "349:\tlearn: 0.3656207\ttotal: 7.83s\tremaining: 14.5s\n",
            "350:\tlearn: 0.3652970\ttotal: 7.85s\tremaining: 14.5s\n",
            "351:\tlearn: 0.3649920\ttotal: 7.87s\tremaining: 14.5s\n",
            "352:\tlearn: 0.3646641\ttotal: 7.89s\tremaining: 14.5s\n",
            "353:\tlearn: 0.3644417\ttotal: 7.92s\tremaining: 14.4s\n",
            "354:\tlearn: 0.3641868\ttotal: 7.95s\tremaining: 14.5s\n",
            "355:\tlearn: 0.3639198\ttotal: 8s\tremaining: 14.5s\n",
            "356:\tlearn: 0.3637482\ttotal: 8.04s\tremaining: 14.5s\n",
            "357:\tlearn: 0.3635673\ttotal: 8.09s\tremaining: 14.5s\n",
            "358:\tlearn: 0.3633436\ttotal: 8.11s\tremaining: 14.5s\n",
            "359:\tlearn: 0.3631502\ttotal: 8.14s\tremaining: 14.5s\n",
            "360:\tlearn: 0.3629442\ttotal: 8.18s\tremaining: 14.5s\n",
            "361:\tlearn: 0.3627042\ttotal: 8.22s\tremaining: 14.5s\n",
            "362:\tlearn: 0.3624533\ttotal: 8.26s\tremaining: 14.5s\n",
            "363:\tlearn: 0.3623271\ttotal: 8.3s\tremaining: 14.5s\n",
            "364:\tlearn: 0.3621542\ttotal: 8.34s\tremaining: 14.5s\n",
            "365:\tlearn: 0.3619394\ttotal: 8.38s\tremaining: 14.5s\n",
            "366:\tlearn: 0.3617070\ttotal: 8.43s\tremaining: 14.5s\n",
            "367:\tlearn: 0.3614785\ttotal: 8.47s\tremaining: 14.5s\n",
            "368:\tlearn: 0.3612207\ttotal: 8.52s\tremaining: 14.6s\n",
            "369:\tlearn: 0.3609971\ttotal: 8.56s\tremaining: 14.6s\n",
            "370:\tlearn: 0.3607502\ttotal: 8.61s\tremaining: 14.6s\n",
            "371:\tlearn: 0.3605398\ttotal: 8.65s\tremaining: 14.6s\n",
            "372:\tlearn: 0.3603292\ttotal: 8.71s\tremaining: 14.6s\n",
            "373:\tlearn: 0.3601274\ttotal: 8.74s\tremaining: 14.6s\n",
            "374:\tlearn: 0.3598842\ttotal: 8.79s\tremaining: 14.6s\n",
            "375:\tlearn: 0.3596523\ttotal: 8.83s\tremaining: 14.7s\n",
            "376:\tlearn: 0.3594025\ttotal: 8.88s\tremaining: 14.7s\n",
            "377:\tlearn: 0.3591639\ttotal: 8.91s\tremaining: 14.7s\n",
            "378:\tlearn: 0.3589464\ttotal: 8.96s\tremaining: 14.7s\n",
            "379:\tlearn: 0.3587512\ttotal: 9s\tremaining: 14.7s\n",
            "380:\tlearn: 0.3585483\ttotal: 9.05s\tremaining: 14.7s\n",
            "381:\tlearn: 0.3582933\ttotal: 9.09s\tremaining: 14.7s\n",
            "382:\tlearn: 0.3580181\ttotal: 9.13s\tremaining: 14.7s\n",
            "383:\tlearn: 0.3577782\ttotal: 9.17s\tremaining: 14.7s\n",
            "384:\tlearn: 0.3575134\ttotal: 9.22s\tremaining: 14.7s\n",
            "385:\tlearn: 0.3572927\ttotal: 9.27s\tremaining: 14.7s\n",
            "386:\tlearn: 0.3570248\ttotal: 9.3s\tremaining: 14.7s\n",
            "387:\tlearn: 0.3568432\ttotal: 9.34s\tremaining: 14.7s\n",
            "388:\tlearn: 0.3566135\ttotal: 9.37s\tremaining: 14.7s\n",
            "389:\tlearn: 0.3565007\ttotal: 9.41s\tremaining: 14.7s\n",
            "390:\tlearn: 0.3563090\ttotal: 9.46s\tremaining: 14.7s\n",
            "391:\tlearn: 0.3560572\ttotal: 9.5s\tremaining: 14.7s\n",
            "392:\tlearn: 0.3558983\ttotal: 9.53s\tremaining: 14.7s\n",
            "393:\tlearn: 0.3556302\ttotal: 9.57s\tremaining: 14.7s\n",
            "394:\tlearn: 0.3554752\ttotal: 9.6s\tremaining: 14.7s\n",
            "395:\tlearn: 0.3551923\ttotal: 9.65s\tremaining: 14.7s\n",
            "396:\tlearn: 0.3548721\ttotal: 9.69s\tremaining: 14.7s\n",
            "397:\tlearn: 0.3546871\ttotal: 9.74s\tremaining: 14.7s\n",
            "398:\tlearn: 0.3544325\ttotal: 9.78s\tremaining: 14.7s\n",
            "399:\tlearn: 0.3541864\ttotal: 9.83s\tremaining: 14.7s\n",
            "400:\tlearn: 0.3539816\ttotal: 9.87s\tremaining: 14.7s\n",
            "401:\tlearn: 0.3537702\ttotal: 9.91s\tremaining: 14.7s\n",
            "402:\tlearn: 0.3535751\ttotal: 9.96s\tremaining: 14.8s\n",
            "403:\tlearn: 0.3534211\ttotal: 10s\tremaining: 14.7s\n",
            "404:\tlearn: 0.3532383\ttotal: 10s\tremaining: 14.8s\n",
            "405:\tlearn: 0.3530212\ttotal: 10.1s\tremaining: 14.8s\n",
            "406:\tlearn: 0.3528969\ttotal: 10.1s\tremaining: 14.7s\n",
            "407:\tlearn: 0.3526412\ttotal: 10.2s\tremaining: 14.8s\n",
            "408:\tlearn: 0.3523041\ttotal: 10.2s\tremaining: 14.8s\n",
            "409:\tlearn: 0.3521677\ttotal: 10.3s\tremaining: 14.8s\n",
            "410:\tlearn: 0.3519424\ttotal: 10.3s\tremaining: 14.8s\n",
            "411:\tlearn: 0.3517282\ttotal: 10.3s\tremaining: 14.8s\n",
            "412:\tlearn: 0.3515912\ttotal: 10.4s\tremaining: 14.8s\n",
            "413:\tlearn: 0.3512884\ttotal: 10.4s\tremaining: 14.8s\n",
            "414:\tlearn: 0.3509586\ttotal: 10.5s\tremaining: 14.8s\n",
            "415:\tlearn: 0.3507415\ttotal: 10.5s\tremaining: 14.8s\n",
            "416:\tlearn: 0.3504427\ttotal: 10.6s\tremaining: 14.8s\n",
            "417:\tlearn: 0.3502866\ttotal: 10.6s\tremaining: 14.8s\n",
            "418:\tlearn: 0.3501208\ttotal: 10.7s\tremaining: 14.8s\n",
            "419:\tlearn: 0.3499293\ttotal: 10.7s\tremaining: 14.8s\n",
            "420:\tlearn: 0.3497264\ttotal: 10.7s\tremaining: 14.8s\n",
            "421:\tlearn: 0.3494494\ttotal: 10.8s\tremaining: 14.7s\n",
            "422:\tlearn: 0.3492502\ttotal: 10.8s\tremaining: 14.7s\n",
            "423:\tlearn: 0.3489917\ttotal: 10.9s\tremaining: 14.7s\n",
            "424:\tlearn: 0.3486777\ttotal: 10.9s\tremaining: 14.7s\n",
            "425:\tlearn: 0.3484470\ttotal: 10.9s\tremaining: 14.7s\n",
            "426:\tlearn: 0.3483507\ttotal: 11s\tremaining: 14.7s\n",
            "427:\tlearn: 0.3482151\ttotal: 11s\tremaining: 14.7s\n",
            "428:\tlearn: 0.3479511\ttotal: 11s\tremaining: 14.7s\n",
            "429:\tlearn: 0.3476732\ttotal: 11.1s\tremaining: 14.7s\n",
            "430:\tlearn: 0.3474018\ttotal: 11.1s\tremaining: 14.7s\n",
            "431:\tlearn: 0.3472553\ttotal: 11.2s\tremaining: 14.7s\n",
            "432:\tlearn: 0.3470546\ttotal: 11.2s\tremaining: 14.7s\n",
            "433:\tlearn: 0.3468880\ttotal: 11.3s\tremaining: 14.7s\n",
            "434:\tlearn: 0.3466378\ttotal: 11.3s\tremaining: 14.7s\n",
            "435:\tlearn: 0.3463548\ttotal: 11.4s\tremaining: 14.7s\n",
            "436:\tlearn: 0.3461544\ttotal: 11.4s\tremaining: 14.7s\n",
            "437:\tlearn: 0.3459368\ttotal: 11.5s\tremaining: 14.7s\n",
            "438:\tlearn: 0.3457244\ttotal: 11.5s\tremaining: 14.7s\n",
            "439:\tlearn: 0.3455022\ttotal: 11.5s\tremaining: 14.7s\n",
            "440:\tlearn: 0.3453233\ttotal: 11.5s\tremaining: 14.6s\n",
            "441:\tlearn: 0.3451638\ttotal: 11.6s\tremaining: 14.6s\n",
            "442:\tlearn: 0.3449814\ttotal: 11.6s\tremaining: 14.6s\n",
            "443:\tlearn: 0.3448505\ttotal: 11.6s\tremaining: 14.5s\n",
            "444:\tlearn: 0.3447580\ttotal: 11.6s\tremaining: 14.5s\n",
            "445:\tlearn: 0.3445601\ttotal: 11.7s\tremaining: 14.5s\n",
            "446:\tlearn: 0.3443417\ttotal: 11.7s\tremaining: 14.5s\n",
            "447:\tlearn: 0.3441439\ttotal: 11.7s\tremaining: 14.4s\n",
            "448:\tlearn: 0.3439798\ttotal: 11.7s\tremaining: 14.4s\n",
            "449:\tlearn: 0.3437766\ttotal: 11.8s\tremaining: 14.4s\n",
            "450:\tlearn: 0.3435155\ttotal: 11.8s\tremaining: 14.3s\n",
            "451:\tlearn: 0.3433049\ttotal: 11.8s\tremaining: 14.3s\n",
            "452:\tlearn: 0.3431314\ttotal: 11.8s\tremaining: 14.3s\n",
            "453:\tlearn: 0.3429831\ttotal: 11.8s\tremaining: 14.2s\n",
            "454:\tlearn: 0.3427488\ttotal: 11.9s\tremaining: 14.2s\n",
            "455:\tlearn: 0.3426137\ttotal: 11.9s\tremaining: 14.2s\n",
            "456:\tlearn: 0.3424168\ttotal: 11.9s\tremaining: 14.2s\n",
            "457:\tlearn: 0.3421862\ttotal: 11.9s\tremaining: 14.1s\n",
            "458:\tlearn: 0.3419765\ttotal: 12s\tremaining: 14.1s\n",
            "459:\tlearn: 0.3418175\ttotal: 12s\tremaining: 14.1s\n",
            "460:\tlearn: 0.3416201\ttotal: 12s\tremaining: 14s\n",
            "461:\tlearn: 0.3413792\ttotal: 12s\tremaining: 14s\n",
            "462:\tlearn: 0.3413079\ttotal: 12s\tremaining: 14s\n",
            "463:\tlearn: 0.3411674\ttotal: 12.1s\tremaining: 13.9s\n",
            "464:\tlearn: 0.3410178\ttotal: 12.1s\tremaining: 13.9s\n",
            "465:\tlearn: 0.3407774\ttotal: 12.1s\tremaining: 13.9s\n",
            "466:\tlearn: 0.3404521\ttotal: 12.1s\tremaining: 13.8s\n",
            "467:\tlearn: 0.3403586\ttotal: 12.1s\tremaining: 13.8s\n",
            "468:\tlearn: 0.3401496\ttotal: 12.2s\tremaining: 13.8s\n",
            "469:\tlearn: 0.3399292\ttotal: 12.2s\tremaining: 13.8s\n",
            "470:\tlearn: 0.3396661\ttotal: 12.2s\tremaining: 13.7s\n",
            "471:\tlearn: 0.3395402\ttotal: 12.2s\tremaining: 13.7s\n",
            "472:\tlearn: 0.3394027\ttotal: 12.3s\tremaining: 13.7s\n",
            "473:\tlearn: 0.3392532\ttotal: 12.3s\tremaining: 13.6s\n",
            "474:\tlearn: 0.3390061\ttotal: 12.3s\tremaining: 13.6s\n",
            "475:\tlearn: 0.3387191\ttotal: 12.3s\tremaining: 13.6s\n",
            "476:\tlearn: 0.3385104\ttotal: 12.3s\tremaining: 13.5s\n",
            "477:\tlearn: 0.3383363\ttotal: 12.4s\tremaining: 13.5s\n",
            "478:\tlearn: 0.3380401\ttotal: 12.4s\tremaining: 13.5s\n",
            "479:\tlearn: 0.3378447\ttotal: 12.4s\tremaining: 13.4s\n",
            "480:\tlearn: 0.3375734\ttotal: 12.4s\tremaining: 13.4s\n",
            "481:\tlearn: 0.3373349\ttotal: 12.5s\tremaining: 13.4s\n",
            "482:\tlearn: 0.3371024\ttotal: 12.5s\tremaining: 13.4s\n",
            "483:\tlearn: 0.3369688\ttotal: 12.5s\tremaining: 13.3s\n",
            "484:\tlearn: 0.3367233\ttotal: 12.5s\tremaining: 13.3s\n",
            "485:\tlearn: 0.3365869\ttotal: 12.5s\tremaining: 13.3s\n",
            "486:\tlearn: 0.3364615\ttotal: 12.6s\tremaining: 13.2s\n",
            "487:\tlearn: 0.3361710\ttotal: 12.6s\tremaining: 13.2s\n",
            "488:\tlearn: 0.3359878\ttotal: 12.6s\tremaining: 13.2s\n",
            "489:\tlearn: 0.3357460\ttotal: 12.6s\tremaining: 13.1s\n",
            "490:\tlearn: 0.3356616\ttotal: 12.6s\tremaining: 13.1s\n",
            "491:\tlearn: 0.3354465\ttotal: 12.7s\tremaining: 13.1s\n",
            "492:\tlearn: 0.3352824\ttotal: 12.7s\tremaining: 13.1s\n",
            "493:\tlearn: 0.3351057\ttotal: 12.7s\tremaining: 13s\n",
            "494:\tlearn: 0.3348695\ttotal: 12.7s\tremaining: 13s\n",
            "495:\tlearn: 0.3347133\ttotal: 12.8s\tremaining: 13s\n",
            "496:\tlearn: 0.3344515\ttotal: 12.8s\tremaining: 12.9s\n",
            "497:\tlearn: 0.3342298\ttotal: 12.8s\tremaining: 12.9s\n",
            "498:\tlearn: 0.3341045\ttotal: 12.8s\tremaining: 12.9s\n",
            "499:\tlearn: 0.3339284\ttotal: 12.9s\tremaining: 12.9s\n",
            "500:\tlearn: 0.3337138\ttotal: 12.9s\tremaining: 12.8s\n",
            "501:\tlearn: 0.3336393\ttotal: 12.9s\tremaining: 12.8s\n",
            "502:\tlearn: 0.3335251\ttotal: 12.9s\tremaining: 12.8s\n",
            "503:\tlearn: 0.3334016\ttotal: 12.9s\tremaining: 12.7s\n",
            "504:\tlearn: 0.3331667\ttotal: 13s\tremaining: 12.7s\n",
            "505:\tlearn: 0.3329419\ttotal: 13s\tremaining: 12.7s\n",
            "506:\tlearn: 0.3327133\ttotal: 13s\tremaining: 12.7s\n",
            "507:\tlearn: 0.3326121\ttotal: 13s\tremaining: 12.6s\n",
            "508:\tlearn: 0.3324383\ttotal: 13.1s\tremaining: 12.6s\n",
            "509:\tlearn: 0.3322918\ttotal: 13.1s\tremaining: 12.6s\n",
            "510:\tlearn: 0.3320016\ttotal: 13.1s\tremaining: 12.5s\n",
            "511:\tlearn: 0.3318524\ttotal: 13.1s\tremaining: 12.5s\n",
            "512:\tlearn: 0.3316194\ttotal: 13.1s\tremaining: 12.5s\n",
            "513:\tlearn: 0.3314880\ttotal: 13.2s\tremaining: 12.4s\n",
            "514:\tlearn: 0.3312774\ttotal: 13.2s\tremaining: 12.4s\n",
            "515:\tlearn: 0.3310777\ttotal: 13.2s\tremaining: 12.4s\n",
            "516:\tlearn: 0.3309469\ttotal: 13.2s\tremaining: 12.4s\n",
            "517:\tlearn: 0.3308517\ttotal: 13.3s\tremaining: 12.3s\n",
            "518:\tlearn: 0.3306272\ttotal: 13.3s\tremaining: 12.3s\n",
            "519:\tlearn: 0.3303841\ttotal: 13.3s\tremaining: 12.3s\n",
            "520:\tlearn: 0.3302576\ttotal: 13.3s\tremaining: 12.3s\n",
            "521:\tlearn: 0.3300618\ttotal: 13.4s\tremaining: 12.2s\n",
            "522:\tlearn: 0.3299669\ttotal: 13.4s\tremaining: 12.2s\n",
            "523:\tlearn: 0.3297591\ttotal: 13.4s\tremaining: 12.2s\n",
            "524:\tlearn: 0.3295727\ttotal: 13.4s\tremaining: 12.1s\n",
            "525:\tlearn: 0.3294207\ttotal: 13.4s\tremaining: 12.1s\n",
            "526:\tlearn: 0.3293529\ttotal: 13.5s\tremaining: 12.1s\n",
            "527:\tlearn: 0.3291688\ttotal: 13.5s\tremaining: 12s\n",
            "528:\tlearn: 0.3289790\ttotal: 13.5s\tremaining: 12s\n",
            "529:\tlearn: 0.3287890\ttotal: 13.5s\tremaining: 12s\n",
            "530:\tlearn: 0.3286208\ttotal: 13.5s\tremaining: 12s\n",
            "531:\tlearn: 0.3283430\ttotal: 13.6s\tremaining: 11.9s\n",
            "532:\tlearn: 0.3281563\ttotal: 13.6s\tremaining: 11.9s\n",
            "533:\tlearn: 0.3280743\ttotal: 13.6s\tremaining: 11.9s\n",
            "534:\tlearn: 0.3279284\ttotal: 13.6s\tremaining: 11.8s\n",
            "535:\tlearn: 0.3276827\ttotal: 13.7s\tremaining: 11.8s\n",
            "536:\tlearn: 0.3275155\ttotal: 13.7s\tremaining: 11.8s\n",
            "537:\tlearn: 0.3273773\ttotal: 13.7s\tremaining: 11.8s\n",
            "538:\tlearn: 0.3272023\ttotal: 13.7s\tremaining: 11.8s\n",
            "539:\tlearn: 0.3270657\ttotal: 13.8s\tremaining: 11.7s\n",
            "540:\tlearn: 0.3268470\ttotal: 13.8s\tremaining: 11.7s\n",
            "541:\tlearn: 0.3267379\ttotal: 13.8s\tremaining: 11.7s\n",
            "542:\tlearn: 0.3265794\ttotal: 13.8s\tremaining: 11.6s\n",
            "543:\tlearn: 0.3264563\ttotal: 13.8s\tremaining: 11.6s\n",
            "544:\tlearn: 0.3262397\ttotal: 13.9s\tremaining: 11.6s\n",
            "545:\tlearn: 0.3260370\ttotal: 13.9s\tremaining: 11.5s\n",
            "546:\tlearn: 0.3258160\ttotal: 13.9s\tremaining: 11.5s\n",
            "547:\tlearn: 0.3256418\ttotal: 13.9s\tremaining: 11.5s\n",
            "548:\tlearn: 0.3254597\ttotal: 14s\tremaining: 11.5s\n",
            "549:\tlearn: 0.3252780\ttotal: 14s\tremaining: 11.4s\n",
            "550:\tlearn: 0.3250487\ttotal: 14s\tremaining: 11.4s\n",
            "551:\tlearn: 0.3248748\ttotal: 14s\tremaining: 11.4s\n",
            "552:\tlearn: 0.3247054\ttotal: 14s\tremaining: 11.4s\n",
            "553:\tlearn: 0.3244586\ttotal: 14.1s\tremaining: 11.3s\n",
            "554:\tlearn: 0.3243371\ttotal: 14.1s\tremaining: 11.3s\n",
            "555:\tlearn: 0.3241773\ttotal: 14.1s\tremaining: 11.3s\n",
            "556:\tlearn: 0.3239724\ttotal: 14.1s\tremaining: 11.2s\n",
            "557:\tlearn: 0.3238473\ttotal: 14.2s\tremaining: 11.2s\n",
            "558:\tlearn: 0.3236658\ttotal: 14.2s\tremaining: 11.2s\n",
            "559:\tlearn: 0.3234940\ttotal: 14.2s\tremaining: 11.2s\n",
            "560:\tlearn: 0.3233202\ttotal: 14.2s\tremaining: 11.1s\n",
            "561:\tlearn: 0.3230908\ttotal: 14.2s\tremaining: 11.1s\n",
            "562:\tlearn: 0.3228377\ttotal: 14.3s\tremaining: 11.1s\n",
            "563:\tlearn: 0.3227098\ttotal: 14.3s\tremaining: 11s\n",
            "564:\tlearn: 0.3225226\ttotal: 14.3s\tremaining: 11s\n",
            "565:\tlearn: 0.3223186\ttotal: 14.3s\tremaining: 11s\n",
            "566:\tlearn: 0.3221639\ttotal: 14.4s\tremaining: 11s\n",
            "567:\tlearn: 0.3220677\ttotal: 14.4s\tremaining: 10.9s\n",
            "568:\tlearn: 0.3219263\ttotal: 14.4s\tremaining: 10.9s\n",
            "569:\tlearn: 0.3217636\ttotal: 14.4s\tremaining: 10.9s\n",
            "570:\tlearn: 0.3216514\ttotal: 14.4s\tremaining: 10.9s\n",
            "571:\tlearn: 0.3214069\ttotal: 14.5s\tremaining: 10.8s\n",
            "572:\tlearn: 0.3212366\ttotal: 14.5s\tremaining: 10.8s\n",
            "573:\tlearn: 0.3211508\ttotal: 14.5s\tremaining: 10.8s\n",
            "574:\tlearn: 0.3209271\ttotal: 14.5s\tremaining: 10.7s\n",
            "575:\tlearn: 0.3207833\ttotal: 14.6s\tremaining: 10.7s\n",
            "576:\tlearn: 0.3206358\ttotal: 14.6s\tremaining: 10.7s\n",
            "577:\tlearn: 0.3205627\ttotal: 14.6s\tremaining: 10.7s\n",
            "578:\tlearn: 0.3202932\ttotal: 14.6s\tremaining: 10.6s\n",
            "579:\tlearn: 0.3200166\ttotal: 14.6s\tremaining: 10.6s\n",
            "580:\tlearn: 0.3197965\ttotal: 14.7s\tremaining: 10.6s\n",
            "581:\tlearn: 0.3196667\ttotal: 14.7s\tremaining: 10.5s\n",
            "582:\tlearn: 0.3195215\ttotal: 14.7s\tremaining: 10.5s\n",
            "583:\tlearn: 0.3194678\ttotal: 14.7s\tremaining: 10.5s\n",
            "584:\tlearn: 0.3193818\ttotal: 14.8s\tremaining: 10.5s\n",
            "585:\tlearn: 0.3192651\ttotal: 14.8s\tremaining: 10.5s\n",
            "586:\tlearn: 0.3190674\ttotal: 14.8s\tremaining: 10.4s\n",
            "587:\tlearn: 0.3189054\ttotal: 14.8s\tremaining: 10.4s\n",
            "588:\tlearn: 0.3188615\ttotal: 14.9s\tremaining: 10.4s\n",
            "589:\tlearn: 0.3187071\ttotal: 14.9s\tremaining: 10.3s\n",
            "590:\tlearn: 0.3185057\ttotal: 14.9s\tremaining: 10.3s\n",
            "591:\tlearn: 0.3182352\ttotal: 14.9s\tremaining: 10.3s\n",
            "592:\tlearn: 0.3180389\ttotal: 14.9s\tremaining: 10.3s\n",
            "593:\tlearn: 0.3178970\ttotal: 15s\tremaining: 10.2s\n",
            "594:\tlearn: 0.3177466\ttotal: 15s\tremaining: 10.2s\n",
            "595:\tlearn: 0.3176155\ttotal: 15s\tremaining: 10.2s\n",
            "596:\tlearn: 0.3174072\ttotal: 15s\tremaining: 10.2s\n",
            "597:\tlearn: 0.3171699\ttotal: 15.1s\tremaining: 10.1s\n",
            "598:\tlearn: 0.3169391\ttotal: 15.1s\tremaining: 10.1s\n",
            "599:\tlearn: 0.3167381\ttotal: 15.1s\tremaining: 10.1s\n",
            "600:\tlearn: 0.3165287\ttotal: 15.1s\tremaining: 10s\n",
            "601:\tlearn: 0.3163339\ttotal: 15.1s\tremaining: 10s\n",
            "602:\tlearn: 0.3161541\ttotal: 15.2s\tremaining: 9.98s\n",
            "603:\tlearn: 0.3159413\ttotal: 15.2s\tremaining: 9.96s\n",
            "604:\tlearn: 0.3157859\ttotal: 15.2s\tremaining: 9.93s\n",
            "605:\tlearn: 0.3156360\ttotal: 15.2s\tremaining: 9.9s\n",
            "606:\tlearn: 0.3153857\ttotal: 15.3s\tremaining: 9.88s\n",
            "607:\tlearn: 0.3152442\ttotal: 15.3s\tremaining: 9.85s\n",
            "608:\tlearn: 0.3150958\ttotal: 15.3s\tremaining: 9.82s\n",
            "609:\tlearn: 0.3149855\ttotal: 15.3s\tremaining: 9.79s\n",
            "610:\tlearn: 0.3148478\ttotal: 15.3s\tremaining: 9.77s\n",
            "611:\tlearn: 0.3147116\ttotal: 15.4s\tremaining: 9.74s\n",
            "612:\tlearn: 0.3145630\ttotal: 15.4s\tremaining: 9.71s\n",
            "613:\tlearn: 0.3143871\ttotal: 15.4s\tremaining: 9.69s\n",
            "614:\tlearn: 0.3142094\ttotal: 15.4s\tremaining: 9.66s\n",
            "615:\tlearn: 0.3140537\ttotal: 15.5s\tremaining: 9.63s\n",
            "616:\tlearn: 0.3139037\ttotal: 15.5s\tremaining: 9.61s\n",
            "617:\tlearn: 0.3136812\ttotal: 15.5s\tremaining: 9.58s\n",
            "618:\tlearn: 0.3135564\ttotal: 15.5s\tremaining: 9.55s\n",
            "619:\tlearn: 0.3134511\ttotal: 15.5s\tremaining: 9.52s\n",
            "620:\tlearn: 0.3132157\ttotal: 15.6s\tremaining: 9.49s\n",
            "621:\tlearn: 0.3130267\ttotal: 15.6s\tremaining: 9.47s\n",
            "622:\tlearn: 0.3127761\ttotal: 15.6s\tremaining: 9.44s\n",
            "623:\tlearn: 0.3125892\ttotal: 15.6s\tremaining: 9.42s\n",
            "624:\tlearn: 0.3124576\ttotal: 15.6s\tremaining: 9.39s\n",
            "625:\tlearn: 0.3122806\ttotal: 15.7s\tremaining: 9.36s\n",
            "626:\tlearn: 0.3121468\ttotal: 15.7s\tremaining: 9.34s\n",
            "627:\tlearn: 0.3119888\ttotal: 15.7s\tremaining: 9.31s\n",
            "628:\tlearn: 0.3118105\ttotal: 15.8s\tremaining: 9.29s\n",
            "629:\tlearn: 0.3116577\ttotal: 15.8s\tremaining: 9.26s\n",
            "630:\tlearn: 0.3115125\ttotal: 15.8s\tremaining: 9.23s\n",
            "631:\tlearn: 0.3113675\ttotal: 15.8s\tremaining: 9.21s\n",
            "632:\tlearn: 0.3111494\ttotal: 15.8s\tremaining: 9.18s\n",
            "633:\tlearn: 0.3109306\ttotal: 15.9s\tremaining: 9.15s\n",
            "634:\tlearn: 0.3107389\ttotal: 15.9s\tremaining: 9.13s\n",
            "635:\tlearn: 0.3105757\ttotal: 15.9s\tremaining: 9.11s\n",
            "636:\tlearn: 0.3104529\ttotal: 15.9s\tremaining: 9.08s\n",
            "637:\tlearn: 0.3103041\ttotal: 16s\tremaining: 9.05s\n",
            "638:\tlearn: 0.3101250\ttotal: 16s\tremaining: 9.03s\n",
            "639:\tlearn: 0.3100075\ttotal: 16s\tremaining: 9s\n",
            "640:\tlearn: 0.3098353\ttotal: 16s\tremaining: 8.97s\n",
            "641:\tlearn: 0.3096686\ttotal: 16s\tremaining: 8.95s\n",
            "642:\tlearn: 0.3096289\ttotal: 16.1s\tremaining: 8.92s\n",
            "643:\tlearn: 0.3094461\ttotal: 16.1s\tremaining: 8.89s\n",
            "644:\tlearn: 0.3093933\ttotal: 16.1s\tremaining: 8.87s\n",
            "645:\tlearn: 0.3092176\ttotal: 16.1s\tremaining: 8.84s\n",
            "646:\tlearn: 0.3090591\ttotal: 16.2s\tremaining: 8.81s\n",
            "647:\tlearn: 0.3089454\ttotal: 16.2s\tremaining: 8.79s\n",
            "648:\tlearn: 0.3087406\ttotal: 16.2s\tremaining: 8.76s\n",
            "649:\tlearn: 0.3084788\ttotal: 16.2s\tremaining: 8.73s\n",
            "650:\tlearn: 0.3083693\ttotal: 16.2s\tremaining: 8.71s\n",
            "651:\tlearn: 0.3082291\ttotal: 16.3s\tremaining: 8.68s\n",
            "652:\tlearn: 0.3081236\ttotal: 16.3s\tremaining: 8.65s\n",
            "653:\tlearn: 0.3079983\ttotal: 16.3s\tremaining: 8.63s\n",
            "654:\tlearn: 0.3077828\ttotal: 16.3s\tremaining: 8.61s\n",
            "655:\tlearn: 0.3076288\ttotal: 16.4s\tremaining: 8.58s\n",
            "656:\tlearn: 0.3074790\ttotal: 16.4s\tremaining: 8.55s\n",
            "657:\tlearn: 0.3073302\ttotal: 16.4s\tremaining: 8.52s\n",
            "658:\tlearn: 0.3071343\ttotal: 16.4s\tremaining: 8.49s\n",
            "659:\tlearn: 0.3069841\ttotal: 16.4s\tremaining: 8.47s\n",
            "660:\tlearn: 0.3068985\ttotal: 16.5s\tremaining: 8.44s\n",
            "661:\tlearn: 0.3067409\ttotal: 16.5s\tremaining: 8.41s\n",
            "662:\tlearn: 0.3065530\ttotal: 16.5s\tremaining: 8.4s\n",
            "663:\tlearn: 0.3064311\ttotal: 16.5s\tremaining: 8.37s\n",
            "664:\tlearn: 0.3063039\ttotal: 16.6s\tremaining: 8.34s\n",
            "665:\tlearn: 0.3060790\ttotal: 16.6s\tremaining: 8.32s\n",
            "666:\tlearn: 0.3058290\ttotal: 16.6s\tremaining: 8.29s\n",
            "667:\tlearn: 0.3057276\ttotal: 16.6s\tremaining: 8.26s\n",
            "668:\tlearn: 0.3055833\ttotal: 16.6s\tremaining: 8.23s\n",
            "669:\tlearn: 0.3054947\ttotal: 16.7s\tremaining: 8.21s\n",
            "670:\tlearn: 0.3053268\ttotal: 16.7s\tremaining: 8.18s\n",
            "671:\tlearn: 0.3051383\ttotal: 16.7s\tremaining: 8.15s\n",
            "672:\tlearn: 0.3049884\ttotal: 16.7s\tremaining: 8.13s\n",
            "673:\tlearn: 0.3048560\ttotal: 16.8s\tremaining: 8.11s\n",
            "674:\tlearn: 0.3047074\ttotal: 16.8s\tremaining: 8.08s\n",
            "675:\tlearn: 0.3045029\ttotal: 16.8s\tremaining: 8.06s\n",
            "676:\tlearn: 0.3043614\ttotal: 16.8s\tremaining: 8.03s\n",
            "677:\tlearn: 0.3041642\ttotal: 16.9s\tremaining: 8.01s\n",
            "678:\tlearn: 0.3040531\ttotal: 16.9s\tremaining: 7.98s\n",
            "679:\tlearn: 0.3039052\ttotal: 16.9s\tremaining: 7.95s\n",
            "680:\tlearn: 0.3036838\ttotal: 16.9s\tremaining: 7.93s\n",
            "681:\tlearn: 0.3035184\ttotal: 17s\tremaining: 7.9s\n",
            "682:\tlearn: 0.3033687\ttotal: 17s\tremaining: 7.88s\n",
            "683:\tlearn: 0.3031876\ttotal: 17s\tremaining: 7.85s\n",
            "684:\tlearn: 0.3031074\ttotal: 17s\tremaining: 7.82s\n",
            "685:\tlearn: 0.3029730\ttotal: 17s\tremaining: 7.8s\n",
            "686:\tlearn: 0.3028297\ttotal: 17.1s\tremaining: 7.77s\n",
            "687:\tlearn: 0.3027710\ttotal: 17.1s\tremaining: 7.74s\n",
            "688:\tlearn: 0.3026131\ttotal: 17.1s\tremaining: 7.72s\n",
            "689:\tlearn: 0.3025468\ttotal: 17.1s\tremaining: 7.69s\n",
            "690:\tlearn: 0.3023607\ttotal: 17.1s\tremaining: 7.66s\n",
            "691:\tlearn: 0.3022474\ttotal: 17.2s\tremaining: 7.64s\n",
            "692:\tlearn: 0.3021652\ttotal: 17.2s\tremaining: 7.61s\n",
            "693:\tlearn: 0.3020416\ttotal: 17.2s\tremaining: 7.58s\n",
            "694:\tlearn: 0.3018656\ttotal: 17.2s\tremaining: 7.56s\n",
            "695:\tlearn: 0.3016936\ttotal: 17.2s\tremaining: 7.53s\n",
            "696:\tlearn: 0.3015729\ttotal: 17.3s\tremaining: 7.5s\n",
            "697:\tlearn: 0.3015092\ttotal: 17.3s\tremaining: 7.48s\n",
            "698:\tlearn: 0.3013666\ttotal: 17.3s\tremaining: 7.45s\n",
            "699:\tlearn: 0.3011719\ttotal: 17.3s\tremaining: 7.43s\n",
            "700:\tlearn: 0.3010704\ttotal: 17.4s\tremaining: 7.4s\n",
            "701:\tlearn: 0.3009403\ttotal: 17.4s\tremaining: 7.38s\n",
            "702:\tlearn: 0.3007436\ttotal: 17.4s\tremaining: 7.35s\n",
            "703:\tlearn: 0.3006446\ttotal: 17.4s\tremaining: 7.32s\n",
            "704:\tlearn: 0.3005479\ttotal: 17.4s\tremaining: 7.3s\n",
            "705:\tlearn: 0.3004261\ttotal: 17.5s\tremaining: 7.27s\n",
            "706:\tlearn: 0.3002381\ttotal: 17.5s\tremaining: 7.24s\n",
            "707:\tlearn: 0.3000634\ttotal: 17.5s\tremaining: 7.22s\n",
            "708:\tlearn: 0.2999380\ttotal: 17.5s\tremaining: 7.19s\n",
            "709:\tlearn: 0.2997452\ttotal: 17.5s\tremaining: 7.17s\n",
            "710:\tlearn: 0.2995699\ttotal: 17.6s\tremaining: 7.14s\n",
            "711:\tlearn: 0.2994254\ttotal: 17.6s\tremaining: 7.12s\n",
            "712:\tlearn: 0.2992164\ttotal: 17.6s\tremaining: 7.09s\n",
            "713:\tlearn: 0.2991116\ttotal: 17.6s\tremaining: 7.06s\n",
            "714:\tlearn: 0.2989613\ttotal: 17.7s\tremaining: 7.04s\n",
            "715:\tlearn: 0.2987851\ttotal: 17.7s\tremaining: 7.01s\n",
            "716:\tlearn: 0.2986414\ttotal: 17.7s\tremaining: 6.99s\n",
            "717:\tlearn: 0.2986268\ttotal: 17.7s\tremaining: 6.96s\n",
            "718:\tlearn: 0.2984854\ttotal: 17.7s\tremaining: 6.93s\n",
            "719:\tlearn: 0.2983573\ttotal: 17.8s\tremaining: 6.91s\n",
            "720:\tlearn: 0.2982128\ttotal: 17.8s\tremaining: 6.89s\n",
            "721:\tlearn: 0.2979958\ttotal: 17.8s\tremaining: 6.86s\n",
            "722:\tlearn: 0.2978725\ttotal: 17.8s\tremaining: 6.84s\n",
            "723:\tlearn: 0.2977676\ttotal: 17.9s\tremaining: 6.81s\n",
            "724:\tlearn: 0.2976836\ttotal: 17.9s\tremaining: 6.78s\n",
            "725:\tlearn: 0.2975770\ttotal: 17.9s\tremaining: 6.76s\n",
            "726:\tlearn: 0.2974332\ttotal: 17.9s\tremaining: 6.73s\n",
            "727:\tlearn: 0.2973632\ttotal: 17.9s\tremaining: 6.71s\n",
            "728:\tlearn: 0.2972378\ttotal: 18s\tremaining: 6.68s\n",
            "729:\tlearn: 0.2970399\ttotal: 18s\tremaining: 6.65s\n",
            "730:\tlearn: 0.2968751\ttotal: 18s\tremaining: 6.63s\n",
            "731:\tlearn: 0.2967492\ttotal: 18s\tremaining: 6.6s\n",
            "732:\tlearn: 0.2966720\ttotal: 18.1s\tremaining: 6.58s\n",
            "733:\tlearn: 0.2964634\ttotal: 18.1s\tremaining: 6.55s\n",
            "734:\tlearn: 0.2963544\ttotal: 18.1s\tremaining: 6.53s\n",
            "735:\tlearn: 0.2963039\ttotal: 18.1s\tremaining: 6.5s\n",
            "736:\tlearn: 0.2961896\ttotal: 18.1s\tremaining: 6.47s\n",
            "737:\tlearn: 0.2960269\ttotal: 18.2s\tremaining: 6.45s\n",
            "738:\tlearn: 0.2958406\ttotal: 18.2s\tremaining: 6.42s\n",
            "739:\tlearn: 0.2957214\ttotal: 18.2s\tremaining: 6.4s\n",
            "740:\tlearn: 0.2956265\ttotal: 18.2s\tremaining: 6.37s\n",
            "741:\tlearn: 0.2954524\ttotal: 18.3s\tremaining: 6.35s\n",
            "742:\tlearn: 0.2953154\ttotal: 18.3s\tremaining: 6.32s\n",
            "743:\tlearn: 0.2952335\ttotal: 18.3s\tremaining: 6.3s\n",
            "744:\tlearn: 0.2951677\ttotal: 18.3s\tremaining: 6.27s\n",
            "745:\tlearn: 0.2950274\ttotal: 18.3s\tremaining: 6.25s\n",
            "746:\tlearn: 0.2948856\ttotal: 18.4s\tremaining: 6.22s\n",
            "747:\tlearn: 0.2947377\ttotal: 18.4s\tremaining: 6.2s\n",
            "748:\tlearn: 0.2944988\ttotal: 18.4s\tremaining: 6.17s\n",
            "749:\tlearn: 0.2943064\ttotal: 18.4s\tremaining: 6.14s\n",
            "750:\tlearn: 0.2941883\ttotal: 18.5s\tremaining: 6.12s\n",
            "751:\tlearn: 0.2940166\ttotal: 18.5s\tremaining: 6.09s\n",
            "752:\tlearn: 0.2938876\ttotal: 18.5s\tremaining: 6.07s\n",
            "753:\tlearn: 0.2937438\ttotal: 18.5s\tremaining: 6.04s\n",
            "754:\tlearn: 0.2936104\ttotal: 18.5s\tremaining: 6.02s\n",
            "755:\tlearn: 0.2934548\ttotal: 18.6s\tremaining: 5.99s\n",
            "756:\tlearn: 0.2933303\ttotal: 18.6s\tremaining: 5.97s\n",
            "757:\tlearn: 0.2932057\ttotal: 18.6s\tremaining: 5.94s\n",
            "758:\tlearn: 0.2930759\ttotal: 18.6s\tremaining: 5.92s\n",
            "759:\tlearn: 0.2929781\ttotal: 18.7s\tremaining: 5.89s\n",
            "760:\tlearn: 0.2927301\ttotal: 18.7s\tremaining: 5.87s\n",
            "761:\tlearn: 0.2925341\ttotal: 18.7s\tremaining: 5.84s\n",
            "762:\tlearn: 0.2923822\ttotal: 18.7s\tremaining: 5.82s\n",
            "763:\tlearn: 0.2921006\ttotal: 18.8s\tremaining: 5.79s\n",
            "764:\tlearn: 0.2919746\ttotal: 18.8s\tremaining: 5.77s\n",
            "765:\tlearn: 0.2918337\ttotal: 18.8s\tremaining: 5.75s\n",
            "766:\tlearn: 0.2917031\ttotal: 18.8s\tremaining: 5.72s\n",
            "767:\tlearn: 0.2914135\ttotal: 18.9s\tremaining: 5.7s\n",
            "768:\tlearn: 0.2912506\ttotal: 18.9s\tremaining: 5.67s\n",
            "769:\tlearn: 0.2911726\ttotal: 18.9s\tremaining: 5.64s\n",
            "770:\tlearn: 0.2910267\ttotal: 18.9s\tremaining: 5.62s\n",
            "771:\tlearn: 0.2908587\ttotal: 18.9s\tremaining: 5.59s\n",
            "772:\tlearn: 0.2907336\ttotal: 19s\tremaining: 5.57s\n",
            "773:\tlearn: 0.2906069\ttotal: 19s\tremaining: 5.54s\n",
            "774:\tlearn: 0.2904905\ttotal: 19s\tremaining: 5.52s\n",
            "775:\tlearn: 0.2903748\ttotal: 19s\tremaining: 5.49s\n",
            "776:\tlearn: 0.2903162\ttotal: 19s\tremaining: 5.46s\n",
            "777:\tlearn: 0.2902001\ttotal: 19.1s\tremaining: 5.44s\n",
            "778:\tlearn: 0.2900042\ttotal: 19.1s\tremaining: 5.42s\n",
            "779:\tlearn: 0.2899336\ttotal: 19.1s\tremaining: 5.39s\n",
            "780:\tlearn: 0.2898778\ttotal: 19.1s\tremaining: 5.37s\n",
            "781:\tlearn: 0.2897247\ttotal: 19.2s\tremaining: 5.34s\n",
            "782:\tlearn: 0.2896137\ttotal: 19.2s\tremaining: 5.32s\n",
            "783:\tlearn: 0.2895370\ttotal: 19.2s\tremaining: 5.29s\n",
            "784:\tlearn: 0.2894057\ttotal: 19.2s\tremaining: 5.26s\n",
            "785:\tlearn: 0.2892640\ttotal: 19.2s\tremaining: 5.24s\n",
            "786:\tlearn: 0.2891035\ttotal: 19.3s\tremaining: 5.21s\n",
            "787:\tlearn: 0.2890308\ttotal: 19.3s\tremaining: 5.19s\n",
            "788:\tlearn: 0.2889939\ttotal: 19.3s\tremaining: 5.17s\n",
            "789:\tlearn: 0.2888701\ttotal: 19.3s\tremaining: 5.14s\n",
            "790:\tlearn: 0.2886520\ttotal: 19.4s\tremaining: 5.11s\n",
            "791:\tlearn: 0.2885063\ttotal: 19.4s\tremaining: 5.09s\n",
            "792:\tlearn: 0.2884206\ttotal: 19.4s\tremaining: 5.06s\n",
            "793:\tlearn: 0.2883454\ttotal: 19.4s\tremaining: 5.04s\n",
            "794:\tlearn: 0.2882230\ttotal: 19.4s\tremaining: 5.01s\n",
            "795:\tlearn: 0.2880140\ttotal: 19.5s\tremaining: 4.99s\n",
            "796:\tlearn: 0.2878837\ttotal: 19.5s\tremaining: 4.96s\n",
            "797:\tlearn: 0.2877761\ttotal: 19.5s\tremaining: 4.94s\n",
            "798:\tlearn: 0.2877038\ttotal: 19.5s\tremaining: 4.92s\n",
            "799:\tlearn: 0.2875513\ttotal: 19.6s\tremaining: 4.89s\n",
            "800:\tlearn: 0.2874368\ttotal: 19.6s\tremaining: 4.87s\n",
            "801:\tlearn: 0.2873375\ttotal: 19.6s\tremaining: 4.84s\n",
            "802:\tlearn: 0.2871487\ttotal: 19.6s\tremaining: 4.81s\n",
            "803:\tlearn: 0.2869977\ttotal: 19.6s\tremaining: 4.79s\n",
            "804:\tlearn: 0.2868432\ttotal: 19.7s\tremaining: 4.76s\n",
            "805:\tlearn: 0.2866696\ttotal: 19.7s\tremaining: 4.74s\n",
            "806:\tlearn: 0.2865489\ttotal: 19.7s\tremaining: 4.71s\n",
            "807:\tlearn: 0.2863775\ttotal: 19.7s\tremaining: 4.69s\n",
            "808:\tlearn: 0.2862453\ttotal: 19.8s\tremaining: 4.67s\n",
            "809:\tlearn: 0.2861363\ttotal: 19.8s\tremaining: 4.64s\n",
            "810:\tlearn: 0.2859562\ttotal: 19.8s\tremaining: 4.62s\n",
            "811:\tlearn: 0.2858848\ttotal: 19.8s\tremaining: 4.59s\n",
            "812:\tlearn: 0.2856894\ttotal: 19.9s\tremaining: 4.57s\n",
            "813:\tlearn: 0.2854973\ttotal: 19.9s\tremaining: 4.54s\n",
            "814:\tlearn: 0.2853755\ttotal: 19.9s\tremaining: 4.52s\n",
            "815:\tlearn: 0.2852222\ttotal: 19.9s\tremaining: 4.49s\n",
            "816:\tlearn: 0.2851080\ttotal: 20s\tremaining: 4.47s\n",
            "817:\tlearn: 0.2850171\ttotal: 20s\tremaining: 4.44s\n",
            "818:\tlearn: 0.2849132\ttotal: 20s\tremaining: 4.42s\n",
            "819:\tlearn: 0.2847448\ttotal: 20s\tremaining: 4.39s\n",
            "820:\tlearn: 0.2845928\ttotal: 20s\tremaining: 4.37s\n",
            "821:\tlearn: 0.2844853\ttotal: 20.1s\tremaining: 4.34s\n",
            "822:\tlearn: 0.2843568\ttotal: 20.1s\tremaining: 4.32s\n",
            "823:\tlearn: 0.2842250\ttotal: 20.1s\tremaining: 4.29s\n",
            "824:\tlearn: 0.2841227\ttotal: 20.1s\tremaining: 4.27s\n",
            "825:\tlearn: 0.2840329\ttotal: 20.1s\tremaining: 4.24s\n",
            "826:\tlearn: 0.2839375\ttotal: 20.2s\tremaining: 4.22s\n",
            "827:\tlearn: 0.2838602\ttotal: 20.2s\tremaining: 4.2s\n",
            "828:\tlearn: 0.2837999\ttotal: 20.2s\tremaining: 4.17s\n",
            "829:\tlearn: 0.2835719\ttotal: 20.2s\tremaining: 4.14s\n",
            "830:\tlearn: 0.2834145\ttotal: 20.3s\tremaining: 4.12s\n",
            "831:\tlearn: 0.2833211\ttotal: 20.3s\tremaining: 4.09s\n",
            "832:\tlearn: 0.2832558\ttotal: 20.3s\tremaining: 4.07s\n",
            "833:\tlearn: 0.2831873\ttotal: 20.3s\tremaining: 4.04s\n",
            "834:\tlearn: 0.2830525\ttotal: 20.3s\tremaining: 4.02s\n",
            "835:\tlearn: 0.2829235\ttotal: 20.4s\tremaining: 4s\n",
            "836:\tlearn: 0.2828273\ttotal: 20.4s\tremaining: 3.97s\n",
            "837:\tlearn: 0.2826577\ttotal: 20.4s\tremaining: 3.95s\n",
            "838:\tlearn: 0.2825322\ttotal: 20.4s\tremaining: 3.92s\n",
            "839:\tlearn: 0.2823707\ttotal: 20.5s\tremaining: 3.9s\n",
            "840:\tlearn: 0.2822479\ttotal: 20.5s\tremaining: 3.87s\n",
            "841:\tlearn: 0.2821072\ttotal: 20.5s\tremaining: 3.85s\n",
            "842:\tlearn: 0.2819515\ttotal: 20.5s\tremaining: 3.82s\n",
            "843:\tlearn: 0.2817674\ttotal: 20.5s\tremaining: 3.79s\n",
            "844:\tlearn: 0.2816294\ttotal: 20.6s\tremaining: 3.77s\n",
            "845:\tlearn: 0.2814849\ttotal: 20.6s\tremaining: 3.75s\n",
            "846:\tlearn: 0.2812964\ttotal: 20.6s\tremaining: 3.72s\n",
            "847:\tlearn: 0.2811546\ttotal: 20.6s\tremaining: 3.7s\n",
            "848:\tlearn: 0.2810380\ttotal: 20.7s\tremaining: 3.67s\n",
            "849:\tlearn: 0.2809778\ttotal: 20.7s\tremaining: 3.65s\n",
            "850:\tlearn: 0.2808052\ttotal: 20.7s\tremaining: 3.62s\n",
            "851:\tlearn: 0.2807061\ttotal: 20.7s\tremaining: 3.6s\n",
            "852:\tlearn: 0.2806083\ttotal: 20.7s\tremaining: 3.57s\n",
            "853:\tlearn: 0.2804955\ttotal: 20.8s\tremaining: 3.55s\n",
            "854:\tlearn: 0.2804266\ttotal: 20.8s\tremaining: 3.53s\n",
            "855:\tlearn: 0.2803472\ttotal: 20.8s\tremaining: 3.5s\n",
            "856:\tlearn: 0.2801855\ttotal: 20.8s\tremaining: 3.48s\n",
            "857:\tlearn: 0.2800845\ttotal: 20.9s\tremaining: 3.45s\n",
            "858:\tlearn: 0.2799995\ttotal: 20.9s\tremaining: 3.43s\n",
            "859:\tlearn: 0.2799341\ttotal: 20.9s\tremaining: 3.4s\n",
            "860:\tlearn: 0.2797642\ttotal: 20.9s\tremaining: 3.38s\n",
            "861:\tlearn: 0.2796677\ttotal: 20.9s\tremaining: 3.35s\n",
            "862:\tlearn: 0.2794975\ttotal: 21s\tremaining: 3.33s\n",
            "863:\tlearn: 0.2794276\ttotal: 21s\tremaining: 3.3s\n",
            "864:\tlearn: 0.2793497\ttotal: 21s\tremaining: 3.28s\n",
            "865:\tlearn: 0.2792150\ttotal: 21s\tremaining: 3.25s\n",
            "866:\tlearn: 0.2791227\ttotal: 21.1s\tremaining: 3.23s\n",
            "867:\tlearn: 0.2789088\ttotal: 21.1s\tremaining: 3.21s\n",
            "868:\tlearn: 0.2788052\ttotal: 21.1s\tremaining: 3.18s\n",
            "869:\tlearn: 0.2787083\ttotal: 21.1s\tremaining: 3.16s\n",
            "870:\tlearn: 0.2786952\ttotal: 21.1s\tremaining: 3.13s\n",
            "871:\tlearn: 0.2786088\ttotal: 21.2s\tremaining: 3.11s\n",
            "872:\tlearn: 0.2784783\ttotal: 21.2s\tremaining: 3.08s\n",
            "873:\tlearn: 0.2783419\ttotal: 21.2s\tremaining: 3.06s\n",
            "874:\tlearn: 0.2782645\ttotal: 21.2s\tremaining: 3.03s\n",
            "875:\tlearn: 0.2781939\ttotal: 21.3s\tremaining: 3.01s\n",
            "876:\tlearn: 0.2780569\ttotal: 21.3s\tremaining: 2.98s\n",
            "877:\tlearn: 0.2779695\ttotal: 21.3s\tremaining: 2.96s\n",
            "878:\tlearn: 0.2778693\ttotal: 21.3s\tremaining: 2.94s\n",
            "879:\tlearn: 0.2777006\ttotal: 21.4s\tremaining: 2.91s\n",
            "880:\tlearn: 0.2776401\ttotal: 21.4s\tremaining: 2.89s\n",
            "881:\tlearn: 0.2775062\ttotal: 21.4s\tremaining: 2.87s\n",
            "882:\tlearn: 0.2773499\ttotal: 21.5s\tremaining: 2.85s\n",
            "883:\tlearn: 0.2772165\ttotal: 21.5s\tremaining: 2.82s\n",
            "884:\tlearn: 0.2770786\ttotal: 21.6s\tremaining: 2.8s\n",
            "885:\tlearn: 0.2769646\ttotal: 21.6s\tremaining: 2.78s\n",
            "886:\tlearn: 0.2768465\ttotal: 21.6s\tremaining: 2.76s\n",
            "887:\tlearn: 0.2767569\ttotal: 21.7s\tremaining: 2.73s\n",
            "888:\tlearn: 0.2766137\ttotal: 21.7s\tremaining: 2.71s\n",
            "889:\tlearn: 0.2765597\ttotal: 21.7s\tremaining: 2.69s\n",
            "890:\tlearn: 0.2764592\ttotal: 21.8s\tremaining: 2.67s\n",
            "891:\tlearn: 0.2763542\ttotal: 21.8s\tremaining: 2.64s\n",
            "892:\tlearn: 0.2763015\ttotal: 21.9s\tremaining: 2.62s\n",
            "893:\tlearn: 0.2761959\ttotal: 21.9s\tremaining: 2.6s\n",
            "894:\tlearn: 0.2761448\ttotal: 22s\tremaining: 2.58s\n",
            "895:\tlearn: 0.2760084\ttotal: 22s\tremaining: 2.55s\n",
            "896:\tlearn: 0.2759032\ttotal: 22s\tremaining: 2.53s\n",
            "897:\tlearn: 0.2757778\ttotal: 22.1s\tremaining: 2.51s\n",
            "898:\tlearn: 0.2756061\ttotal: 22.1s\tremaining: 2.48s\n",
            "899:\tlearn: 0.2755427\ttotal: 22.1s\tremaining: 2.46s\n",
            "900:\tlearn: 0.2754460\ttotal: 22.2s\tremaining: 2.44s\n",
            "901:\tlearn: 0.2753582\ttotal: 22.2s\tremaining: 2.41s\n",
            "902:\tlearn: 0.2751458\ttotal: 22.3s\tremaining: 2.39s\n",
            "903:\tlearn: 0.2750440\ttotal: 22.3s\tremaining: 2.37s\n",
            "904:\tlearn: 0.2749078\ttotal: 22.3s\tremaining: 2.34s\n",
            "905:\tlearn: 0.2748252\ttotal: 22.4s\tremaining: 2.32s\n",
            "906:\tlearn: 0.2747387\ttotal: 22.4s\tremaining: 2.29s\n",
            "907:\tlearn: 0.2745693\ttotal: 22.4s\tremaining: 2.27s\n",
            "908:\tlearn: 0.2744644\ttotal: 22.5s\tremaining: 2.25s\n",
            "909:\tlearn: 0.2742882\ttotal: 22.5s\tremaining: 2.23s\n",
            "910:\tlearn: 0.2741512\ttotal: 22.5s\tremaining: 2.2s\n",
            "911:\tlearn: 0.2739877\ttotal: 22.6s\tremaining: 2.18s\n",
            "912:\tlearn: 0.2738747\ttotal: 22.6s\tremaining: 2.15s\n",
            "913:\tlearn: 0.2738135\ttotal: 22.7s\tremaining: 2.13s\n",
            "914:\tlearn: 0.2736733\ttotal: 22.7s\tremaining: 2.11s\n",
            "915:\tlearn: 0.2734942\ttotal: 22.7s\tremaining: 2.08s\n",
            "916:\tlearn: 0.2734088\ttotal: 22.8s\tremaining: 2.06s\n",
            "917:\tlearn: 0.2732714\ttotal: 22.8s\tremaining: 2.04s\n",
            "918:\tlearn: 0.2731955\ttotal: 22.9s\tremaining: 2.02s\n",
            "919:\tlearn: 0.2731283\ttotal: 22.9s\tremaining: 1.99s\n",
            "920:\tlearn: 0.2729659\ttotal: 23s\tremaining: 1.97s\n",
            "921:\tlearn: 0.2729385\ttotal: 23s\tremaining: 1.95s\n",
            "922:\tlearn: 0.2729182\ttotal: 23s\tremaining: 1.92s\n",
            "923:\tlearn: 0.2727740\ttotal: 23.1s\tremaining: 1.9s\n",
            "924:\tlearn: 0.2726259\ttotal: 23.1s\tremaining: 1.87s\n",
            "925:\tlearn: 0.2725590\ttotal: 23.2s\tremaining: 1.85s\n",
            "926:\tlearn: 0.2724257\ttotal: 23.2s\tremaining: 1.83s\n",
            "927:\tlearn: 0.2723299\ttotal: 23.2s\tremaining: 1.8s\n",
            "928:\tlearn: 0.2722258\ttotal: 23.3s\tremaining: 1.78s\n",
            "929:\tlearn: 0.2720594\ttotal: 23.3s\tremaining: 1.75s\n",
            "930:\tlearn: 0.2719967\ttotal: 23.3s\tremaining: 1.73s\n",
            "931:\tlearn: 0.2719092\ttotal: 23.4s\tremaining: 1.71s\n",
            "932:\tlearn: 0.2718060\ttotal: 23.4s\tremaining: 1.68s\n",
            "933:\tlearn: 0.2716609\ttotal: 23.5s\tremaining: 1.66s\n",
            "934:\tlearn: 0.2715803\ttotal: 23.5s\tremaining: 1.63s\n",
            "935:\tlearn: 0.2714919\ttotal: 23.5s\tremaining: 1.61s\n",
            "936:\tlearn: 0.2714246\ttotal: 23.6s\tremaining: 1.58s\n",
            "937:\tlearn: 0.2712984\ttotal: 23.6s\tremaining: 1.56s\n",
            "938:\tlearn: 0.2711231\ttotal: 23.7s\tremaining: 1.54s\n",
            "939:\tlearn: 0.2710372\ttotal: 23.7s\tremaining: 1.51s\n",
            "940:\tlearn: 0.2708617\ttotal: 23.8s\tremaining: 1.49s\n",
            "941:\tlearn: 0.2707243\ttotal: 23.8s\tremaining: 1.47s\n",
            "942:\tlearn: 0.2706230\ttotal: 23.8s\tremaining: 1.44s\n",
            "943:\tlearn: 0.2705264\ttotal: 23.9s\tremaining: 1.42s\n",
            "944:\tlearn: 0.2704274\ttotal: 23.9s\tremaining: 1.39s\n",
            "945:\tlearn: 0.2703789\ttotal: 24s\tremaining: 1.37s\n",
            "946:\tlearn: 0.2703246\ttotal: 24s\tremaining: 1.34s\n",
            "947:\tlearn: 0.2701825\ttotal: 24.1s\tremaining: 1.32s\n",
            "948:\tlearn: 0.2699983\ttotal: 24.1s\tremaining: 1.3s\n",
            "949:\tlearn: 0.2698882\ttotal: 24.2s\tremaining: 1.27s\n",
            "950:\tlearn: 0.2697540\ttotal: 24.3s\tremaining: 1.25s\n",
            "951:\tlearn: 0.2696353\ttotal: 24.3s\tremaining: 1.22s\n",
            "952:\tlearn: 0.2694598\ttotal: 24.3s\tremaining: 1.2s\n",
            "953:\tlearn: 0.2693539\ttotal: 24.4s\tremaining: 1.18s\n",
            "954:\tlearn: 0.2692003\ttotal: 24.4s\tremaining: 1.15s\n",
            "955:\tlearn: 0.2691108\ttotal: 24.5s\tremaining: 1.13s\n",
            "956:\tlearn: 0.2689038\ttotal: 24.5s\tremaining: 1.1s\n",
            "957:\tlearn: 0.2688237\ttotal: 24.5s\tremaining: 1.07s\n",
            "958:\tlearn: 0.2686557\ttotal: 24.6s\tremaining: 1.05s\n",
            "959:\tlearn: 0.2685985\ttotal: 24.6s\tremaining: 1.02s\n",
            "960:\tlearn: 0.2684707\ttotal: 24.7s\tremaining: 1s\n",
            "961:\tlearn: 0.2683194\ttotal: 24.7s\tremaining: 976ms\n",
            "962:\tlearn: 0.2681504\ttotal: 24.8s\tremaining: 951ms\n",
            "963:\tlearn: 0.2679933\ttotal: 24.8s\tremaining: 927ms\n",
            "964:\tlearn: 0.2678689\ttotal: 24.9s\tremaining: 902ms\n",
            "965:\tlearn: 0.2677409\ttotal: 24.9s\tremaining: 877ms\n",
            "966:\tlearn: 0.2675816\ttotal: 25s\tremaining: 852ms\n",
            "967:\tlearn: 0.2675426\ttotal: 25s\tremaining: 826ms\n",
            "968:\tlearn: 0.2674995\ttotal: 25s\tremaining: 801ms\n",
            "969:\tlearn: 0.2674394\ttotal: 25.1s\tremaining: 776ms\n",
            "970:\tlearn: 0.2673338\ttotal: 25.1s\tremaining: 751ms\n",
            "971:\tlearn: 0.2671886\ttotal: 25.2s\tremaining: 725ms\n",
            "972:\tlearn: 0.2670369\ttotal: 25.2s\tremaining: 700ms\n",
            "973:\tlearn: 0.2669185\ttotal: 25.3s\tremaining: 674ms\n",
            "974:\tlearn: 0.2667557\ttotal: 25.3s\tremaining: 649ms\n",
            "975:\tlearn: 0.2666190\ttotal: 25.3s\tremaining: 623ms\n",
            "976:\tlearn: 0.2665553\ttotal: 25.3s\tremaining: 597ms\n",
            "977:\tlearn: 0.2664462\ttotal: 25.4s\tremaining: 571ms\n",
            "978:\tlearn: 0.2663854\ttotal: 25.4s\tremaining: 544ms\n",
            "979:\tlearn: 0.2662768\ttotal: 25.4s\tremaining: 519ms\n",
            "980:\tlearn: 0.2661819\ttotal: 25.4s\tremaining: 493ms\n",
            "981:\tlearn: 0.2660170\ttotal: 25.5s\tremaining: 467ms\n",
            "982:\tlearn: 0.2658775\ttotal: 25.5s\tremaining: 441ms\n",
            "983:\tlearn: 0.2657914\ttotal: 25.5s\tremaining: 415ms\n",
            "984:\tlearn: 0.2656549\ttotal: 25.5s\tremaining: 389ms\n",
            "985:\tlearn: 0.2655068\ttotal: 25.5s\tremaining: 363ms\n",
            "986:\tlearn: 0.2653961\ttotal: 25.6s\tremaining: 337ms\n",
            "987:\tlearn: 0.2653105\ttotal: 25.6s\tremaining: 311ms\n",
            "988:\tlearn: 0.2652411\ttotal: 25.6s\tremaining: 285ms\n",
            "989:\tlearn: 0.2651332\ttotal: 25.6s\tremaining: 259ms\n",
            "990:\tlearn: 0.2649922\ttotal: 25.6s\tremaining: 233ms\n",
            "991:\tlearn: 0.2649235\ttotal: 25.7s\tremaining: 207ms\n",
            "992:\tlearn: 0.2648609\ttotal: 25.7s\tremaining: 181ms\n",
            "993:\tlearn: 0.2648029\ttotal: 25.7s\tremaining: 155ms\n",
            "994:\tlearn: 0.2647408\ttotal: 25.7s\tremaining: 129ms\n",
            "995:\tlearn: 0.2647262\ttotal: 25.8s\tremaining: 103ms\n",
            "996:\tlearn: 0.2645863\ttotal: 25.8s\tremaining: 77.6ms\n",
            "997:\tlearn: 0.2645340\ttotal: 25.8s\tremaining: 51.7ms\n",
            "998:\tlearn: 0.2644418\ttotal: 25.8s\tremaining: 25.9ms\n",
            "999:\tlearn: 0.2642488\ttotal: 25.8s\tremaining: 0us\n",
            "0:\tlearn: 0.6813833\ttotal: 27.3ms\tremaining: 27.3s\n",
            "1:\tlearn: 0.6666088\ttotal: 57.9ms\tremaining: 28.9s\n",
            "2:\tlearn: 0.6562695\ttotal: 77.9ms\tremaining: 25.9s\n",
            "3:\tlearn: 0.6460494\ttotal: 99.8ms\tremaining: 24.9s\n",
            "4:\tlearn: 0.6360863\ttotal: 119ms\tremaining: 23.8s\n",
            "5:\tlearn: 0.6266490\ttotal: 142ms\tremaining: 23.6s\n",
            "6:\tlearn: 0.6189919\ttotal: 160ms\tremaining: 22.7s\n",
            "7:\tlearn: 0.6114605\ttotal: 182ms\tremaining: 22.5s\n",
            "8:\tlearn: 0.6054590\ttotal: 201ms\tremaining: 22.1s\n",
            "9:\tlearn: 0.5988320\ttotal: 224ms\tremaining: 22.1s\n",
            "10:\tlearn: 0.5932797\ttotal: 252ms\tremaining: 22.6s\n",
            "11:\tlearn: 0.5882816\ttotal: 271ms\tremaining: 22.3s\n",
            "12:\tlearn: 0.5802735\ttotal: 292ms\tremaining: 22.2s\n",
            "13:\tlearn: 0.5749322\ttotal: 314ms\tremaining: 22.1s\n",
            "14:\tlearn: 0.5700907\ttotal: 335ms\tremaining: 22s\n",
            "15:\tlearn: 0.5661243\ttotal: 355ms\tremaining: 21.9s\n",
            "16:\tlearn: 0.5604715\ttotal: 376ms\tremaining: 21.7s\n",
            "17:\tlearn: 0.5561946\ttotal: 393ms\tremaining: 21.5s\n",
            "18:\tlearn: 0.5532066\ttotal: 416ms\tremaining: 21.5s\n",
            "19:\tlearn: 0.5488709\ttotal: 437ms\tremaining: 21.4s\n",
            "20:\tlearn: 0.5445454\ttotal: 459ms\tremaining: 21.4s\n",
            "21:\tlearn: 0.5406781\ttotal: 487ms\tremaining: 21.6s\n",
            "22:\tlearn: 0.5374831\ttotal: 508ms\tremaining: 21.6s\n",
            "23:\tlearn: 0.5346547\ttotal: 533ms\tremaining: 21.7s\n",
            "24:\tlearn: 0.5320334\ttotal: 551ms\tremaining: 21.5s\n",
            "25:\tlearn: 0.5270636\ttotal: 573ms\tremaining: 21.5s\n",
            "26:\tlearn: 0.5232404\ttotal: 592ms\tremaining: 21.3s\n",
            "27:\tlearn: 0.5211311\ttotal: 614ms\tremaining: 21.3s\n",
            "28:\tlearn: 0.5188534\ttotal: 632ms\tremaining: 21.2s\n",
            "29:\tlearn: 0.5170777\ttotal: 653ms\tremaining: 21.1s\n",
            "30:\tlearn: 0.5150345\ttotal: 678ms\tremaining: 21.2s\n",
            "31:\tlearn: 0.5136302\ttotal: 699ms\tremaining: 21.2s\n",
            "32:\tlearn: 0.5110227\ttotal: 720ms\tremaining: 21.1s\n",
            "33:\tlearn: 0.5082698\ttotal: 741ms\tremaining: 21.1s\n",
            "34:\tlearn: 0.5068817\ttotal: 758ms\tremaining: 20.9s\n",
            "35:\tlearn: 0.5055218\ttotal: 783ms\tremaining: 21s\n",
            "36:\tlearn: 0.5039220\ttotal: 805ms\tremaining: 20.9s\n",
            "37:\tlearn: 0.5022202\ttotal: 823ms\tremaining: 20.8s\n",
            "38:\tlearn: 0.5009906\ttotal: 845ms\tremaining: 20.8s\n",
            "39:\tlearn: 0.4997060\ttotal: 867ms\tremaining: 20.8s\n",
            "40:\tlearn: 0.4978694\ttotal: 900ms\tremaining: 21.1s\n",
            "41:\tlearn: 0.4957953\ttotal: 923ms\tremaining: 21.1s\n",
            "42:\tlearn: 0.4945240\ttotal: 942ms\tremaining: 21s\n",
            "43:\tlearn: 0.4922212\ttotal: 963ms\tremaining: 20.9s\n",
            "44:\tlearn: 0.4909046\ttotal: 981ms\tremaining: 20.8s\n",
            "45:\tlearn: 0.4899200\ttotal: 1s\tremaining: 20.8s\n",
            "46:\tlearn: 0.4889154\ttotal: 1.02s\tremaining: 20.7s\n",
            "47:\tlearn: 0.4877390\ttotal: 1.06s\tremaining: 21s\n",
            "48:\tlearn: 0.4861414\ttotal: 1.08s\tremaining: 20.9s\n",
            "49:\tlearn: 0.4848078\ttotal: 1.1s\tremaining: 21s\n",
            "50:\tlearn: 0.4837458\ttotal: 1.13s\tremaining: 21s\n",
            "51:\tlearn: 0.4828106\ttotal: 1.15s\tremaining: 20.9s\n",
            "52:\tlearn: 0.4809230\ttotal: 1.17s\tremaining: 20.9s\n",
            "53:\tlearn: 0.4798569\ttotal: 1.19s\tremaining: 20.9s\n",
            "54:\tlearn: 0.4790483\ttotal: 1.21s\tremaining: 20.8s\n",
            "55:\tlearn: 0.4781232\ttotal: 1.23s\tremaining: 20.8s\n",
            "56:\tlearn: 0.4773792\ttotal: 1.25s\tremaining: 20.7s\n",
            "57:\tlearn: 0.4767681\ttotal: 1.27s\tremaining: 20.7s\n",
            "58:\tlearn: 0.4761271\ttotal: 1.3s\tremaining: 20.7s\n",
            "59:\tlearn: 0.4752280\ttotal: 1.33s\tremaining: 20.8s\n",
            "60:\tlearn: 0.4743872\ttotal: 1.34s\tremaining: 20.7s\n",
            "61:\tlearn: 0.4734649\ttotal: 1.37s\tremaining: 20.7s\n",
            "62:\tlearn: 0.4721530\ttotal: 1.39s\tremaining: 20.7s\n",
            "63:\tlearn: 0.4714971\ttotal: 1.41s\tremaining: 20.6s\n",
            "64:\tlearn: 0.4708773\ttotal: 1.43s\tremaining: 20.6s\n",
            "65:\tlearn: 0.4699466\ttotal: 1.45s\tremaining: 20.6s\n",
            "66:\tlearn: 0.4689992\ttotal: 1.47s\tremaining: 20.5s\n",
            "67:\tlearn: 0.4680852\ttotal: 1.5s\tremaining: 20.6s\n",
            "68:\tlearn: 0.4664731\ttotal: 1.52s\tremaining: 20.5s\n",
            "69:\tlearn: 0.4657851\ttotal: 1.55s\tremaining: 20.6s\n",
            "70:\tlearn: 0.4652201\ttotal: 1.57s\tremaining: 20.5s\n",
            "71:\tlearn: 0.4646361\ttotal: 1.59s\tremaining: 20.5s\n",
            "72:\tlearn: 0.4641197\ttotal: 1.61s\tremaining: 20.5s\n",
            "73:\tlearn: 0.4637047\ttotal: 1.63s\tremaining: 20.4s\n",
            "74:\tlearn: 0.4629365\ttotal: 1.65s\tremaining: 20.4s\n",
            "75:\tlearn: 0.4623601\ttotal: 1.67s\tremaining: 20.4s\n",
            "76:\tlearn: 0.4617129\ttotal: 1.69s\tremaining: 20.3s\n",
            "77:\tlearn: 0.4611329\ttotal: 1.72s\tremaining: 20.3s\n",
            "78:\tlearn: 0.4601862\ttotal: 1.73s\tremaining: 20.2s\n",
            "79:\tlearn: 0.4595134\ttotal: 1.76s\tremaining: 20.3s\n",
            "80:\tlearn: 0.4589153\ttotal: 1.79s\tremaining: 20.3s\n",
            "81:\tlearn: 0.4584412\ttotal: 1.81s\tremaining: 20.3s\n",
            "82:\tlearn: 0.4579219\ttotal: 1.83s\tremaining: 20.2s\n",
            "83:\tlearn: 0.4573020\ttotal: 1.85s\tremaining: 20.2s\n",
            "84:\tlearn: 0.4565972\ttotal: 1.87s\tremaining: 20.2s\n",
            "85:\tlearn: 0.4559506\ttotal: 1.9s\tremaining: 20.2s\n",
            "86:\tlearn: 0.4555185\ttotal: 1.92s\tremaining: 20.1s\n",
            "87:\tlearn: 0.4547367\ttotal: 1.94s\tremaining: 20.1s\n",
            "88:\tlearn: 0.4540228\ttotal: 1.96s\tremaining: 20.1s\n",
            "89:\tlearn: 0.4533281\ttotal: 1.99s\tremaining: 20.1s\n",
            "90:\tlearn: 0.4526474\ttotal: 2.01s\tremaining: 20.1s\n",
            "91:\tlearn: 0.4516357\ttotal: 2.03s\tremaining: 20.1s\n",
            "92:\tlearn: 0.4513422\ttotal: 2.06s\tremaining: 20.1s\n",
            "93:\tlearn: 0.4508590\ttotal: 2.09s\tremaining: 20.1s\n",
            "94:\tlearn: 0.4503095\ttotal: 2.11s\tremaining: 20.1s\n",
            "95:\tlearn: 0.4494665\ttotal: 2.13s\tremaining: 20s\n",
            "96:\tlearn: 0.4489037\ttotal: 2.15s\tremaining: 20s\n",
            "97:\tlearn: 0.4483819\ttotal: 2.17s\tremaining: 20s\n",
            "98:\tlearn: 0.4478002\ttotal: 2.2s\tremaining: 20s\n",
            "99:\tlearn: 0.4471997\ttotal: 2.22s\tremaining: 20s\n",
            "100:\tlearn: 0.4466874\ttotal: 2.24s\tremaining: 19.9s\n",
            "101:\tlearn: 0.4462471\ttotal: 2.26s\tremaining: 19.9s\n",
            "102:\tlearn: 0.4457809\ttotal: 2.29s\tremaining: 19.9s\n",
            "103:\tlearn: 0.4453865\ttotal: 2.3s\tremaining: 19.8s\n",
            "104:\tlearn: 0.4450903\ttotal: 2.33s\tremaining: 19.8s\n",
            "105:\tlearn: 0.4434165\ttotal: 2.35s\tremaining: 19.8s\n",
            "106:\tlearn: 0.4428908\ttotal: 2.37s\tremaining: 19.8s\n",
            "107:\tlearn: 0.4423470\ttotal: 2.39s\tremaining: 19.8s\n",
            "108:\tlearn: 0.4417632\ttotal: 2.42s\tremaining: 19.8s\n",
            "109:\tlearn: 0.4413573\ttotal: 2.44s\tremaining: 19.7s\n",
            "110:\tlearn: 0.4409286\ttotal: 2.46s\tremaining: 19.7s\n",
            "111:\tlearn: 0.4403373\ttotal: 2.48s\tremaining: 19.7s\n",
            "112:\tlearn: 0.4398469\ttotal: 2.5s\tremaining: 19.6s\n",
            "113:\tlearn: 0.4393375\ttotal: 2.52s\tremaining: 19.6s\n",
            "114:\tlearn: 0.4389428\ttotal: 2.54s\tremaining: 19.5s\n",
            "115:\tlearn: 0.4386017\ttotal: 2.56s\tremaining: 19.5s\n",
            "116:\tlearn: 0.4381893\ttotal: 2.58s\tremaining: 19.5s\n",
            "117:\tlearn: 0.4377618\ttotal: 2.61s\tremaining: 19.5s\n",
            "118:\tlearn: 0.4373206\ttotal: 2.63s\tremaining: 19.5s\n",
            "119:\tlearn: 0.4369634\ttotal: 2.66s\tremaining: 19.5s\n",
            "120:\tlearn: 0.4365633\ttotal: 2.68s\tremaining: 19.4s\n",
            "121:\tlearn: 0.4361434\ttotal: 2.7s\tremaining: 19.4s\n",
            "122:\tlearn: 0.4357626\ttotal: 2.72s\tremaining: 19.4s\n",
            "123:\tlearn: 0.4352278\ttotal: 2.75s\tremaining: 19.4s\n",
            "124:\tlearn: 0.4348613\ttotal: 2.77s\tremaining: 19.4s\n",
            "125:\tlearn: 0.4344462\ttotal: 2.79s\tremaining: 19.3s\n",
            "126:\tlearn: 0.4340869\ttotal: 2.81s\tremaining: 19.3s\n",
            "127:\tlearn: 0.4337232\ttotal: 2.83s\tremaining: 19.3s\n",
            "128:\tlearn: 0.4334501\ttotal: 2.86s\tremaining: 19.3s\n",
            "129:\tlearn: 0.4330153\ttotal: 2.89s\tremaining: 19.3s\n",
            "130:\tlearn: 0.4326358\ttotal: 2.91s\tremaining: 19.3s\n",
            "131:\tlearn: 0.4321281\ttotal: 2.93s\tremaining: 19.3s\n",
            "132:\tlearn: 0.4317947\ttotal: 2.95s\tremaining: 19.2s\n",
            "133:\tlearn: 0.4314898\ttotal: 2.97s\tremaining: 19.2s\n",
            "134:\tlearn: 0.4309499\ttotal: 2.99s\tremaining: 19.2s\n",
            "135:\tlearn: 0.4297112\ttotal: 3.01s\tremaining: 19.1s\n",
            "136:\tlearn: 0.4292080\ttotal: 3.03s\tremaining: 19.1s\n",
            "137:\tlearn: 0.4288676\ttotal: 3.08s\tremaining: 19.2s\n",
            "138:\tlearn: 0.4284058\ttotal: 3.1s\tremaining: 19.2s\n",
            "139:\tlearn: 0.4280323\ttotal: 3.12s\tremaining: 19.2s\n",
            "140:\tlearn: 0.4275608\ttotal: 3.14s\tremaining: 19.1s\n",
            "141:\tlearn: 0.4270935\ttotal: 3.16s\tremaining: 19.1s\n",
            "142:\tlearn: 0.4266517\ttotal: 3.18s\tremaining: 19.1s\n",
            "143:\tlearn: 0.4262649\ttotal: 3.21s\tremaining: 19.1s\n",
            "144:\tlearn: 0.4260048\ttotal: 3.23s\tremaining: 19.1s\n",
            "145:\tlearn: 0.4255386\ttotal: 3.25s\tremaining: 19s\n",
            "146:\tlearn: 0.4251225\ttotal: 3.28s\tremaining: 19s\n",
            "147:\tlearn: 0.4248166\ttotal: 3.3s\tremaining: 19s\n",
            "148:\tlearn: 0.4245204\ttotal: 3.32s\tremaining: 19s\n",
            "149:\tlearn: 0.4239246\ttotal: 3.34s\tremaining: 18.9s\n",
            "150:\tlearn: 0.4237414\ttotal: 3.36s\tremaining: 18.9s\n",
            "151:\tlearn: 0.4233417\ttotal: 3.38s\tremaining: 18.9s\n",
            "152:\tlearn: 0.4230600\ttotal: 3.4s\tremaining: 18.8s\n",
            "153:\tlearn: 0.4224890\ttotal: 3.42s\tremaining: 18.8s\n",
            "154:\tlearn: 0.4222567\ttotal: 3.44s\tremaining: 18.8s\n",
            "155:\tlearn: 0.4218993\ttotal: 3.47s\tremaining: 18.8s\n",
            "156:\tlearn: 0.4215869\ttotal: 3.49s\tremaining: 18.8s\n",
            "157:\tlearn: 0.4212726\ttotal: 3.52s\tremaining: 18.7s\n",
            "158:\tlearn: 0.4209749\ttotal: 3.54s\tremaining: 18.7s\n",
            "159:\tlearn: 0.4207416\ttotal: 3.56s\tremaining: 18.7s\n",
            "160:\tlearn: 0.4204274\ttotal: 3.58s\tremaining: 18.7s\n",
            "161:\tlearn: 0.4200883\ttotal: 3.6s\tremaining: 18.6s\n",
            "162:\tlearn: 0.4197239\ttotal: 3.62s\tremaining: 18.6s\n",
            "163:\tlearn: 0.4193790\ttotal: 3.65s\tremaining: 18.6s\n",
            "164:\tlearn: 0.4191881\ttotal: 3.66s\tremaining: 18.5s\n",
            "165:\tlearn: 0.4188937\ttotal: 3.69s\tremaining: 18.5s\n",
            "166:\tlearn: 0.4184891\ttotal: 3.71s\tremaining: 18.5s\n",
            "167:\tlearn: 0.4182011\ttotal: 3.73s\tremaining: 18.5s\n",
            "168:\tlearn: 0.4178597\ttotal: 3.75s\tremaining: 18.5s\n",
            "169:\tlearn: 0.4175939\ttotal: 3.77s\tremaining: 18.4s\n",
            "170:\tlearn: 0.4171576\ttotal: 3.79s\tremaining: 18.4s\n",
            "171:\tlearn: 0.4168346\ttotal: 3.81s\tremaining: 18.4s\n",
            "172:\tlearn: 0.4164882\ttotal: 3.83s\tremaining: 18.3s\n",
            "173:\tlearn: 0.4162570\ttotal: 3.86s\tremaining: 18.3s\n",
            "174:\tlearn: 0.4159500\ttotal: 3.88s\tremaining: 18.3s\n",
            "175:\tlearn: 0.4156671\ttotal: 3.9s\tremaining: 18.3s\n",
            "176:\tlearn: 0.4153852\ttotal: 3.93s\tremaining: 18.3s\n",
            "177:\tlearn: 0.4150969\ttotal: 3.95s\tremaining: 18.3s\n",
            "178:\tlearn: 0.4146527\ttotal: 3.98s\tremaining: 18.2s\n",
            "179:\tlearn: 0.4144139\ttotal: 4s\tremaining: 18.2s\n",
            "180:\tlearn: 0.4140841\ttotal: 4.02s\tremaining: 18.2s\n",
            "181:\tlearn: 0.4138558\ttotal: 4.04s\tremaining: 18.1s\n",
            "182:\tlearn: 0.4133928\ttotal: 4.06s\tremaining: 18.1s\n",
            "183:\tlearn: 0.4131685\ttotal: 4.09s\tremaining: 18.1s\n",
            "184:\tlearn: 0.4128269\ttotal: 4.12s\tremaining: 18.1s\n",
            "185:\tlearn: 0.4126101\ttotal: 4.14s\tremaining: 18.1s\n",
            "186:\tlearn: 0.4091483\ttotal: 4.17s\tremaining: 18.1s\n",
            "187:\tlearn: 0.4088308\ttotal: 4.19s\tremaining: 18.1s\n",
            "188:\tlearn: 0.4086166\ttotal: 4.21s\tremaining: 18.1s\n",
            "189:\tlearn: 0.4082856\ttotal: 4.23s\tremaining: 18s\n",
            "190:\tlearn: 0.4080347\ttotal: 4.25s\tremaining: 18s\n",
            "191:\tlearn: 0.4077022\ttotal: 4.28s\tremaining: 18s\n",
            "192:\tlearn: 0.4074943\ttotal: 4.29s\tremaining: 18s\n",
            "193:\tlearn: 0.4071364\ttotal: 4.32s\tremaining: 17.9s\n",
            "194:\tlearn: 0.4068467\ttotal: 4.33s\tremaining: 17.9s\n",
            "195:\tlearn: 0.4065016\ttotal: 4.37s\tremaining: 17.9s\n",
            "196:\tlearn: 0.4062545\ttotal: 4.38s\tremaining: 17.9s\n",
            "197:\tlearn: 0.4059361\ttotal: 4.41s\tremaining: 17.9s\n",
            "198:\tlearn: 0.4056370\ttotal: 4.43s\tremaining: 17.8s\n",
            "199:\tlearn: 0.4053468\ttotal: 4.45s\tremaining: 17.8s\n",
            "200:\tlearn: 0.4051525\ttotal: 4.47s\tremaining: 17.8s\n",
            "201:\tlearn: 0.4049295\ttotal: 4.49s\tremaining: 17.7s\n",
            "202:\tlearn: 0.4045708\ttotal: 4.51s\tremaining: 17.7s\n",
            "203:\tlearn: 0.4043981\ttotal: 4.53s\tremaining: 17.7s\n",
            "204:\tlearn: 0.4040250\ttotal: 4.55s\tremaining: 17.7s\n",
            "205:\tlearn: 0.4038198\ttotal: 4.58s\tremaining: 17.7s\n",
            "206:\tlearn: 0.4035470\ttotal: 4.6s\tremaining: 17.6s\n",
            "207:\tlearn: 0.4032295\ttotal: 4.62s\tremaining: 17.6s\n",
            "208:\tlearn: 0.4029110\ttotal: 4.64s\tremaining: 17.6s\n",
            "209:\tlearn: 0.4026320\ttotal: 4.66s\tremaining: 17.5s\n",
            "210:\tlearn: 0.4024911\ttotal: 4.68s\tremaining: 17.5s\n",
            "211:\tlearn: 0.4023020\ttotal: 4.7s\tremaining: 17.5s\n",
            "212:\tlearn: 0.4020254\ttotal: 4.73s\tremaining: 17.5s\n",
            "213:\tlearn: 0.4017234\ttotal: 4.75s\tremaining: 17.4s\n",
            "214:\tlearn: 0.4014874\ttotal: 4.77s\tremaining: 17.4s\n",
            "215:\tlearn: 0.4012553\ttotal: 4.8s\tremaining: 17.4s\n",
            "216:\tlearn: 0.4008888\ttotal: 4.82s\tremaining: 17.4s\n",
            "217:\tlearn: 0.4006494\ttotal: 4.84s\tremaining: 17.4s\n",
            "218:\tlearn: 0.4003373\ttotal: 4.86s\tremaining: 17.3s\n",
            "219:\tlearn: 0.4000763\ttotal: 4.88s\tremaining: 17.3s\n",
            "220:\tlearn: 0.3997761\ttotal: 4.91s\tremaining: 17.3s\n",
            "221:\tlearn: 0.3995447\ttotal: 4.93s\tremaining: 17.3s\n",
            "222:\tlearn: 0.3992477\ttotal: 4.95s\tremaining: 17.3s\n",
            "223:\tlearn: 0.3990407\ttotal: 4.97s\tremaining: 17.2s\n",
            "224:\tlearn: 0.3988376\ttotal: 5s\tremaining: 17.2s\n",
            "225:\tlearn: 0.3986233\ttotal: 5.03s\tremaining: 17.2s\n",
            "226:\tlearn: 0.3982773\ttotal: 5.05s\tremaining: 17.2s\n",
            "227:\tlearn: 0.3980164\ttotal: 5.07s\tremaining: 17.2s\n",
            "228:\tlearn: 0.3976171\ttotal: 5.1s\tremaining: 17.2s\n",
            "229:\tlearn: 0.3973931\ttotal: 5.13s\tremaining: 17.2s\n",
            "230:\tlearn: 0.3971378\ttotal: 5.15s\tremaining: 17.1s\n",
            "231:\tlearn: 0.3965287\ttotal: 5.17s\tremaining: 17.1s\n",
            "232:\tlearn: 0.3962134\ttotal: 5.19s\tremaining: 17.1s\n",
            "233:\tlearn: 0.3958943\ttotal: 5.22s\tremaining: 17.1s\n",
            "234:\tlearn: 0.3956159\ttotal: 5.24s\tremaining: 17s\n",
            "235:\tlearn: 0.3952212\ttotal: 5.26s\tremaining: 17s\n",
            "236:\tlearn: 0.3949139\ttotal: 5.28s\tremaining: 17s\n",
            "237:\tlearn: 0.3945334\ttotal: 5.31s\tremaining: 17s\n",
            "238:\tlearn: 0.3942017\ttotal: 5.33s\tremaining: 17s\n",
            "239:\tlearn: 0.3938324\ttotal: 5.35s\tremaining: 16.9s\n",
            "240:\tlearn: 0.3936296\ttotal: 5.37s\tremaining: 16.9s\n",
            "241:\tlearn: 0.3933634\ttotal: 5.39s\tremaining: 16.9s\n",
            "242:\tlearn: 0.3930819\ttotal: 5.41s\tremaining: 16.9s\n",
            "243:\tlearn: 0.3928387\ttotal: 5.44s\tremaining: 16.9s\n",
            "244:\tlearn: 0.3925973\ttotal: 5.46s\tremaining: 16.8s\n",
            "245:\tlearn: 0.3923109\ttotal: 5.49s\tremaining: 16.8s\n",
            "246:\tlearn: 0.3920673\ttotal: 5.5s\tremaining: 16.8s\n",
            "247:\tlearn: 0.3918107\ttotal: 5.53s\tremaining: 16.8s\n",
            "248:\tlearn: 0.3915844\ttotal: 5.55s\tremaining: 16.7s\n",
            "249:\tlearn: 0.3913018\ttotal: 5.57s\tremaining: 16.7s\n",
            "250:\tlearn: 0.3909712\ttotal: 5.59s\tremaining: 16.7s\n",
            "251:\tlearn: 0.3907063\ttotal: 5.62s\tremaining: 16.7s\n",
            "252:\tlearn: 0.3903459\ttotal: 5.63s\tremaining: 16.6s\n",
            "253:\tlearn: 0.3900184\ttotal: 5.66s\tremaining: 16.6s\n",
            "254:\tlearn: 0.3897031\ttotal: 5.68s\tremaining: 16.6s\n",
            "255:\tlearn: 0.3895130\ttotal: 5.7s\tremaining: 16.6s\n",
            "256:\tlearn: 0.3891903\ttotal: 5.72s\tremaining: 16.6s\n",
            "257:\tlearn: 0.3889239\ttotal: 5.75s\tremaining: 16.5s\n",
            "258:\tlearn: 0.3886628\ttotal: 5.77s\tremaining: 16.5s\n",
            "259:\tlearn: 0.3882878\ttotal: 5.79s\tremaining: 16.5s\n",
            "260:\tlearn: 0.3879512\ttotal: 5.81s\tremaining: 16.5s\n",
            "261:\tlearn: 0.3875771\ttotal: 5.83s\tremaining: 16.4s\n",
            "262:\tlearn: 0.3872571\ttotal: 5.85s\tremaining: 16.4s\n",
            "263:\tlearn: 0.3869468\ttotal: 5.88s\tremaining: 16.4s\n",
            "264:\tlearn: 0.3866226\ttotal: 5.9s\tremaining: 16.4s\n",
            "265:\tlearn: 0.3863130\ttotal: 5.92s\tremaining: 16.3s\n",
            "266:\tlearn: 0.3859951\ttotal: 5.95s\tremaining: 16.3s\n",
            "267:\tlearn: 0.3857378\ttotal: 5.96s\tremaining: 16.3s\n",
            "268:\tlearn: 0.3854627\ttotal: 5.99s\tremaining: 16.3s\n",
            "269:\tlearn: 0.3852345\ttotal: 6s\tremaining: 16.2s\n",
            "270:\tlearn: 0.3848806\ttotal: 6.03s\tremaining: 16.2s\n",
            "271:\tlearn: 0.3846550\ttotal: 6.04s\tremaining: 16.2s\n",
            "272:\tlearn: 0.3844298\ttotal: 6.07s\tremaining: 16.2s\n",
            "273:\tlearn: 0.3841508\ttotal: 6.09s\tremaining: 16.1s\n",
            "274:\tlearn: 0.3839478\ttotal: 6.13s\tremaining: 16.2s\n",
            "275:\tlearn: 0.3836606\ttotal: 6.15s\tremaining: 16.1s\n",
            "276:\tlearn: 0.3833931\ttotal: 6.17s\tremaining: 16.1s\n",
            "277:\tlearn: 0.3830509\ttotal: 6.19s\tremaining: 16.1s\n",
            "278:\tlearn: 0.3827897\ttotal: 6.22s\tremaining: 16.1s\n",
            "279:\tlearn: 0.3825276\ttotal: 6.24s\tremaining: 16s\n",
            "280:\tlearn: 0.3822173\ttotal: 6.26s\tremaining: 16s\n",
            "281:\tlearn: 0.3818956\ttotal: 6.28s\tremaining: 16s\n",
            "282:\tlearn: 0.3816849\ttotal: 6.31s\tremaining: 16s\n",
            "283:\tlearn: 0.3814208\ttotal: 6.33s\tremaining: 16s\n",
            "284:\tlearn: 0.3812080\ttotal: 6.35s\tremaining: 15.9s\n",
            "285:\tlearn: 0.3809733\ttotal: 6.37s\tremaining: 15.9s\n",
            "286:\tlearn: 0.3807564\ttotal: 6.39s\tremaining: 15.9s\n",
            "287:\tlearn: 0.3804495\ttotal: 6.41s\tremaining: 15.9s\n",
            "288:\tlearn: 0.3802108\ttotal: 6.44s\tremaining: 15.8s\n",
            "289:\tlearn: 0.3800158\ttotal: 6.46s\tremaining: 15.8s\n",
            "290:\tlearn: 0.3797821\ttotal: 6.48s\tremaining: 15.8s\n",
            "291:\tlearn: 0.3794848\ttotal: 6.5s\tremaining: 15.8s\n",
            "292:\tlearn: 0.3792677\ttotal: 6.53s\tremaining: 15.8s\n",
            "293:\tlearn: 0.3789838\ttotal: 6.55s\tremaining: 15.7s\n",
            "294:\tlearn: 0.3787481\ttotal: 6.57s\tremaining: 15.7s\n",
            "295:\tlearn: 0.3784867\ttotal: 6.59s\tremaining: 15.7s\n",
            "296:\tlearn: 0.3781170\ttotal: 6.61s\tremaining: 15.7s\n",
            "297:\tlearn: 0.3778081\ttotal: 6.63s\tremaining: 15.6s\n",
            "298:\tlearn: 0.3776097\ttotal: 6.65s\tremaining: 15.6s\n",
            "299:\tlearn: 0.3774031\ttotal: 6.67s\tremaining: 15.6s\n",
            "300:\tlearn: 0.3770318\ttotal: 6.69s\tremaining: 15.5s\n",
            "301:\tlearn: 0.3767815\ttotal: 6.72s\tremaining: 15.5s\n",
            "302:\tlearn: 0.3765083\ttotal: 6.74s\tremaining: 15.5s\n",
            "303:\tlearn: 0.3763060\ttotal: 6.76s\tremaining: 15.5s\n",
            "304:\tlearn: 0.3761067\ttotal: 6.79s\tremaining: 15.5s\n",
            "305:\tlearn: 0.3759189\ttotal: 6.81s\tremaining: 15.4s\n",
            "306:\tlearn: 0.3756634\ttotal: 6.83s\tremaining: 15.4s\n",
            "307:\tlearn: 0.3754245\ttotal: 6.85s\tremaining: 15.4s\n",
            "308:\tlearn: 0.3751533\ttotal: 6.87s\tremaining: 15.4s\n",
            "309:\tlearn: 0.3748533\ttotal: 6.89s\tremaining: 15.3s\n",
            "310:\tlearn: 0.3746739\ttotal: 6.91s\tremaining: 15.3s\n",
            "311:\tlearn: 0.3744954\ttotal: 6.93s\tremaining: 15.3s\n",
            "312:\tlearn: 0.3741801\ttotal: 6.96s\tremaining: 15.3s\n",
            "313:\tlearn: 0.3739599\ttotal: 6.99s\tremaining: 15.3s\n",
            "314:\tlearn: 0.3737154\ttotal: 7.01s\tremaining: 15.2s\n",
            "315:\tlearn: 0.3735556\ttotal: 7.03s\tremaining: 15.2s\n",
            "316:\tlearn: 0.3733601\ttotal: 7.05s\tremaining: 15.2s\n",
            "317:\tlearn: 0.3730840\ttotal: 7.08s\tremaining: 15.2s\n",
            "318:\tlearn: 0.3727306\ttotal: 7.1s\tremaining: 15.2s\n",
            "319:\tlearn: 0.3724513\ttotal: 7.13s\tremaining: 15.2s\n",
            "320:\tlearn: 0.3721683\ttotal: 7.16s\tremaining: 15.1s\n",
            "321:\tlearn: 0.3719290\ttotal: 7.19s\tremaining: 15.1s\n",
            "322:\tlearn: 0.3717586\ttotal: 7.21s\tremaining: 15.1s\n",
            "323:\tlearn: 0.3714292\ttotal: 7.24s\tremaining: 15.1s\n",
            "324:\tlearn: 0.3710892\ttotal: 7.26s\tremaining: 15.1s\n",
            "325:\tlearn: 0.3708511\ttotal: 7.28s\tremaining: 15s\n",
            "326:\tlearn: 0.3706650\ttotal: 7.3s\tremaining: 15s\n",
            "327:\tlearn: 0.3704874\ttotal: 7.32s\tremaining: 15s\n",
            "328:\tlearn: 0.3702315\ttotal: 7.34s\tremaining: 15s\n",
            "329:\tlearn: 0.3699471\ttotal: 7.36s\tremaining: 14.9s\n",
            "330:\tlearn: 0.3696959\ttotal: 7.38s\tremaining: 14.9s\n",
            "331:\tlearn: 0.3695015\ttotal: 7.41s\tremaining: 14.9s\n",
            "332:\tlearn: 0.3692936\ttotal: 7.43s\tremaining: 14.9s\n",
            "333:\tlearn: 0.3691161\ttotal: 7.45s\tremaining: 14.8s\n",
            "334:\tlearn: 0.3690034\ttotal: 7.48s\tremaining: 14.8s\n",
            "335:\tlearn: 0.3687401\ttotal: 7.5s\tremaining: 14.8s\n",
            "336:\tlearn: 0.3684308\ttotal: 7.52s\tremaining: 14.8s\n",
            "337:\tlearn: 0.3681955\ttotal: 7.55s\tremaining: 14.8s\n",
            "338:\tlearn: 0.3679147\ttotal: 7.57s\tremaining: 14.8s\n",
            "339:\tlearn: 0.3676380\ttotal: 7.59s\tremaining: 14.7s\n",
            "340:\tlearn: 0.3674610\ttotal: 7.61s\tremaining: 14.7s\n",
            "341:\tlearn: 0.3671515\ttotal: 7.63s\tremaining: 14.7s\n",
            "342:\tlearn: 0.3669368\ttotal: 7.66s\tremaining: 14.7s\n",
            "343:\tlearn: 0.3666401\ttotal: 7.68s\tremaining: 14.6s\n",
            "344:\tlearn: 0.3664642\ttotal: 7.7s\tremaining: 14.6s\n",
            "345:\tlearn: 0.3661708\ttotal: 7.72s\tremaining: 14.6s\n",
            "346:\tlearn: 0.3659460\ttotal: 7.74s\tremaining: 14.6s\n",
            "347:\tlearn: 0.3656480\ttotal: 7.76s\tremaining: 14.5s\n",
            "348:\tlearn: 0.3654541\ttotal: 7.78s\tremaining: 14.5s\n",
            "349:\tlearn: 0.3651219\ttotal: 7.8s\tremaining: 14.5s\n",
            "350:\tlearn: 0.3648644\ttotal: 7.83s\tremaining: 14.5s\n",
            "351:\tlearn: 0.3645654\ttotal: 7.85s\tremaining: 14.5s\n",
            "352:\tlearn: 0.3643936\ttotal: 7.87s\tremaining: 14.4s\n",
            "353:\tlearn: 0.3642053\ttotal: 7.89s\tremaining: 14.4s\n",
            "354:\tlearn: 0.3637790\ttotal: 7.92s\tremaining: 14.4s\n",
            "355:\tlearn: 0.3635252\ttotal: 7.94s\tremaining: 14.4s\n",
            "356:\tlearn: 0.3633414\ttotal: 7.96s\tremaining: 14.3s\n",
            "357:\tlearn: 0.3630957\ttotal: 7.98s\tremaining: 14.3s\n",
            "358:\tlearn: 0.3628666\ttotal: 8s\tremaining: 14.3s\n",
            "359:\tlearn: 0.3626221\ttotal: 8.02s\tremaining: 14.3s\n",
            "360:\tlearn: 0.3623505\ttotal: 8.05s\tremaining: 14.3s\n",
            "361:\tlearn: 0.3620974\ttotal: 8.07s\tremaining: 14.2s\n",
            "362:\tlearn: 0.3619449\ttotal: 8.1s\tremaining: 14.2s\n",
            "363:\tlearn: 0.3617575\ttotal: 8.12s\tremaining: 14.2s\n",
            "364:\tlearn: 0.3615627\ttotal: 8.15s\tremaining: 14.2s\n",
            "365:\tlearn: 0.3613317\ttotal: 8.17s\tremaining: 14.2s\n",
            "366:\tlearn: 0.3611675\ttotal: 8.19s\tremaining: 14.1s\n",
            "367:\tlearn: 0.3609614\ttotal: 8.21s\tremaining: 14.1s\n",
            "368:\tlearn: 0.3606600\ttotal: 8.24s\tremaining: 14.1s\n",
            "369:\tlearn: 0.3604305\ttotal: 8.29s\tremaining: 14.1s\n",
            "370:\tlearn: 0.3602334\ttotal: 8.33s\tremaining: 14.1s\n",
            "371:\tlearn: 0.3600251\ttotal: 8.37s\tremaining: 14.1s\n",
            "372:\tlearn: 0.3598182\ttotal: 8.4s\tremaining: 14.1s\n",
            "373:\tlearn: 0.3595451\ttotal: 8.45s\tremaining: 14.1s\n",
            "374:\tlearn: 0.3592565\ttotal: 8.5s\tremaining: 14.2s\n",
            "375:\tlearn: 0.3589262\ttotal: 8.53s\tremaining: 14.2s\n",
            "376:\tlearn: 0.3586312\ttotal: 8.58s\tremaining: 14.2s\n",
            "377:\tlearn: 0.3584555\ttotal: 8.62s\tremaining: 14.2s\n",
            "378:\tlearn: 0.3581550\ttotal: 8.67s\tremaining: 14.2s\n",
            "379:\tlearn: 0.3579540\ttotal: 8.72s\tremaining: 14.2s\n",
            "380:\tlearn: 0.3577040\ttotal: 8.76s\tremaining: 14.2s\n",
            "381:\tlearn: 0.3575216\ttotal: 8.81s\tremaining: 14.2s\n",
            "382:\tlearn: 0.3572216\ttotal: 8.84s\tremaining: 14.2s\n",
            "383:\tlearn: 0.3570128\ttotal: 8.88s\tremaining: 14.2s\n",
            "384:\tlearn: 0.3568169\ttotal: 8.93s\tremaining: 14.3s\n",
            "385:\tlearn: 0.3566950\ttotal: 8.97s\tremaining: 14.3s\n",
            "386:\tlearn: 0.3565149\ttotal: 9.01s\tremaining: 14.3s\n",
            "387:\tlearn: 0.3563957\ttotal: 9.04s\tremaining: 14.3s\n",
            "388:\tlearn: 0.3562056\ttotal: 9.08s\tremaining: 14.3s\n",
            "389:\tlearn: 0.3558318\ttotal: 9.13s\tremaining: 14.3s\n",
            "390:\tlearn: 0.3556163\ttotal: 9.18s\tremaining: 14.3s\n",
            "391:\tlearn: 0.3553771\ttotal: 9.22s\tremaining: 14.3s\n",
            "392:\tlearn: 0.3551158\ttotal: 9.26s\tremaining: 14.3s\n",
            "393:\tlearn: 0.3548839\ttotal: 9.3s\tremaining: 14.3s\n",
            "394:\tlearn: 0.3546612\ttotal: 9.34s\tremaining: 14.3s\n",
            "395:\tlearn: 0.3544089\ttotal: 9.39s\tremaining: 14.3s\n",
            "396:\tlearn: 0.3541212\ttotal: 9.43s\tremaining: 14.3s\n",
            "397:\tlearn: 0.3539044\ttotal: 9.47s\tremaining: 14.3s\n",
            "398:\tlearn: 0.3536718\ttotal: 9.51s\tremaining: 14.3s\n",
            "399:\tlearn: 0.3535097\ttotal: 9.56s\tremaining: 14.3s\n",
            "400:\tlearn: 0.3532172\ttotal: 9.61s\tremaining: 14.3s\n",
            "401:\tlearn: 0.3528940\ttotal: 9.65s\tremaining: 14.4s\n",
            "402:\tlearn: 0.3527080\ttotal: 9.68s\tremaining: 14.3s\n",
            "403:\tlearn: 0.3524524\ttotal: 9.73s\tremaining: 14.4s\n",
            "404:\tlearn: 0.3522519\ttotal: 9.78s\tremaining: 14.4s\n",
            "405:\tlearn: 0.3521039\ttotal: 9.82s\tremaining: 14.4s\n",
            "406:\tlearn: 0.3519522\ttotal: 9.85s\tremaining: 14.4s\n",
            "407:\tlearn: 0.3517888\ttotal: 9.89s\tremaining: 14.4s\n",
            "408:\tlearn: 0.3516411\ttotal: 9.94s\tremaining: 14.4s\n",
            "409:\tlearn: 0.3513922\ttotal: 9.97s\tremaining: 14.4s\n",
            "410:\tlearn: 0.3511729\ttotal: 10s\tremaining: 14.4s\n",
            "411:\tlearn: 0.3509658\ttotal: 10.1s\tremaining: 14.4s\n",
            "412:\tlearn: 0.3507494\ttotal: 10.1s\tremaining: 14.4s\n",
            "413:\tlearn: 0.3505849\ttotal: 10.2s\tremaining: 14.4s\n",
            "414:\tlearn: 0.3503973\ttotal: 10.2s\tremaining: 14.4s\n",
            "415:\tlearn: 0.3501896\ttotal: 10.3s\tremaining: 14.4s\n",
            "416:\tlearn: 0.3499978\ttotal: 10.3s\tremaining: 14.4s\n",
            "417:\tlearn: 0.3497560\ttotal: 10.3s\tremaining: 14.4s\n",
            "418:\tlearn: 0.3495824\ttotal: 10.4s\tremaining: 14.4s\n",
            "419:\tlearn: 0.3493670\ttotal: 10.4s\tremaining: 14.4s\n",
            "420:\tlearn: 0.3491801\ttotal: 10.5s\tremaining: 14.4s\n",
            "421:\tlearn: 0.3490183\ttotal: 10.5s\tremaining: 14.4s\n",
            "422:\tlearn: 0.3487156\ttotal: 10.5s\tremaining: 14.3s\n",
            "423:\tlearn: 0.3485254\ttotal: 10.6s\tremaining: 14.3s\n",
            "424:\tlearn: 0.3483825\ttotal: 10.6s\tremaining: 14.3s\n",
            "425:\tlearn: 0.3480998\ttotal: 10.6s\tremaining: 14.3s\n",
            "426:\tlearn: 0.3479257\ttotal: 10.7s\tremaining: 14.3s\n",
            "427:\tlearn: 0.3476703\ttotal: 10.7s\tremaining: 14.3s\n",
            "428:\tlearn: 0.3474647\ttotal: 10.8s\tremaining: 14.3s\n",
            "429:\tlearn: 0.3471718\ttotal: 10.8s\tremaining: 14.3s\n",
            "430:\tlearn: 0.3470514\ttotal: 10.9s\tremaining: 14.3s\n",
            "431:\tlearn: 0.3468264\ttotal: 10.9s\tremaining: 14.3s\n",
            "432:\tlearn: 0.3466415\ttotal: 10.9s\tremaining: 14.3s\n",
            "433:\tlearn: 0.3464605\ttotal: 11s\tremaining: 14.3s\n",
            "434:\tlearn: 0.3461586\ttotal: 11s\tremaining: 14.3s\n",
            "435:\tlearn: 0.3459754\ttotal: 11s\tremaining: 14.3s\n",
            "436:\tlearn: 0.3456308\ttotal: 11.1s\tremaining: 14.3s\n",
            "437:\tlearn: 0.3453929\ttotal: 11.1s\tremaining: 14.3s\n",
            "438:\tlearn: 0.3452360\ttotal: 11.1s\tremaining: 14.2s\n",
            "439:\tlearn: 0.3449933\ttotal: 11.2s\tremaining: 14.2s\n",
            "440:\tlearn: 0.3448539\ttotal: 11.2s\tremaining: 14.2s\n",
            "441:\tlearn: 0.3446082\ttotal: 11.3s\tremaining: 14.2s\n",
            "442:\tlearn: 0.3443062\ttotal: 11.3s\tremaining: 14.2s\n",
            "443:\tlearn: 0.3441367\ttotal: 11.3s\tremaining: 14.2s\n",
            "444:\tlearn: 0.3438994\ttotal: 11.4s\tremaining: 14.2s\n",
            "445:\tlearn: 0.3437308\ttotal: 11.4s\tremaining: 14.2s\n",
            "446:\tlearn: 0.3436077\ttotal: 11.5s\tremaining: 14.2s\n",
            "447:\tlearn: 0.3433595\ttotal: 11.5s\tremaining: 14.2s\n",
            "448:\tlearn: 0.3430949\ttotal: 11.6s\tremaining: 14.2s\n",
            "449:\tlearn: 0.3428003\ttotal: 11.6s\tremaining: 14.2s\n",
            "450:\tlearn: 0.3426071\ttotal: 11.7s\tremaining: 14.2s\n",
            "451:\tlearn: 0.3423417\ttotal: 11.7s\tremaining: 14.2s\n",
            "452:\tlearn: 0.3421115\ttotal: 11.7s\tremaining: 14.2s\n",
            "453:\tlearn: 0.3419608\ttotal: 11.8s\tremaining: 14.2s\n",
            "454:\tlearn: 0.3417506\ttotal: 11.8s\tremaining: 14.2s\n",
            "455:\tlearn: 0.3415700\ttotal: 11.9s\tremaining: 14.2s\n",
            "456:\tlearn: 0.3414482\ttotal: 11.9s\tremaining: 14.1s\n",
            "457:\tlearn: 0.3413063\ttotal: 11.9s\tremaining: 14.1s\n",
            "458:\tlearn: 0.3411109\ttotal: 11.9s\tremaining: 14.1s\n",
            "459:\tlearn: 0.3409983\ttotal: 12s\tremaining: 14s\n",
            "460:\tlearn: 0.3407294\ttotal: 12s\tremaining: 14s\n",
            "461:\tlearn: 0.3404961\ttotal: 12s\tremaining: 14s\n",
            "462:\tlearn: 0.3403588\ttotal: 12s\tremaining: 13.9s\n",
            "463:\tlearn: 0.3401614\ttotal: 12s\tremaining: 13.9s\n",
            "464:\tlearn: 0.3400089\ttotal: 12.1s\tremaining: 13.9s\n",
            "465:\tlearn: 0.3397921\ttotal: 12.1s\tremaining: 13.9s\n",
            "466:\tlearn: 0.3395508\ttotal: 12.1s\tremaining: 13.8s\n",
            "467:\tlearn: 0.3393217\ttotal: 12.1s\tremaining: 13.8s\n",
            "468:\tlearn: 0.3391012\ttotal: 12.2s\tremaining: 13.8s\n",
            "469:\tlearn: 0.3389219\ttotal: 12.2s\tremaining: 13.7s\n",
            "470:\tlearn: 0.3386882\ttotal: 12.2s\tremaining: 13.7s\n",
            "471:\tlearn: 0.3385514\ttotal: 12.2s\tremaining: 13.7s\n",
            "472:\tlearn: 0.3383409\ttotal: 12.2s\tremaining: 13.6s\n",
            "473:\tlearn: 0.3381251\ttotal: 12.3s\tremaining: 13.6s\n",
            "474:\tlearn: 0.3380200\ttotal: 12.3s\tremaining: 13.6s\n",
            "475:\tlearn: 0.3378598\ttotal: 12.3s\tremaining: 13.6s\n",
            "476:\tlearn: 0.3377197\ttotal: 12.4s\tremaining: 13.6s\n",
            "477:\tlearn: 0.3375544\ttotal: 12.4s\tremaining: 13.5s\n",
            "478:\tlearn: 0.3373446\ttotal: 12.4s\tremaining: 13.5s\n",
            "479:\tlearn: 0.3372232\ttotal: 12.4s\tremaining: 13.5s\n",
            "480:\tlearn: 0.3370771\ttotal: 12.4s\tremaining: 13.4s\n",
            "481:\tlearn: 0.3368450\ttotal: 12.5s\tremaining: 13.4s\n",
            "482:\tlearn: 0.3366587\ttotal: 12.5s\tremaining: 13.4s\n",
            "483:\tlearn: 0.3364743\ttotal: 12.5s\tremaining: 13.3s\n",
            "484:\tlearn: 0.3362037\ttotal: 12.5s\tremaining: 13.3s\n",
            "485:\tlearn: 0.3360116\ttotal: 12.5s\tremaining: 13.3s\n",
            "486:\tlearn: 0.3358258\ttotal: 12.6s\tremaining: 13.2s\n",
            "487:\tlearn: 0.3356628\ttotal: 12.6s\tremaining: 13.2s\n",
            "488:\tlearn: 0.3354649\ttotal: 12.6s\tremaining: 13.2s\n",
            "489:\tlearn: 0.3352588\ttotal: 12.6s\tremaining: 13.1s\n",
            "490:\tlearn: 0.3350443\ttotal: 12.7s\tremaining: 13.1s\n",
            "491:\tlearn: 0.3347873\ttotal: 12.7s\tremaining: 13.1s\n",
            "492:\tlearn: 0.3345857\ttotal: 12.7s\tremaining: 13.1s\n",
            "493:\tlearn: 0.3344426\ttotal: 12.7s\tremaining: 13s\n",
            "494:\tlearn: 0.3342479\ttotal: 12.7s\tremaining: 13s\n",
            "495:\tlearn: 0.3341068\ttotal: 12.8s\tremaining: 13s\n",
            "496:\tlearn: 0.3339535\ttotal: 12.8s\tremaining: 12.9s\n",
            "497:\tlearn: 0.3336440\ttotal: 12.8s\tremaining: 12.9s\n",
            "498:\tlearn: 0.3334791\ttotal: 12.8s\tremaining: 12.9s\n",
            "499:\tlearn: 0.3333415\ttotal: 12.8s\tremaining: 12.8s\n",
            "500:\tlearn: 0.3331308\ttotal: 12.9s\tremaining: 12.8s\n",
            "501:\tlearn: 0.3329624\ttotal: 12.9s\tremaining: 12.8s\n",
            "502:\tlearn: 0.3327336\ttotal: 12.9s\tremaining: 12.7s\n",
            "503:\tlearn: 0.3325943\ttotal: 12.9s\tremaining: 12.7s\n",
            "504:\tlearn: 0.3323796\ttotal: 13s\tremaining: 12.7s\n",
            "505:\tlearn: 0.3322367\ttotal: 13s\tremaining: 12.7s\n",
            "506:\tlearn: 0.3320760\ttotal: 13s\tremaining: 12.6s\n",
            "507:\tlearn: 0.3319087\ttotal: 13s\tremaining: 12.6s\n",
            "508:\tlearn: 0.3316233\ttotal: 13s\tremaining: 12.6s\n",
            "509:\tlearn: 0.3314943\ttotal: 13.1s\tremaining: 12.6s\n",
            "510:\tlearn: 0.3312361\ttotal: 13.1s\tremaining: 12.5s\n",
            "511:\tlearn: 0.3310726\ttotal: 13.1s\tremaining: 12.5s\n",
            "512:\tlearn: 0.3309042\ttotal: 13.1s\tremaining: 12.5s\n",
            "513:\tlearn: 0.3307262\ttotal: 13.2s\tremaining: 12.4s\n",
            "514:\tlearn: 0.3304892\ttotal: 13.2s\tremaining: 12.4s\n",
            "515:\tlearn: 0.3303307\ttotal: 13.2s\tremaining: 12.4s\n",
            "516:\tlearn: 0.3301880\ttotal: 13.2s\tremaining: 12.4s\n",
            "517:\tlearn: 0.3299305\ttotal: 13.3s\tremaining: 12.3s\n",
            "518:\tlearn: 0.3296888\ttotal: 13.3s\tremaining: 12.3s\n",
            "519:\tlearn: 0.3293602\ttotal: 13.3s\tremaining: 12.3s\n",
            "520:\tlearn: 0.3291541\ttotal: 13.3s\tremaining: 12.3s\n",
            "521:\tlearn: 0.3289368\ttotal: 13.4s\tremaining: 12.2s\n",
            "522:\tlearn: 0.3287251\ttotal: 13.4s\tremaining: 12.2s\n",
            "523:\tlearn: 0.3286228\ttotal: 13.4s\tremaining: 12.2s\n",
            "524:\tlearn: 0.3284927\ttotal: 13.4s\tremaining: 12.1s\n",
            "525:\tlearn: 0.3283150\ttotal: 13.4s\tremaining: 12.1s\n",
            "526:\tlearn: 0.3281417\ttotal: 13.5s\tremaining: 12.1s\n",
            "527:\tlearn: 0.3280071\ttotal: 13.5s\tremaining: 12.1s\n",
            "528:\tlearn: 0.3278578\ttotal: 13.5s\tremaining: 12s\n",
            "529:\tlearn: 0.3276408\ttotal: 13.5s\tremaining: 12s\n",
            "530:\tlearn: 0.3274648\ttotal: 13.5s\tremaining: 12s\n",
            "531:\tlearn: 0.3273777\ttotal: 13.6s\tremaining: 11.9s\n",
            "532:\tlearn: 0.3272103\ttotal: 13.6s\tremaining: 11.9s\n",
            "533:\tlearn: 0.3271506\ttotal: 13.6s\tremaining: 11.9s\n",
            "534:\tlearn: 0.3269745\ttotal: 13.6s\tremaining: 11.9s\n",
            "535:\tlearn: 0.3267870\ttotal: 13.7s\tremaining: 11.8s\n",
            "536:\tlearn: 0.3266414\ttotal: 13.7s\tremaining: 11.8s\n",
            "537:\tlearn: 0.3264792\ttotal: 13.7s\tremaining: 11.8s\n",
            "538:\tlearn: 0.3261968\ttotal: 13.7s\tremaining: 11.7s\n",
            "539:\tlearn: 0.3259546\ttotal: 13.7s\tremaining: 11.7s\n",
            "540:\tlearn: 0.3258031\ttotal: 13.8s\tremaining: 11.7s\n",
            "541:\tlearn: 0.3256974\ttotal: 13.8s\tremaining: 11.7s\n",
            "542:\tlearn: 0.3255277\ttotal: 13.8s\tremaining: 11.6s\n",
            "543:\tlearn: 0.3253827\ttotal: 13.8s\tremaining: 11.6s\n",
            "544:\tlearn: 0.3252170\ttotal: 13.9s\tremaining: 11.6s\n",
            "545:\tlearn: 0.3250051\ttotal: 13.9s\tremaining: 11.5s\n",
            "546:\tlearn: 0.3247673\ttotal: 13.9s\tremaining: 11.5s\n",
            "547:\tlearn: 0.3245430\ttotal: 13.9s\tremaining: 11.5s\n",
            "548:\tlearn: 0.3243499\ttotal: 13.9s\tremaining: 11.5s\n",
            "549:\tlearn: 0.3242050\ttotal: 14s\tremaining: 11.4s\n",
            "550:\tlearn: 0.3240149\ttotal: 14s\tremaining: 11.4s\n",
            "551:\tlearn: 0.3239117\ttotal: 14s\tremaining: 11.4s\n",
            "552:\tlearn: 0.3236755\ttotal: 14s\tremaining: 11.3s\n",
            "553:\tlearn: 0.3235177\ttotal: 14.1s\tremaining: 11.3s\n",
            "554:\tlearn: 0.3233217\ttotal: 14.1s\tremaining: 11.3s\n",
            "555:\tlearn: 0.3231014\ttotal: 14.1s\tremaining: 11.3s\n",
            "556:\tlearn: 0.3228486\ttotal: 14.1s\tremaining: 11.2s\n",
            "557:\tlearn: 0.3226543\ttotal: 14.1s\tremaining: 11.2s\n",
            "558:\tlearn: 0.3225606\ttotal: 14.2s\tremaining: 11.2s\n",
            "559:\tlearn: 0.3224174\ttotal: 14.2s\tremaining: 11.1s\n",
            "560:\tlearn: 0.3222718\ttotal: 14.2s\tremaining: 11.1s\n",
            "561:\tlearn: 0.3220827\ttotal: 14.2s\tremaining: 11.1s\n",
            "562:\tlearn: 0.3218765\ttotal: 14.3s\tremaining: 11.1s\n",
            "563:\tlearn: 0.3217533\ttotal: 14.3s\tremaining: 11s\n",
            "564:\tlearn: 0.3215828\ttotal: 14.3s\tremaining: 11s\n",
            "565:\tlearn: 0.3214790\ttotal: 14.3s\tremaining: 11s\n",
            "566:\tlearn: 0.3213418\ttotal: 14.4s\tremaining: 11s\n",
            "567:\tlearn: 0.3210939\ttotal: 14.4s\tremaining: 10.9s\n",
            "568:\tlearn: 0.3208327\ttotal: 14.4s\tremaining: 10.9s\n",
            "569:\tlearn: 0.3206151\ttotal: 14.4s\tremaining: 10.9s\n",
            "570:\tlearn: 0.3204744\ttotal: 14.4s\tremaining: 10.9s\n",
            "571:\tlearn: 0.3202772\ttotal: 14.5s\tremaining: 10.8s\n",
            "572:\tlearn: 0.3200410\ttotal: 14.5s\tremaining: 10.8s\n",
            "573:\tlearn: 0.3198685\ttotal: 14.5s\tremaining: 10.8s\n",
            "574:\tlearn: 0.3197806\ttotal: 14.5s\tremaining: 10.7s\n",
            "575:\tlearn: 0.3195667\ttotal: 14.6s\tremaining: 10.7s\n",
            "576:\tlearn: 0.3194003\ttotal: 14.6s\tremaining: 10.7s\n",
            "577:\tlearn: 0.3191879\ttotal: 14.6s\tremaining: 10.7s\n",
            "578:\tlearn: 0.3190355\ttotal: 14.6s\tremaining: 10.6s\n",
            "579:\tlearn: 0.3189087\ttotal: 14.6s\tremaining: 10.6s\n",
            "580:\tlearn: 0.3186934\ttotal: 14.7s\tremaining: 10.6s\n",
            "581:\tlearn: 0.3184730\ttotal: 14.7s\tremaining: 10.6s\n",
            "582:\tlearn: 0.3183233\ttotal: 14.7s\tremaining: 10.5s\n",
            "583:\tlearn: 0.3182658\ttotal: 14.7s\tremaining: 10.5s\n",
            "584:\tlearn: 0.3180500\ttotal: 14.7s\tremaining: 10.5s\n",
            "585:\tlearn: 0.3177777\ttotal: 14.8s\tremaining: 10.4s\n",
            "586:\tlearn: 0.3175322\ttotal: 14.8s\tremaining: 10.4s\n",
            "587:\tlearn: 0.3173461\ttotal: 14.8s\tremaining: 10.4s\n",
            "588:\tlearn: 0.3171784\ttotal: 14.8s\tremaining: 10.4s\n",
            "589:\tlearn: 0.3168764\ttotal: 14.9s\tremaining: 10.3s\n",
            "590:\tlearn: 0.3166669\ttotal: 14.9s\tremaining: 10.3s\n",
            "591:\tlearn: 0.3164618\ttotal: 14.9s\tremaining: 10.3s\n",
            "592:\tlearn: 0.3162754\ttotal: 14.9s\tremaining: 10.2s\n",
            "593:\tlearn: 0.3160807\ttotal: 14.9s\tremaining: 10.2s\n",
            "594:\tlearn: 0.3158399\ttotal: 15s\tremaining: 10.2s\n",
            "595:\tlearn: 0.3156557\ttotal: 15s\tremaining: 10.2s\n",
            "596:\tlearn: 0.3155244\ttotal: 15s\tremaining: 10.1s\n",
            "597:\tlearn: 0.3153979\ttotal: 15s\tremaining: 10.1s\n",
            "598:\tlearn: 0.3152099\ttotal: 15.1s\tremaining: 10.1s\n",
            "599:\tlearn: 0.3150184\ttotal: 15.1s\tremaining: 10s\n",
            "600:\tlearn: 0.3149479\ttotal: 15.1s\tremaining: 10s\n",
            "601:\tlearn: 0.3147517\ttotal: 15.1s\tremaining: 10s\n",
            "602:\tlearn: 0.3146536\ttotal: 15.2s\tremaining: 9.97s\n",
            "603:\tlearn: 0.3146111\ttotal: 15.2s\tremaining: 9.95s\n",
            "604:\tlearn: 0.3144482\ttotal: 15.2s\tremaining: 9.92s\n",
            "605:\tlearn: 0.3142653\ttotal: 15.2s\tremaining: 9.89s\n",
            "606:\tlearn: 0.3140950\ttotal: 15.2s\tremaining: 9.86s\n",
            "607:\tlearn: 0.3139106\ttotal: 15.3s\tremaining: 9.84s\n",
            "608:\tlearn: 0.3138736\ttotal: 15.3s\tremaining: 9.81s\n",
            "609:\tlearn: 0.3137363\ttotal: 15.3s\tremaining: 9.78s\n",
            "610:\tlearn: 0.3136134\ttotal: 15.3s\tremaining: 9.77s\n",
            "611:\tlearn: 0.3134241\ttotal: 15.4s\tremaining: 9.74s\n",
            "612:\tlearn: 0.3132789\ttotal: 15.4s\tremaining: 9.71s\n",
            "613:\tlearn: 0.3130982\ttotal: 15.4s\tremaining: 9.68s\n",
            "614:\tlearn: 0.3129770\ttotal: 15.4s\tremaining: 9.65s\n",
            "615:\tlearn: 0.3128250\ttotal: 15.4s\tremaining: 9.63s\n",
            "616:\tlearn: 0.3125661\ttotal: 15.5s\tremaining: 9.6s\n",
            "617:\tlearn: 0.3124379\ttotal: 15.5s\tremaining: 9.57s\n",
            "618:\tlearn: 0.3122657\ttotal: 15.5s\tremaining: 9.54s\n",
            "619:\tlearn: 0.3120836\ttotal: 15.5s\tremaining: 9.52s\n",
            "620:\tlearn: 0.3118983\ttotal: 15.6s\tremaining: 9.49s\n",
            "621:\tlearn: 0.3117780\ttotal: 15.6s\tremaining: 9.47s\n",
            "622:\tlearn: 0.3115930\ttotal: 15.6s\tremaining: 9.44s\n",
            "623:\tlearn: 0.3114539\ttotal: 15.6s\tremaining: 9.41s\n",
            "624:\tlearn: 0.3113681\ttotal: 15.6s\tremaining: 9.39s\n",
            "625:\tlearn: 0.3112247\ttotal: 15.7s\tremaining: 9.36s\n",
            "626:\tlearn: 0.3109816\ttotal: 15.7s\tremaining: 9.33s\n",
            "627:\tlearn: 0.3108749\ttotal: 15.7s\tremaining: 9.3s\n",
            "628:\tlearn: 0.3107582\ttotal: 15.7s\tremaining: 9.28s\n",
            "629:\tlearn: 0.3105358\ttotal: 15.7s\tremaining: 9.25s\n",
            "630:\tlearn: 0.3103174\ttotal: 15.8s\tremaining: 9.23s\n",
            "631:\tlearn: 0.3101303\ttotal: 15.8s\tremaining: 9.2s\n",
            "632:\tlearn: 0.3099588\ttotal: 15.8s\tremaining: 9.17s\n",
            "633:\tlearn: 0.3098314\ttotal: 15.8s\tremaining: 9.14s\n",
            "634:\tlearn: 0.3097038\ttotal: 15.9s\tremaining: 9.12s\n",
            "635:\tlearn: 0.3095568\ttotal: 15.9s\tremaining: 9.09s\n",
            "636:\tlearn: 0.3092944\ttotal: 15.9s\tremaining: 9.06s\n",
            "637:\tlearn: 0.3090873\ttotal: 15.9s\tremaining: 9.04s\n",
            "638:\tlearn: 0.3088687\ttotal: 15.9s\tremaining: 9.01s\n",
            "639:\tlearn: 0.3087083\ttotal: 16s\tremaining: 8.98s\n",
            "640:\tlearn: 0.3085868\ttotal: 16s\tremaining: 8.96s\n",
            "641:\tlearn: 0.3084735\ttotal: 16s\tremaining: 8.94s\n",
            "642:\tlearn: 0.3083465\ttotal: 16s\tremaining: 8.91s\n",
            "643:\tlearn: 0.3081989\ttotal: 16.1s\tremaining: 8.88s\n",
            "644:\tlearn: 0.3080218\ttotal: 16.1s\tremaining: 8.85s\n",
            "645:\tlearn: 0.3079243\ttotal: 16.1s\tremaining: 8.83s\n",
            "646:\tlearn: 0.3078237\ttotal: 16.1s\tremaining: 8.8s\n",
            "647:\tlearn: 0.3076341\ttotal: 16.2s\tremaining: 8.77s\n",
            "648:\tlearn: 0.3074629\ttotal: 16.2s\tremaining: 8.75s\n",
            "649:\tlearn: 0.3072702\ttotal: 16.2s\tremaining: 8.72s\n",
            "650:\tlearn: 0.3071687\ttotal: 16.2s\tremaining: 8.7s\n",
            "651:\tlearn: 0.3069781\ttotal: 16.3s\tremaining: 8.67s\n",
            "652:\tlearn: 0.3068590\ttotal: 16.3s\tremaining: 8.65s\n",
            "653:\tlearn: 0.3067020\ttotal: 16.3s\tremaining: 8.62s\n",
            "654:\tlearn: 0.3064622\ttotal: 16.3s\tremaining: 8.59s\n",
            "655:\tlearn: 0.3063272\ttotal: 16.3s\tremaining: 8.57s\n",
            "656:\tlearn: 0.3062066\ttotal: 16.4s\tremaining: 8.54s\n",
            "657:\tlearn: 0.3060413\ttotal: 16.4s\tremaining: 8.52s\n",
            "658:\tlearn: 0.3058795\ttotal: 16.4s\tremaining: 8.49s\n",
            "659:\tlearn: 0.3057415\ttotal: 16.4s\tremaining: 8.47s\n",
            "660:\tlearn: 0.3056339\ttotal: 16.5s\tremaining: 8.44s\n",
            "661:\tlearn: 0.3054314\ttotal: 16.5s\tremaining: 8.41s\n",
            "662:\tlearn: 0.3052562\ttotal: 16.5s\tremaining: 8.38s\n",
            "663:\tlearn: 0.3052350\ttotal: 16.5s\tremaining: 8.36s\n",
            "664:\tlearn: 0.3050472\ttotal: 16.5s\tremaining: 8.33s\n",
            "665:\tlearn: 0.3049110\ttotal: 16.6s\tremaining: 8.3s\n",
            "666:\tlearn: 0.3046453\ttotal: 16.6s\tremaining: 8.28s\n",
            "667:\tlearn: 0.3045165\ttotal: 16.6s\tremaining: 8.25s\n",
            "668:\tlearn: 0.3043882\ttotal: 16.6s\tremaining: 8.23s\n",
            "669:\tlearn: 0.3043669\ttotal: 16.6s\tremaining: 8.2s\n",
            "670:\tlearn: 0.3041660\ttotal: 16.7s\tremaining: 8.17s\n",
            "671:\tlearn: 0.3040454\ttotal: 16.7s\tremaining: 8.14s\n",
            "672:\tlearn: 0.3038242\ttotal: 16.7s\tremaining: 8.12s\n",
            "673:\tlearn: 0.3037527\ttotal: 16.7s\tremaining: 8.09s\n",
            "674:\tlearn: 0.3035981\ttotal: 16.8s\tremaining: 8.06s\n",
            "675:\tlearn: 0.3035786\ttotal: 16.8s\tremaining: 8.04s\n",
            "676:\tlearn: 0.3033893\ttotal: 16.8s\tremaining: 8.01s\n",
            "677:\tlearn: 0.3033326\ttotal: 16.8s\tremaining: 7.99s\n",
            "678:\tlearn: 0.3031737\ttotal: 16.8s\tremaining: 7.96s\n",
            "679:\tlearn: 0.3030788\ttotal: 16.9s\tremaining: 7.94s\n",
            "680:\tlearn: 0.3029075\ttotal: 16.9s\tremaining: 7.91s\n",
            "681:\tlearn: 0.3027939\ttotal: 16.9s\tremaining: 7.88s\n",
            "682:\tlearn: 0.3026442\ttotal: 16.9s\tremaining: 7.86s\n",
            "683:\tlearn: 0.3024205\ttotal: 17s\tremaining: 7.83s\n",
            "684:\tlearn: 0.3023976\ttotal: 17s\tremaining: 7.8s\n",
            "685:\tlearn: 0.3021492\ttotal: 17s\tremaining: 7.78s\n",
            "686:\tlearn: 0.3020347\ttotal: 17s\tremaining: 7.75s\n",
            "687:\tlearn: 0.3018616\ttotal: 17s\tremaining: 7.73s\n",
            "688:\tlearn: 0.3016822\ttotal: 17.1s\tremaining: 7.7s\n",
            "689:\tlearn: 0.3015594\ttotal: 17.1s\tremaining: 7.68s\n",
            "690:\tlearn: 0.3013741\ttotal: 17.1s\tremaining: 7.65s\n",
            "691:\tlearn: 0.3012500\ttotal: 17.1s\tremaining: 7.63s\n",
            "692:\tlearn: 0.3010802\ttotal: 17.2s\tremaining: 7.6s\n",
            "693:\tlearn: 0.3009106\ttotal: 17.2s\tremaining: 7.57s\n",
            "694:\tlearn: 0.3008935\ttotal: 17.2s\tremaining: 7.55s\n",
            "695:\tlearn: 0.3007289\ttotal: 17.2s\tremaining: 7.52s\n",
            "696:\tlearn: 0.3006185\ttotal: 17.2s\tremaining: 7.5s\n",
            "697:\tlearn: 0.3004401\ttotal: 17.3s\tremaining: 7.47s\n",
            "698:\tlearn: 0.3002803\ttotal: 17.3s\tremaining: 7.45s\n",
            "699:\tlearn: 0.3001223\ttotal: 17.3s\tremaining: 7.42s\n",
            "700:\tlearn: 0.2999571\ttotal: 17.3s\tremaining: 7.4s\n",
            "701:\tlearn: 0.2997321\ttotal: 17.4s\tremaining: 7.38s\n",
            "702:\tlearn: 0.2995353\ttotal: 17.4s\tremaining: 7.35s\n",
            "703:\tlearn: 0.2993119\ttotal: 17.4s\tremaining: 7.32s\n",
            "704:\tlearn: 0.2991875\ttotal: 17.4s\tremaining: 7.3s\n",
            "705:\tlearn: 0.2990555\ttotal: 17.5s\tremaining: 7.27s\n",
            "706:\tlearn: 0.2988674\ttotal: 17.5s\tremaining: 7.25s\n",
            "707:\tlearn: 0.2987522\ttotal: 17.5s\tremaining: 7.22s\n",
            "708:\tlearn: 0.2985683\ttotal: 17.5s\tremaining: 7.2s\n",
            "709:\tlearn: 0.2984816\ttotal: 17.6s\tremaining: 7.17s\n",
            "710:\tlearn: 0.2983204\ttotal: 17.6s\tremaining: 7.14s\n",
            "711:\tlearn: 0.2981930\ttotal: 17.6s\tremaining: 7.12s\n",
            "712:\tlearn: 0.2980799\ttotal: 17.6s\tremaining: 7.09s\n",
            "713:\tlearn: 0.2979976\ttotal: 17.6s\tremaining: 7.07s\n",
            "714:\tlearn: 0.2978437\ttotal: 17.7s\tremaining: 7.04s\n",
            "715:\tlearn: 0.2977205\ttotal: 17.7s\tremaining: 7.02s\n",
            "716:\tlearn: 0.2976079\ttotal: 17.7s\tremaining: 6.99s\n",
            "717:\tlearn: 0.2974662\ttotal: 17.7s\tremaining: 6.96s\n",
            "718:\tlearn: 0.2973194\ttotal: 17.8s\tremaining: 6.94s\n",
            "719:\tlearn: 0.2971489\ttotal: 17.8s\tremaining: 6.91s\n",
            "720:\tlearn: 0.2969960\ttotal: 17.8s\tremaining: 6.88s\n",
            "721:\tlearn: 0.2968586\ttotal: 17.8s\tremaining: 6.86s\n",
            "722:\tlearn: 0.2967289\ttotal: 17.8s\tremaining: 6.83s\n",
            "723:\tlearn: 0.2966183\ttotal: 17.9s\tremaining: 6.81s\n",
            "724:\tlearn: 0.2964819\ttotal: 17.9s\tremaining: 6.78s\n",
            "725:\tlearn: 0.2962562\ttotal: 17.9s\tremaining: 6.76s\n",
            "726:\tlearn: 0.2961428\ttotal: 17.9s\tremaining: 6.73s\n",
            "727:\tlearn: 0.2959199\ttotal: 18s\tremaining: 6.71s\n",
            "728:\tlearn: 0.2957492\ttotal: 18s\tremaining: 6.68s\n",
            "729:\tlearn: 0.2955653\ttotal: 18s\tremaining: 6.66s\n",
            "730:\tlearn: 0.2954392\ttotal: 18s\tremaining: 6.63s\n",
            "731:\tlearn: 0.2953694\ttotal: 18s\tremaining: 6.6s\n",
            "732:\tlearn: 0.2952297\ttotal: 18.1s\tremaining: 6.58s\n",
            "733:\tlearn: 0.2949682\ttotal: 18.1s\tremaining: 6.55s\n",
            "734:\tlearn: 0.2949470\ttotal: 18.1s\tremaining: 6.53s\n",
            "735:\tlearn: 0.2948000\ttotal: 18.1s\tremaining: 6.51s\n",
            "736:\tlearn: 0.2946231\ttotal: 18.2s\tremaining: 6.48s\n",
            "737:\tlearn: 0.2945080\ttotal: 18.2s\tremaining: 6.46s\n",
            "738:\tlearn: 0.2944104\ttotal: 18.2s\tremaining: 6.43s\n",
            "739:\tlearn: 0.2942557\ttotal: 18.2s\tremaining: 6.4s\n",
            "740:\tlearn: 0.2940399\ttotal: 18.2s\tremaining: 6.38s\n",
            "741:\tlearn: 0.2939069\ttotal: 18.3s\tremaining: 6.35s\n",
            "742:\tlearn: 0.2937300\ttotal: 18.3s\tremaining: 6.33s\n",
            "743:\tlearn: 0.2936264\ttotal: 18.3s\tremaining: 6.3s\n",
            "744:\tlearn: 0.2935399\ttotal: 18.3s\tremaining: 6.28s\n",
            "745:\tlearn: 0.2934233\ttotal: 18.4s\tremaining: 6.25s\n",
            "746:\tlearn: 0.2932699\ttotal: 18.4s\tremaining: 6.23s\n",
            "747:\tlearn: 0.2931486\ttotal: 18.4s\tremaining: 6.2s\n",
            "748:\tlearn: 0.2930642\ttotal: 18.4s\tremaining: 6.18s\n",
            "749:\tlearn: 0.2928962\ttotal: 18.5s\tremaining: 6.15s\n",
            "750:\tlearn: 0.2927013\ttotal: 18.5s\tremaining: 6.13s\n",
            "751:\tlearn: 0.2924755\ttotal: 18.5s\tremaining: 6.1s\n",
            "752:\tlearn: 0.2923741\ttotal: 18.5s\tremaining: 6.08s\n",
            "753:\tlearn: 0.2922085\ttotal: 18.6s\tremaining: 6.05s\n",
            "754:\tlearn: 0.2920371\ttotal: 18.6s\tremaining: 6.03s\n",
            "755:\tlearn: 0.2918105\ttotal: 18.6s\tremaining: 6s\n",
            "756:\tlearn: 0.2917097\ttotal: 18.6s\tremaining: 5.98s\n",
            "757:\tlearn: 0.2915777\ttotal: 18.6s\tremaining: 5.95s\n",
            "758:\tlearn: 0.2913160\ttotal: 18.7s\tremaining: 5.92s\n",
            "759:\tlearn: 0.2912413\ttotal: 18.7s\tremaining: 5.9s\n",
            "760:\tlearn: 0.2911078\ttotal: 18.7s\tremaining: 5.87s\n",
            "761:\tlearn: 0.2908693\ttotal: 18.7s\tremaining: 5.85s\n",
            "762:\tlearn: 0.2907666\ttotal: 18.7s\tremaining: 5.82s\n",
            "763:\tlearn: 0.2906044\ttotal: 18.8s\tremaining: 5.8s\n",
            "764:\tlearn: 0.2904486\ttotal: 18.8s\tremaining: 5.77s\n",
            "765:\tlearn: 0.2902619\ttotal: 18.8s\tremaining: 5.75s\n",
            "766:\tlearn: 0.2900854\ttotal: 18.8s\tremaining: 5.72s\n",
            "767:\tlearn: 0.2898709\ttotal: 18.8s\tremaining: 5.69s\n",
            "768:\tlearn: 0.2897588\ttotal: 18.9s\tremaining: 5.67s\n",
            "769:\tlearn: 0.2896554\ttotal: 18.9s\tremaining: 5.64s\n",
            "770:\tlearn: 0.2895104\ttotal: 18.9s\tremaining: 5.62s\n",
            "771:\tlearn: 0.2893755\ttotal: 18.9s\tremaining: 5.59s\n",
            "772:\tlearn: 0.2891007\ttotal: 19s\tremaining: 5.57s\n",
            "773:\tlearn: 0.2889992\ttotal: 19s\tremaining: 5.55s\n",
            "774:\tlearn: 0.2888953\ttotal: 19s\tremaining: 5.52s\n",
            "775:\tlearn: 0.2886831\ttotal: 19s\tremaining: 5.49s\n",
            "776:\tlearn: 0.2885815\ttotal: 19.1s\tremaining: 5.47s\n",
            "777:\tlearn: 0.2885606\ttotal: 19.1s\tremaining: 5.44s\n",
            "778:\tlearn: 0.2884369\ttotal: 19.1s\tremaining: 5.42s\n",
            "779:\tlearn: 0.2883571\ttotal: 19.1s\tremaining: 5.39s\n",
            "780:\tlearn: 0.2881491\ttotal: 19.1s\tremaining: 5.37s\n",
            "781:\tlearn: 0.2879951\ttotal: 19.2s\tremaining: 5.34s\n",
            "782:\tlearn: 0.2878335\ttotal: 19.2s\tremaining: 5.32s\n",
            "783:\tlearn: 0.2876734\ttotal: 19.2s\tremaining: 5.29s\n",
            "784:\tlearn: 0.2875407\ttotal: 19.2s\tremaining: 5.27s\n",
            "785:\tlearn: 0.2874346\ttotal: 19.3s\tremaining: 5.24s\n",
            "786:\tlearn: 0.2873462\ttotal: 19.3s\tremaining: 5.22s\n",
            "787:\tlearn: 0.2872220\ttotal: 19.3s\tremaining: 5.19s\n",
            "788:\tlearn: 0.2871480\ttotal: 19.3s\tremaining: 5.17s\n",
            "789:\tlearn: 0.2870489\ttotal: 19.3s\tremaining: 5.14s\n",
            "790:\tlearn: 0.2869514\ttotal: 19.4s\tremaining: 5.11s\n",
            "791:\tlearn: 0.2867937\ttotal: 19.4s\tremaining: 5.09s\n",
            "792:\tlearn: 0.2866093\ttotal: 19.4s\tremaining: 5.07s\n",
            "793:\tlearn: 0.2864570\ttotal: 19.4s\tremaining: 5.04s\n",
            "794:\tlearn: 0.2863302\ttotal: 19.5s\tremaining: 5.02s\n",
            "795:\tlearn: 0.2862478\ttotal: 19.5s\tremaining: 4.99s\n",
            "796:\tlearn: 0.2861089\ttotal: 19.5s\tremaining: 4.97s\n",
            "797:\tlearn: 0.2859799\ttotal: 19.5s\tremaining: 4.94s\n",
            "798:\tlearn: 0.2859149\ttotal: 19.6s\tremaining: 4.92s\n",
            "799:\tlearn: 0.2857783\ttotal: 19.6s\tremaining: 4.89s\n",
            "800:\tlearn: 0.2857006\ttotal: 19.6s\tremaining: 4.87s\n",
            "801:\tlearn: 0.2855247\ttotal: 19.6s\tremaining: 4.84s\n",
            "802:\tlearn: 0.2853965\ttotal: 19.6s\tremaining: 4.82s\n",
            "803:\tlearn: 0.2852755\ttotal: 19.7s\tremaining: 4.79s\n",
            "804:\tlearn: 0.2850968\ttotal: 19.7s\tremaining: 4.77s\n",
            "805:\tlearn: 0.2849833\ttotal: 19.7s\tremaining: 4.74s\n",
            "806:\tlearn: 0.2849677\ttotal: 19.7s\tremaining: 4.72s\n",
            "807:\tlearn: 0.2848995\ttotal: 19.7s\tremaining: 4.69s\n",
            "808:\tlearn: 0.2847003\ttotal: 19.8s\tremaining: 4.67s\n",
            "809:\tlearn: 0.2846285\ttotal: 19.8s\tremaining: 4.64s\n",
            "810:\tlearn: 0.2844956\ttotal: 19.8s\tremaining: 4.62s\n",
            "811:\tlearn: 0.2843813\ttotal: 19.8s\tremaining: 4.59s\n",
            "812:\tlearn: 0.2842848\ttotal: 19.9s\tremaining: 4.57s\n",
            "813:\tlearn: 0.2841787\ttotal: 19.9s\tremaining: 4.54s\n",
            "814:\tlearn: 0.2840061\ttotal: 19.9s\tremaining: 4.52s\n",
            "815:\tlearn: 0.2838903\ttotal: 19.9s\tremaining: 4.49s\n",
            "816:\tlearn: 0.2837545\ttotal: 19.9s\tremaining: 4.47s\n",
            "817:\tlearn: 0.2836676\ttotal: 20s\tremaining: 4.44s\n",
            "818:\tlearn: 0.2835397\ttotal: 20s\tremaining: 4.42s\n",
            "819:\tlearn: 0.2833561\ttotal: 20s\tremaining: 4.39s\n",
            "820:\tlearn: 0.2832762\ttotal: 20s\tremaining: 4.37s\n",
            "821:\tlearn: 0.2831835\ttotal: 20.1s\tremaining: 4.34s\n",
            "822:\tlearn: 0.2830319\ttotal: 20.1s\tremaining: 4.32s\n",
            "823:\tlearn: 0.2829202\ttotal: 20.1s\tremaining: 4.29s\n",
            "824:\tlearn: 0.2827928\ttotal: 20.1s\tremaining: 4.27s\n",
            "825:\tlearn: 0.2825651\ttotal: 20.1s\tremaining: 4.24s\n",
            "826:\tlearn: 0.2824176\ttotal: 20.2s\tremaining: 4.22s\n",
            "827:\tlearn: 0.2822732\ttotal: 20.2s\tremaining: 4.2s\n",
            "828:\tlearn: 0.2821634\ttotal: 20.2s\tremaining: 4.17s\n",
            "829:\tlearn: 0.2819456\ttotal: 20.2s\tremaining: 4.14s\n",
            "830:\tlearn: 0.2818702\ttotal: 20.3s\tremaining: 4.12s\n",
            "831:\tlearn: 0.2816922\ttotal: 20.3s\tremaining: 4.1s\n",
            "832:\tlearn: 0.2815702\ttotal: 20.3s\tremaining: 4.07s\n",
            "833:\tlearn: 0.2815509\ttotal: 20.3s\tremaining: 4.04s\n",
            "834:\tlearn: 0.2814142\ttotal: 20.3s\tremaining: 4.02s\n",
            "835:\tlearn: 0.2812277\ttotal: 20.4s\tremaining: 4s\n",
            "836:\tlearn: 0.2810869\ttotal: 20.4s\tremaining: 3.97s\n",
            "837:\tlearn: 0.2809058\ttotal: 20.4s\tremaining: 3.95s\n",
            "838:\tlearn: 0.2806873\ttotal: 20.5s\tremaining: 3.92s\n",
            "839:\tlearn: 0.2805957\ttotal: 20.5s\tremaining: 3.9s\n",
            "840:\tlearn: 0.2804505\ttotal: 20.5s\tremaining: 3.88s\n",
            "841:\tlearn: 0.2802888\ttotal: 20.5s\tremaining: 3.85s\n",
            "842:\tlearn: 0.2801622\ttotal: 20.5s\tremaining: 3.83s\n",
            "843:\tlearn: 0.2799328\ttotal: 20.6s\tremaining: 3.8s\n",
            "844:\tlearn: 0.2798872\ttotal: 20.6s\tremaining: 3.78s\n",
            "845:\tlearn: 0.2797601\ttotal: 20.6s\tremaining: 3.75s\n",
            "846:\tlearn: 0.2796476\ttotal: 20.6s\tremaining: 3.73s\n",
            "847:\tlearn: 0.2795038\ttotal: 20.6s\tremaining: 3.7s\n",
            "848:\tlearn: 0.2793575\ttotal: 20.7s\tremaining: 3.68s\n",
            "849:\tlearn: 0.2792483\ttotal: 20.7s\tremaining: 3.65s\n",
            "850:\tlearn: 0.2791406\ttotal: 20.7s\tremaining: 3.63s\n",
            "851:\tlearn: 0.2790284\ttotal: 20.7s\tremaining: 3.6s\n",
            "852:\tlearn: 0.2789004\ttotal: 20.8s\tremaining: 3.58s\n",
            "853:\tlearn: 0.2787089\ttotal: 20.8s\tremaining: 3.55s\n",
            "854:\tlearn: 0.2786084\ttotal: 20.8s\tremaining: 3.53s\n",
            "855:\tlearn: 0.2785055\ttotal: 20.8s\tremaining: 3.5s\n",
            "856:\tlearn: 0.2783557\ttotal: 20.8s\tremaining: 3.48s\n",
            "857:\tlearn: 0.2782855\ttotal: 20.9s\tremaining: 3.45s\n",
            "858:\tlearn: 0.2780766\ttotal: 20.9s\tremaining: 3.43s\n",
            "859:\tlearn: 0.2779758\ttotal: 20.9s\tremaining: 3.4s\n",
            "860:\tlearn: 0.2778899\ttotal: 20.9s\tremaining: 3.38s\n",
            "861:\tlearn: 0.2778224\ttotal: 21s\tremaining: 3.35s\n",
            "862:\tlearn: 0.2777114\ttotal: 21s\tremaining: 3.33s\n",
            "863:\tlearn: 0.2775244\ttotal: 21s\tremaining: 3.31s\n",
            "864:\tlearn: 0.2773579\ttotal: 21s\tremaining: 3.28s\n",
            "865:\tlearn: 0.2773375\ttotal: 21s\tremaining: 3.26s\n",
            "866:\tlearn: 0.2771232\ttotal: 21.1s\tremaining: 3.23s\n",
            "867:\tlearn: 0.2769881\ttotal: 21.1s\tremaining: 3.21s\n",
            "868:\tlearn: 0.2768544\ttotal: 21.1s\tremaining: 3.18s\n",
            "869:\tlearn: 0.2767371\ttotal: 21.1s\tremaining: 3.16s\n",
            "870:\tlearn: 0.2766661\ttotal: 21.2s\tremaining: 3.13s\n",
            "871:\tlearn: 0.2765487\ttotal: 21.2s\tremaining: 3.11s\n",
            "872:\tlearn: 0.2764227\ttotal: 21.2s\tremaining: 3.08s\n",
            "873:\tlearn: 0.2762794\ttotal: 21.2s\tremaining: 3.06s\n",
            "874:\tlearn: 0.2762068\ttotal: 21.2s\tremaining: 3.04s\n",
            "875:\tlearn: 0.2760798\ttotal: 21.3s\tremaining: 3.01s\n",
            "876:\tlearn: 0.2759421\ttotal: 21.3s\tremaining: 2.99s\n",
            "877:\tlearn: 0.2757585\ttotal: 21.3s\tremaining: 2.96s\n",
            "878:\tlearn: 0.2756449\ttotal: 21.3s\tremaining: 2.94s\n",
            "879:\tlearn: 0.2755144\ttotal: 21.4s\tremaining: 2.91s\n",
            "880:\tlearn: 0.2754117\ttotal: 21.4s\tremaining: 2.89s\n",
            "881:\tlearn: 0.2752721\ttotal: 21.4s\tremaining: 2.86s\n",
            "882:\tlearn: 0.2751680\ttotal: 21.4s\tremaining: 2.84s\n",
            "883:\tlearn: 0.2750073\ttotal: 21.5s\tremaining: 2.82s\n",
            "884:\tlearn: 0.2748637\ttotal: 21.5s\tremaining: 2.79s\n",
            "885:\tlearn: 0.2746851\ttotal: 21.5s\tremaining: 2.77s\n",
            "886:\tlearn: 0.2745247\ttotal: 21.5s\tremaining: 2.74s\n",
            "887:\tlearn: 0.2744057\ttotal: 21.5s\tremaining: 2.72s\n",
            "888:\tlearn: 0.2742890\ttotal: 21.6s\tremaining: 2.69s\n",
            "889:\tlearn: 0.2742767\ttotal: 21.6s\tremaining: 2.67s\n",
            "890:\tlearn: 0.2741904\ttotal: 21.6s\tremaining: 2.64s\n",
            "891:\tlearn: 0.2740794\ttotal: 21.6s\tremaining: 2.62s\n",
            "892:\tlearn: 0.2739811\ttotal: 21.7s\tremaining: 2.6s\n",
            "893:\tlearn: 0.2738536\ttotal: 21.7s\tremaining: 2.57s\n",
            "894:\tlearn: 0.2737039\ttotal: 21.7s\tremaining: 2.54s\n",
            "895:\tlearn: 0.2735013\ttotal: 21.7s\tremaining: 2.52s\n",
            "896:\tlearn: 0.2733790\ttotal: 21.8s\tremaining: 2.5s\n",
            "897:\tlearn: 0.2732597\ttotal: 21.8s\tremaining: 2.48s\n",
            "898:\tlearn: 0.2731240\ttotal: 21.9s\tremaining: 2.46s\n",
            "899:\tlearn: 0.2730139\ttotal: 21.9s\tremaining: 2.43s\n",
            "900:\tlearn: 0.2729113\ttotal: 21.9s\tremaining: 2.41s\n",
            "901:\tlearn: 0.2728197\ttotal: 22s\tremaining: 2.39s\n",
            "902:\tlearn: 0.2726713\ttotal: 22s\tremaining: 2.36s\n",
            "903:\tlearn: 0.2725490\ttotal: 22s\tremaining: 2.34s\n",
            "904:\tlearn: 0.2724129\ttotal: 22.1s\tremaining: 2.32s\n",
            "905:\tlearn: 0.2721976\ttotal: 22.1s\tremaining: 2.29s\n",
            "906:\tlearn: 0.2720608\ttotal: 22.2s\tremaining: 2.27s\n",
            "907:\tlearn: 0.2720127\ttotal: 22.2s\tremaining: 2.25s\n",
            "908:\tlearn: 0.2719993\ttotal: 22.3s\tremaining: 2.23s\n",
            "909:\tlearn: 0.2718835\ttotal: 22.3s\tremaining: 2.21s\n",
            "910:\tlearn: 0.2718735\ttotal: 22.3s\tremaining: 2.18s\n",
            "911:\tlearn: 0.2717527\ttotal: 22.4s\tremaining: 2.16s\n",
            "912:\tlearn: 0.2716115\ttotal: 22.4s\tremaining: 2.14s\n",
            "913:\tlearn: 0.2715287\ttotal: 22.5s\tremaining: 2.11s\n",
            "914:\tlearn: 0.2713827\ttotal: 22.5s\tremaining: 2.09s\n",
            "915:\tlearn: 0.2711771\ttotal: 22.6s\tremaining: 2.07s\n",
            "916:\tlearn: 0.2710355\ttotal: 22.6s\tremaining: 2.04s\n",
            "917:\tlearn: 0.2709818\ttotal: 22.6s\tremaining: 2.02s\n",
            "918:\tlearn: 0.2708635\ttotal: 22.7s\tremaining: 2s\n",
            "919:\tlearn: 0.2707059\ttotal: 22.7s\tremaining: 1.98s\n",
            "920:\tlearn: 0.2705601\ttotal: 22.8s\tremaining: 1.95s\n",
            "921:\tlearn: 0.2704432\ttotal: 22.8s\tremaining: 1.93s\n",
            "922:\tlearn: 0.2703556\ttotal: 22.9s\tremaining: 1.91s\n",
            "923:\tlearn: 0.2702333\ttotal: 22.9s\tremaining: 1.88s\n",
            "924:\tlearn: 0.2700914\ttotal: 22.9s\tremaining: 1.86s\n",
            "925:\tlearn: 0.2698856\ttotal: 23s\tremaining: 1.84s\n",
            "926:\tlearn: 0.2697468\ttotal: 23s\tremaining: 1.81s\n",
            "927:\tlearn: 0.2697056\ttotal: 23.1s\tremaining: 1.79s\n",
            "928:\tlearn: 0.2695315\ttotal: 23.1s\tremaining: 1.76s\n",
            "929:\tlearn: 0.2693752\ttotal: 23.1s\tremaining: 1.74s\n",
            "930:\tlearn: 0.2691440\ttotal: 23.2s\tremaining: 1.72s\n",
            "931:\tlearn: 0.2690104\ttotal: 23.2s\tremaining: 1.7s\n",
            "932:\tlearn: 0.2688767\ttotal: 23.3s\tremaining: 1.67s\n",
            "933:\tlearn: 0.2687464\ttotal: 23.3s\tremaining: 1.65s\n",
            "934:\tlearn: 0.2685809\ttotal: 23.4s\tremaining: 1.62s\n",
            "935:\tlearn: 0.2684765\ttotal: 23.4s\tremaining: 1.6s\n",
            "936:\tlearn: 0.2683744\ttotal: 23.5s\tremaining: 1.58s\n",
            "937:\tlearn: 0.2682813\ttotal: 23.5s\tremaining: 1.55s\n",
            "938:\tlearn: 0.2680494\ttotal: 23.6s\tremaining: 1.53s\n",
            "939:\tlearn: 0.2679822\ttotal: 23.6s\tremaining: 1.51s\n",
            "940:\tlearn: 0.2678693\ttotal: 23.6s\tremaining: 1.48s\n",
            "941:\tlearn: 0.2677632\ttotal: 23.7s\tremaining: 1.46s\n",
            "942:\tlearn: 0.2676978\ttotal: 23.7s\tremaining: 1.43s\n",
            "943:\tlearn: 0.2674964\ttotal: 23.8s\tremaining: 1.41s\n",
            "944:\tlearn: 0.2673333\ttotal: 23.8s\tremaining: 1.39s\n",
            "945:\tlearn: 0.2671997\ttotal: 23.8s\tremaining: 1.36s\n",
            "946:\tlearn: 0.2670617\ttotal: 23.9s\tremaining: 1.34s\n",
            "947:\tlearn: 0.2669837\ttotal: 23.9s\tremaining: 1.31s\n",
            "948:\tlearn: 0.2669362\ttotal: 24s\tremaining: 1.29s\n",
            "949:\tlearn: 0.2667436\ttotal: 24s\tremaining: 1.26s\n",
            "950:\tlearn: 0.2666206\ttotal: 24.1s\tremaining: 1.24s\n",
            "951:\tlearn: 0.2663961\ttotal: 24.1s\tremaining: 1.21s\n",
            "952:\tlearn: 0.2662738\ttotal: 24.1s\tremaining: 1.19s\n",
            "953:\tlearn: 0.2661710\ttotal: 24.2s\tremaining: 1.17s\n",
            "954:\tlearn: 0.2659822\ttotal: 24.2s\tremaining: 1.14s\n",
            "955:\tlearn: 0.2657389\ttotal: 24.3s\tremaining: 1.12s\n",
            "956:\tlearn: 0.2656563\ttotal: 24.3s\tremaining: 1.09s\n",
            "957:\tlearn: 0.2655286\ttotal: 24.3s\tremaining: 1.07s\n",
            "958:\tlearn: 0.2654302\ttotal: 24.4s\tremaining: 1.04s\n",
            "959:\tlearn: 0.2652549\ttotal: 24.4s\tremaining: 1.02s\n",
            "960:\tlearn: 0.2651046\ttotal: 24.5s\tremaining: 992ms\n",
            "961:\tlearn: 0.2649637\ttotal: 24.5s\tremaining: 968ms\n",
            "962:\tlearn: 0.2648436\ttotal: 24.6s\tremaining: 943ms\n",
            "963:\tlearn: 0.2647476\ttotal: 24.6s\tremaining: 919ms\n",
            "964:\tlearn: 0.2646331\ttotal: 24.6s\tremaining: 894ms\n",
            "965:\tlearn: 0.2645367\ttotal: 24.7s\tremaining: 869ms\n",
            "966:\tlearn: 0.2645144\ttotal: 24.7s\tremaining: 844ms\n",
            "967:\tlearn: 0.2644189\ttotal: 24.8s\tremaining: 819ms\n",
            "968:\tlearn: 0.2642455\ttotal: 24.8s\tremaining: 794ms\n",
            "969:\tlearn: 0.2641947\ttotal: 24.9s\tremaining: 769ms\n",
            "970:\tlearn: 0.2640689\ttotal: 24.9s\tremaining: 744ms\n",
            "971:\tlearn: 0.2639456\ttotal: 25s\tremaining: 719ms\n",
            "972:\tlearn: 0.2638142\ttotal: 25s\tremaining: 693ms\n",
            "973:\tlearn: 0.2636506\ttotal: 25s\tremaining: 668ms\n",
            "974:\tlearn: 0.2635293\ttotal: 25.1s\tremaining: 643ms\n",
            "975:\tlearn: 0.2634159\ttotal: 25.1s\tremaining: 618ms\n",
            "976:\tlearn: 0.2632599\ttotal: 25.2s\tremaining: 592ms\n",
            "977:\tlearn: 0.2631826\ttotal: 25.2s\tremaining: 567ms\n",
            "978:\tlearn: 0.2631050\ttotal: 25.2s\tremaining: 541ms\n",
            "979:\tlearn: 0.2630125\ttotal: 25.3s\tremaining: 516ms\n",
            "980:\tlearn: 0.2628511\ttotal: 25.3s\tremaining: 491ms\n",
            "981:\tlearn: 0.2627423\ttotal: 25.4s\tremaining: 465ms\n",
            "982:\tlearn: 0.2626184\ttotal: 25.4s\tremaining: 439ms\n",
            "983:\tlearn: 0.2624987\ttotal: 25.4s\tremaining: 413ms\n",
            "984:\tlearn: 0.2623220\ttotal: 25.4s\tremaining: 387ms\n",
            "985:\tlearn: 0.2621942\ttotal: 25.4s\tremaining: 361ms\n",
            "986:\tlearn: 0.2620192\ttotal: 25.5s\tremaining: 335ms\n",
            "987:\tlearn: 0.2618955\ttotal: 25.5s\tremaining: 310ms\n",
            "988:\tlearn: 0.2617520\ttotal: 25.5s\tremaining: 284ms\n",
            "989:\tlearn: 0.2615700\ttotal: 25.5s\tremaining: 258ms\n",
            "990:\tlearn: 0.2614492\ttotal: 25.6s\tremaining: 232ms\n",
            "991:\tlearn: 0.2613685\ttotal: 25.6s\tremaining: 206ms\n",
            "992:\tlearn: 0.2612821\ttotal: 25.6s\tremaining: 181ms\n",
            "993:\tlearn: 0.2612013\ttotal: 25.6s\tremaining: 155ms\n",
            "994:\tlearn: 0.2611359\ttotal: 25.6s\tremaining: 129ms\n",
            "995:\tlearn: 0.2610085\ttotal: 25.7s\tremaining: 103ms\n",
            "996:\tlearn: 0.2608813\ttotal: 25.7s\tremaining: 77.3ms\n",
            "997:\tlearn: 0.2607926\ttotal: 25.7s\tremaining: 51.5ms\n",
            "998:\tlearn: 0.2606593\ttotal: 25.7s\tremaining: 25.8ms\n",
            "999:\tlearn: 0.2605414\ttotal: 25.8s\tremaining: 0us\n",
            "0:\tlearn: 0.6787501\ttotal: 20.9ms\tremaining: 20.9s\n",
            "1:\tlearn: 0.6679344\ttotal: 41.3ms\tremaining: 20.6s\n",
            "2:\tlearn: 0.6581870\ttotal: 65.3ms\tremaining: 21.7s\n",
            "3:\tlearn: 0.6471521\ttotal: 86.5ms\tremaining: 21.5s\n",
            "4:\tlearn: 0.6376659\ttotal: 105ms\tremaining: 21s\n",
            "5:\tlearn: 0.6289684\ttotal: 128ms\tremaining: 21.1s\n",
            "6:\tlearn: 0.6188987\ttotal: 149ms\tremaining: 21.2s\n",
            "7:\tlearn: 0.6091240\ttotal: 172ms\tremaining: 21.3s\n",
            "8:\tlearn: 0.6016177\ttotal: 193ms\tremaining: 21.2s\n",
            "9:\tlearn: 0.5947233\ttotal: 213ms\tremaining: 21s\n",
            "10:\tlearn: 0.5884902\ttotal: 254ms\tremaining: 22.8s\n",
            "11:\tlearn: 0.5829614\ttotal: 273ms\tremaining: 22.4s\n",
            "12:\tlearn: 0.5781304\ttotal: 293ms\tremaining: 22.2s\n",
            "13:\tlearn: 0.5734677\ttotal: 312ms\tremaining: 22s\n",
            "14:\tlearn: 0.5677356\ttotal: 334ms\tremaining: 21.9s\n",
            "15:\tlearn: 0.5636091\ttotal: 353ms\tremaining: 21.7s\n",
            "16:\tlearn: 0.5599397\ttotal: 375ms\tremaining: 21.7s\n",
            "17:\tlearn: 0.5554856\ttotal: 394ms\tremaining: 21.5s\n",
            "18:\tlearn: 0.5502240\ttotal: 416ms\tremaining: 21.5s\n",
            "19:\tlearn: 0.5469261\ttotal: 434ms\tremaining: 21.3s\n",
            "20:\tlearn: 0.5424091\ttotal: 458ms\tremaining: 21.4s\n",
            "21:\tlearn: 0.5401375\ttotal: 481ms\tremaining: 21.4s\n",
            "22:\tlearn: 0.5382960\ttotal: 503ms\tremaining: 21.4s\n",
            "23:\tlearn: 0.5345492\ttotal: 522ms\tremaining: 21.2s\n",
            "24:\tlearn: 0.5321689\ttotal: 549ms\tremaining: 21.4s\n",
            "25:\tlearn: 0.5292820\ttotal: 568ms\tremaining: 21.3s\n",
            "26:\tlearn: 0.5256516\ttotal: 589ms\tremaining: 21.2s\n",
            "27:\tlearn: 0.5236178\ttotal: 610ms\tremaining: 21.2s\n",
            "28:\tlearn: 0.5208057\ttotal: 632ms\tremaining: 21.1s\n",
            "29:\tlearn: 0.5188977\ttotal: 650ms\tremaining: 21s\n",
            "30:\tlearn: 0.5155978\ttotal: 686ms\tremaining: 21.4s\n",
            "31:\tlearn: 0.5143202\ttotal: 707ms\tremaining: 21.4s\n",
            "32:\tlearn: 0.5121013\ttotal: 727ms\tremaining: 21.3s\n",
            "33:\tlearn: 0.5101683\ttotal: 748ms\tremaining: 21.3s\n",
            "34:\tlearn: 0.5086879\ttotal: 773ms\tremaining: 21.3s\n",
            "35:\tlearn: 0.5075947\ttotal: 805ms\tremaining: 21.6s\n",
            "36:\tlearn: 0.5053287\ttotal: 826ms\tremaining: 21.5s\n",
            "37:\tlearn: 0.5036671\ttotal: 849ms\tremaining: 21.5s\n",
            "38:\tlearn: 0.5007604\ttotal: 873ms\tremaining: 21.5s\n",
            "39:\tlearn: 0.4993226\ttotal: 898ms\tremaining: 21.6s\n",
            "40:\tlearn: 0.4979934\ttotal: 922ms\tremaining: 21.6s\n",
            "41:\tlearn: 0.4895006\ttotal: 944ms\tremaining: 21.5s\n",
            "42:\tlearn: 0.4881582\ttotal: 964ms\tremaining: 21.4s\n",
            "43:\tlearn: 0.4870470\ttotal: 989ms\tremaining: 21.5s\n",
            "44:\tlearn: 0.4857497\ttotal: 1.01s\tremaining: 21.4s\n",
            "45:\tlearn: 0.4845118\ttotal: 1.03s\tremaining: 21.3s\n",
            "46:\tlearn: 0.4837550\ttotal: 1.05s\tremaining: 21.4s\n",
            "47:\tlearn: 0.4827428\ttotal: 1.07s\tremaining: 21.3s\n",
            "48:\tlearn: 0.4820063\ttotal: 1.1s\tremaining: 21.3s\n",
            "49:\tlearn: 0.4811376\ttotal: 1.13s\tremaining: 21.5s\n",
            "50:\tlearn: 0.4801096\ttotal: 1.16s\tremaining: 21.5s\n",
            "51:\tlearn: 0.4789399\ttotal: 1.18s\tremaining: 21.5s\n",
            "52:\tlearn: 0.4782109\ttotal: 1.2s\tremaining: 21.4s\n",
            "53:\tlearn: 0.4773609\ttotal: 1.22s\tremaining: 21.3s\n",
            "54:\tlearn: 0.4762440\ttotal: 1.24s\tremaining: 21.4s\n",
            "55:\tlearn: 0.4753501\ttotal: 1.26s\tremaining: 21.3s\n",
            "56:\tlearn: 0.4744409\ttotal: 1.29s\tremaining: 21.3s\n",
            "57:\tlearn: 0.4733525\ttotal: 1.31s\tremaining: 21.3s\n",
            "58:\tlearn: 0.4727067\ttotal: 1.33s\tremaining: 21.3s\n",
            "59:\tlearn: 0.4716861\ttotal: 1.35s\tremaining: 21.2s\n",
            "60:\tlearn: 0.4709490\ttotal: 1.37s\tremaining: 21.1s\n",
            "61:\tlearn: 0.4700837\ttotal: 1.4s\tremaining: 21.2s\n",
            "62:\tlearn: 0.4692673\ttotal: 1.42s\tremaining: 21.1s\n",
            "63:\tlearn: 0.4685376\ttotal: 1.44s\tremaining: 21.1s\n",
            "64:\tlearn: 0.4678716\ttotal: 1.46s\tremaining: 21s\n",
            "65:\tlearn: 0.4673354\ttotal: 1.48s\tremaining: 21s\n",
            "66:\tlearn: 0.4667365\ttotal: 1.5s\tremaining: 20.9s\n",
            "67:\tlearn: 0.4662510\ttotal: 1.53s\tremaining: 21s\n",
            "68:\tlearn: 0.4656095\ttotal: 1.55s\tremaining: 20.9s\n",
            "69:\tlearn: 0.4650543\ttotal: 1.57s\tremaining: 20.9s\n",
            "70:\tlearn: 0.4642044\ttotal: 1.59s\tremaining: 20.8s\n",
            "71:\tlearn: 0.4631782\ttotal: 1.61s\tremaining: 20.8s\n",
            "72:\tlearn: 0.4623363\ttotal: 1.63s\tremaining: 20.7s\n",
            "73:\tlearn: 0.4617226\ttotal: 1.66s\tremaining: 20.7s\n",
            "74:\tlearn: 0.4602770\ttotal: 1.67s\tremaining: 20.6s\n",
            "75:\tlearn: 0.4598125\ttotal: 1.69s\tremaining: 20.6s\n",
            "76:\tlearn: 0.4593780\ttotal: 1.71s\tremaining: 20.5s\n",
            "77:\tlearn: 0.4586637\ttotal: 1.74s\tremaining: 20.6s\n",
            "78:\tlearn: 0.4580670\ttotal: 1.76s\tremaining: 20.6s\n",
            "79:\tlearn: 0.4567581\ttotal: 1.8s\tremaining: 20.7s\n",
            "80:\tlearn: 0.4564270\ttotal: 1.82s\tremaining: 20.7s\n",
            "81:\tlearn: 0.4558149\ttotal: 1.85s\tremaining: 20.7s\n",
            "82:\tlearn: 0.4552100\ttotal: 1.87s\tremaining: 20.6s\n",
            "83:\tlearn: 0.4548755\ttotal: 1.89s\tremaining: 20.6s\n",
            "84:\tlearn: 0.4543431\ttotal: 1.91s\tremaining: 20.6s\n",
            "85:\tlearn: 0.4539811\ttotal: 1.93s\tremaining: 20.5s\n",
            "86:\tlearn: 0.4535219\ttotal: 1.96s\tremaining: 20.5s\n",
            "87:\tlearn: 0.4531169\ttotal: 1.98s\tremaining: 20.5s\n",
            "88:\tlearn: 0.4526053\ttotal: 2s\tremaining: 20.5s\n",
            "89:\tlearn: 0.4518654\ttotal: 2.02s\tremaining: 20.5s\n",
            "90:\tlearn: 0.4514262\ttotal: 2.05s\tremaining: 20.4s\n",
            "91:\tlearn: 0.4509198\ttotal: 2.07s\tremaining: 20.4s\n",
            "92:\tlearn: 0.4504679\ttotal: 2.09s\tremaining: 20.4s\n",
            "93:\tlearn: 0.4498337\ttotal: 2.11s\tremaining: 20.3s\n",
            "94:\tlearn: 0.4494091\ttotal: 2.13s\tremaining: 20.3s\n",
            "95:\tlearn: 0.4489074\ttotal: 2.15s\tremaining: 20.2s\n",
            "96:\tlearn: 0.4484823\ttotal: 2.18s\tremaining: 20.3s\n",
            "97:\tlearn: 0.4480295\ttotal: 2.2s\tremaining: 20.3s\n",
            "98:\tlearn: 0.4476093\ttotal: 2.23s\tremaining: 20.3s\n",
            "99:\tlearn: 0.4470849\ttotal: 2.25s\tremaining: 20.2s\n",
            "100:\tlearn: 0.4465882\ttotal: 2.27s\tremaining: 20.2s\n",
            "101:\tlearn: 0.4459846\ttotal: 2.29s\tremaining: 20.2s\n",
            "102:\tlearn: 0.4450906\ttotal: 2.31s\tremaining: 20.1s\n",
            "103:\tlearn: 0.4445101\ttotal: 2.33s\tremaining: 20.1s\n",
            "104:\tlearn: 0.4439814\ttotal: 2.35s\tremaining: 20s\n",
            "105:\tlearn: 0.4435338\ttotal: 2.37s\tremaining: 20s\n",
            "106:\tlearn: 0.4431225\ttotal: 2.4s\tremaining: 20s\n",
            "107:\tlearn: 0.4425800\ttotal: 2.42s\tremaining: 20s\n",
            "108:\tlearn: 0.4422842\ttotal: 2.44s\tremaining: 20s\n",
            "109:\tlearn: 0.4418700\ttotal: 2.46s\tremaining: 19.9s\n",
            "110:\tlearn: 0.4413451\ttotal: 2.49s\tremaining: 19.9s\n",
            "111:\tlearn: 0.4410940\ttotal: 2.51s\tremaining: 19.9s\n",
            "112:\tlearn: 0.4407235\ttotal: 2.53s\tremaining: 19.8s\n",
            "113:\tlearn: 0.4402714\ttotal: 2.55s\tremaining: 19.8s\n",
            "114:\tlearn: 0.4396993\ttotal: 2.57s\tremaining: 19.8s\n",
            "115:\tlearn: 0.4392411\ttotal: 2.59s\tremaining: 19.7s\n",
            "116:\tlearn: 0.4385167\ttotal: 2.62s\tremaining: 19.8s\n",
            "117:\tlearn: 0.4381365\ttotal: 2.64s\tremaining: 19.7s\n",
            "118:\tlearn: 0.4376324\ttotal: 2.66s\tremaining: 19.7s\n",
            "119:\tlearn: 0.4372488\ttotal: 2.68s\tremaining: 19.7s\n",
            "120:\tlearn: 0.4369139\ttotal: 2.71s\tremaining: 19.7s\n",
            "121:\tlearn: 0.4363055\ttotal: 2.73s\tremaining: 19.6s\n",
            "122:\tlearn: 0.4359114\ttotal: 2.75s\tremaining: 19.6s\n",
            "123:\tlearn: 0.4353856\ttotal: 2.77s\tremaining: 19.5s\n",
            "124:\tlearn: 0.4313723\ttotal: 2.79s\tremaining: 19.6s\n",
            "125:\tlearn: 0.4310077\ttotal: 2.83s\tremaining: 19.6s\n",
            "126:\tlearn: 0.4306894\ttotal: 2.85s\tremaining: 19.6s\n",
            "127:\tlearn: 0.4301838\ttotal: 2.87s\tremaining: 19.6s\n",
            "128:\tlearn: 0.4297875\ttotal: 2.9s\tremaining: 19.6s\n",
            "129:\tlearn: 0.4293966\ttotal: 2.92s\tremaining: 19.6s\n",
            "130:\tlearn: 0.4290793\ttotal: 2.94s\tremaining: 19.5s\n",
            "131:\tlearn: 0.4287052\ttotal: 2.96s\tremaining: 19.5s\n",
            "132:\tlearn: 0.4283039\ttotal: 2.98s\tremaining: 19.4s\n",
            "133:\tlearn: 0.4279734\ttotal: 3s\tremaining: 19.4s\n",
            "134:\tlearn: 0.4275515\ttotal: 3.03s\tremaining: 19.4s\n",
            "135:\tlearn: 0.4272368\ttotal: 3.06s\tremaining: 19.4s\n",
            "136:\tlearn: 0.4269031\ttotal: 3.08s\tremaining: 19.4s\n",
            "137:\tlearn: 0.4266060\ttotal: 3.1s\tremaining: 19.3s\n",
            "138:\tlearn: 0.4263472\ttotal: 3.12s\tremaining: 19.3s\n",
            "139:\tlearn: 0.4260162\ttotal: 3.14s\tremaining: 19.3s\n",
            "140:\tlearn: 0.4257269\ttotal: 3.16s\tremaining: 19.3s\n",
            "141:\tlearn: 0.4253217\ttotal: 3.18s\tremaining: 19.2s\n",
            "142:\tlearn: 0.4250479\ttotal: 3.21s\tremaining: 19.2s\n",
            "143:\tlearn: 0.4246144\ttotal: 3.23s\tremaining: 19.2s\n",
            "144:\tlearn: 0.4241936\ttotal: 3.26s\tremaining: 19.2s\n",
            "145:\tlearn: 0.4238062\ttotal: 3.28s\tremaining: 19.2s\n",
            "146:\tlearn: 0.4235328\ttotal: 3.3s\tremaining: 19.2s\n",
            "147:\tlearn: 0.4231846\ttotal: 3.32s\tremaining: 19.1s\n",
            "148:\tlearn: 0.4228884\ttotal: 3.35s\tremaining: 19.1s\n",
            "149:\tlearn: 0.4225828\ttotal: 3.37s\tremaining: 19.1s\n",
            "150:\tlearn: 0.4221386\ttotal: 3.39s\tremaining: 19s\n",
            "151:\tlearn: 0.4217507\ttotal: 3.41s\tremaining: 19s\n",
            "152:\tlearn: 0.4214890\ttotal: 3.43s\tremaining: 19s\n",
            "153:\tlearn: 0.4211558\ttotal: 3.45s\tremaining: 19s\n",
            "154:\tlearn: 0.4209044\ttotal: 3.48s\tremaining: 19s\n",
            "155:\tlearn: 0.4205467\ttotal: 3.5s\tremaining: 18.9s\n",
            "156:\tlearn: 0.4201162\ttotal: 3.52s\tremaining: 18.9s\n",
            "157:\tlearn: 0.4198330\ttotal: 3.54s\tremaining: 18.9s\n",
            "158:\tlearn: 0.4195126\ttotal: 3.57s\tremaining: 18.9s\n",
            "159:\tlearn: 0.4191406\ttotal: 3.59s\tremaining: 18.8s\n",
            "160:\tlearn: 0.4188002\ttotal: 3.61s\tremaining: 18.8s\n",
            "161:\tlearn: 0.4184336\ttotal: 3.63s\tremaining: 18.8s\n",
            "162:\tlearn: 0.4181005\ttotal: 3.65s\tremaining: 18.7s\n",
            "163:\tlearn: 0.4177580\ttotal: 3.67s\tremaining: 18.7s\n",
            "164:\tlearn: 0.4174016\ttotal: 3.7s\tremaining: 18.7s\n",
            "165:\tlearn: 0.4171374\ttotal: 3.72s\tremaining: 18.7s\n",
            "166:\tlearn: 0.4168863\ttotal: 3.74s\tremaining: 18.7s\n",
            "167:\tlearn: 0.4166659\ttotal: 3.76s\tremaining: 18.6s\n",
            "168:\tlearn: 0.4163483\ttotal: 3.79s\tremaining: 18.6s\n",
            "169:\tlearn: 0.4161082\ttotal: 3.82s\tremaining: 18.7s\n",
            "170:\tlearn: 0.4157663\ttotal: 3.85s\tremaining: 18.7s\n",
            "171:\tlearn: 0.4155041\ttotal: 3.87s\tremaining: 18.6s\n",
            "172:\tlearn: 0.4152195\ttotal: 3.89s\tremaining: 18.6s\n",
            "173:\tlearn: 0.4148444\ttotal: 3.92s\tremaining: 18.6s\n",
            "174:\tlearn: 0.4146823\ttotal: 3.94s\tremaining: 18.6s\n",
            "175:\tlearn: 0.4142762\ttotal: 3.96s\tremaining: 18.5s\n",
            "176:\tlearn: 0.4140845\ttotal: 3.98s\tremaining: 18.5s\n",
            "177:\tlearn: 0.4138231\ttotal: 4s\tremaining: 18.5s\n",
            "178:\tlearn: 0.4134633\ttotal: 4.03s\tremaining: 18.5s\n",
            "179:\tlearn: 0.4131774\ttotal: 4.05s\tremaining: 18.5s\n",
            "180:\tlearn: 0.4129096\ttotal: 4.08s\tremaining: 18.4s\n",
            "181:\tlearn: 0.4125809\ttotal: 4.1s\tremaining: 18.4s\n",
            "182:\tlearn: 0.4122791\ttotal: 4.12s\tremaining: 18.4s\n",
            "183:\tlearn: 0.4119098\ttotal: 4.15s\tremaining: 18.4s\n",
            "184:\tlearn: 0.4116171\ttotal: 4.17s\tremaining: 18.4s\n",
            "185:\tlearn: 0.4112747\ttotal: 4.19s\tremaining: 18.3s\n",
            "186:\tlearn: 0.4109523\ttotal: 4.21s\tremaining: 18.3s\n",
            "187:\tlearn: 0.4106358\ttotal: 4.23s\tremaining: 18.3s\n",
            "188:\tlearn: 0.4103973\ttotal: 4.25s\tremaining: 18.3s\n",
            "189:\tlearn: 0.4099803\ttotal: 4.28s\tremaining: 18.2s\n",
            "190:\tlearn: 0.4096886\ttotal: 4.3s\tremaining: 18.2s\n",
            "191:\tlearn: 0.4093845\ttotal: 4.33s\tremaining: 18.2s\n",
            "192:\tlearn: 0.4091904\ttotal: 4.35s\tremaining: 18.2s\n",
            "193:\tlearn: 0.4089943\ttotal: 4.37s\tremaining: 18.2s\n",
            "194:\tlearn: 0.4086711\ttotal: 4.4s\tremaining: 18.1s\n",
            "195:\tlearn: 0.4084921\ttotal: 4.42s\tremaining: 18.1s\n",
            "196:\tlearn: 0.4082145\ttotal: 4.43s\tremaining: 18.1s\n",
            "197:\tlearn: 0.4079873\ttotal: 4.46s\tremaining: 18.1s\n",
            "198:\tlearn: 0.4077311\ttotal: 4.48s\tremaining: 18s\n",
            "199:\tlearn: 0.4074426\ttotal: 4.5s\tremaining: 18s\n",
            "200:\tlearn: 0.4071471\ttotal: 4.53s\tremaining: 18s\n",
            "201:\tlearn: 0.4068158\ttotal: 4.55s\tremaining: 18s\n",
            "202:\tlearn: 0.4064995\ttotal: 4.58s\tremaining: 18s\n",
            "203:\tlearn: 0.4062294\ttotal: 4.59s\tremaining: 17.9s\n",
            "204:\tlearn: 0.4058028\ttotal: 4.62s\tremaining: 17.9s\n",
            "205:\tlearn: 0.4055684\ttotal: 4.64s\tremaining: 17.9s\n",
            "206:\tlearn: 0.4053161\ttotal: 4.66s\tremaining: 17.8s\n",
            "207:\tlearn: 0.4050741\ttotal: 4.68s\tremaining: 17.8s\n",
            "208:\tlearn: 0.4047954\ttotal: 4.7s\tremaining: 17.8s\n",
            "209:\tlearn: 0.4044779\ttotal: 4.72s\tremaining: 17.8s\n",
            "210:\tlearn: 0.4042609\ttotal: 4.75s\tremaining: 17.8s\n",
            "211:\tlearn: 0.4039777\ttotal: 4.78s\tremaining: 17.8s\n",
            "212:\tlearn: 0.4037039\ttotal: 4.8s\tremaining: 17.7s\n",
            "213:\tlearn: 0.4034166\ttotal: 4.83s\tremaining: 17.7s\n",
            "214:\tlearn: 0.4031644\ttotal: 4.85s\tremaining: 17.7s\n",
            "215:\tlearn: 0.4028273\ttotal: 4.87s\tremaining: 17.7s\n",
            "216:\tlearn: 0.4024489\ttotal: 4.89s\tremaining: 17.7s\n",
            "217:\tlearn: 0.4021016\ttotal: 4.91s\tremaining: 17.6s\n",
            "218:\tlearn: 0.4018363\ttotal: 4.94s\tremaining: 17.6s\n",
            "219:\tlearn: 0.4015376\ttotal: 4.96s\tremaining: 17.6s\n",
            "220:\tlearn: 0.4013064\ttotal: 4.99s\tremaining: 17.6s\n",
            "221:\tlearn: 0.4010105\ttotal: 5.01s\tremaining: 17.6s\n",
            "222:\tlearn: 0.4006145\ttotal: 5.04s\tremaining: 17.5s\n",
            "223:\tlearn: 0.4002703\ttotal: 5.06s\tremaining: 17.5s\n",
            "224:\tlearn: 0.3999897\ttotal: 5.08s\tremaining: 17.5s\n",
            "225:\tlearn: 0.3997468\ttotal: 5.1s\tremaining: 17.5s\n",
            "226:\tlearn: 0.3995355\ttotal: 5.12s\tremaining: 17.4s\n",
            "227:\tlearn: 0.3993618\ttotal: 5.14s\tremaining: 17.4s\n",
            "228:\tlearn: 0.3990612\ttotal: 5.17s\tremaining: 17.4s\n",
            "229:\tlearn: 0.3987856\ttotal: 5.2s\tremaining: 17.4s\n",
            "230:\tlearn: 0.3984239\ttotal: 5.22s\tremaining: 17.4s\n",
            "231:\tlearn: 0.3981714\ttotal: 5.24s\tremaining: 17.3s\n",
            "232:\tlearn: 0.3979053\ttotal: 5.26s\tremaining: 17.3s\n",
            "233:\tlearn: 0.3976940\ttotal: 5.28s\tremaining: 17.3s\n",
            "234:\tlearn: 0.3974003\ttotal: 5.3s\tremaining: 17.3s\n",
            "235:\tlearn: 0.3970925\ttotal: 5.32s\tremaining: 17.2s\n",
            "236:\tlearn: 0.3968602\ttotal: 5.34s\tremaining: 17.2s\n",
            "237:\tlearn: 0.3966615\ttotal: 5.37s\tremaining: 17.2s\n",
            "238:\tlearn: 0.3963365\ttotal: 5.39s\tremaining: 17.2s\n",
            "239:\tlearn: 0.3959975\ttotal: 5.41s\tremaining: 17.1s\n",
            "240:\tlearn: 0.3956414\ttotal: 5.44s\tremaining: 17.1s\n",
            "241:\tlearn: 0.3953998\ttotal: 5.46s\tremaining: 17.1s\n",
            "242:\tlearn: 0.3950650\ttotal: 5.48s\tremaining: 17.1s\n",
            "243:\tlearn: 0.3947883\ttotal: 5.5s\tremaining: 17s\n",
            "244:\tlearn: 0.3945021\ttotal: 5.52s\tremaining: 17s\n",
            "245:\tlearn: 0.3942041\ttotal: 5.54s\tremaining: 17s\n",
            "246:\tlearn: 0.3939906\ttotal: 5.56s\tremaining: 17s\n",
            "247:\tlearn: 0.3936389\ttotal: 5.59s\tremaining: 17s\n",
            "248:\tlearn: 0.3933437\ttotal: 5.61s\tremaining: 16.9s\n",
            "249:\tlearn: 0.3929388\ttotal: 5.63s\tremaining: 16.9s\n",
            "250:\tlearn: 0.3925005\ttotal: 5.65s\tremaining: 16.9s\n",
            "251:\tlearn: 0.3922357\ttotal: 5.68s\tremaining: 16.8s\n",
            "252:\tlearn: 0.3920393\ttotal: 5.7s\tremaining: 16.8s\n",
            "253:\tlearn: 0.3918373\ttotal: 5.72s\tremaining: 16.8s\n",
            "254:\tlearn: 0.3915428\ttotal: 5.74s\tremaining: 16.8s\n",
            "255:\tlearn: 0.3913255\ttotal: 5.76s\tremaining: 16.7s\n",
            "256:\tlearn: 0.3911287\ttotal: 5.78s\tremaining: 16.7s\n",
            "257:\tlearn: 0.3909265\ttotal: 5.8s\tremaining: 16.7s\n",
            "258:\tlearn: 0.3907021\ttotal: 5.84s\tremaining: 16.7s\n",
            "259:\tlearn: 0.3903898\ttotal: 5.86s\tremaining: 16.7s\n",
            "260:\tlearn: 0.3900373\ttotal: 5.88s\tremaining: 16.7s\n",
            "261:\tlearn: 0.3898125\ttotal: 5.91s\tremaining: 16.6s\n",
            "262:\tlearn: 0.3896139\ttotal: 5.92s\tremaining: 16.6s\n",
            "263:\tlearn: 0.3893679\ttotal: 5.94s\tremaining: 16.6s\n",
            "264:\tlearn: 0.3890974\ttotal: 5.96s\tremaining: 16.5s\n",
            "265:\tlearn: 0.3886884\ttotal: 5.99s\tremaining: 16.5s\n",
            "266:\tlearn: 0.3884064\ttotal: 6.01s\tremaining: 16.5s\n",
            "267:\tlearn: 0.3881053\ttotal: 6.04s\tremaining: 16.5s\n",
            "268:\tlearn: 0.3877547\ttotal: 6.06s\tremaining: 16.5s\n",
            "269:\tlearn: 0.3874427\ttotal: 6.08s\tremaining: 16.4s\n",
            "270:\tlearn: 0.3872384\ttotal: 6.1s\tremaining: 16.4s\n",
            "271:\tlearn: 0.3870174\ttotal: 6.13s\tremaining: 16.4s\n",
            "272:\tlearn: 0.3867395\ttotal: 6.15s\tremaining: 16.4s\n",
            "273:\tlearn: 0.3864761\ttotal: 6.17s\tremaining: 16.4s\n",
            "274:\tlearn: 0.3862501\ttotal: 6.2s\tremaining: 16.3s\n",
            "275:\tlearn: 0.3859191\ttotal: 6.23s\tremaining: 16.3s\n",
            "276:\tlearn: 0.3856498\ttotal: 6.25s\tremaining: 16.3s\n",
            "277:\tlearn: 0.3853671\ttotal: 6.27s\tremaining: 16.3s\n",
            "278:\tlearn: 0.3850573\ttotal: 6.29s\tremaining: 16.3s\n",
            "279:\tlearn: 0.3847841\ttotal: 6.31s\tremaining: 16.2s\n",
            "280:\tlearn: 0.3845366\ttotal: 6.33s\tremaining: 16.2s\n",
            "281:\tlearn: 0.3842246\ttotal: 6.35s\tremaining: 16.2s\n",
            "282:\tlearn: 0.3840055\ttotal: 6.37s\tremaining: 16.1s\n",
            "283:\tlearn: 0.3837636\ttotal: 6.4s\tremaining: 16.1s\n",
            "284:\tlearn: 0.3833960\ttotal: 6.42s\tremaining: 16.1s\n",
            "285:\tlearn: 0.3831654\ttotal: 6.45s\tremaining: 16.1s\n",
            "286:\tlearn: 0.3828856\ttotal: 6.47s\tremaining: 16.1s\n",
            "287:\tlearn: 0.3825950\ttotal: 6.49s\tremaining: 16s\n",
            "288:\tlearn: 0.3822950\ttotal: 6.51s\tremaining: 16s\n",
            "289:\tlearn: 0.3820255\ttotal: 6.53s\tremaining: 16s\n",
            "290:\tlearn: 0.3817971\ttotal: 6.55s\tremaining: 16s\n",
            "291:\tlearn: 0.3815881\ttotal: 6.57s\tremaining: 15.9s\n",
            "292:\tlearn: 0.3813816\ttotal: 6.59s\tremaining: 15.9s\n",
            "293:\tlearn: 0.3812047\ttotal: 6.62s\tremaining: 15.9s\n",
            "294:\tlearn: 0.3809626\ttotal: 6.64s\tremaining: 15.9s\n",
            "295:\tlearn: 0.3806505\ttotal: 6.67s\tremaining: 15.9s\n",
            "296:\tlearn: 0.3804112\ttotal: 6.68s\tremaining: 15.8s\n",
            "297:\tlearn: 0.3801902\ttotal: 6.71s\tremaining: 15.8s\n",
            "298:\tlearn: 0.3799862\ttotal: 6.74s\tremaining: 15.8s\n",
            "299:\tlearn: 0.3797086\ttotal: 6.76s\tremaining: 15.8s\n",
            "300:\tlearn: 0.3795195\ttotal: 6.78s\tremaining: 15.7s\n",
            "301:\tlearn: 0.3792402\ttotal: 6.8s\tremaining: 15.7s\n",
            "302:\tlearn: 0.3789931\ttotal: 6.83s\tremaining: 15.7s\n",
            "303:\tlearn: 0.3786375\ttotal: 6.86s\tremaining: 15.7s\n",
            "304:\tlearn: 0.3783663\ttotal: 6.89s\tremaining: 15.7s\n",
            "305:\tlearn: 0.3780752\ttotal: 6.91s\tremaining: 15.7s\n",
            "306:\tlearn: 0.3778641\ttotal: 6.93s\tremaining: 15.6s\n",
            "307:\tlearn: 0.3776773\ttotal: 6.95s\tremaining: 15.6s\n",
            "308:\tlearn: 0.3773903\ttotal: 6.97s\tremaining: 15.6s\n",
            "309:\tlearn: 0.3771369\ttotal: 6.99s\tremaining: 15.6s\n",
            "310:\tlearn: 0.3768778\ttotal: 7.01s\tremaining: 15.5s\n",
            "311:\tlearn: 0.3766449\ttotal: 7.03s\tremaining: 15.5s\n",
            "312:\tlearn: 0.3763874\ttotal: 7.05s\tremaining: 15.5s\n",
            "313:\tlearn: 0.3761353\ttotal: 7.07s\tremaining: 15.4s\n",
            "314:\tlearn: 0.3758354\ttotal: 7.1s\tremaining: 15.4s\n",
            "315:\tlearn: 0.3756216\ttotal: 7.12s\tremaining: 15.4s\n",
            "316:\tlearn: 0.3753900\ttotal: 7.14s\tremaining: 15.4s\n",
            "317:\tlearn: 0.3750857\ttotal: 7.16s\tremaining: 15.4s\n",
            "318:\tlearn: 0.3748491\ttotal: 7.18s\tremaining: 15.3s\n",
            "319:\tlearn: 0.3746515\ttotal: 7.2s\tremaining: 15.3s\n",
            "320:\tlearn: 0.3744176\ttotal: 7.23s\tremaining: 15.3s\n",
            "321:\tlearn: 0.3741840\ttotal: 7.25s\tremaining: 15.3s\n",
            "322:\tlearn: 0.3738991\ttotal: 7.27s\tremaining: 15.2s\n",
            "323:\tlearn: 0.3736887\ttotal: 7.29s\tremaining: 15.2s\n",
            "324:\tlearn: 0.3735186\ttotal: 7.32s\tremaining: 15.2s\n",
            "325:\tlearn: 0.3732676\ttotal: 7.34s\tremaining: 15.2s\n",
            "326:\tlearn: 0.3730551\ttotal: 7.36s\tremaining: 15.1s\n",
            "327:\tlearn: 0.3728377\ttotal: 7.38s\tremaining: 15.1s\n",
            "328:\tlearn: 0.3725584\ttotal: 7.4s\tremaining: 15.1s\n",
            "329:\tlearn: 0.3723443\ttotal: 7.43s\tremaining: 15.1s\n",
            "330:\tlearn: 0.3721859\ttotal: 7.45s\tremaining: 15.1s\n",
            "331:\tlearn: 0.3719720\ttotal: 7.47s\tremaining: 15s\n",
            "332:\tlearn: 0.3717691\ttotal: 7.49s\tremaining: 15s\n",
            "333:\tlearn: 0.3715437\ttotal: 7.51s\tremaining: 15s\n",
            "334:\tlearn: 0.3712488\ttotal: 7.54s\tremaining: 15s\n",
            "335:\tlearn: 0.3710439\ttotal: 7.56s\tremaining: 14.9s\n",
            "336:\tlearn: 0.3708912\ttotal: 7.58s\tremaining: 14.9s\n",
            "337:\tlearn: 0.3706502\ttotal: 7.6s\tremaining: 14.9s\n",
            "338:\tlearn: 0.3703410\ttotal: 7.62s\tremaining: 14.9s\n",
            "339:\tlearn: 0.3701688\ttotal: 7.64s\tremaining: 14.8s\n",
            "340:\tlearn: 0.3698835\ttotal: 7.66s\tremaining: 14.8s\n",
            "341:\tlearn: 0.3695883\ttotal: 7.69s\tremaining: 14.8s\n",
            "342:\tlearn: 0.3693000\ttotal: 7.71s\tremaining: 14.8s\n",
            "343:\tlearn: 0.3691344\ttotal: 7.72s\tremaining: 14.7s\n",
            "344:\tlearn: 0.3687403\ttotal: 7.75s\tremaining: 14.7s\n",
            "345:\tlearn: 0.3684279\ttotal: 7.77s\tremaining: 14.7s\n",
            "346:\tlearn: 0.3682213\ttotal: 7.8s\tremaining: 14.7s\n",
            "347:\tlearn: 0.3679751\ttotal: 7.82s\tremaining: 14.7s\n",
            "348:\tlearn: 0.3676774\ttotal: 7.85s\tremaining: 14.6s\n",
            "349:\tlearn: 0.3674430\ttotal: 7.87s\tremaining: 14.6s\n",
            "350:\tlearn: 0.3672381\ttotal: 7.89s\tremaining: 14.6s\n",
            "351:\tlearn: 0.3670459\ttotal: 7.92s\tremaining: 14.6s\n",
            "352:\tlearn: 0.3668708\ttotal: 7.93s\tremaining: 14.5s\n",
            "353:\tlearn: 0.3666331\ttotal: 7.97s\tremaining: 14.5s\n",
            "354:\tlearn: 0.3663139\ttotal: 7.99s\tremaining: 14.5s\n",
            "355:\tlearn: 0.3661036\ttotal: 8.01s\tremaining: 14.5s\n",
            "356:\tlearn: 0.3658609\ttotal: 8.03s\tremaining: 14.5s\n",
            "357:\tlearn: 0.3656737\ttotal: 8.05s\tremaining: 14.4s\n",
            "358:\tlearn: 0.3653484\ttotal: 8.07s\tremaining: 14.4s\n",
            "359:\tlearn: 0.3650761\ttotal: 8.09s\tremaining: 14.4s\n",
            "360:\tlearn: 0.3649253\ttotal: 8.12s\tremaining: 14.4s\n",
            "361:\tlearn: 0.3647702\ttotal: 8.14s\tremaining: 14.3s\n",
            "362:\tlearn: 0.3644722\ttotal: 8.16s\tremaining: 14.3s\n",
            "363:\tlearn: 0.3643054\ttotal: 8.19s\tremaining: 14.3s\n",
            "364:\tlearn: 0.3640655\ttotal: 8.21s\tremaining: 14.3s\n",
            "365:\tlearn: 0.3637999\ttotal: 8.23s\tremaining: 14.3s\n",
            "366:\tlearn: 0.3634729\ttotal: 8.25s\tremaining: 14.2s\n",
            "367:\tlearn: 0.3632584\ttotal: 8.27s\tremaining: 14.2s\n",
            "368:\tlearn: 0.3630523\ttotal: 8.3s\tremaining: 14.2s\n",
            "369:\tlearn: 0.3628241\ttotal: 8.31s\tremaining: 14.2s\n",
            "370:\tlearn: 0.3627103\ttotal: 8.34s\tremaining: 14.1s\n",
            "371:\tlearn: 0.3624469\ttotal: 8.36s\tremaining: 14.1s\n",
            "372:\tlearn: 0.3621677\ttotal: 8.4s\tremaining: 14.1s\n",
            "373:\tlearn: 0.3619473\ttotal: 8.44s\tremaining: 14.1s\n",
            "374:\tlearn: 0.3617425\ttotal: 8.46s\tremaining: 14.1s\n",
            "375:\tlearn: 0.3614140\ttotal: 8.49s\tremaining: 14.1s\n",
            "376:\tlearn: 0.3612537\ttotal: 8.53s\tremaining: 14.1s\n",
            "377:\tlearn: 0.3610163\ttotal: 8.58s\tremaining: 14.1s\n",
            "378:\tlearn: 0.3607868\ttotal: 8.63s\tremaining: 14.1s\n",
            "379:\tlearn: 0.3606510\ttotal: 8.67s\tremaining: 14.1s\n",
            "380:\tlearn: 0.3603634\ttotal: 8.72s\tremaining: 14.2s\n",
            "381:\tlearn: 0.3601677\ttotal: 8.76s\tremaining: 14.2s\n",
            "382:\tlearn: 0.3599691\ttotal: 8.8s\tremaining: 14.2s\n",
            "383:\tlearn: 0.3597392\ttotal: 8.85s\tremaining: 14.2s\n",
            "384:\tlearn: 0.3595700\ttotal: 8.9s\tremaining: 14.2s\n",
            "385:\tlearn: 0.3592365\ttotal: 8.95s\tremaining: 14.2s\n",
            "386:\tlearn: 0.3589862\ttotal: 8.97s\tremaining: 14.2s\n",
            "387:\tlearn: 0.3586502\ttotal: 9.03s\tremaining: 14.2s\n",
            "388:\tlearn: 0.3584667\ttotal: 9.09s\tremaining: 14.3s\n",
            "389:\tlearn: 0.3582014\ttotal: 9.13s\tremaining: 14.3s\n",
            "390:\tlearn: 0.3580011\ttotal: 9.18s\tremaining: 14.3s\n",
            "391:\tlearn: 0.3577733\ttotal: 9.21s\tremaining: 14.3s\n",
            "392:\tlearn: 0.3575096\ttotal: 9.26s\tremaining: 14.3s\n",
            "393:\tlearn: 0.3572907\ttotal: 9.31s\tremaining: 14.3s\n",
            "394:\tlearn: 0.3570182\ttotal: 9.35s\tremaining: 14.3s\n",
            "395:\tlearn: 0.3568608\ttotal: 9.39s\tremaining: 14.3s\n",
            "396:\tlearn: 0.3567100\ttotal: 9.44s\tremaining: 14.3s\n",
            "397:\tlearn: 0.3564840\ttotal: 9.47s\tremaining: 14.3s\n",
            "398:\tlearn: 0.3562903\ttotal: 9.51s\tremaining: 14.3s\n",
            "399:\tlearn: 0.3559202\ttotal: 9.56s\tremaining: 14.3s\n",
            "400:\tlearn: 0.3557431\ttotal: 9.59s\tremaining: 14.3s\n",
            "401:\tlearn: 0.3555836\ttotal: 9.63s\tremaining: 14.3s\n",
            "402:\tlearn: 0.3553660\ttotal: 9.67s\tremaining: 14.3s\n",
            "403:\tlearn: 0.3550999\ttotal: 9.71s\tremaining: 14.3s\n",
            "404:\tlearn: 0.3549672\ttotal: 9.76s\tremaining: 14.3s\n",
            "405:\tlearn: 0.3547320\ttotal: 9.8s\tremaining: 14.3s\n",
            "406:\tlearn: 0.3546065\ttotal: 9.84s\tremaining: 14.3s\n",
            "407:\tlearn: 0.3544456\ttotal: 9.89s\tremaining: 14.4s\n",
            "408:\tlearn: 0.3542163\ttotal: 9.94s\tremaining: 14.4s\n",
            "409:\tlearn: 0.3540659\ttotal: 9.99s\tremaining: 14.4s\n",
            "410:\tlearn: 0.3538407\ttotal: 10s\tremaining: 14.4s\n",
            "411:\tlearn: 0.3536771\ttotal: 10.1s\tremaining: 14.3s\n",
            "412:\tlearn: 0.3534529\ttotal: 10.1s\tremaining: 14.3s\n",
            "413:\tlearn: 0.3533337\ttotal: 10.1s\tremaining: 14.3s\n",
            "414:\tlearn: 0.3531984\ttotal: 10.2s\tremaining: 14.4s\n",
            "415:\tlearn: 0.3530116\ttotal: 10.2s\tremaining: 14.4s\n",
            "416:\tlearn: 0.3528210\ttotal: 10.3s\tremaining: 14.4s\n",
            "417:\tlearn: 0.3525561\ttotal: 10.3s\tremaining: 14.4s\n",
            "418:\tlearn: 0.3523492\ttotal: 10.4s\tremaining: 14.4s\n",
            "419:\tlearn: 0.3521228\ttotal: 10.4s\tremaining: 14.4s\n",
            "420:\tlearn: 0.3518787\ttotal: 10.5s\tremaining: 14.4s\n",
            "421:\tlearn: 0.3517319\ttotal: 10.5s\tremaining: 14.4s\n",
            "422:\tlearn: 0.3514600\ttotal: 10.5s\tremaining: 14.4s\n",
            "423:\tlearn: 0.3512892\ttotal: 10.6s\tremaining: 14.4s\n",
            "424:\tlearn: 0.3511161\ttotal: 10.6s\tremaining: 14.4s\n",
            "425:\tlearn: 0.3509861\ttotal: 10.7s\tremaining: 14.4s\n",
            "426:\tlearn: 0.3508347\ttotal: 10.7s\tremaining: 14.4s\n",
            "427:\tlearn: 0.3506366\ttotal: 10.7s\tremaining: 14.4s\n",
            "428:\tlearn: 0.3504044\ttotal: 10.8s\tremaining: 14.4s\n",
            "429:\tlearn: 0.3502251\ttotal: 10.8s\tremaining: 14.4s\n",
            "430:\tlearn: 0.3501308\ttotal: 10.9s\tremaining: 14.4s\n",
            "431:\tlearn: 0.3498561\ttotal: 10.9s\tremaining: 14.4s\n",
            "432:\tlearn: 0.3496315\ttotal: 11s\tremaining: 14.4s\n",
            "433:\tlearn: 0.3494781\ttotal: 11s\tremaining: 14.4s\n",
            "434:\tlearn: 0.3492373\ttotal: 11.1s\tremaining: 14.4s\n",
            "435:\tlearn: 0.3490292\ttotal: 11.1s\tremaining: 14.3s\n",
            "436:\tlearn: 0.3488817\ttotal: 11.1s\tremaining: 14.3s\n",
            "437:\tlearn: 0.3486371\ttotal: 11.2s\tremaining: 14.3s\n",
            "438:\tlearn: 0.3483930\ttotal: 11.2s\tremaining: 14.3s\n",
            "439:\tlearn: 0.3480641\ttotal: 11.2s\tremaining: 14.3s\n",
            "440:\tlearn: 0.3479615\ttotal: 11.3s\tremaining: 14.3s\n",
            "441:\tlearn: 0.3477982\ttotal: 11.3s\tremaining: 14.3s\n",
            "442:\tlearn: 0.3475740\ttotal: 11.4s\tremaining: 14.3s\n",
            "443:\tlearn: 0.3473185\ttotal: 11.4s\tremaining: 14.3s\n",
            "444:\tlearn: 0.3471228\ttotal: 11.5s\tremaining: 14.3s\n",
            "445:\tlearn: 0.3468960\ttotal: 11.5s\tremaining: 14.3s\n",
            "446:\tlearn: 0.3466842\ttotal: 11.6s\tremaining: 14.3s\n",
            "447:\tlearn: 0.3465141\ttotal: 11.6s\tremaining: 14.3s\n",
            "448:\tlearn: 0.3462441\ttotal: 11.6s\tremaining: 14.3s\n",
            "449:\tlearn: 0.3461089\ttotal: 11.7s\tremaining: 14.3s\n",
            "450:\tlearn: 0.3459058\ttotal: 11.7s\tremaining: 14.3s\n",
            "451:\tlearn: 0.3456803\ttotal: 11.8s\tremaining: 14.3s\n",
            "452:\tlearn: 0.3454779\ttotal: 11.8s\tremaining: 14.3s\n",
            "453:\tlearn: 0.3452709\ttotal: 11.9s\tremaining: 14.3s\n",
            "454:\tlearn: 0.3449666\ttotal: 11.9s\tremaining: 14.3s\n",
            "455:\tlearn: 0.3447862\ttotal: 11.9s\tremaining: 14.3s\n",
            "456:\tlearn: 0.3446536\ttotal: 12s\tremaining: 14.2s\n",
            "457:\tlearn: 0.3445494\ttotal: 12s\tremaining: 14.2s\n",
            "458:\tlearn: 0.3443410\ttotal: 12.1s\tremaining: 14.2s\n",
            "459:\tlearn: 0.3441823\ttotal: 12.1s\tremaining: 14.2s\n",
            "460:\tlearn: 0.3440240\ttotal: 12.1s\tremaining: 14.2s\n",
            "461:\tlearn: 0.3438842\ttotal: 12.1s\tremaining: 14.1s\n",
            "462:\tlearn: 0.3436366\ttotal: 12.2s\tremaining: 14.1s\n",
            "463:\tlearn: 0.3434970\ttotal: 12.2s\tremaining: 14.1s\n",
            "464:\tlearn: 0.3433062\ttotal: 12.2s\tremaining: 14s\n",
            "465:\tlearn: 0.3431361\ttotal: 12.2s\tremaining: 14s\n",
            "466:\tlearn: 0.3429142\ttotal: 12.2s\tremaining: 14s\n",
            "467:\tlearn: 0.3427204\ttotal: 12.3s\tremaining: 13.9s\n",
            "468:\tlearn: 0.3424868\ttotal: 12.3s\tremaining: 13.9s\n",
            "469:\tlearn: 0.3423354\ttotal: 12.3s\tremaining: 13.9s\n",
            "470:\tlearn: 0.3421374\ttotal: 12.3s\tremaining: 13.8s\n",
            "471:\tlearn: 0.3419740\ttotal: 12.3s\tremaining: 13.8s\n",
            "472:\tlearn: 0.3417220\ttotal: 12.4s\tremaining: 13.8s\n",
            "473:\tlearn: 0.3414976\ttotal: 12.4s\tremaining: 13.8s\n",
            "474:\tlearn: 0.3413286\ttotal: 12.4s\tremaining: 13.7s\n",
            "475:\tlearn: 0.3412384\ttotal: 12.4s\tremaining: 13.7s\n",
            "476:\tlearn: 0.3409641\ttotal: 12.5s\tremaining: 13.7s\n",
            "477:\tlearn: 0.3406960\ttotal: 12.5s\tremaining: 13.6s\n",
            "478:\tlearn: 0.3404487\ttotal: 12.5s\tremaining: 13.6s\n",
            "479:\tlearn: 0.3402778\ttotal: 12.5s\tremaining: 13.6s\n",
            "480:\tlearn: 0.3400655\ttotal: 12.5s\tremaining: 13.5s\n",
            "481:\tlearn: 0.3398787\ttotal: 12.6s\tremaining: 13.5s\n",
            "482:\tlearn: 0.3397900\ttotal: 12.6s\tremaining: 13.5s\n",
            "483:\tlearn: 0.3395928\ttotal: 12.6s\tremaining: 13.4s\n",
            "484:\tlearn: 0.3394211\ttotal: 12.6s\tremaining: 13.4s\n",
            "485:\tlearn: 0.3392801\ttotal: 12.7s\tremaining: 13.4s\n",
            "486:\tlearn: 0.3390208\ttotal: 12.7s\tremaining: 13.4s\n",
            "487:\tlearn: 0.3388028\ttotal: 12.7s\tremaining: 13.3s\n",
            "488:\tlearn: 0.3386369\ttotal: 12.7s\tremaining: 13.3s\n",
            "489:\tlearn: 0.3384281\ttotal: 12.7s\tremaining: 13.3s\n",
            "490:\tlearn: 0.3382744\ttotal: 12.8s\tremaining: 13.2s\n",
            "491:\tlearn: 0.3380904\ttotal: 12.8s\tremaining: 13.2s\n",
            "492:\tlearn: 0.3379402\ttotal: 12.8s\tremaining: 13.2s\n",
            "493:\tlearn: 0.3376795\ttotal: 12.8s\tremaining: 13.1s\n",
            "494:\tlearn: 0.3374503\ttotal: 12.9s\tremaining: 13.1s\n",
            "495:\tlearn: 0.3373078\ttotal: 12.9s\tremaining: 13.1s\n",
            "496:\tlearn: 0.3371601\ttotal: 12.9s\tremaining: 13.1s\n",
            "497:\tlearn: 0.3369476\ttotal: 12.9s\tremaining: 13s\n",
            "498:\tlearn: 0.3367509\ttotal: 12.9s\tremaining: 13s\n",
            "499:\tlearn: 0.3365159\ttotal: 13s\tremaining: 13s\n",
            "500:\tlearn: 0.3362295\ttotal: 13s\tremaining: 12.9s\n",
            "501:\tlearn: 0.3361051\ttotal: 13s\tremaining: 12.9s\n",
            "502:\tlearn: 0.3359059\ttotal: 13s\tremaining: 12.9s\n",
            "503:\tlearn: 0.3357015\ttotal: 13.1s\tremaining: 12.9s\n",
            "504:\tlearn: 0.3355010\ttotal: 13.1s\tremaining: 12.8s\n",
            "505:\tlearn: 0.3353514\ttotal: 13.1s\tremaining: 12.8s\n",
            "506:\tlearn: 0.3351790\ttotal: 13.1s\tremaining: 12.8s\n",
            "507:\tlearn: 0.3351368\ttotal: 13.2s\tremaining: 12.7s\n",
            "508:\tlearn: 0.3349954\ttotal: 13.2s\tremaining: 12.7s\n",
            "509:\tlearn: 0.3347583\ttotal: 13.2s\tremaining: 12.7s\n",
            "510:\tlearn: 0.3345791\ttotal: 13.2s\tremaining: 12.6s\n",
            "511:\tlearn: 0.3343526\ttotal: 13.2s\tremaining: 12.6s\n",
            "512:\tlearn: 0.3342127\ttotal: 13.3s\tremaining: 12.6s\n",
            "513:\tlearn: 0.3341023\ttotal: 13.3s\tremaining: 12.6s\n",
            "514:\tlearn: 0.3339488\ttotal: 13.3s\tremaining: 12.5s\n",
            "515:\tlearn: 0.3338196\ttotal: 13.3s\tremaining: 12.5s\n",
            "516:\tlearn: 0.3335965\ttotal: 13.4s\tremaining: 12.5s\n",
            "517:\tlearn: 0.3333911\ttotal: 13.4s\tremaining: 12.4s\n",
            "518:\tlearn: 0.3332564\ttotal: 13.4s\tremaining: 12.4s\n",
            "519:\tlearn: 0.3330828\ttotal: 13.4s\tremaining: 12.4s\n",
            "520:\tlearn: 0.3327868\ttotal: 13.4s\tremaining: 12.4s\n",
            "521:\tlearn: 0.3325599\ttotal: 13.5s\tremaining: 12.3s\n",
            "522:\tlearn: 0.3324068\ttotal: 13.5s\tremaining: 12.3s\n",
            "523:\tlearn: 0.3322355\ttotal: 13.5s\tremaining: 12.3s\n",
            "524:\tlearn: 0.3321181\ttotal: 13.5s\tremaining: 12.2s\n",
            "525:\tlearn: 0.3319674\ttotal: 13.6s\tremaining: 12.2s\n",
            "526:\tlearn: 0.3318561\ttotal: 13.6s\tremaining: 12.2s\n",
            "527:\tlearn: 0.3317274\ttotal: 13.6s\tremaining: 12.1s\n",
            "528:\tlearn: 0.3315074\ttotal: 13.6s\tremaining: 12.1s\n",
            "529:\tlearn: 0.3313542\ttotal: 13.6s\tremaining: 12.1s\n",
            "530:\tlearn: 0.3310524\ttotal: 13.7s\tremaining: 12.1s\n",
            "531:\tlearn: 0.3308825\ttotal: 13.7s\tremaining: 12s\n",
            "532:\tlearn: 0.3306573\ttotal: 13.7s\tremaining: 12s\n",
            "533:\tlearn: 0.3304870\ttotal: 13.7s\tremaining: 12s\n",
            "534:\tlearn: 0.3302606\ttotal: 13.8s\tremaining: 12s\n",
            "535:\tlearn: 0.3300832\ttotal: 13.8s\tremaining: 11.9s\n",
            "536:\tlearn: 0.3299209\ttotal: 13.8s\tremaining: 11.9s\n",
            "537:\tlearn: 0.3297638\ttotal: 13.8s\tremaining: 11.9s\n",
            "538:\tlearn: 0.3296249\ttotal: 13.8s\tremaining: 11.8s\n",
            "539:\tlearn: 0.3293300\ttotal: 13.9s\tremaining: 11.8s\n",
            "540:\tlearn: 0.3290481\ttotal: 13.9s\tremaining: 11.8s\n",
            "541:\tlearn: 0.3290075\ttotal: 13.9s\tremaining: 11.8s\n",
            "542:\tlearn: 0.3287534\ttotal: 13.9s\tremaining: 11.7s\n",
            "543:\tlearn: 0.3285561\ttotal: 13.9s\tremaining: 11.7s\n",
            "544:\tlearn: 0.3283655\ttotal: 14s\tremaining: 11.7s\n",
            "545:\tlearn: 0.3282863\ttotal: 14s\tremaining: 11.6s\n",
            "546:\tlearn: 0.3280933\ttotal: 14s\tremaining: 11.6s\n",
            "547:\tlearn: 0.3278852\ttotal: 14s\tremaining: 11.6s\n",
            "548:\tlearn: 0.3277269\ttotal: 14.1s\tremaining: 11.6s\n",
            "549:\tlearn: 0.3275850\ttotal: 14.1s\tremaining: 11.5s\n",
            "550:\tlearn: 0.3273738\ttotal: 14.1s\tremaining: 11.5s\n",
            "551:\tlearn: 0.3271486\ttotal: 14.1s\tremaining: 11.5s\n",
            "552:\tlearn: 0.3270228\ttotal: 14.2s\tremaining: 11.4s\n",
            "553:\tlearn: 0.3268221\ttotal: 14.2s\tremaining: 11.4s\n",
            "554:\tlearn: 0.3266701\ttotal: 14.2s\tremaining: 11.4s\n",
            "555:\tlearn: 0.3264285\ttotal: 14.2s\tremaining: 11.4s\n",
            "556:\tlearn: 0.3261764\ttotal: 14.2s\tremaining: 11.3s\n",
            "557:\tlearn: 0.3260144\ttotal: 14.3s\tremaining: 11.3s\n",
            "558:\tlearn: 0.3257642\ttotal: 14.3s\tremaining: 11.3s\n",
            "559:\tlearn: 0.3257211\ttotal: 14.3s\tremaining: 11.3s\n",
            "560:\tlearn: 0.3254881\ttotal: 14.3s\tremaining: 11.2s\n",
            "561:\tlearn: 0.3253601\ttotal: 14.4s\tremaining: 11.2s\n",
            "562:\tlearn: 0.3251684\ttotal: 14.4s\tremaining: 11.2s\n",
            "563:\tlearn: 0.3249750\ttotal: 14.4s\tremaining: 11.1s\n",
            "564:\tlearn: 0.3249420\ttotal: 14.4s\tremaining: 11.1s\n",
            "565:\tlearn: 0.3248291\ttotal: 14.4s\tremaining: 11.1s\n",
            "566:\tlearn: 0.3246170\ttotal: 14.5s\tremaining: 11s\n",
            "567:\tlearn: 0.3244961\ttotal: 14.5s\tremaining: 11s\n",
            "568:\tlearn: 0.3242600\ttotal: 14.5s\tremaining: 11s\n",
            "569:\tlearn: 0.3241017\ttotal: 14.5s\tremaining: 11s\n",
            "570:\tlearn: 0.3239199\ttotal: 14.6s\tremaining: 10.9s\n",
            "571:\tlearn: 0.3236941\ttotal: 14.6s\tremaining: 10.9s\n",
            "572:\tlearn: 0.3235728\ttotal: 14.6s\tremaining: 10.9s\n",
            "573:\tlearn: 0.3234379\ttotal: 14.6s\tremaining: 10.9s\n",
            "574:\tlearn: 0.3234062\ttotal: 14.6s\tremaining: 10.8s\n",
            "575:\tlearn: 0.3232809\ttotal: 14.7s\tremaining: 10.8s\n",
            "576:\tlearn: 0.3231024\ttotal: 14.7s\tremaining: 10.8s\n",
            "577:\tlearn: 0.3229537\ttotal: 14.7s\tremaining: 10.7s\n",
            "578:\tlearn: 0.3227383\ttotal: 14.7s\tremaining: 10.7s\n",
            "579:\tlearn: 0.3225523\ttotal: 14.8s\tremaining: 10.7s\n",
            "580:\tlearn: 0.3223826\ttotal: 14.8s\tremaining: 10.7s\n",
            "581:\tlearn: 0.3222913\ttotal: 14.8s\tremaining: 10.6s\n",
            "582:\tlearn: 0.3221363\ttotal: 14.8s\tremaining: 10.6s\n",
            "583:\tlearn: 0.3219286\ttotal: 14.8s\tremaining: 10.6s\n",
            "584:\tlearn: 0.3218231\ttotal: 14.9s\tremaining: 10.5s\n",
            "585:\tlearn: 0.3215947\ttotal: 14.9s\tremaining: 10.5s\n",
            "586:\tlearn: 0.3214536\ttotal: 14.9s\tremaining: 10.5s\n",
            "587:\tlearn: 0.3212678\ttotal: 14.9s\tremaining: 10.5s\n",
            "588:\tlearn: 0.3210165\ttotal: 15s\tremaining: 10.4s\n",
            "589:\tlearn: 0.3208269\ttotal: 15s\tremaining: 10.4s\n",
            "590:\tlearn: 0.3206990\ttotal: 15s\tremaining: 10.4s\n",
            "591:\tlearn: 0.3205309\ttotal: 15s\tremaining: 10.4s\n",
            "592:\tlearn: 0.3204320\ttotal: 15.1s\tremaining: 10.3s\n",
            "593:\tlearn: 0.3203029\ttotal: 15.1s\tremaining: 10.3s\n",
            "594:\tlearn: 0.3201676\ttotal: 15.1s\tremaining: 10.3s\n",
            "595:\tlearn: 0.3199905\ttotal: 15.1s\tremaining: 10.3s\n",
            "596:\tlearn: 0.3198140\ttotal: 15.1s\tremaining: 10.2s\n",
            "597:\tlearn: 0.3195233\ttotal: 15.2s\tremaining: 10.2s\n",
            "598:\tlearn: 0.3194320\ttotal: 15.2s\tremaining: 10.2s\n",
            "599:\tlearn: 0.3192680\ttotal: 15.2s\tremaining: 10.1s\n",
            "600:\tlearn: 0.3190350\ttotal: 15.2s\tremaining: 10.1s\n",
            "601:\tlearn: 0.3188485\ttotal: 15.3s\tremaining: 10.1s\n",
            "602:\tlearn: 0.3187096\ttotal: 15.3s\tremaining: 10.1s\n",
            "603:\tlearn: 0.3186009\ttotal: 15.3s\tremaining: 10s\n",
            "604:\tlearn: 0.3184492\ttotal: 15.3s\tremaining: 10s\n",
            "605:\tlearn: 0.3183155\ttotal: 15.3s\tremaining: 9.98s\n",
            "606:\tlearn: 0.3181936\ttotal: 15.4s\tremaining: 9.95s\n",
            "607:\tlearn: 0.3179427\ttotal: 15.4s\tremaining: 9.92s\n",
            "608:\tlearn: 0.3177666\ttotal: 15.4s\tremaining: 9.9s\n",
            "609:\tlearn: 0.3175850\ttotal: 15.4s\tremaining: 9.87s\n",
            "610:\tlearn: 0.3174110\ttotal: 15.5s\tremaining: 9.84s\n",
            "611:\tlearn: 0.3172260\ttotal: 15.5s\tremaining: 9.82s\n",
            "612:\tlearn: 0.3170277\ttotal: 15.5s\tremaining: 9.79s\n",
            "613:\tlearn: 0.3168835\ttotal: 15.5s\tremaining: 9.76s\n",
            "614:\tlearn: 0.3167524\ttotal: 15.5s\tremaining: 9.73s\n",
            "615:\tlearn: 0.3164785\ttotal: 15.6s\tremaining: 9.7s\n",
            "616:\tlearn: 0.3162990\ttotal: 15.6s\tremaining: 9.68s\n",
            "617:\tlearn: 0.3161824\ttotal: 15.6s\tremaining: 9.65s\n",
            "618:\tlearn: 0.3160146\ttotal: 15.6s\tremaining: 9.63s\n",
            "619:\tlearn: 0.3158635\ttotal: 15.7s\tremaining: 9.6s\n",
            "620:\tlearn: 0.3156960\ttotal: 15.7s\tremaining: 9.57s\n",
            "621:\tlearn: 0.3154983\ttotal: 15.7s\tremaining: 9.54s\n",
            "622:\tlearn: 0.3153663\ttotal: 15.7s\tremaining: 9.52s\n",
            "623:\tlearn: 0.3151794\ttotal: 15.7s\tremaining: 9.49s\n",
            "624:\tlearn: 0.3150790\ttotal: 15.8s\tremaining: 9.46s\n",
            "625:\tlearn: 0.3149014\ttotal: 15.8s\tremaining: 9.43s\n",
            "626:\tlearn: 0.3147767\ttotal: 15.8s\tremaining: 9.41s\n",
            "627:\tlearn: 0.3145733\ttotal: 15.8s\tremaining: 9.38s\n",
            "628:\tlearn: 0.3144374\ttotal: 15.9s\tremaining: 9.36s\n",
            "629:\tlearn: 0.3143577\ttotal: 15.9s\tremaining: 9.33s\n",
            "630:\tlearn: 0.3141683\ttotal: 15.9s\tremaining: 9.31s\n",
            "631:\tlearn: 0.3140381\ttotal: 15.9s\tremaining: 9.28s\n",
            "632:\tlearn: 0.3138223\ttotal: 16s\tremaining: 9.25s\n",
            "633:\tlearn: 0.3136971\ttotal: 16s\tremaining: 9.22s\n",
            "634:\tlearn: 0.3135362\ttotal: 16s\tremaining: 9.2s\n",
            "635:\tlearn: 0.3134011\ttotal: 16s\tremaining: 9.17s\n",
            "636:\tlearn: 0.3133725\ttotal: 16s\tremaining: 9.14s\n",
            "637:\tlearn: 0.3132591\ttotal: 16.1s\tremaining: 9.12s\n",
            "638:\tlearn: 0.3129901\ttotal: 16.1s\tremaining: 9.1s\n",
            "639:\tlearn: 0.3128939\ttotal: 16.1s\tremaining: 9.07s\n",
            "640:\tlearn: 0.3127814\ttotal: 16.2s\tremaining: 9.05s\n",
            "641:\tlearn: 0.3126258\ttotal: 16.2s\tremaining: 9.02s\n",
            "642:\tlearn: 0.3124031\ttotal: 16.2s\tremaining: 8.99s\n",
            "643:\tlearn: 0.3122312\ttotal: 16.2s\tremaining: 8.96s\n",
            "644:\tlearn: 0.3122004\ttotal: 16.2s\tremaining: 8.94s\n",
            "645:\tlearn: 0.3120160\ttotal: 16.3s\tremaining: 8.91s\n",
            "646:\tlearn: 0.3119305\ttotal: 16.3s\tremaining: 8.88s\n",
            "647:\tlearn: 0.3117546\ttotal: 16.3s\tremaining: 8.86s\n",
            "648:\tlearn: 0.3116605\ttotal: 16.3s\tremaining: 8.83s\n",
            "649:\tlearn: 0.3115993\ttotal: 16.3s\tremaining: 8.8s\n",
            "650:\tlearn: 0.3114510\ttotal: 16.4s\tremaining: 8.77s\n",
            "651:\tlearn: 0.3113264\ttotal: 16.4s\tremaining: 8.74s\n",
            "652:\tlearn: 0.3111659\ttotal: 16.4s\tremaining: 8.72s\n",
            "653:\tlearn: 0.3110440\ttotal: 16.4s\tremaining: 8.69s\n",
            "654:\tlearn: 0.3108339\ttotal: 16.4s\tremaining: 8.66s\n",
            "655:\tlearn: 0.3106533\ttotal: 16.5s\tremaining: 8.64s\n",
            "656:\tlearn: 0.3104832\ttotal: 16.5s\tremaining: 8.61s\n",
            "657:\tlearn: 0.3102998\ttotal: 16.5s\tremaining: 8.59s\n",
            "658:\tlearn: 0.3101531\ttotal: 16.5s\tremaining: 8.56s\n",
            "659:\tlearn: 0.3099848\ttotal: 16.6s\tremaining: 8.53s\n",
            "660:\tlearn: 0.3098441\ttotal: 16.6s\tremaining: 8.5s\n",
            "661:\tlearn: 0.3097311\ttotal: 16.6s\tremaining: 8.48s\n",
            "662:\tlearn: 0.3096081\ttotal: 16.6s\tremaining: 8.45s\n",
            "663:\tlearn: 0.3094619\ttotal: 16.6s\tremaining: 8.42s\n",
            "664:\tlearn: 0.3093434\ttotal: 16.7s\tremaining: 8.4s\n",
            "665:\tlearn: 0.3091596\ttotal: 16.7s\tremaining: 8.37s\n",
            "666:\tlearn: 0.3089895\ttotal: 16.7s\tremaining: 8.35s\n",
            "667:\tlearn: 0.3089661\ttotal: 16.7s\tremaining: 8.32s\n",
            "668:\tlearn: 0.3087621\ttotal: 16.8s\tremaining: 8.29s\n",
            "669:\tlearn: 0.3085698\ttotal: 16.8s\tremaining: 8.27s\n",
            "670:\tlearn: 0.3083895\ttotal: 16.8s\tremaining: 8.24s\n",
            "671:\tlearn: 0.3082685\ttotal: 16.8s\tremaining: 8.21s\n",
            "672:\tlearn: 0.3080608\ttotal: 16.9s\tremaining: 8.19s\n",
            "673:\tlearn: 0.3078763\ttotal: 16.9s\tremaining: 8.16s\n",
            "674:\tlearn: 0.3077165\ttotal: 16.9s\tremaining: 8.13s\n",
            "675:\tlearn: 0.3075456\ttotal: 16.9s\tremaining: 8.11s\n",
            "676:\tlearn: 0.3072794\ttotal: 16.9s\tremaining: 8.08s\n",
            "677:\tlearn: 0.3071257\ttotal: 17s\tremaining: 8.06s\n",
            "678:\tlearn: 0.3068990\ttotal: 17s\tremaining: 8.03s\n",
            "679:\tlearn: 0.3066855\ttotal: 17s\tremaining: 8s\n",
            "680:\tlearn: 0.3066663\ttotal: 17s\tremaining: 7.97s\n",
            "681:\tlearn: 0.3065281\ttotal: 17s\tremaining: 7.95s\n",
            "682:\tlearn: 0.3064074\ttotal: 17.1s\tremaining: 7.92s\n",
            "683:\tlearn: 0.3062113\ttotal: 17.1s\tremaining: 7.9s\n",
            "684:\tlearn: 0.3059998\ttotal: 17.1s\tremaining: 7.88s\n",
            "685:\tlearn: 0.3058414\ttotal: 17.2s\tremaining: 7.86s\n",
            "686:\tlearn: 0.3056347\ttotal: 17.2s\tremaining: 7.83s\n",
            "687:\tlearn: 0.3054165\ttotal: 17.2s\tremaining: 7.8s\n",
            "688:\tlearn: 0.3051669\ttotal: 17.2s\tremaining: 7.78s\n",
            "689:\tlearn: 0.3049806\ttotal: 17.3s\tremaining: 7.75s\n",
            "690:\tlearn: 0.3048490\ttotal: 17.3s\tremaining: 7.72s\n",
            "691:\tlearn: 0.3047008\ttotal: 17.3s\tremaining: 7.7s\n",
            "692:\tlearn: 0.3045797\ttotal: 17.3s\tremaining: 7.67s\n",
            "693:\tlearn: 0.3043513\ttotal: 17.3s\tremaining: 7.64s\n",
            "694:\tlearn: 0.3042329\ttotal: 17.4s\tremaining: 7.62s\n",
            "695:\tlearn: 0.3040966\ttotal: 17.4s\tremaining: 7.59s\n",
            "696:\tlearn: 0.3038653\ttotal: 17.4s\tremaining: 7.57s\n",
            "697:\tlearn: 0.3037270\ttotal: 17.4s\tremaining: 7.54s\n",
            "698:\tlearn: 0.3035482\ttotal: 17.4s\tremaining: 7.51s\n",
            "699:\tlearn: 0.3034406\ttotal: 17.5s\tremaining: 7.49s\n",
            "700:\tlearn: 0.3032366\ttotal: 17.5s\tremaining: 7.46s\n",
            "701:\tlearn: 0.3029588\ttotal: 17.5s\tremaining: 7.43s\n",
            "702:\tlearn: 0.3028502\ttotal: 17.5s\tremaining: 7.41s\n",
            "703:\tlearn: 0.3026403\ttotal: 17.6s\tremaining: 7.38s\n",
            "704:\tlearn: 0.3024813\ttotal: 17.6s\tremaining: 7.36s\n",
            "705:\tlearn: 0.3023473\ttotal: 17.6s\tremaining: 7.33s\n",
            "706:\tlearn: 0.3021483\ttotal: 17.6s\tremaining: 7.3s\n",
            "707:\tlearn: 0.3019961\ttotal: 17.6s\tremaining: 7.28s\n",
            "708:\tlearn: 0.3019018\ttotal: 17.7s\tremaining: 7.25s\n",
            "709:\tlearn: 0.3018679\ttotal: 17.7s\tremaining: 7.22s\n",
            "710:\tlearn: 0.3017102\ttotal: 17.7s\tremaining: 7.2s\n",
            "711:\tlearn: 0.3016066\ttotal: 17.7s\tremaining: 7.17s\n",
            "712:\tlearn: 0.3014483\ttotal: 17.8s\tremaining: 7.15s\n",
            "713:\tlearn: 0.3013565\ttotal: 17.8s\tremaining: 7.12s\n",
            "714:\tlearn: 0.3012299\ttotal: 17.8s\tremaining: 7.1s\n",
            "715:\tlearn: 0.3012020\ttotal: 17.8s\tremaining: 7.07s\n",
            "716:\tlearn: 0.3010270\ttotal: 17.8s\tremaining: 7.04s\n",
            "717:\tlearn: 0.3009025\ttotal: 17.9s\tremaining: 7.02s\n",
            "718:\tlearn: 0.3007152\ttotal: 17.9s\tremaining: 6.99s\n",
            "719:\tlearn: 0.3005777\ttotal: 17.9s\tremaining: 6.97s\n",
            "720:\tlearn: 0.3003750\ttotal: 17.9s\tremaining: 6.94s\n",
            "721:\tlearn: 0.3002750\ttotal: 18s\tremaining: 6.91s\n",
            "722:\tlearn: 0.3001287\ttotal: 18s\tremaining: 6.89s\n",
            "723:\tlearn: 0.2999660\ttotal: 18s\tremaining: 6.86s\n",
            "724:\tlearn: 0.2998386\ttotal: 18s\tremaining: 6.84s\n",
            "725:\tlearn: 0.2997170\ttotal: 18s\tremaining: 6.81s\n",
            "726:\tlearn: 0.2995859\ttotal: 18.1s\tremaining: 6.78s\n",
            "727:\tlearn: 0.2993816\ttotal: 18.1s\tremaining: 6.76s\n",
            "728:\tlearn: 0.2992111\ttotal: 18.1s\tremaining: 6.74s\n",
            "729:\tlearn: 0.2990492\ttotal: 18.1s\tremaining: 6.71s\n",
            "730:\tlearn: 0.2989122\ttotal: 18.2s\tremaining: 6.68s\n",
            "731:\tlearn: 0.2987801\ttotal: 18.2s\tremaining: 6.66s\n",
            "732:\tlearn: 0.2986919\ttotal: 18.2s\tremaining: 6.63s\n",
            "733:\tlearn: 0.2984721\ttotal: 18.2s\tremaining: 6.61s\n",
            "734:\tlearn: 0.2983734\ttotal: 18.3s\tremaining: 6.58s\n",
            "735:\tlearn: 0.2982487\ttotal: 18.3s\tremaining: 6.56s\n",
            "736:\tlearn: 0.2980196\ttotal: 18.3s\tremaining: 6.53s\n",
            "737:\tlearn: 0.2978660\ttotal: 18.3s\tremaining: 6.5s\n",
            "738:\tlearn: 0.2977645\ttotal: 18.3s\tremaining: 6.48s\n",
            "739:\tlearn: 0.2976297\ttotal: 18.4s\tremaining: 6.45s\n",
            "740:\tlearn: 0.2974343\ttotal: 18.4s\tremaining: 6.42s\n",
            "741:\tlearn: 0.2971710\ttotal: 18.4s\tremaining: 6.4s\n",
            "742:\tlearn: 0.2970502\ttotal: 18.4s\tremaining: 6.37s\n",
            "743:\tlearn: 0.2968955\ttotal: 18.5s\tremaining: 6.35s\n",
            "744:\tlearn: 0.2967710\ttotal: 18.5s\tremaining: 6.32s\n",
            "745:\tlearn: 0.2966932\ttotal: 18.5s\tremaining: 6.3s\n",
            "746:\tlearn: 0.2965495\ttotal: 18.5s\tremaining: 6.27s\n",
            "747:\tlearn: 0.2963680\ttotal: 18.5s\tremaining: 6.24s\n",
            "748:\tlearn: 0.2961537\ttotal: 18.6s\tremaining: 6.22s\n",
            "749:\tlearn: 0.2960385\ttotal: 18.6s\tremaining: 6.19s\n",
            "750:\tlearn: 0.2959420\ttotal: 18.6s\tremaining: 6.17s\n",
            "751:\tlearn: 0.2958007\ttotal: 18.6s\tremaining: 6.14s\n",
            "752:\tlearn: 0.2956985\ttotal: 18.7s\tremaining: 6.12s\n",
            "753:\tlearn: 0.2955706\ttotal: 18.7s\tremaining: 6.09s\n",
            "754:\tlearn: 0.2954371\ttotal: 18.7s\tremaining: 6.07s\n",
            "755:\tlearn: 0.2952961\ttotal: 18.7s\tremaining: 6.04s\n",
            "756:\tlearn: 0.2950699\ttotal: 18.7s\tremaining: 6.02s\n",
            "757:\tlearn: 0.2948969\ttotal: 18.8s\tremaining: 5.99s\n",
            "758:\tlearn: 0.2948046\ttotal: 18.8s\tremaining: 5.96s\n",
            "759:\tlearn: 0.2946637\ttotal: 18.8s\tremaining: 5.94s\n",
            "760:\tlearn: 0.2944628\ttotal: 18.8s\tremaining: 5.91s\n",
            "761:\tlearn: 0.2942802\ttotal: 18.8s\tremaining: 5.88s\n",
            "762:\tlearn: 0.2940971\ttotal: 18.9s\tremaining: 5.86s\n",
            "763:\tlearn: 0.2939883\ttotal: 18.9s\tremaining: 5.84s\n",
            "764:\tlearn: 0.2939648\ttotal: 18.9s\tremaining: 5.81s\n",
            "765:\tlearn: 0.2937814\ttotal: 18.9s\tremaining: 5.79s\n",
            "766:\tlearn: 0.2936793\ttotal: 19s\tremaining: 5.76s\n",
            "767:\tlearn: 0.2935481\ttotal: 19s\tremaining: 5.73s\n",
            "768:\tlearn: 0.2933926\ttotal: 19s\tremaining: 5.71s\n",
            "769:\tlearn: 0.2932210\ttotal: 19s\tremaining: 5.68s\n",
            "770:\tlearn: 0.2930720\ttotal: 19.1s\tremaining: 5.66s\n",
            "771:\tlearn: 0.2928907\ttotal: 19.1s\tremaining: 5.63s\n",
            "772:\tlearn: 0.2927825\ttotal: 19.1s\tremaining: 5.61s\n",
            "773:\tlearn: 0.2927090\ttotal: 19.1s\tremaining: 5.59s\n",
            "774:\tlearn: 0.2925761\ttotal: 19.2s\tremaining: 5.56s\n",
            "775:\tlearn: 0.2924969\ttotal: 19.2s\tremaining: 5.54s\n",
            "776:\tlearn: 0.2923088\ttotal: 19.2s\tremaining: 5.51s\n",
            "777:\tlearn: 0.2922893\ttotal: 19.2s\tremaining: 5.48s\n",
            "778:\tlearn: 0.2922193\ttotal: 19.2s\tremaining: 5.46s\n",
            "779:\tlearn: 0.2920728\ttotal: 19.3s\tremaining: 5.43s\n",
            "780:\tlearn: 0.2919491\ttotal: 19.3s\tremaining: 5.41s\n",
            "781:\tlearn: 0.2917515\ttotal: 19.3s\tremaining: 5.38s\n",
            "782:\tlearn: 0.2915361\ttotal: 19.3s\tremaining: 5.36s\n",
            "783:\tlearn: 0.2912740\ttotal: 19.4s\tremaining: 5.33s\n",
            "784:\tlearn: 0.2911563\ttotal: 19.4s\tremaining: 5.3s\n",
            "785:\tlearn: 0.2910430\ttotal: 19.4s\tremaining: 5.28s\n",
            "786:\tlearn: 0.2908972\ttotal: 19.4s\tremaining: 5.25s\n",
            "787:\tlearn: 0.2907508\ttotal: 19.4s\tremaining: 5.23s\n",
            "788:\tlearn: 0.2906102\ttotal: 19.5s\tremaining: 5.2s\n",
            "789:\tlearn: 0.2905225\ttotal: 19.5s\tremaining: 5.18s\n",
            "790:\tlearn: 0.2904034\ttotal: 19.5s\tremaining: 5.15s\n",
            "791:\tlearn: 0.2903097\ttotal: 19.5s\tremaining: 5.13s\n",
            "792:\tlearn: 0.2901629\ttotal: 19.6s\tremaining: 5.1s\n",
            "793:\tlearn: 0.2900198\ttotal: 19.6s\tremaining: 5.08s\n",
            "794:\tlearn: 0.2897580\ttotal: 19.6s\tremaining: 5.05s\n",
            "795:\tlearn: 0.2897389\ttotal: 19.6s\tremaining: 5.03s\n",
            "796:\tlearn: 0.2896024\ttotal: 19.6s\tremaining: 5s\n",
            "797:\tlearn: 0.2894986\ttotal: 19.7s\tremaining: 4.97s\n",
            "798:\tlearn: 0.2893810\ttotal: 19.7s\tremaining: 4.95s\n",
            "799:\tlearn: 0.2892775\ttotal: 19.7s\tremaining: 4.92s\n",
            "800:\tlearn: 0.2891371\ttotal: 19.7s\tremaining: 4.9s\n",
            "801:\tlearn: 0.2889035\ttotal: 19.7s\tremaining: 4.88s\n",
            "802:\tlearn: 0.2887546\ttotal: 19.8s\tremaining: 4.85s\n",
            "803:\tlearn: 0.2886094\ttotal: 19.8s\tremaining: 4.83s\n",
            "804:\tlearn: 0.2884745\ttotal: 19.8s\tremaining: 4.8s\n",
            "805:\tlearn: 0.2884055\ttotal: 19.8s\tremaining: 4.77s\n",
            "806:\tlearn: 0.2882507\ttotal: 19.9s\tremaining: 4.75s\n",
            "807:\tlearn: 0.2881483\ttotal: 19.9s\tremaining: 4.72s\n",
            "808:\tlearn: 0.2881317\ttotal: 19.9s\tremaining: 4.7s\n",
            "809:\tlearn: 0.2879875\ttotal: 19.9s\tremaining: 4.67s\n",
            "810:\tlearn: 0.2878087\ttotal: 19.9s\tremaining: 4.65s\n",
            "811:\tlearn: 0.2876509\ttotal: 20s\tremaining: 4.62s\n",
            "812:\tlearn: 0.2875350\ttotal: 20s\tremaining: 4.6s\n",
            "813:\tlearn: 0.2874628\ttotal: 20s\tremaining: 4.57s\n",
            "814:\tlearn: 0.2872746\ttotal: 20s\tremaining: 4.55s\n",
            "815:\tlearn: 0.2872217\ttotal: 20.1s\tremaining: 4.52s\n",
            "816:\tlearn: 0.2871160\ttotal: 20.1s\tremaining: 4.5s\n",
            "817:\tlearn: 0.2870130\ttotal: 20.1s\tremaining: 4.47s\n",
            "818:\tlearn: 0.2868193\ttotal: 20.1s\tremaining: 4.45s\n",
            "819:\tlearn: 0.2866581\ttotal: 20.2s\tremaining: 4.42s\n",
            "820:\tlearn: 0.2865221\ttotal: 20.2s\tremaining: 4.4s\n",
            "821:\tlearn: 0.2863909\ttotal: 20.2s\tremaining: 4.38s\n",
            "822:\tlearn: 0.2862610\ttotal: 20.2s\tremaining: 4.35s\n",
            "823:\tlearn: 0.2861136\ttotal: 20.3s\tremaining: 4.33s\n",
            "824:\tlearn: 0.2860206\ttotal: 20.3s\tremaining: 4.3s\n",
            "825:\tlearn: 0.2858819\ttotal: 20.3s\tremaining: 4.28s\n",
            "826:\tlearn: 0.2857841\ttotal: 20.3s\tremaining: 4.25s\n",
            "827:\tlearn: 0.2856977\ttotal: 20.3s\tremaining: 4.22s\n",
            "828:\tlearn: 0.2855065\ttotal: 20.4s\tremaining: 4.2s\n",
            "829:\tlearn: 0.2853501\ttotal: 20.4s\tremaining: 4.17s\n",
            "830:\tlearn: 0.2851729\ttotal: 20.4s\tremaining: 4.15s\n",
            "831:\tlearn: 0.2850728\ttotal: 20.4s\tremaining: 4.13s\n",
            "832:\tlearn: 0.2849941\ttotal: 20.5s\tremaining: 4.1s\n",
            "833:\tlearn: 0.2848782\ttotal: 20.5s\tremaining: 4.08s\n",
            "834:\tlearn: 0.2846785\ttotal: 20.5s\tremaining: 4.05s\n",
            "835:\tlearn: 0.2845151\ttotal: 20.5s\tremaining: 4.03s\n",
            "836:\tlearn: 0.2843558\ttotal: 20.5s\tremaining: 4s\n",
            "837:\tlearn: 0.2842500\ttotal: 20.6s\tremaining: 3.98s\n",
            "838:\tlearn: 0.2841068\ttotal: 20.6s\tremaining: 3.95s\n",
            "839:\tlearn: 0.2840876\ttotal: 20.6s\tremaining: 3.93s\n",
            "840:\tlearn: 0.2839750\ttotal: 20.6s\tremaining: 3.9s\n",
            "841:\tlearn: 0.2838072\ttotal: 20.7s\tremaining: 3.88s\n",
            "842:\tlearn: 0.2836171\ttotal: 20.7s\tremaining: 3.85s\n",
            "843:\tlearn: 0.2835259\ttotal: 20.7s\tremaining: 3.83s\n",
            "844:\tlearn: 0.2834148\ttotal: 20.7s\tremaining: 3.8s\n",
            "845:\tlearn: 0.2832365\ttotal: 20.7s\tremaining: 3.78s\n",
            "846:\tlearn: 0.2830691\ttotal: 20.8s\tremaining: 3.75s\n",
            "847:\tlearn: 0.2829292\ttotal: 20.8s\tremaining: 3.73s\n",
            "848:\tlearn: 0.2828171\ttotal: 20.8s\tremaining: 3.7s\n",
            "849:\tlearn: 0.2826904\ttotal: 20.8s\tremaining: 3.68s\n",
            "850:\tlearn: 0.2825662\ttotal: 20.9s\tremaining: 3.65s\n",
            "851:\tlearn: 0.2824053\ttotal: 20.9s\tremaining: 3.63s\n",
            "852:\tlearn: 0.2822959\ttotal: 20.9s\tremaining: 3.6s\n",
            "853:\tlearn: 0.2821409\ttotal: 20.9s\tremaining: 3.58s\n",
            "854:\tlearn: 0.2819623\ttotal: 20.9s\tremaining: 3.55s\n",
            "855:\tlearn: 0.2818336\ttotal: 21s\tremaining: 3.53s\n",
            "856:\tlearn: 0.2816935\ttotal: 21s\tremaining: 3.5s\n",
            "857:\tlearn: 0.2814429\ttotal: 21s\tremaining: 3.48s\n",
            "858:\tlearn: 0.2813546\ttotal: 21s\tremaining: 3.45s\n",
            "859:\tlearn: 0.2811904\ttotal: 21.1s\tremaining: 3.43s\n",
            "860:\tlearn: 0.2810612\ttotal: 21.1s\tremaining: 3.4s\n",
            "861:\tlearn: 0.2809976\ttotal: 21.1s\tremaining: 3.38s\n",
            "862:\tlearn: 0.2808648\ttotal: 21.1s\tremaining: 3.35s\n",
            "863:\tlearn: 0.2807642\ttotal: 21.2s\tremaining: 3.33s\n",
            "864:\tlearn: 0.2806229\ttotal: 21.2s\tremaining: 3.31s\n",
            "865:\tlearn: 0.2805727\ttotal: 21.2s\tremaining: 3.28s\n",
            "866:\tlearn: 0.2804272\ttotal: 21.2s\tremaining: 3.26s\n",
            "867:\tlearn: 0.2803551\ttotal: 21.3s\tremaining: 3.23s\n",
            "868:\tlearn: 0.2802351\ttotal: 21.3s\tremaining: 3.21s\n",
            "869:\tlearn: 0.2801164\ttotal: 21.3s\tremaining: 3.18s\n",
            "870:\tlearn: 0.2798336\ttotal: 21.3s\tremaining: 3.16s\n",
            "871:\tlearn: 0.2797082\ttotal: 21.3s\tremaining: 3.13s\n",
            "872:\tlearn: 0.2795213\ttotal: 21.4s\tremaining: 3.11s\n",
            "873:\tlearn: 0.2793607\ttotal: 21.4s\tremaining: 3.08s\n",
            "874:\tlearn: 0.2792412\ttotal: 21.4s\tremaining: 3.06s\n",
            "875:\tlearn: 0.2790644\ttotal: 21.4s\tremaining: 3.03s\n",
            "876:\tlearn: 0.2788650\ttotal: 21.5s\tremaining: 3.01s\n",
            "877:\tlearn: 0.2787901\ttotal: 21.5s\tremaining: 2.98s\n",
            "878:\tlearn: 0.2786971\ttotal: 21.5s\tremaining: 2.96s\n",
            "879:\tlearn: 0.2786158\ttotal: 21.5s\tremaining: 2.93s\n",
            "880:\tlearn: 0.2784835\ttotal: 21.5s\tremaining: 2.91s\n",
            "881:\tlearn: 0.2783879\ttotal: 21.6s\tremaining: 2.88s\n",
            "882:\tlearn: 0.2782787\ttotal: 21.6s\tremaining: 2.86s\n",
            "883:\tlearn: 0.2781664\ttotal: 21.6s\tremaining: 2.83s\n",
            "884:\tlearn: 0.2781206\ttotal: 21.6s\tremaining: 2.81s\n",
            "885:\tlearn: 0.2780052\ttotal: 21.6s\tremaining: 2.78s\n",
            "886:\tlearn: 0.2778730\ttotal: 21.7s\tremaining: 2.76s\n",
            "887:\tlearn: 0.2777201\ttotal: 21.7s\tremaining: 2.74s\n",
            "888:\tlearn: 0.2775765\ttotal: 21.7s\tremaining: 2.71s\n",
            "889:\tlearn: 0.2774944\ttotal: 21.7s\tremaining: 2.69s\n",
            "890:\tlearn: 0.2773618\ttotal: 21.8s\tremaining: 2.66s\n",
            "891:\tlearn: 0.2771678\ttotal: 21.8s\tremaining: 2.64s\n",
            "892:\tlearn: 0.2770225\ttotal: 21.8s\tremaining: 2.61s\n",
            "893:\tlearn: 0.2768988\ttotal: 21.8s\tremaining: 2.59s\n",
            "894:\tlearn: 0.2767914\ttotal: 21.8s\tremaining: 2.56s\n",
            "895:\tlearn: 0.2767027\ttotal: 21.9s\tremaining: 2.54s\n",
            "896:\tlearn: 0.2765666\ttotal: 21.9s\tremaining: 2.52s\n",
            "897:\tlearn: 0.2764378\ttotal: 21.9s\tremaining: 2.49s\n",
            "898:\tlearn: 0.2763117\ttotal: 22s\tremaining: 2.47s\n",
            "899:\tlearn: 0.2761202\ttotal: 22s\tremaining: 2.44s\n",
            "900:\tlearn: 0.2759279\ttotal: 22s\tremaining: 2.42s\n",
            "901:\tlearn: 0.2757813\ttotal: 22.1s\tremaining: 2.4s\n",
            "902:\tlearn: 0.2756609\ttotal: 22.1s\tremaining: 2.37s\n",
            "903:\tlearn: 0.2755179\ttotal: 22.1s\tremaining: 2.35s\n",
            "904:\tlearn: 0.2754445\ttotal: 22.2s\tremaining: 2.33s\n",
            "905:\tlearn: 0.2753416\ttotal: 22.2s\tremaining: 2.31s\n",
            "906:\tlearn: 0.2752431\ttotal: 22.3s\tremaining: 2.28s\n",
            "907:\tlearn: 0.2751075\ttotal: 22.3s\tremaining: 2.26s\n",
            "908:\tlearn: 0.2749962\ttotal: 22.3s\tremaining: 2.24s\n",
            "909:\tlearn: 0.2749298\ttotal: 22.4s\tremaining: 2.21s\n",
            "910:\tlearn: 0.2748056\ttotal: 22.4s\tremaining: 2.19s\n",
            "911:\tlearn: 0.2746875\ttotal: 22.5s\tremaining: 2.17s\n",
            "912:\tlearn: 0.2745693\ttotal: 22.5s\tremaining: 2.15s\n",
            "913:\tlearn: 0.2743845\ttotal: 22.6s\tremaining: 2.12s\n",
            "914:\tlearn: 0.2742450\ttotal: 22.6s\tremaining: 2.1s\n",
            "915:\tlearn: 0.2741698\ttotal: 22.7s\tremaining: 2.08s\n",
            "916:\tlearn: 0.2740284\ttotal: 22.7s\tremaining: 2.06s\n",
            "917:\tlearn: 0.2739374\ttotal: 22.7s\tremaining: 2.03s\n",
            "918:\tlearn: 0.2738049\ttotal: 22.8s\tremaining: 2.01s\n",
            "919:\tlearn: 0.2736570\ttotal: 22.8s\tremaining: 1.98s\n",
            "920:\tlearn: 0.2735815\ttotal: 22.8s\tremaining: 1.96s\n",
            "921:\tlearn: 0.2734278\ttotal: 22.9s\tremaining: 1.94s\n",
            "922:\tlearn: 0.2734116\ttotal: 22.9s\tremaining: 1.91s\n",
            "923:\tlearn: 0.2732631\ttotal: 23s\tremaining: 1.89s\n",
            "924:\tlearn: 0.2731039\ttotal: 23s\tremaining: 1.86s\n",
            "925:\tlearn: 0.2729963\ttotal: 23s\tremaining: 1.84s\n",
            "926:\tlearn: 0.2728847\ttotal: 23.1s\tremaining: 1.82s\n",
            "927:\tlearn: 0.2728128\ttotal: 23.1s\tremaining: 1.79s\n",
            "928:\tlearn: 0.2727084\ttotal: 23.2s\tremaining: 1.77s\n",
            "929:\tlearn: 0.2726385\ttotal: 23.2s\tremaining: 1.75s\n",
            "930:\tlearn: 0.2725308\ttotal: 23.3s\tremaining: 1.73s\n",
            "931:\tlearn: 0.2724113\ttotal: 23.3s\tremaining: 1.7s\n",
            "932:\tlearn: 0.2722785\ttotal: 23.3s\tremaining: 1.68s\n",
            "933:\tlearn: 0.2721479\ttotal: 23.4s\tremaining: 1.65s\n",
            "934:\tlearn: 0.2719878\ttotal: 23.4s\tremaining: 1.63s\n",
            "935:\tlearn: 0.2718651\ttotal: 23.5s\tremaining: 1.6s\n",
            "936:\tlearn: 0.2718076\ttotal: 23.5s\tremaining: 1.58s\n",
            "937:\tlearn: 0.2716499\ttotal: 23.6s\tremaining: 1.56s\n",
            "938:\tlearn: 0.2715152\ttotal: 23.6s\tremaining: 1.53s\n",
            "939:\tlearn: 0.2713970\ttotal: 23.6s\tremaining: 1.51s\n",
            "940:\tlearn: 0.2713071\ttotal: 23.7s\tremaining: 1.49s\n",
            "941:\tlearn: 0.2711662\ttotal: 23.7s\tremaining: 1.46s\n",
            "942:\tlearn: 0.2709914\ttotal: 23.8s\tremaining: 1.44s\n",
            "943:\tlearn: 0.2709076\ttotal: 23.8s\tremaining: 1.41s\n",
            "944:\tlearn: 0.2707000\ttotal: 23.9s\tremaining: 1.39s\n",
            "945:\tlearn: 0.2705718\ttotal: 23.9s\tremaining: 1.36s\n",
            "946:\tlearn: 0.2704741\ttotal: 24s\tremaining: 1.34s\n",
            "947:\tlearn: 0.2704172\ttotal: 24s\tremaining: 1.32s\n",
            "948:\tlearn: 0.2702691\ttotal: 24s\tremaining: 1.29s\n",
            "949:\tlearn: 0.2701882\ttotal: 24.1s\tremaining: 1.27s\n",
            "950:\tlearn: 0.2700437\ttotal: 24.1s\tremaining: 1.24s\n",
            "951:\tlearn: 0.2699356\ttotal: 24.2s\tremaining: 1.22s\n",
            "952:\tlearn: 0.2698179\ttotal: 24.2s\tremaining: 1.19s\n",
            "953:\tlearn: 0.2697348\ttotal: 24.3s\tremaining: 1.17s\n",
            "954:\tlearn: 0.2696213\ttotal: 24.3s\tremaining: 1.15s\n",
            "955:\tlearn: 0.2695370\ttotal: 24.4s\tremaining: 1.12s\n",
            "956:\tlearn: 0.2693888\ttotal: 24.4s\tremaining: 1.1s\n",
            "957:\tlearn: 0.2692496\ttotal: 24.4s\tremaining: 1.07s\n",
            "958:\tlearn: 0.2691130\ttotal: 24.5s\tremaining: 1.05s\n",
            "959:\tlearn: 0.2690113\ttotal: 24.5s\tremaining: 1.02s\n",
            "960:\tlearn: 0.2689959\ttotal: 24.6s\tremaining: 997ms\n",
            "961:\tlearn: 0.2688667\ttotal: 24.6s\tremaining: 973ms\n",
            "962:\tlearn: 0.2687038\ttotal: 24.7s\tremaining: 948ms\n",
            "963:\tlearn: 0.2685778\ttotal: 24.7s\tremaining: 923ms\n",
            "964:\tlearn: 0.2684853\ttotal: 24.8s\tremaining: 898ms\n",
            "965:\tlearn: 0.2683937\ttotal: 24.8s\tremaining: 873ms\n",
            "966:\tlearn: 0.2683128\ttotal: 24.8s\tremaining: 848ms\n",
            "967:\tlearn: 0.2681603\ttotal: 24.9s\tremaining: 823ms\n",
            "968:\tlearn: 0.2680884\ttotal: 24.9s\tremaining: 798ms\n",
            "969:\tlearn: 0.2680235\ttotal: 25s\tremaining: 773ms\n",
            "970:\tlearn: 0.2679702\ttotal: 25s\tremaining: 747ms\n",
            "971:\tlearn: 0.2677976\ttotal: 25.1s\tremaining: 722ms\n",
            "972:\tlearn: 0.2677121\ttotal: 25.1s\tremaining: 697ms\n",
            "973:\tlearn: 0.2675594\ttotal: 25.2s\tremaining: 672ms\n",
            "974:\tlearn: 0.2674478\ttotal: 25.2s\tremaining: 646ms\n",
            "975:\tlearn: 0.2673130\ttotal: 25.3s\tremaining: 621ms\n",
            "976:\tlearn: 0.2672376\ttotal: 25.3s\tremaining: 596ms\n",
            "977:\tlearn: 0.2670351\ttotal: 25.4s\tremaining: 570ms\n",
            "978:\tlearn: 0.2669131\ttotal: 25.4s\tremaining: 545ms\n",
            "979:\tlearn: 0.2667958\ttotal: 25.4s\tremaining: 519ms\n",
            "980:\tlearn: 0.2666575\ttotal: 25.5s\tremaining: 494ms\n",
            "981:\tlearn: 0.2665088\ttotal: 25.5s\tremaining: 468ms\n",
            "982:\tlearn: 0.2663932\ttotal: 25.6s\tremaining: 442ms\n",
            "983:\tlearn: 0.2661783\ttotal: 25.6s\tremaining: 416ms\n",
            "984:\tlearn: 0.2660604\ttotal: 25.6s\tremaining: 390ms\n",
            "985:\tlearn: 0.2659460\ttotal: 25.6s\tremaining: 364ms\n",
            "986:\tlearn: 0.2658417\ttotal: 25.7s\tremaining: 338ms\n",
            "987:\tlearn: 0.2657459\ttotal: 25.7s\tremaining: 312ms\n",
            "988:\tlearn: 0.2656002\ttotal: 25.7s\tremaining: 286ms\n",
            "989:\tlearn: 0.2655296\ttotal: 25.7s\tremaining: 260ms\n",
            "990:\tlearn: 0.2654246\ttotal: 25.8s\tremaining: 234ms\n",
            "991:\tlearn: 0.2652774\ttotal: 25.8s\tremaining: 208ms\n",
            "992:\tlearn: 0.2652051\ttotal: 25.8s\tremaining: 182ms\n",
            "993:\tlearn: 0.2651054\ttotal: 25.8s\tremaining: 156ms\n",
            "994:\tlearn: 0.2649787\ttotal: 25.8s\tremaining: 130ms\n",
            "995:\tlearn: 0.2648198\ttotal: 25.9s\tremaining: 104ms\n",
            "996:\tlearn: 0.2647180\ttotal: 25.9s\tremaining: 77.9ms\n",
            "997:\tlearn: 0.2647015\ttotal: 25.9s\tremaining: 51.9ms\n",
            "998:\tlearn: 0.2645854\ttotal: 25.9s\tremaining: 26ms\n",
            "999:\tlearn: 0.2644750\ttotal: 26s\tremaining: 0us\n",
            "0:\tlearn: 0.6806775\ttotal: 21.2ms\tremaining: 21.2s\n",
            "1:\tlearn: 0.6655236\ttotal: 43.1ms\tremaining: 21.5s\n",
            "2:\tlearn: 0.6564946\ttotal: 61.1ms\tremaining: 20.3s\n",
            "3:\tlearn: 0.6461114\ttotal: 84.8ms\tremaining: 21.1s\n",
            "4:\tlearn: 0.6390127\ttotal: 104ms\tremaining: 20.7s\n",
            "5:\tlearn: 0.6299627\ttotal: 126ms\tremaining: 20.9s\n",
            "6:\tlearn: 0.6212787\ttotal: 146ms\tremaining: 20.7s\n",
            "7:\tlearn: 0.6141088\ttotal: 170ms\tremaining: 21.1s\n",
            "8:\tlearn: 0.6061020\ttotal: 190ms\tremaining: 20.9s\n",
            "9:\tlearn: 0.6000186\ttotal: 212ms\tremaining: 21s\n",
            "10:\tlearn: 0.5950720\ttotal: 241ms\tremaining: 21.7s\n",
            "11:\tlearn: 0.5890368\ttotal: 261ms\tremaining: 21.5s\n",
            "12:\tlearn: 0.5834376\ttotal: 283ms\tremaining: 21.5s\n",
            "13:\tlearn: 0.5779282\ttotal: 305ms\tremaining: 21.5s\n",
            "14:\tlearn: 0.5702331\ttotal: 324ms\tremaining: 21.3s\n",
            "15:\tlearn: 0.5649800\ttotal: 354ms\tremaining: 21.8s\n",
            "16:\tlearn: 0.5608377\ttotal: 383ms\tremaining: 22.1s\n",
            "17:\tlearn: 0.5579822\ttotal: 419ms\tremaining: 22.8s\n",
            "18:\tlearn: 0.5513782\ttotal: 449ms\tremaining: 23.2s\n",
            "19:\tlearn: 0.5488248\ttotal: 479ms\tremaining: 23.5s\n",
            "20:\tlearn: 0.5437397\ttotal: 499ms\tremaining: 23.3s\n",
            "21:\tlearn: 0.5392615\ttotal: 524ms\tremaining: 23.3s\n",
            "22:\tlearn: 0.5356362\ttotal: 542ms\tremaining: 23s\n",
            "23:\tlearn: 0.5321063\ttotal: 566ms\tremaining: 23s\n",
            "24:\tlearn: 0.5300914\ttotal: 585ms\tremaining: 22.8s\n",
            "25:\tlearn: 0.5282692\ttotal: 608ms\tremaining: 22.8s\n",
            "26:\tlearn: 0.5234524\ttotal: 627ms\tremaining: 22.6s\n",
            "27:\tlearn: 0.5215262\ttotal: 656ms\tremaining: 22.8s\n",
            "28:\tlearn: 0.5180382\ttotal: 678ms\tremaining: 22.7s\n",
            "29:\tlearn: 0.5149962\ttotal: 700ms\tremaining: 22.6s\n",
            "30:\tlearn: 0.5062053\ttotal: 722ms\tremaining: 22.6s\n",
            "31:\tlearn: 0.5047845\ttotal: 745ms\tremaining: 22.5s\n",
            "32:\tlearn: 0.5027158\ttotal: 766ms\tremaining: 22.4s\n",
            "33:\tlearn: 0.5009438\ttotal: 786ms\tremaining: 22.3s\n",
            "34:\tlearn: 0.4993909\ttotal: 808ms\tremaining: 22.3s\n",
            "35:\tlearn: 0.4977282\ttotal: 830ms\tremaining: 22.2s\n",
            "36:\tlearn: 0.4960179\ttotal: 850ms\tremaining: 22.1s\n",
            "37:\tlearn: 0.4944414\ttotal: 883ms\tremaining: 22.3s\n",
            "38:\tlearn: 0.4927622\ttotal: 905ms\tremaining: 22.3s\n",
            "39:\tlearn: 0.4915405\ttotal: 937ms\tremaining: 22.5s\n",
            "40:\tlearn: 0.4902371\ttotal: 956ms\tremaining: 22.4s\n",
            "41:\tlearn: 0.4890433\ttotal: 978ms\tremaining: 22.3s\n",
            "42:\tlearn: 0.4874724\ttotal: 997ms\tremaining: 22.2s\n",
            "43:\tlearn: 0.4855003\ttotal: 1.02s\tremaining: 22.1s\n",
            "44:\tlearn: 0.4841858\ttotal: 1.04s\tremaining: 22s\n",
            "45:\tlearn: 0.4835340\ttotal: 1.06s\tremaining: 22s\n",
            "46:\tlearn: 0.4825845\ttotal: 1.08s\tremaining: 21.9s\n",
            "47:\tlearn: 0.4816584\ttotal: 1.11s\tremaining: 22.1s\n",
            "48:\tlearn: 0.4810018\ttotal: 1.13s\tremaining: 22s\n",
            "49:\tlearn: 0.4805014\ttotal: 1.15s\tremaining: 21.9s\n",
            "50:\tlearn: 0.4796500\ttotal: 1.17s\tremaining: 21.9s\n",
            "51:\tlearn: 0.4773455\ttotal: 1.2s\tremaining: 21.8s\n",
            "52:\tlearn: 0.4764447\ttotal: 1.21s\tremaining: 21.7s\n",
            "53:\tlearn: 0.4757652\ttotal: 1.24s\tremaining: 21.6s\n",
            "54:\tlearn: 0.4745599\ttotal: 1.25s\tremaining: 21.6s\n",
            "55:\tlearn: 0.4737522\ttotal: 1.28s\tremaining: 21.5s\n",
            "56:\tlearn: 0.4727505\ttotal: 1.31s\tremaining: 21.6s\n",
            "57:\tlearn: 0.4718782\ttotal: 1.33s\tremaining: 21.6s\n",
            "58:\tlearn: 0.4710910\ttotal: 1.35s\tremaining: 21.5s\n",
            "59:\tlearn: 0.4702587\ttotal: 1.39s\tremaining: 21.7s\n",
            "60:\tlearn: 0.4693607\ttotal: 1.41s\tremaining: 21.7s\n",
            "61:\tlearn: 0.4684433\ttotal: 1.43s\tremaining: 21.7s\n",
            "62:\tlearn: 0.4676400\ttotal: 1.45s\tremaining: 21.6s\n",
            "63:\tlearn: 0.4668740\ttotal: 1.47s\tremaining: 21.6s\n",
            "64:\tlearn: 0.4660524\ttotal: 1.5s\tremaining: 21.5s\n",
            "65:\tlearn: 0.4655337\ttotal: 1.53s\tremaining: 21.6s\n",
            "66:\tlearn: 0.4640337\ttotal: 1.55s\tremaining: 21.5s\n",
            "67:\tlearn: 0.4633752\ttotal: 1.57s\tremaining: 21.5s\n",
            "68:\tlearn: 0.4625936\ttotal: 1.59s\tremaining: 21.4s\n",
            "69:\tlearn: 0.4616445\ttotal: 1.61s\tremaining: 21.4s\n",
            "70:\tlearn: 0.4608040\ttotal: 1.63s\tremaining: 21.3s\n",
            "71:\tlearn: 0.4598794\ttotal: 1.65s\tremaining: 21.3s\n",
            "72:\tlearn: 0.4591416\ttotal: 1.67s\tremaining: 21.3s\n",
            "73:\tlearn: 0.4585860\ttotal: 1.7s\tremaining: 21.3s\n",
            "74:\tlearn: 0.4577502\ttotal: 1.72s\tremaining: 21.2s\n",
            "75:\tlearn: 0.4570674\ttotal: 1.75s\tremaining: 21.3s\n",
            "76:\tlearn: 0.4554973\ttotal: 1.77s\tremaining: 21.2s\n",
            "77:\tlearn: 0.4549333\ttotal: 1.79s\tremaining: 21.2s\n",
            "78:\tlearn: 0.4544105\ttotal: 1.81s\tremaining: 21.2s\n",
            "79:\tlearn: 0.4538092\ttotal: 1.83s\tremaining: 21.1s\n",
            "80:\tlearn: 0.4471895\ttotal: 1.86s\tremaining: 21.1s\n",
            "81:\tlearn: 0.4466652\ttotal: 1.88s\tremaining: 21s\n",
            "82:\tlearn: 0.4460726\ttotal: 1.9s\tremaining: 21s\n",
            "83:\tlearn: 0.4456517\ttotal: 1.92s\tremaining: 20.9s\n",
            "84:\tlearn: 0.4452034\ttotal: 1.94s\tremaining: 20.9s\n",
            "85:\tlearn: 0.4446323\ttotal: 1.97s\tremaining: 21s\n",
            "86:\tlearn: 0.4441227\ttotal: 1.99s\tremaining: 20.9s\n",
            "87:\tlearn: 0.4434788\ttotal: 2.02s\tremaining: 21s\n",
            "88:\tlearn: 0.4431547\ttotal: 2.04s\tremaining: 20.9s\n",
            "89:\tlearn: 0.4426503\ttotal: 2.06s\tremaining: 20.9s\n",
            "90:\tlearn: 0.4421759\ttotal: 2.09s\tremaining: 20.8s\n",
            "91:\tlearn: 0.4418293\ttotal: 2.11s\tremaining: 20.8s\n",
            "92:\tlearn: 0.4415115\ttotal: 2.13s\tremaining: 20.8s\n",
            "93:\tlearn: 0.4412096\ttotal: 2.15s\tremaining: 20.8s\n",
            "94:\tlearn: 0.4408536\ttotal: 2.18s\tremaining: 20.8s\n",
            "95:\tlearn: 0.4402921\ttotal: 2.21s\tremaining: 20.8s\n",
            "96:\tlearn: 0.4399072\ttotal: 2.23s\tremaining: 20.8s\n",
            "97:\tlearn: 0.4393271\ttotal: 2.25s\tremaining: 20.7s\n",
            "98:\tlearn: 0.4388603\ttotal: 2.27s\tremaining: 20.7s\n",
            "99:\tlearn: 0.4383957\ttotal: 2.29s\tremaining: 20.7s\n",
            "100:\tlearn: 0.4380143\ttotal: 2.32s\tremaining: 20.6s\n",
            "101:\tlearn: 0.4373421\ttotal: 2.34s\tremaining: 20.6s\n",
            "102:\tlearn: 0.4370769\ttotal: 2.36s\tremaining: 20.5s\n",
            "103:\tlearn: 0.4324988\ttotal: 2.4s\tremaining: 20.7s\n",
            "104:\tlearn: 0.4321670\ttotal: 2.42s\tremaining: 20.7s\n",
            "105:\tlearn: 0.4318142\ttotal: 2.45s\tremaining: 20.7s\n",
            "106:\tlearn: 0.4315442\ttotal: 2.47s\tremaining: 20.6s\n",
            "107:\tlearn: 0.4312722\ttotal: 2.49s\tremaining: 20.6s\n",
            "108:\tlearn: 0.4309760\ttotal: 2.51s\tremaining: 20.5s\n",
            "109:\tlearn: 0.4305595\ttotal: 2.53s\tremaining: 20.5s\n",
            "110:\tlearn: 0.4302017\ttotal: 2.56s\tremaining: 20.5s\n",
            "111:\tlearn: 0.4298485\ttotal: 2.57s\tremaining: 20.4s\n",
            "112:\tlearn: 0.4294573\ttotal: 2.6s\tremaining: 20.4s\n",
            "113:\tlearn: 0.4292207\ttotal: 2.62s\tremaining: 20.4s\n",
            "114:\tlearn: 0.4288330\ttotal: 2.65s\tremaining: 20.4s\n",
            "115:\tlearn: 0.4284496\ttotal: 2.67s\tremaining: 20.4s\n",
            "116:\tlearn: 0.4280232\ttotal: 2.69s\tremaining: 20.3s\n",
            "117:\tlearn: 0.4276384\ttotal: 2.72s\tremaining: 20.3s\n",
            "118:\tlearn: 0.4272720\ttotal: 2.74s\tremaining: 20.3s\n",
            "119:\tlearn: 0.4269202\ttotal: 2.76s\tremaining: 20.2s\n",
            "120:\tlearn: 0.4265118\ttotal: 2.78s\tremaining: 20.2s\n",
            "121:\tlearn: 0.4261109\ttotal: 2.8s\tremaining: 20.2s\n",
            "122:\tlearn: 0.4256915\ttotal: 2.83s\tremaining: 20.2s\n",
            "123:\tlearn: 0.4253664\ttotal: 2.85s\tremaining: 20.2s\n",
            "124:\tlearn: 0.4250421\ttotal: 2.88s\tremaining: 20.1s\n",
            "125:\tlearn: 0.4245603\ttotal: 2.9s\tremaining: 20.1s\n",
            "126:\tlearn: 0.4241379\ttotal: 2.92s\tremaining: 20.1s\n",
            "127:\tlearn: 0.4238285\ttotal: 2.94s\tremaining: 20s\n",
            "128:\tlearn: 0.4234434\ttotal: 2.96s\tremaining: 20s\n",
            "129:\tlearn: 0.4231947\ttotal: 2.99s\tremaining: 20s\n",
            "130:\tlearn: 0.4228433\ttotal: 3.01s\tremaining: 19.9s\n",
            "131:\tlearn: 0.4224116\ttotal: 3.03s\tremaining: 19.9s\n",
            "132:\tlearn: 0.4219503\ttotal: 3.06s\tremaining: 19.9s\n",
            "133:\tlearn: 0.4215761\ttotal: 3.08s\tremaining: 19.9s\n",
            "134:\tlearn: 0.4212484\ttotal: 3.1s\tremaining: 19.9s\n",
            "135:\tlearn: 0.4209483\ttotal: 3.12s\tremaining: 19.8s\n",
            "136:\tlearn: 0.4206443\ttotal: 3.14s\tremaining: 19.8s\n",
            "137:\tlearn: 0.4202842\ttotal: 3.16s\tremaining: 19.8s\n",
            "138:\tlearn: 0.4199630\ttotal: 3.19s\tremaining: 19.7s\n",
            "139:\tlearn: 0.4196380\ttotal: 3.21s\tremaining: 19.7s\n",
            "140:\tlearn: 0.4193929\ttotal: 3.23s\tremaining: 19.7s\n",
            "141:\tlearn: 0.4190942\ttotal: 3.26s\tremaining: 19.7s\n",
            "142:\tlearn: 0.4187934\ttotal: 3.29s\tremaining: 19.8s\n",
            "143:\tlearn: 0.4184406\ttotal: 3.32s\tremaining: 19.7s\n",
            "144:\tlearn: 0.4181030\ttotal: 3.34s\tremaining: 19.7s\n",
            "145:\tlearn: 0.4177815\ttotal: 3.36s\tremaining: 19.7s\n",
            "146:\tlearn: 0.4175154\ttotal: 3.38s\tremaining: 19.6s\n",
            "147:\tlearn: 0.4170386\ttotal: 3.42s\tremaining: 19.7s\n",
            "148:\tlearn: 0.4168171\ttotal: 3.44s\tremaining: 19.7s\n",
            "149:\tlearn: 0.4164812\ttotal: 3.47s\tremaining: 19.7s\n",
            "150:\tlearn: 0.4161585\ttotal: 3.5s\tremaining: 19.7s\n",
            "151:\tlearn: 0.4158170\ttotal: 3.52s\tremaining: 19.6s\n",
            "152:\tlearn: 0.4154794\ttotal: 3.54s\tremaining: 19.6s\n",
            "153:\tlearn: 0.4151248\ttotal: 3.56s\tremaining: 19.6s\n",
            "154:\tlearn: 0.4149356\ttotal: 3.58s\tremaining: 19.5s\n",
            "155:\tlearn: 0.4147452\ttotal: 3.6s\tremaining: 19.5s\n",
            "156:\tlearn: 0.4145436\ttotal: 3.63s\tremaining: 19.5s\n",
            "157:\tlearn: 0.4141506\ttotal: 3.65s\tremaining: 19.4s\n",
            "158:\tlearn: 0.4138528\ttotal: 3.67s\tremaining: 19.4s\n",
            "159:\tlearn: 0.4136570\ttotal: 3.7s\tremaining: 19.4s\n",
            "160:\tlearn: 0.4134071\ttotal: 3.72s\tremaining: 19.4s\n",
            "161:\tlearn: 0.4130754\ttotal: 3.74s\tremaining: 19.4s\n",
            "162:\tlearn: 0.4128602\ttotal: 3.76s\tremaining: 19.3s\n",
            "163:\tlearn: 0.4125141\ttotal: 3.78s\tremaining: 19.3s\n",
            "164:\tlearn: 0.4121898\ttotal: 3.81s\tremaining: 19.3s\n",
            "165:\tlearn: 0.4117417\ttotal: 3.83s\tremaining: 19.2s\n",
            "166:\tlearn: 0.4114046\ttotal: 3.85s\tremaining: 19.2s\n",
            "167:\tlearn: 0.4110860\ttotal: 3.87s\tremaining: 19.2s\n",
            "168:\tlearn: 0.4108680\ttotal: 3.89s\tremaining: 19.2s\n",
            "169:\tlearn: 0.4106252\ttotal: 3.94s\tremaining: 19.2s\n",
            "170:\tlearn: 0.4103643\ttotal: 3.98s\tremaining: 19.3s\n",
            "171:\tlearn: 0.4099197\ttotal: 4.01s\tremaining: 19.3s\n",
            "172:\tlearn: 0.4097049\ttotal: 4.03s\tremaining: 19.3s\n",
            "173:\tlearn: 0.4093628\ttotal: 4.05s\tremaining: 19.2s\n",
            "174:\tlearn: 0.4091154\ttotal: 4.07s\tremaining: 19.2s\n",
            "175:\tlearn: 0.4088891\ttotal: 4.09s\tremaining: 19.1s\n",
            "176:\tlearn: 0.4086093\ttotal: 4.11s\tremaining: 19.1s\n",
            "177:\tlearn: 0.4083841\ttotal: 4.13s\tremaining: 19.1s\n",
            "178:\tlearn: 0.4081082\ttotal: 4.16s\tremaining: 19.1s\n",
            "179:\tlearn: 0.4077415\ttotal: 4.18s\tremaining: 19.1s\n",
            "180:\tlearn: 0.4075733\ttotal: 4.2s\tremaining: 19s\n",
            "181:\tlearn: 0.4073687\ttotal: 4.22s\tremaining: 19s\n",
            "182:\tlearn: 0.4070057\ttotal: 4.25s\tremaining: 19s\n",
            "183:\tlearn: 0.4067753\ttotal: 4.27s\tremaining: 18.9s\n",
            "184:\tlearn: 0.4065282\ttotal: 4.29s\tremaining: 18.9s\n",
            "185:\tlearn: 0.4062443\ttotal: 4.31s\tremaining: 18.9s\n",
            "186:\tlearn: 0.4060270\ttotal: 4.33s\tremaining: 18.8s\n",
            "187:\tlearn: 0.4057445\ttotal: 4.38s\tremaining: 18.9s\n",
            "188:\tlearn: 0.4055376\ttotal: 4.41s\tremaining: 18.9s\n",
            "189:\tlearn: 0.4052651\ttotal: 4.44s\tremaining: 18.9s\n",
            "190:\tlearn: 0.4049156\ttotal: 4.47s\tremaining: 18.9s\n",
            "191:\tlearn: 0.4046160\ttotal: 4.49s\tremaining: 18.9s\n",
            "192:\tlearn: 0.4044374\ttotal: 4.51s\tremaining: 18.9s\n",
            "193:\tlearn: 0.4041679\ttotal: 4.53s\tremaining: 18.8s\n",
            "194:\tlearn: 0.4037313\ttotal: 4.55s\tremaining: 18.8s\n",
            "195:\tlearn: 0.4035312\ttotal: 4.57s\tremaining: 18.8s\n",
            "196:\tlearn: 0.4033186\ttotal: 4.6s\tremaining: 18.8s\n",
            "197:\tlearn: 0.4030214\ttotal: 4.62s\tremaining: 18.7s\n",
            "198:\tlearn: 0.4027156\ttotal: 4.64s\tremaining: 18.7s\n",
            "199:\tlearn: 0.4025210\ttotal: 4.66s\tremaining: 18.7s\n",
            "200:\tlearn: 0.4022850\ttotal: 4.68s\tremaining: 18.6s\n",
            "201:\tlearn: 0.4019814\ttotal: 4.71s\tremaining: 18.6s\n",
            "202:\tlearn: 0.4016547\ttotal: 4.73s\tremaining: 18.6s\n",
            "203:\tlearn: 0.4014211\ttotal: 4.75s\tremaining: 18.5s\n",
            "204:\tlearn: 0.4011065\ttotal: 4.78s\tremaining: 18.5s\n",
            "205:\tlearn: 0.4009209\ttotal: 4.79s\tremaining: 18.5s\n",
            "206:\tlearn: 0.4006993\ttotal: 4.82s\tremaining: 18.5s\n",
            "207:\tlearn: 0.4004314\ttotal: 4.84s\tremaining: 18.4s\n",
            "208:\tlearn: 0.4001890\ttotal: 4.87s\tremaining: 18.4s\n",
            "209:\tlearn: 0.3998811\ttotal: 4.89s\tremaining: 18.4s\n",
            "210:\tlearn: 0.3995616\ttotal: 4.91s\tremaining: 18.4s\n",
            "211:\tlearn: 0.3993494\ttotal: 4.93s\tremaining: 18.3s\n",
            "212:\tlearn: 0.3989743\ttotal: 4.96s\tremaining: 18.3s\n",
            "213:\tlearn: 0.3985065\ttotal: 4.98s\tremaining: 18.3s\n",
            "214:\tlearn: 0.3982439\ttotal: 5s\tremaining: 18.3s\n",
            "215:\tlearn: 0.3977932\ttotal: 5.02s\tremaining: 18.2s\n",
            "216:\tlearn: 0.3974875\ttotal: 5.05s\tremaining: 18.2s\n",
            "217:\tlearn: 0.3972624\ttotal: 5.07s\tremaining: 18.2s\n",
            "218:\tlearn: 0.3970075\ttotal: 5.09s\tremaining: 18.2s\n",
            "219:\tlearn: 0.3965961\ttotal: 5.12s\tremaining: 18.2s\n",
            "220:\tlearn: 0.3962714\ttotal: 5.14s\tremaining: 18.1s\n",
            "221:\tlearn: 0.3959888\ttotal: 5.16s\tremaining: 18.1s\n",
            "222:\tlearn: 0.3957839\ttotal: 5.18s\tremaining: 18.1s\n",
            "223:\tlearn: 0.3954939\ttotal: 5.2s\tremaining: 18s\n",
            "224:\tlearn: 0.3952310\ttotal: 5.22s\tremaining: 18s\n",
            "225:\tlearn: 0.3949707\ttotal: 5.25s\tremaining: 18s\n",
            "226:\tlearn: 0.3947170\ttotal: 5.28s\tremaining: 18s\n",
            "227:\tlearn: 0.3944563\ttotal: 5.3s\tremaining: 17.9s\n",
            "228:\tlearn: 0.3942921\ttotal: 5.32s\tremaining: 17.9s\n",
            "229:\tlearn: 0.3940960\ttotal: 5.34s\tremaining: 17.9s\n",
            "230:\tlearn: 0.3939120\ttotal: 5.36s\tremaining: 17.8s\n",
            "231:\tlearn: 0.3936100\ttotal: 5.38s\tremaining: 17.8s\n",
            "232:\tlearn: 0.3933444\ttotal: 5.41s\tremaining: 17.8s\n",
            "233:\tlearn: 0.3930791\ttotal: 5.45s\tremaining: 17.8s\n",
            "234:\tlearn: 0.3926915\ttotal: 5.47s\tremaining: 17.8s\n",
            "235:\tlearn: 0.3923169\ttotal: 5.5s\tremaining: 17.8s\n",
            "236:\tlearn: 0.3920133\ttotal: 5.52s\tremaining: 17.8s\n",
            "237:\tlearn: 0.3917481\ttotal: 5.54s\tremaining: 17.7s\n",
            "238:\tlearn: 0.3914897\ttotal: 5.57s\tremaining: 17.7s\n",
            "239:\tlearn: 0.3912587\ttotal: 5.59s\tremaining: 17.7s\n",
            "240:\tlearn: 0.3910118\ttotal: 5.62s\tremaining: 17.7s\n",
            "241:\tlearn: 0.3907617\ttotal: 5.63s\tremaining: 17.7s\n",
            "242:\tlearn: 0.3904168\ttotal: 5.66s\tremaining: 17.6s\n",
            "243:\tlearn: 0.3901239\ttotal: 5.68s\tremaining: 17.6s\n",
            "244:\tlearn: 0.3898340\ttotal: 5.71s\tremaining: 17.6s\n",
            "245:\tlearn: 0.3895492\ttotal: 5.73s\tremaining: 17.6s\n",
            "246:\tlearn: 0.3892058\ttotal: 5.75s\tremaining: 17.5s\n",
            "247:\tlearn: 0.3888824\ttotal: 5.77s\tremaining: 17.5s\n",
            "248:\tlearn: 0.3885397\ttotal: 5.8s\tremaining: 17.5s\n",
            "249:\tlearn: 0.3882476\ttotal: 5.82s\tremaining: 17.4s\n",
            "250:\tlearn: 0.3879043\ttotal: 5.84s\tremaining: 17.4s\n",
            "251:\tlearn: 0.3876403\ttotal: 5.86s\tremaining: 17.4s\n",
            "252:\tlearn: 0.3873317\ttotal: 5.88s\tremaining: 17.4s\n",
            "253:\tlearn: 0.3870996\ttotal: 5.91s\tremaining: 17.3s\n",
            "254:\tlearn: 0.3868496\ttotal: 5.93s\tremaining: 17.3s\n",
            "255:\tlearn: 0.3865161\ttotal: 5.96s\tremaining: 17.3s\n",
            "256:\tlearn: 0.3863205\ttotal: 5.98s\tremaining: 17.3s\n",
            "257:\tlearn: 0.3861632\ttotal: 6s\tremaining: 17.3s\n",
            "258:\tlearn: 0.3858259\ttotal: 6.03s\tremaining: 17.2s\n",
            "259:\tlearn: 0.3856263\ttotal: 6.04s\tremaining: 17.2s\n",
            "260:\tlearn: 0.3852917\ttotal: 6.07s\tremaining: 17.2s\n",
            "261:\tlearn: 0.3850584\ttotal: 6.09s\tremaining: 17.2s\n",
            "262:\tlearn: 0.3847959\ttotal: 6.11s\tremaining: 17.1s\n",
            "263:\tlearn: 0.3844801\ttotal: 6.14s\tremaining: 17.1s\n",
            "264:\tlearn: 0.3840984\ttotal: 6.16s\tremaining: 17.1s\n",
            "265:\tlearn: 0.3838847\ttotal: 6.18s\tremaining: 17.1s\n",
            "266:\tlearn: 0.3836170\ttotal: 6.2s\tremaining: 17s\n",
            "267:\tlearn: 0.3834295\ttotal: 6.22s\tremaining: 17s\n",
            "268:\tlearn: 0.3831474\ttotal: 6.25s\tremaining: 17s\n",
            "269:\tlearn: 0.3827935\ttotal: 6.27s\tremaining: 16.9s\n",
            "270:\tlearn: 0.3825778\ttotal: 6.29s\tremaining: 16.9s\n",
            "271:\tlearn: 0.3823055\ttotal: 6.31s\tremaining: 16.9s\n",
            "272:\tlearn: 0.3820204\ttotal: 6.33s\tremaining: 16.9s\n",
            "273:\tlearn: 0.3817817\ttotal: 6.36s\tremaining: 16.8s\n",
            "274:\tlearn: 0.3815100\ttotal: 6.38s\tremaining: 16.8s\n",
            "275:\tlearn: 0.3812276\ttotal: 6.4s\tremaining: 16.8s\n",
            "276:\tlearn: 0.3808967\ttotal: 6.42s\tremaining: 16.8s\n",
            "277:\tlearn: 0.3806053\ttotal: 6.45s\tremaining: 16.8s\n",
            "278:\tlearn: 0.3803305\ttotal: 6.48s\tremaining: 16.8s\n",
            "279:\tlearn: 0.3801480\ttotal: 6.5s\tremaining: 16.7s\n",
            "280:\tlearn: 0.3797726\ttotal: 6.53s\tremaining: 16.7s\n",
            "281:\tlearn: 0.3795622\ttotal: 6.56s\tremaining: 16.7s\n",
            "282:\tlearn: 0.3793177\ttotal: 6.58s\tremaining: 16.7s\n",
            "283:\tlearn: 0.3790717\ttotal: 6.6s\tremaining: 16.6s\n",
            "284:\tlearn: 0.3787991\ttotal: 6.62s\tremaining: 16.6s\n",
            "285:\tlearn: 0.3783726\ttotal: 6.64s\tremaining: 16.6s\n",
            "286:\tlearn: 0.3781275\ttotal: 6.66s\tremaining: 16.6s\n",
            "287:\tlearn: 0.3778917\ttotal: 6.68s\tremaining: 16.5s\n",
            "288:\tlearn: 0.3776409\ttotal: 6.7s\tremaining: 16.5s\n",
            "289:\tlearn: 0.3773927\ttotal: 6.72s\tremaining: 16.5s\n",
            "290:\tlearn: 0.3771373\ttotal: 6.74s\tremaining: 16.4s\n",
            "291:\tlearn: 0.3769759\ttotal: 6.77s\tremaining: 16.4s\n",
            "292:\tlearn: 0.3767502\ttotal: 6.79s\tremaining: 16.4s\n",
            "293:\tlearn: 0.3764682\ttotal: 6.81s\tremaining: 16.4s\n",
            "294:\tlearn: 0.3762993\ttotal: 6.84s\tremaining: 16.3s\n",
            "295:\tlearn: 0.3760993\ttotal: 6.85s\tremaining: 16.3s\n",
            "296:\tlearn: 0.3758637\ttotal: 6.88s\tremaining: 16.3s\n",
            "297:\tlearn: 0.3755684\ttotal: 6.9s\tremaining: 16.3s\n",
            "298:\tlearn: 0.3752054\ttotal: 6.92s\tremaining: 16.2s\n",
            "299:\tlearn: 0.3749621\ttotal: 6.94s\tremaining: 16.2s\n",
            "300:\tlearn: 0.3747106\ttotal: 6.96s\tremaining: 16.2s\n",
            "301:\tlearn: 0.3743682\ttotal: 7s\tremaining: 16.2s\n",
            "302:\tlearn: 0.3741069\ttotal: 7.02s\tremaining: 16.2s\n",
            "303:\tlearn: 0.3738477\ttotal: 7.05s\tremaining: 16.1s\n",
            "304:\tlearn: 0.3735578\ttotal: 7.07s\tremaining: 16.1s\n",
            "305:\tlearn: 0.3733942\ttotal: 7.09s\tremaining: 16.1s\n",
            "306:\tlearn: 0.3731696\ttotal: 7.11s\tremaining: 16.1s\n",
            "307:\tlearn: 0.3727297\ttotal: 7.13s\tremaining: 16s\n",
            "308:\tlearn: 0.3725396\ttotal: 7.15s\tremaining: 16s\n",
            "309:\tlearn: 0.3722544\ttotal: 7.17s\tremaining: 16s\n",
            "310:\tlearn: 0.3721372\ttotal: 7.19s\tremaining: 15.9s\n",
            "311:\tlearn: 0.3718284\ttotal: 7.23s\tremaining: 15.9s\n",
            "312:\tlearn: 0.3716078\ttotal: 7.25s\tremaining: 15.9s\n",
            "313:\tlearn: 0.3714012\ttotal: 7.27s\tremaining: 15.9s\n",
            "314:\tlearn: 0.3711491\ttotal: 7.29s\tremaining: 15.8s\n",
            "315:\tlearn: 0.3708024\ttotal: 7.31s\tremaining: 15.8s\n",
            "316:\tlearn: 0.3705769\ttotal: 7.33s\tremaining: 15.8s\n",
            "317:\tlearn: 0.3703328\ttotal: 7.35s\tremaining: 15.8s\n",
            "318:\tlearn: 0.3700556\ttotal: 7.37s\tremaining: 15.7s\n",
            "319:\tlearn: 0.3698485\ttotal: 7.39s\tremaining: 15.7s\n",
            "320:\tlearn: 0.3696811\ttotal: 7.41s\tremaining: 15.7s\n",
            "321:\tlearn: 0.3694634\ttotal: 7.44s\tremaining: 15.7s\n",
            "322:\tlearn: 0.3691225\ttotal: 7.47s\tremaining: 15.7s\n",
            "323:\tlearn: 0.3688548\ttotal: 7.5s\tremaining: 15.6s\n",
            "324:\tlearn: 0.3686525\ttotal: 7.52s\tremaining: 15.6s\n",
            "325:\tlearn: 0.3683588\ttotal: 7.54s\tremaining: 15.6s\n",
            "326:\tlearn: 0.3681437\ttotal: 7.56s\tremaining: 15.6s\n",
            "327:\tlearn: 0.3679139\ttotal: 7.58s\tremaining: 15.5s\n",
            "328:\tlearn: 0.3677040\ttotal: 7.61s\tremaining: 15.5s\n",
            "329:\tlearn: 0.3674048\ttotal: 7.63s\tremaining: 15.5s\n",
            "330:\tlearn: 0.3671342\ttotal: 7.66s\tremaining: 15.5s\n",
            "331:\tlearn: 0.3669252\ttotal: 7.68s\tremaining: 15.4s\n",
            "332:\tlearn: 0.3666802\ttotal: 7.7s\tremaining: 15.4s\n",
            "333:\tlearn: 0.3664519\ttotal: 7.72s\tremaining: 15.4s\n",
            "334:\tlearn: 0.3661825\ttotal: 7.74s\tremaining: 15.4s\n",
            "335:\tlearn: 0.3659789\ttotal: 7.76s\tremaining: 15.3s\n",
            "336:\tlearn: 0.3658030\ttotal: 7.78s\tremaining: 15.3s\n",
            "337:\tlearn: 0.3656255\ttotal: 7.8s\tremaining: 15.3s\n",
            "338:\tlearn: 0.3653576\ttotal: 7.83s\tremaining: 15.3s\n",
            "339:\tlearn: 0.3651917\ttotal: 7.86s\tremaining: 15.3s\n",
            "340:\tlearn: 0.3650289\ttotal: 7.88s\tremaining: 15.2s\n",
            "341:\tlearn: 0.3646902\ttotal: 7.91s\tremaining: 15.2s\n",
            "342:\tlearn: 0.3643895\ttotal: 7.93s\tremaining: 15.2s\n",
            "343:\tlearn: 0.3641098\ttotal: 7.95s\tremaining: 15.2s\n",
            "344:\tlearn: 0.3638921\ttotal: 7.97s\tremaining: 15.1s\n",
            "345:\tlearn: 0.3636127\ttotal: 7.99s\tremaining: 15.1s\n",
            "346:\tlearn: 0.3634119\ttotal: 8.01s\tremaining: 15.1s\n",
            "347:\tlearn: 0.3631490\ttotal: 8.03s\tremaining: 15s\n",
            "348:\tlearn: 0.3630381\ttotal: 8.05s\tremaining: 15s\n",
            "349:\tlearn: 0.3627691\ttotal: 8.08s\tremaining: 15s\n",
            "350:\tlearn: 0.3625180\ttotal: 8.1s\tremaining: 15s\n",
            "351:\tlearn: 0.3623185\ttotal: 8.12s\tremaining: 15s\n",
            "352:\tlearn: 0.3621673\ttotal: 8.14s\tremaining: 14.9s\n",
            "353:\tlearn: 0.3620102\ttotal: 8.16s\tremaining: 14.9s\n",
            "354:\tlearn: 0.3618010\ttotal: 8.18s\tremaining: 14.9s\n",
            "355:\tlearn: 0.3615538\ttotal: 8.21s\tremaining: 14.9s\n",
            "356:\tlearn: 0.3612945\ttotal: 8.23s\tremaining: 14.8s\n",
            "357:\tlearn: 0.3610966\ttotal: 8.25s\tremaining: 14.8s\n",
            "358:\tlearn: 0.3608478\ttotal: 8.27s\tremaining: 14.8s\n",
            "359:\tlearn: 0.3606029\ttotal: 8.3s\tremaining: 14.8s\n",
            "360:\tlearn: 0.3604463\ttotal: 8.32s\tremaining: 14.7s\n",
            "361:\tlearn: 0.3602381\ttotal: 8.34s\tremaining: 14.7s\n",
            "362:\tlearn: 0.3600143\ttotal: 8.36s\tremaining: 14.7s\n",
            "363:\tlearn: 0.3597772\ttotal: 8.39s\tremaining: 14.7s\n",
            "364:\tlearn: 0.3595621\ttotal: 8.42s\tremaining: 14.6s\n",
            "365:\tlearn: 0.3593377\ttotal: 8.47s\tremaining: 14.7s\n",
            "366:\tlearn: 0.3591466\ttotal: 8.51s\tremaining: 14.7s\n",
            "367:\tlearn: 0.3589542\ttotal: 8.54s\tremaining: 14.7s\n",
            "368:\tlearn: 0.3587175\ttotal: 8.58s\tremaining: 14.7s\n",
            "369:\tlearn: 0.3585167\ttotal: 8.62s\tremaining: 14.7s\n",
            "370:\tlearn: 0.3583182\ttotal: 8.65s\tremaining: 14.7s\n",
            "371:\tlearn: 0.3581452\ttotal: 8.68s\tremaining: 14.7s\n",
            "372:\tlearn: 0.3577877\ttotal: 8.73s\tremaining: 14.7s\n",
            "373:\tlearn: 0.3576607\ttotal: 8.78s\tremaining: 14.7s\n",
            "374:\tlearn: 0.3574822\ttotal: 8.81s\tremaining: 14.7s\n",
            "375:\tlearn: 0.3572885\ttotal: 8.86s\tremaining: 14.7s\n",
            "376:\tlearn: 0.3570573\ttotal: 8.91s\tremaining: 14.7s\n",
            "377:\tlearn: 0.3567843\ttotal: 8.96s\tremaining: 14.7s\n",
            "378:\tlearn: 0.3565596\ttotal: 9s\tremaining: 14.7s\n",
            "379:\tlearn: 0.3562950\ttotal: 9.05s\tremaining: 14.8s\n",
            "380:\tlearn: 0.3559876\ttotal: 9.09s\tremaining: 14.8s\n",
            "381:\tlearn: 0.3557876\ttotal: 9.14s\tremaining: 14.8s\n",
            "382:\tlearn: 0.3555119\ttotal: 9.18s\tremaining: 14.8s\n",
            "383:\tlearn: 0.3552929\ttotal: 9.22s\tremaining: 14.8s\n",
            "384:\tlearn: 0.3550133\ttotal: 9.26s\tremaining: 14.8s\n",
            "385:\tlearn: 0.3548388\ttotal: 9.3s\tremaining: 14.8s\n",
            "386:\tlearn: 0.3545705\ttotal: 9.34s\tremaining: 14.8s\n",
            "387:\tlearn: 0.3543061\ttotal: 9.4s\tremaining: 14.8s\n",
            "388:\tlearn: 0.3540209\ttotal: 9.44s\tremaining: 14.8s\n",
            "389:\tlearn: 0.3538484\ttotal: 9.48s\tremaining: 14.8s\n",
            "390:\tlearn: 0.3536208\ttotal: 9.53s\tremaining: 14.8s\n",
            "391:\tlearn: 0.3534067\ttotal: 9.57s\tremaining: 14.8s\n",
            "392:\tlearn: 0.3530903\ttotal: 9.63s\tremaining: 14.9s\n",
            "393:\tlearn: 0.3528615\ttotal: 9.67s\tremaining: 14.9s\n",
            "394:\tlearn: 0.3526462\ttotal: 9.71s\tremaining: 14.9s\n",
            "395:\tlearn: 0.3522823\ttotal: 9.76s\tremaining: 14.9s\n",
            "396:\tlearn: 0.3520184\ttotal: 9.8s\tremaining: 14.9s\n",
            "397:\tlearn: 0.3517927\ttotal: 9.85s\tremaining: 14.9s\n",
            "398:\tlearn: 0.3515846\ttotal: 9.89s\tremaining: 14.9s\n",
            "399:\tlearn: 0.3513799\ttotal: 9.93s\tremaining: 14.9s\n",
            "400:\tlearn: 0.3512036\ttotal: 9.97s\tremaining: 14.9s\n",
            "401:\tlearn: 0.3510084\ttotal: 10s\tremaining: 14.9s\n",
            "402:\tlearn: 0.3506994\ttotal: 10.1s\tremaining: 14.9s\n",
            "403:\tlearn: 0.3503997\ttotal: 10.1s\tremaining: 14.9s\n",
            "404:\tlearn: 0.3502357\ttotal: 10.1s\tremaining: 14.9s\n",
            "405:\tlearn: 0.3500572\ttotal: 10.2s\tremaining: 14.9s\n",
            "406:\tlearn: 0.3498210\ttotal: 10.2s\tremaining: 14.9s\n",
            "407:\tlearn: 0.3496431\ttotal: 10.3s\tremaining: 14.9s\n",
            "408:\tlearn: 0.3494176\ttotal: 10.3s\tremaining: 14.9s\n",
            "409:\tlearn: 0.3490779\ttotal: 10.4s\tremaining: 14.9s\n",
            "410:\tlearn: 0.3489167\ttotal: 10.4s\tremaining: 15s\n",
            "411:\tlearn: 0.3487807\ttotal: 10.5s\tremaining: 15s\n",
            "412:\tlearn: 0.3485449\ttotal: 10.5s\tremaining: 15s\n",
            "413:\tlearn: 0.3482839\ttotal: 10.6s\tremaining: 15s\n",
            "414:\tlearn: 0.3481432\ttotal: 10.6s\tremaining: 15s\n",
            "415:\tlearn: 0.3479854\ttotal: 10.7s\tremaining: 15s\n",
            "416:\tlearn: 0.3478195\ttotal: 10.7s\tremaining: 15s\n",
            "417:\tlearn: 0.3476242\ttotal: 10.8s\tremaining: 15s\n",
            "418:\tlearn: 0.3474205\ttotal: 10.8s\tremaining: 15s\n",
            "419:\tlearn: 0.3471607\ttotal: 10.8s\tremaining: 14.9s\n",
            "420:\tlearn: 0.3468553\ttotal: 10.9s\tremaining: 14.9s\n",
            "421:\tlearn: 0.3466443\ttotal: 10.9s\tremaining: 14.9s\n",
            "422:\tlearn: 0.3464686\ttotal: 11s\tremaining: 14.9s\n",
            "423:\tlearn: 0.3462355\ttotal: 11s\tremaining: 15s\n",
            "424:\tlearn: 0.3459896\ttotal: 11.1s\tremaining: 15s\n",
            "425:\tlearn: 0.3458968\ttotal: 11.1s\tremaining: 14.9s\n",
            "426:\tlearn: 0.3456788\ttotal: 11.1s\tremaining: 14.9s\n",
            "427:\tlearn: 0.3455124\ttotal: 11.2s\tremaining: 14.9s\n",
            "428:\tlearn: 0.3452732\ttotal: 11.2s\tremaining: 14.9s\n",
            "429:\tlearn: 0.3450297\ttotal: 11.3s\tremaining: 14.9s\n",
            "430:\tlearn: 0.3448946\ttotal: 11.3s\tremaining: 14.9s\n",
            "431:\tlearn: 0.3446545\ttotal: 11.3s\tremaining: 14.9s\n",
            "432:\tlearn: 0.3445000\ttotal: 11.4s\tremaining: 14.9s\n",
            "433:\tlearn: 0.3443092\ttotal: 11.4s\tremaining: 14.9s\n",
            "434:\tlearn: 0.3441247\ttotal: 11.5s\tremaining: 14.9s\n",
            "435:\tlearn: 0.3439488\ttotal: 11.5s\tremaining: 14.9s\n",
            "436:\tlearn: 0.3437741\ttotal: 11.5s\tremaining: 14.9s\n",
            "437:\tlearn: 0.3434940\ttotal: 11.6s\tremaining: 14.9s\n",
            "438:\tlearn: 0.3432465\ttotal: 11.6s\tremaining: 14.9s\n",
            "439:\tlearn: 0.3430846\ttotal: 11.7s\tremaining: 14.9s\n",
            "440:\tlearn: 0.3428682\ttotal: 11.7s\tremaining: 14.8s\n",
            "441:\tlearn: 0.3427096\ttotal: 11.7s\tremaining: 14.8s\n",
            "442:\tlearn: 0.3424572\ttotal: 11.8s\tremaining: 14.8s\n",
            "443:\tlearn: 0.3422459\ttotal: 11.8s\tremaining: 14.8s\n",
            "444:\tlearn: 0.3419164\ttotal: 11.9s\tremaining: 14.8s\n",
            "445:\tlearn: 0.3416925\ttotal: 11.9s\tremaining: 14.8s\n",
            "446:\tlearn: 0.3415820\ttotal: 12s\tremaining: 14.8s\n",
            "447:\tlearn: 0.3413491\ttotal: 12s\tremaining: 14.8s\n",
            "448:\tlearn: 0.3411752\ttotal: 12s\tremaining: 14.8s\n",
            "449:\tlearn: 0.3409437\ttotal: 12.1s\tremaining: 14.7s\n",
            "450:\tlearn: 0.3407519\ttotal: 12.1s\tremaining: 14.7s\n",
            "451:\tlearn: 0.3404775\ttotal: 12.1s\tremaining: 14.7s\n",
            "452:\tlearn: 0.3402902\ttotal: 12.1s\tremaining: 14.6s\n",
            "453:\tlearn: 0.3401207\ttotal: 12.2s\tremaining: 14.6s\n",
            "454:\tlearn: 0.3399211\ttotal: 12.2s\tremaining: 14.6s\n",
            "455:\tlearn: 0.3396994\ttotal: 12.2s\tremaining: 14.5s\n",
            "456:\tlearn: 0.3394916\ttotal: 12.2s\tremaining: 14.5s\n",
            "457:\tlearn: 0.3392794\ttotal: 12.2s\tremaining: 14.5s\n",
            "458:\tlearn: 0.3391534\ttotal: 12.3s\tremaining: 14.4s\n",
            "459:\tlearn: 0.3389478\ttotal: 12.3s\tremaining: 14.4s\n",
            "460:\tlearn: 0.3388053\ttotal: 12.3s\tremaining: 14.4s\n",
            "461:\tlearn: 0.3386438\ttotal: 12.3s\tremaining: 14.4s\n",
            "462:\tlearn: 0.3384367\ttotal: 12.4s\tremaining: 14.3s\n",
            "463:\tlearn: 0.3383076\ttotal: 12.4s\tremaining: 14.3s\n",
            "464:\tlearn: 0.3381466\ttotal: 12.4s\tremaining: 14.3s\n",
            "465:\tlearn: 0.3377938\ttotal: 12.4s\tremaining: 14.2s\n",
            "466:\tlearn: 0.3377074\ttotal: 12.4s\tremaining: 14.2s\n",
            "467:\tlearn: 0.3375515\ttotal: 12.5s\tremaining: 14.2s\n",
            "468:\tlearn: 0.3373574\ttotal: 12.5s\tremaining: 14.1s\n",
            "469:\tlearn: 0.3372134\ttotal: 12.5s\tremaining: 14.1s\n",
            "470:\tlearn: 0.3370933\ttotal: 12.5s\tremaining: 14.1s\n",
            "471:\tlearn: 0.3368741\ttotal: 12.6s\tremaining: 14s\n",
            "472:\tlearn: 0.3367139\ttotal: 12.6s\tremaining: 14s\n",
            "473:\tlearn: 0.3364707\ttotal: 12.6s\tremaining: 14s\n",
            "474:\tlearn: 0.3361668\ttotal: 12.6s\tremaining: 14s\n",
            "475:\tlearn: 0.3359653\ttotal: 12.7s\tremaining: 13.9s\n",
            "476:\tlearn: 0.3358028\ttotal: 12.7s\tremaining: 13.9s\n",
            "477:\tlearn: 0.3356268\ttotal: 12.7s\tremaining: 13.9s\n",
            "478:\tlearn: 0.3355157\ttotal: 12.7s\tremaining: 13.8s\n",
            "479:\tlearn: 0.3353617\ttotal: 12.8s\tremaining: 13.8s\n",
            "480:\tlearn: 0.3351957\ttotal: 12.8s\tremaining: 13.8s\n",
            "481:\tlearn: 0.3350222\ttotal: 12.8s\tremaining: 13.7s\n",
            "482:\tlearn: 0.3348318\ttotal: 12.8s\tremaining: 13.7s\n",
            "483:\tlearn: 0.3346064\ttotal: 12.8s\tremaining: 13.7s\n",
            "484:\tlearn: 0.3344913\ttotal: 12.9s\tremaining: 13.7s\n",
            "485:\tlearn: 0.3343150\ttotal: 12.9s\tremaining: 13.6s\n",
            "486:\tlearn: 0.3342335\ttotal: 12.9s\tremaining: 13.6s\n",
            "487:\tlearn: 0.3339346\ttotal: 12.9s\tremaining: 13.6s\n",
            "488:\tlearn: 0.3337587\ttotal: 12.9s\tremaining: 13.5s\n",
            "489:\tlearn: 0.3336123\ttotal: 13s\tremaining: 13.5s\n",
            "490:\tlearn: 0.3333817\ttotal: 13s\tremaining: 13.5s\n",
            "491:\tlearn: 0.3331613\ttotal: 13s\tremaining: 13.4s\n",
            "492:\tlearn: 0.3330388\ttotal: 13s\tremaining: 13.4s\n",
            "493:\tlearn: 0.3329284\ttotal: 13.1s\tremaining: 13.4s\n",
            "494:\tlearn: 0.3327792\ttotal: 13.1s\tremaining: 13.3s\n",
            "495:\tlearn: 0.3326360\ttotal: 13.1s\tremaining: 13.3s\n",
            "496:\tlearn: 0.3325416\ttotal: 13.1s\tremaining: 13.3s\n",
            "497:\tlearn: 0.3323397\ttotal: 13.1s\tremaining: 13.2s\n",
            "498:\tlearn: 0.3320114\ttotal: 13.2s\tremaining: 13.2s\n",
            "499:\tlearn: 0.3318315\ttotal: 13.2s\tremaining: 13.2s\n",
            "500:\tlearn: 0.3316410\ttotal: 13.2s\tremaining: 13.2s\n",
            "501:\tlearn: 0.3314865\ttotal: 13.2s\tremaining: 13.1s\n",
            "502:\tlearn: 0.3312657\ttotal: 13.3s\tremaining: 13.1s\n",
            "503:\tlearn: 0.3310760\ttotal: 13.3s\tremaining: 13.1s\n",
            "504:\tlearn: 0.3309572\ttotal: 13.3s\tremaining: 13s\n",
            "505:\tlearn: 0.3308328\ttotal: 13.3s\tremaining: 13s\n",
            "506:\tlearn: 0.3307338\ttotal: 13.3s\tremaining: 13s\n",
            "507:\tlearn: 0.3304671\ttotal: 13.4s\tremaining: 12.9s\n",
            "508:\tlearn: 0.3302614\ttotal: 13.4s\tremaining: 12.9s\n",
            "509:\tlearn: 0.3300967\ttotal: 13.4s\tremaining: 12.9s\n",
            "510:\tlearn: 0.3299787\ttotal: 13.4s\tremaining: 12.9s\n",
            "511:\tlearn: 0.3297911\ttotal: 13.5s\tremaining: 12.8s\n",
            "512:\tlearn: 0.3296179\ttotal: 13.5s\tremaining: 12.8s\n",
            "513:\tlearn: 0.3294529\ttotal: 13.5s\tremaining: 12.8s\n",
            "514:\tlearn: 0.3293056\ttotal: 13.5s\tremaining: 12.7s\n",
            "515:\tlearn: 0.3291012\ttotal: 13.5s\tremaining: 12.7s\n",
            "516:\tlearn: 0.3290245\ttotal: 13.6s\tremaining: 12.7s\n",
            "517:\tlearn: 0.3288065\ttotal: 13.6s\tremaining: 12.6s\n",
            "518:\tlearn: 0.3285156\ttotal: 13.6s\tremaining: 12.6s\n",
            "519:\tlearn: 0.3282615\ttotal: 13.6s\tremaining: 12.6s\n",
            "520:\tlearn: 0.3280541\ttotal: 13.7s\tremaining: 12.6s\n",
            "521:\tlearn: 0.3278777\ttotal: 13.7s\tremaining: 12.5s\n",
            "522:\tlearn: 0.3277117\ttotal: 13.7s\tremaining: 12.5s\n",
            "523:\tlearn: 0.3273978\ttotal: 13.7s\tremaining: 12.5s\n",
            "524:\tlearn: 0.3272246\ttotal: 13.7s\tremaining: 12.4s\n",
            "525:\tlearn: 0.3270317\ttotal: 13.8s\tremaining: 12.4s\n",
            "526:\tlearn: 0.3268535\ttotal: 13.8s\tremaining: 12.4s\n",
            "527:\tlearn: 0.3266606\ttotal: 13.8s\tremaining: 12.3s\n",
            "528:\tlearn: 0.3266046\ttotal: 13.8s\tremaining: 12.3s\n",
            "529:\tlearn: 0.3264190\ttotal: 13.9s\tremaining: 12.3s\n",
            "530:\tlearn: 0.3261746\ttotal: 13.9s\tremaining: 12.3s\n",
            "531:\tlearn: 0.3260187\ttotal: 13.9s\tremaining: 12.2s\n",
            "532:\tlearn: 0.3258768\ttotal: 13.9s\tremaining: 12.2s\n",
            "533:\tlearn: 0.3257273\ttotal: 13.9s\tremaining: 12.2s\n",
            "534:\tlearn: 0.3255775\ttotal: 14s\tremaining: 12.1s\n",
            "535:\tlearn: 0.3255349\ttotal: 14s\tremaining: 12.1s\n",
            "536:\tlearn: 0.3253055\ttotal: 14s\tremaining: 12.1s\n",
            "537:\tlearn: 0.3250532\ttotal: 14s\tremaining: 12.1s\n",
            "538:\tlearn: 0.3249046\ttotal: 14.1s\tremaining: 12s\n",
            "539:\tlearn: 0.3246477\ttotal: 14.1s\tremaining: 12s\n",
            "540:\tlearn: 0.3243064\ttotal: 14.1s\tremaining: 12s\n",
            "541:\tlearn: 0.3241640\ttotal: 14.1s\tremaining: 11.9s\n",
            "542:\tlearn: 0.3240071\ttotal: 14.1s\tremaining: 11.9s\n",
            "543:\tlearn: 0.3238556\ttotal: 14.2s\tremaining: 11.9s\n",
            "544:\tlearn: 0.3235992\ttotal: 14.2s\tremaining: 11.8s\n",
            "545:\tlearn: 0.3235128\ttotal: 14.2s\tremaining: 11.8s\n",
            "546:\tlearn: 0.3233551\ttotal: 14.2s\tremaining: 11.8s\n",
            "547:\tlearn: 0.3230804\ttotal: 14.3s\tremaining: 11.8s\n",
            "548:\tlearn: 0.3229207\ttotal: 14.3s\tremaining: 11.7s\n",
            "549:\tlearn: 0.3227746\ttotal: 14.3s\tremaining: 11.7s\n",
            "550:\tlearn: 0.3225538\ttotal: 14.3s\tremaining: 11.7s\n",
            "551:\tlearn: 0.3223965\ttotal: 14.3s\tremaining: 11.6s\n",
            "552:\tlearn: 0.3222279\ttotal: 14.4s\tremaining: 11.6s\n",
            "553:\tlearn: 0.3220725\ttotal: 14.4s\tremaining: 11.6s\n",
            "554:\tlearn: 0.3219052\ttotal: 14.4s\tremaining: 11.5s\n",
            "555:\tlearn: 0.3217327\ttotal: 14.4s\tremaining: 11.5s\n",
            "556:\tlearn: 0.3216261\ttotal: 14.4s\tremaining: 11.5s\n",
            "557:\tlearn: 0.3214716\ttotal: 14.5s\tremaining: 11.5s\n",
            "558:\tlearn: 0.3212643\ttotal: 14.5s\tremaining: 11.4s\n",
            "559:\tlearn: 0.3211164\ttotal: 14.5s\tremaining: 11.4s\n",
            "560:\tlearn: 0.3208744\ttotal: 14.5s\tremaining: 11.4s\n",
            "561:\tlearn: 0.3206170\ttotal: 14.6s\tremaining: 11.4s\n",
            "562:\tlearn: 0.3203392\ttotal: 14.6s\tremaining: 11.3s\n",
            "563:\tlearn: 0.3200915\ttotal: 14.6s\tremaining: 11.3s\n",
            "564:\tlearn: 0.3199014\ttotal: 14.7s\tremaining: 11.3s\n",
            "565:\tlearn: 0.3197358\ttotal: 14.7s\tremaining: 11.3s\n",
            "566:\tlearn: 0.3195759\ttotal: 14.7s\tremaining: 11.2s\n",
            "567:\tlearn: 0.3193895\ttotal: 14.7s\tremaining: 11.2s\n",
            "568:\tlearn: 0.3191790\ttotal: 14.7s\tremaining: 11.2s\n",
            "569:\tlearn: 0.3189945\ttotal: 14.8s\tremaining: 11.1s\n",
            "570:\tlearn: 0.3188049\ttotal: 14.8s\tremaining: 11.1s\n",
            "571:\tlearn: 0.3186279\ttotal: 14.8s\tremaining: 11.1s\n",
            "572:\tlearn: 0.3184707\ttotal: 14.8s\tremaining: 11.1s\n",
            "573:\tlearn: 0.3182504\ttotal: 14.9s\tremaining: 11s\n",
            "574:\tlearn: 0.3181578\ttotal: 14.9s\tremaining: 11s\n",
            "575:\tlearn: 0.3179828\ttotal: 14.9s\tremaining: 11s\n",
            "576:\tlearn: 0.3179493\ttotal: 14.9s\tremaining: 10.9s\n",
            "577:\tlearn: 0.3178220\ttotal: 14.9s\tremaining: 10.9s\n",
            "578:\tlearn: 0.3176827\ttotal: 15s\tremaining: 10.9s\n",
            "579:\tlearn: 0.3175224\ttotal: 15s\tremaining: 10.9s\n",
            "580:\tlearn: 0.3174211\ttotal: 15s\tremaining: 10.8s\n",
            "581:\tlearn: 0.3172789\ttotal: 15s\tremaining: 10.8s\n",
            "582:\tlearn: 0.3171020\ttotal: 15.1s\tremaining: 10.8s\n",
            "583:\tlearn: 0.3169627\ttotal: 15.1s\tremaining: 10.7s\n",
            "584:\tlearn: 0.3168440\ttotal: 15.1s\tremaining: 10.7s\n",
            "585:\tlearn: 0.3165649\ttotal: 15.1s\tremaining: 10.7s\n",
            "586:\tlearn: 0.3163833\ttotal: 15.1s\tremaining: 10.7s\n",
            "587:\tlearn: 0.3162100\ttotal: 15.2s\tremaining: 10.6s\n",
            "588:\tlearn: 0.3161711\ttotal: 15.2s\tremaining: 10.6s\n",
            "589:\tlearn: 0.3159773\ttotal: 15.2s\tremaining: 10.6s\n",
            "590:\tlearn: 0.3159595\ttotal: 15.2s\tremaining: 10.5s\n",
            "591:\tlearn: 0.3157734\ttotal: 15.2s\tremaining: 10.5s\n",
            "592:\tlearn: 0.3155964\ttotal: 15.3s\tremaining: 10.5s\n",
            "593:\tlearn: 0.3153882\ttotal: 15.3s\tremaining: 10.4s\n",
            "594:\tlearn: 0.3152576\ttotal: 15.3s\tremaining: 10.4s\n",
            "595:\tlearn: 0.3150510\ttotal: 15.3s\tremaining: 10.4s\n",
            "596:\tlearn: 0.3147948\ttotal: 15.4s\tremaining: 10.4s\n",
            "597:\tlearn: 0.3146628\ttotal: 15.4s\tremaining: 10.3s\n",
            "598:\tlearn: 0.3144692\ttotal: 15.4s\tremaining: 10.3s\n",
            "599:\tlearn: 0.3143310\ttotal: 15.4s\tremaining: 10.3s\n",
            "600:\tlearn: 0.3141201\ttotal: 15.4s\tremaining: 10.3s\n",
            "601:\tlearn: 0.3139275\ttotal: 15.5s\tremaining: 10.2s\n",
            "602:\tlearn: 0.3137018\ttotal: 15.5s\tremaining: 10.2s\n",
            "603:\tlearn: 0.3135893\ttotal: 15.5s\tremaining: 10.2s\n",
            "604:\tlearn: 0.3134028\ttotal: 15.5s\tremaining: 10.1s\n",
            "605:\tlearn: 0.3132335\ttotal: 15.6s\tremaining: 10.1s\n",
            "606:\tlearn: 0.3131240\ttotal: 15.6s\tremaining: 10.1s\n",
            "607:\tlearn: 0.3128801\ttotal: 15.6s\tremaining: 10.1s\n",
            "608:\tlearn: 0.3127300\ttotal: 15.6s\tremaining: 10s\n",
            "609:\tlearn: 0.3126160\ttotal: 15.7s\tremaining: 10s\n",
            "610:\tlearn: 0.3124600\ttotal: 15.7s\tremaining: 9.98s\n",
            "611:\tlearn: 0.3123802\ttotal: 15.7s\tremaining: 9.96s\n",
            "612:\tlearn: 0.3122234\ttotal: 15.7s\tremaining: 9.93s\n",
            "613:\tlearn: 0.3120852\ttotal: 15.8s\tremaining: 9.9s\n",
            "614:\tlearn: 0.3119171\ttotal: 15.8s\tremaining: 9.88s\n",
            "615:\tlearn: 0.3118136\ttotal: 15.8s\tremaining: 9.85s\n",
            "616:\tlearn: 0.3116610\ttotal: 15.8s\tremaining: 9.82s\n",
            "617:\tlearn: 0.3114445\ttotal: 15.8s\tremaining: 9.79s\n",
            "618:\tlearn: 0.3111604\ttotal: 15.9s\tremaining: 9.77s\n",
            "619:\tlearn: 0.3110453\ttotal: 15.9s\tremaining: 9.74s\n",
            "620:\tlearn: 0.3108830\ttotal: 15.9s\tremaining: 9.71s\n",
            "621:\tlearn: 0.3107367\ttotal: 15.9s\tremaining: 9.68s\n",
            "622:\tlearn: 0.3105452\ttotal: 15.9s\tremaining: 9.65s\n",
            "623:\tlearn: 0.3104329\ttotal: 16s\tremaining: 9.63s\n",
            "624:\tlearn: 0.3101879\ttotal: 16s\tremaining: 9.6s\n",
            "625:\tlearn: 0.3100156\ttotal: 16s\tremaining: 9.57s\n",
            "626:\tlearn: 0.3098846\ttotal: 16s\tremaining: 9.54s\n",
            "627:\tlearn: 0.3096758\ttotal: 16.1s\tremaining: 9.51s\n",
            "628:\tlearn: 0.3095162\ttotal: 16.1s\tremaining: 9.49s\n",
            "629:\tlearn: 0.3093347\ttotal: 16.1s\tremaining: 9.46s\n",
            "630:\tlearn: 0.3092309\ttotal: 16.1s\tremaining: 9.44s\n",
            "631:\tlearn: 0.3090936\ttotal: 16.2s\tremaining: 9.41s\n",
            "632:\tlearn: 0.3088708\ttotal: 16.2s\tremaining: 9.38s\n",
            "633:\tlearn: 0.3086645\ttotal: 16.2s\tremaining: 9.35s\n",
            "634:\tlearn: 0.3085343\ttotal: 16.2s\tremaining: 9.32s\n",
            "635:\tlearn: 0.3085104\ttotal: 16.2s\tremaining: 9.29s\n",
            "636:\tlearn: 0.3083439\ttotal: 16.3s\tremaining: 9.27s\n",
            "637:\tlearn: 0.3081608\ttotal: 16.3s\tremaining: 9.24s\n",
            "638:\tlearn: 0.3080177\ttotal: 16.3s\tremaining: 9.21s\n",
            "639:\tlearn: 0.3079911\ttotal: 16.3s\tremaining: 9.18s\n",
            "640:\tlearn: 0.3079226\ttotal: 16.3s\tremaining: 9.15s\n",
            "641:\tlearn: 0.3078137\ttotal: 16.4s\tremaining: 9.13s\n",
            "642:\tlearn: 0.3077072\ttotal: 16.4s\tremaining: 9.1s\n",
            "643:\tlearn: 0.3075712\ttotal: 16.4s\tremaining: 9.07s\n",
            "644:\tlearn: 0.3075469\ttotal: 16.4s\tremaining: 9.05s\n",
            "645:\tlearn: 0.3074300\ttotal: 16.5s\tremaining: 9.02s\n",
            "646:\tlearn: 0.3073464\ttotal: 16.5s\tremaining: 8.99s\n",
            "647:\tlearn: 0.3072033\ttotal: 16.5s\tremaining: 8.96s\n",
            "648:\tlearn: 0.3070371\ttotal: 16.5s\tremaining: 8.94s\n",
            "649:\tlearn: 0.3068757\ttotal: 16.6s\tremaining: 8.91s\n",
            "650:\tlearn: 0.3067359\ttotal: 16.6s\tremaining: 8.88s\n",
            "651:\tlearn: 0.3065248\ttotal: 16.6s\tremaining: 8.86s\n",
            "652:\tlearn: 0.3063944\ttotal: 16.6s\tremaining: 8.83s\n",
            "653:\tlearn: 0.3061816\ttotal: 16.6s\tremaining: 8.81s\n",
            "654:\tlearn: 0.3060057\ttotal: 16.7s\tremaining: 8.79s\n",
            "655:\tlearn: 0.3058199\ttotal: 16.7s\tremaining: 8.76s\n",
            "656:\tlearn: 0.3056801\ttotal: 16.7s\tremaining: 8.73s\n",
            "657:\tlearn: 0.3055581\ttotal: 16.8s\tremaining: 8.71s\n",
            "658:\tlearn: 0.3053605\ttotal: 16.8s\tremaining: 8.68s\n",
            "659:\tlearn: 0.3051689\ttotal: 16.8s\tremaining: 8.66s\n",
            "660:\tlearn: 0.3049818\ttotal: 16.8s\tremaining: 8.63s\n",
            "661:\tlearn: 0.3047993\ttotal: 16.9s\tremaining: 8.61s\n",
            "662:\tlearn: 0.3047784\ttotal: 16.9s\tremaining: 8.58s\n",
            "663:\tlearn: 0.3046879\ttotal: 16.9s\tremaining: 8.55s\n",
            "664:\tlearn: 0.3045981\ttotal: 16.9s\tremaining: 8.52s\n",
            "665:\tlearn: 0.3044563\ttotal: 16.9s\tremaining: 8.49s\n",
            "666:\tlearn: 0.3043080\ttotal: 17s\tremaining: 8.46s\n",
            "667:\tlearn: 0.3042500\ttotal: 17s\tremaining: 8.44s\n",
            "668:\tlearn: 0.3041170\ttotal: 17s\tremaining: 8.41s\n",
            "669:\tlearn: 0.3039298\ttotal: 17s\tremaining: 8.39s\n",
            "670:\tlearn: 0.3038095\ttotal: 17s\tremaining: 8.36s\n",
            "671:\tlearn: 0.3036498\ttotal: 17.1s\tremaining: 8.33s\n",
            "672:\tlearn: 0.3035501\ttotal: 17.1s\tremaining: 8.3s\n",
            "673:\tlearn: 0.3034197\ttotal: 17.1s\tremaining: 8.28s\n",
            "674:\tlearn: 0.3032452\ttotal: 17.1s\tremaining: 8.25s\n",
            "675:\tlearn: 0.3031030\ttotal: 17.2s\tremaining: 8.22s\n",
            "676:\tlearn: 0.3029531\ttotal: 17.2s\tremaining: 8.2s\n",
            "677:\tlearn: 0.3027930\ttotal: 17.2s\tremaining: 8.17s\n",
            "678:\tlearn: 0.3026318\ttotal: 17.2s\tremaining: 8.14s\n",
            "679:\tlearn: 0.3024825\ttotal: 17.3s\tremaining: 8.12s\n",
            "680:\tlearn: 0.3022833\ttotal: 17.3s\tremaining: 8.09s\n",
            "681:\tlearn: 0.3020941\ttotal: 17.3s\tremaining: 8.06s\n",
            "682:\tlearn: 0.3019421\ttotal: 17.3s\tremaining: 8.04s\n",
            "683:\tlearn: 0.3017652\ttotal: 17.3s\tremaining: 8.01s\n",
            "684:\tlearn: 0.3016377\ttotal: 17.4s\tremaining: 7.98s\n",
            "685:\tlearn: 0.3014771\ttotal: 17.4s\tremaining: 7.95s\n",
            "686:\tlearn: 0.3013314\ttotal: 17.4s\tremaining: 7.92s\n",
            "687:\tlearn: 0.3012083\ttotal: 17.4s\tremaining: 7.9s\n",
            "688:\tlearn: 0.3010839\ttotal: 17.4s\tremaining: 7.87s\n",
            "689:\tlearn: 0.3009925\ttotal: 17.5s\tremaining: 7.85s\n",
            "690:\tlearn: 0.3008634\ttotal: 17.5s\tremaining: 7.82s\n",
            "691:\tlearn: 0.3007034\ttotal: 17.5s\tremaining: 7.79s\n",
            "692:\tlearn: 0.3005725\ttotal: 17.5s\tremaining: 7.77s\n",
            "693:\tlearn: 0.3003113\ttotal: 17.6s\tremaining: 7.74s\n",
            "694:\tlearn: 0.3001611\ttotal: 17.6s\tremaining: 7.72s\n",
            "695:\tlearn: 0.3000081\ttotal: 17.6s\tremaining: 7.69s\n",
            "696:\tlearn: 0.2998493\ttotal: 17.6s\tremaining: 7.66s\n",
            "697:\tlearn: 0.2996826\ttotal: 17.6s\tremaining: 7.64s\n",
            "698:\tlearn: 0.2995067\ttotal: 17.7s\tremaining: 7.62s\n",
            "699:\tlearn: 0.2994570\ttotal: 17.7s\tremaining: 7.59s\n",
            "700:\tlearn: 0.2993635\ttotal: 17.7s\tremaining: 7.57s\n",
            "701:\tlearn: 0.2992454\ttotal: 17.8s\tremaining: 7.54s\n",
            "702:\tlearn: 0.2991498\ttotal: 17.8s\tremaining: 7.51s\n",
            "703:\tlearn: 0.2990063\ttotal: 17.8s\tremaining: 7.48s\n",
            "704:\tlearn: 0.2988119\ttotal: 17.8s\tremaining: 7.46s\n",
            "705:\tlearn: 0.2986329\ttotal: 17.8s\tremaining: 7.43s\n",
            "706:\tlearn: 0.2985371\ttotal: 17.9s\tremaining: 7.4s\n",
            "707:\tlearn: 0.2983336\ttotal: 17.9s\tremaining: 7.37s\n",
            "708:\tlearn: 0.2981969\ttotal: 17.9s\tremaining: 7.35s\n",
            "709:\tlearn: 0.2980928\ttotal: 17.9s\tremaining: 7.32s\n",
            "710:\tlearn: 0.2980017\ttotal: 18s\tremaining: 7.3s\n",
            "711:\tlearn: 0.2978657\ttotal: 18s\tremaining: 7.27s\n",
            "712:\tlearn: 0.2976690\ttotal: 18s\tremaining: 7.24s\n",
            "713:\tlearn: 0.2975580\ttotal: 18s\tremaining: 7.22s\n",
            "714:\tlearn: 0.2974355\ttotal: 18s\tremaining: 7.19s\n",
            "715:\tlearn: 0.2972883\ttotal: 18.1s\tremaining: 7.16s\n",
            "716:\tlearn: 0.2971115\ttotal: 18.1s\tremaining: 7.14s\n",
            "717:\tlearn: 0.2969750\ttotal: 18.1s\tremaining: 7.11s\n",
            "718:\tlearn: 0.2967812\ttotal: 18.1s\tremaining: 7.09s\n",
            "719:\tlearn: 0.2966986\ttotal: 18.2s\tremaining: 7.06s\n",
            "720:\tlearn: 0.2966803\ttotal: 18.2s\tremaining: 7.03s\n",
            "721:\tlearn: 0.2965455\ttotal: 18.2s\tremaining: 7.01s\n",
            "722:\tlearn: 0.2964952\ttotal: 18.2s\tremaining: 6.98s\n",
            "723:\tlearn: 0.2963747\ttotal: 18.2s\tremaining: 6.95s\n",
            "724:\tlearn: 0.2962383\ttotal: 18.3s\tremaining: 6.93s\n",
            "725:\tlearn: 0.2961261\ttotal: 18.3s\tremaining: 6.9s\n",
            "726:\tlearn: 0.2959104\ttotal: 18.3s\tremaining: 6.87s\n",
            "727:\tlearn: 0.2958312\ttotal: 18.3s\tremaining: 6.85s\n",
            "728:\tlearn: 0.2957309\ttotal: 18.4s\tremaining: 6.82s\n",
            "729:\tlearn: 0.2955508\ttotal: 18.4s\tremaining: 6.8s\n",
            "730:\tlearn: 0.2954247\ttotal: 18.4s\tremaining: 6.77s\n",
            "731:\tlearn: 0.2952766\ttotal: 18.4s\tremaining: 6.74s\n",
            "732:\tlearn: 0.2950769\ttotal: 18.5s\tremaining: 6.72s\n",
            "733:\tlearn: 0.2948887\ttotal: 18.5s\tremaining: 6.69s\n",
            "734:\tlearn: 0.2947275\ttotal: 18.5s\tremaining: 6.67s\n",
            "735:\tlearn: 0.2945254\ttotal: 18.5s\tremaining: 6.64s\n",
            "736:\tlearn: 0.2942881\ttotal: 18.5s\tremaining: 6.61s\n",
            "737:\tlearn: 0.2942239\ttotal: 18.6s\tremaining: 6.59s\n",
            "738:\tlearn: 0.2941197\ttotal: 18.6s\tremaining: 6.56s\n",
            "739:\tlearn: 0.2939649\ttotal: 18.6s\tremaining: 6.54s\n",
            "740:\tlearn: 0.2937559\ttotal: 18.6s\tremaining: 6.51s\n",
            "741:\tlearn: 0.2936279\ttotal: 18.6s\tremaining: 6.48s\n",
            "742:\tlearn: 0.2935477\ttotal: 18.7s\tremaining: 6.46s\n",
            "743:\tlearn: 0.2933259\ttotal: 18.7s\tremaining: 6.43s\n",
            "744:\tlearn: 0.2932168\ttotal: 18.7s\tremaining: 6.41s\n",
            "745:\tlearn: 0.2930873\ttotal: 18.7s\tremaining: 6.38s\n",
            "746:\tlearn: 0.2929702\ttotal: 18.8s\tremaining: 6.36s\n",
            "747:\tlearn: 0.2927584\ttotal: 18.8s\tremaining: 6.33s\n",
            "748:\tlearn: 0.2925894\ttotal: 18.8s\tremaining: 6.31s\n",
            "749:\tlearn: 0.2924276\ttotal: 18.8s\tremaining: 6.28s\n",
            "750:\tlearn: 0.2922322\ttotal: 18.9s\tremaining: 6.25s\n",
            "751:\tlearn: 0.2921014\ttotal: 18.9s\tremaining: 6.23s\n",
            "752:\tlearn: 0.2919020\ttotal: 18.9s\tremaining: 6.2s\n",
            "753:\tlearn: 0.2918525\ttotal: 18.9s\tremaining: 6.17s\n",
            "754:\tlearn: 0.2916883\ttotal: 18.9s\tremaining: 6.15s\n",
            "755:\tlearn: 0.2915959\ttotal: 19s\tremaining: 6.12s\n",
            "756:\tlearn: 0.2914251\ttotal: 19s\tremaining: 6.1s\n",
            "757:\tlearn: 0.2914005\ttotal: 19s\tremaining: 6.07s\n",
            "758:\tlearn: 0.2912947\ttotal: 19s\tremaining: 6.04s\n",
            "759:\tlearn: 0.2911316\ttotal: 19.1s\tremaining: 6.02s\n",
            "760:\tlearn: 0.2910060\ttotal: 19.1s\tremaining: 5.99s\n",
            "761:\tlearn: 0.2908602\ttotal: 19.1s\tremaining: 5.96s\n",
            "762:\tlearn: 0.2907741\ttotal: 19.1s\tremaining: 5.94s\n",
            "763:\tlearn: 0.2906256\ttotal: 19.1s\tremaining: 5.91s\n",
            "764:\tlearn: 0.2904939\ttotal: 19.2s\tremaining: 5.89s\n",
            "765:\tlearn: 0.2903610\ttotal: 19.2s\tremaining: 5.86s\n",
            "766:\tlearn: 0.2901197\ttotal: 19.2s\tremaining: 5.84s\n",
            "767:\tlearn: 0.2899681\ttotal: 19.2s\tremaining: 5.81s\n",
            "768:\tlearn: 0.2896911\ttotal: 19.3s\tremaining: 5.79s\n",
            "769:\tlearn: 0.2895317\ttotal: 19.3s\tremaining: 5.76s\n",
            "770:\tlearn: 0.2894125\ttotal: 19.3s\tremaining: 5.73s\n",
            "771:\tlearn: 0.2892422\ttotal: 19.3s\tremaining: 5.71s\n",
            "772:\tlearn: 0.2891402\ttotal: 19.3s\tremaining: 5.68s\n",
            "773:\tlearn: 0.2889823\ttotal: 19.4s\tremaining: 5.66s\n",
            "774:\tlearn: 0.2888650\ttotal: 19.4s\tremaining: 5.63s\n",
            "775:\tlearn: 0.2887609\ttotal: 19.4s\tremaining: 5.6s\n",
            "776:\tlearn: 0.2887429\ttotal: 19.4s\tremaining: 5.58s\n",
            "777:\tlearn: 0.2886963\ttotal: 19.5s\tremaining: 5.55s\n",
            "778:\tlearn: 0.2884595\ttotal: 19.5s\tremaining: 5.53s\n",
            "779:\tlearn: 0.2882807\ttotal: 19.5s\tremaining: 5.5s\n",
            "780:\tlearn: 0.2881711\ttotal: 19.5s\tremaining: 5.47s\n",
            "781:\tlearn: 0.2880741\ttotal: 19.5s\tremaining: 5.45s\n",
            "782:\tlearn: 0.2879673\ttotal: 19.6s\tremaining: 5.42s\n",
            "783:\tlearn: 0.2878560\ttotal: 19.6s\tremaining: 5.4s\n",
            "784:\tlearn: 0.2876885\ttotal: 19.6s\tremaining: 5.37s\n",
            "785:\tlearn: 0.2875929\ttotal: 19.6s\tremaining: 5.34s\n",
            "786:\tlearn: 0.2873480\ttotal: 19.7s\tremaining: 5.32s\n",
            "787:\tlearn: 0.2872227\ttotal: 19.7s\tremaining: 5.3s\n",
            "788:\tlearn: 0.2871439\ttotal: 19.7s\tremaining: 5.27s\n",
            "789:\tlearn: 0.2869239\ttotal: 19.7s\tremaining: 5.25s\n",
            "790:\tlearn: 0.2866877\ttotal: 19.8s\tremaining: 5.22s\n",
            "791:\tlearn: 0.2865873\ttotal: 19.8s\tremaining: 5.2s\n",
            "792:\tlearn: 0.2864450\ttotal: 19.8s\tremaining: 5.17s\n",
            "793:\tlearn: 0.2863656\ttotal: 19.8s\tremaining: 5.14s\n",
            "794:\tlearn: 0.2862116\ttotal: 19.8s\tremaining: 5.12s\n",
            "795:\tlearn: 0.2860716\ttotal: 19.9s\tremaining: 5.09s\n",
            "796:\tlearn: 0.2859685\ttotal: 19.9s\tremaining: 5.07s\n",
            "797:\tlearn: 0.2858242\ttotal: 19.9s\tremaining: 5.04s\n",
            "798:\tlearn: 0.2856905\ttotal: 19.9s\tremaining: 5.02s\n",
            "799:\tlearn: 0.2855415\ttotal: 20s\tremaining: 4.99s\n",
            "800:\tlearn: 0.2854053\ttotal: 20s\tremaining: 4.96s\n",
            "801:\tlearn: 0.2851938\ttotal: 20s\tremaining: 4.94s\n",
            "802:\tlearn: 0.2850606\ttotal: 20s\tremaining: 4.92s\n",
            "803:\tlearn: 0.2849459\ttotal: 20.1s\tremaining: 4.89s\n",
            "804:\tlearn: 0.2847817\ttotal: 20.1s\tremaining: 4.87s\n",
            "805:\tlearn: 0.2847192\ttotal: 20.1s\tremaining: 4.84s\n",
            "806:\tlearn: 0.2845879\ttotal: 20.1s\tremaining: 4.81s\n",
            "807:\tlearn: 0.2844647\ttotal: 20.1s\tremaining: 4.79s\n",
            "808:\tlearn: 0.2842761\ttotal: 20.2s\tremaining: 4.76s\n",
            "809:\tlearn: 0.2841407\ttotal: 20.2s\tremaining: 4.74s\n",
            "810:\tlearn: 0.2840071\ttotal: 20.2s\tremaining: 4.71s\n",
            "811:\tlearn: 0.2838989\ttotal: 20.2s\tremaining: 4.68s\n",
            "812:\tlearn: 0.2837883\ttotal: 20.3s\tremaining: 4.66s\n",
            "813:\tlearn: 0.2835448\ttotal: 20.3s\tremaining: 4.63s\n",
            "814:\tlearn: 0.2834108\ttotal: 20.3s\tremaining: 4.61s\n",
            "815:\tlearn: 0.2833036\ttotal: 20.3s\tremaining: 4.58s\n",
            "816:\tlearn: 0.2832835\ttotal: 20.4s\tremaining: 4.56s\n",
            "817:\tlearn: 0.2831576\ttotal: 20.4s\tremaining: 4.53s\n",
            "818:\tlearn: 0.2829680\ttotal: 20.4s\tremaining: 4.51s\n",
            "819:\tlearn: 0.2828094\ttotal: 20.4s\tremaining: 4.48s\n",
            "820:\tlearn: 0.2827452\ttotal: 20.4s\tremaining: 4.46s\n",
            "821:\tlearn: 0.2826730\ttotal: 20.5s\tremaining: 4.43s\n",
            "822:\tlearn: 0.2825394\ttotal: 20.5s\tremaining: 4.4s\n",
            "823:\tlearn: 0.2823994\ttotal: 20.5s\tremaining: 4.38s\n",
            "824:\tlearn: 0.2822025\ttotal: 20.5s\tremaining: 4.36s\n",
            "825:\tlearn: 0.2819642\ttotal: 20.6s\tremaining: 4.33s\n",
            "826:\tlearn: 0.2817631\ttotal: 20.6s\tremaining: 4.3s\n",
            "827:\tlearn: 0.2815863\ttotal: 20.6s\tremaining: 4.28s\n",
            "828:\tlearn: 0.2814117\ttotal: 20.6s\tremaining: 4.25s\n",
            "829:\tlearn: 0.2812352\ttotal: 20.6s\tremaining: 4.23s\n",
            "830:\tlearn: 0.2811211\ttotal: 20.7s\tremaining: 4.2s\n",
            "831:\tlearn: 0.2809088\ttotal: 20.7s\tremaining: 4.18s\n",
            "832:\tlearn: 0.2808224\ttotal: 20.7s\tremaining: 4.15s\n",
            "833:\tlearn: 0.2807279\ttotal: 20.7s\tremaining: 4.13s\n",
            "834:\tlearn: 0.2806228\ttotal: 20.8s\tremaining: 4.1s\n",
            "835:\tlearn: 0.2805403\ttotal: 20.8s\tremaining: 4.08s\n",
            "836:\tlearn: 0.2803763\ttotal: 20.8s\tremaining: 4.05s\n",
            "837:\tlearn: 0.2802134\ttotal: 20.8s\tremaining: 4.03s\n",
            "838:\tlearn: 0.2801230\ttotal: 20.9s\tremaining: 4s\n",
            "839:\tlearn: 0.2800025\ttotal: 20.9s\tremaining: 3.98s\n",
            "840:\tlearn: 0.2799150\ttotal: 20.9s\tremaining: 3.95s\n",
            "841:\tlearn: 0.2798102\ttotal: 20.9s\tremaining: 3.92s\n",
            "842:\tlearn: 0.2797188\ttotal: 20.9s\tremaining: 3.9s\n",
            "843:\tlearn: 0.2795455\ttotal: 21s\tremaining: 3.88s\n",
            "844:\tlearn: 0.2794365\ttotal: 21s\tremaining: 3.85s\n",
            "845:\tlearn: 0.2792598\ttotal: 21s\tremaining: 3.82s\n",
            "846:\tlearn: 0.2790831\ttotal: 21s\tremaining: 3.8s\n",
            "847:\tlearn: 0.2789467\ttotal: 21.1s\tremaining: 3.77s\n",
            "848:\tlearn: 0.2788022\ttotal: 21.1s\tremaining: 3.75s\n",
            "849:\tlearn: 0.2786181\ttotal: 21.1s\tremaining: 3.72s\n",
            "850:\tlearn: 0.2784723\ttotal: 21.1s\tremaining: 3.7s\n",
            "851:\tlearn: 0.2783452\ttotal: 21.1s\tremaining: 3.67s\n",
            "852:\tlearn: 0.2782067\ttotal: 21.2s\tremaining: 3.65s\n",
            "853:\tlearn: 0.2779760\ttotal: 21.2s\tremaining: 3.62s\n",
            "854:\tlearn: 0.2778082\ttotal: 21.2s\tremaining: 3.6s\n",
            "855:\tlearn: 0.2776402\ttotal: 21.2s\tremaining: 3.57s\n",
            "856:\tlearn: 0.2775308\ttotal: 21.3s\tremaining: 3.55s\n",
            "857:\tlearn: 0.2773964\ttotal: 21.3s\tremaining: 3.52s\n",
            "858:\tlearn: 0.2773776\ttotal: 21.3s\tremaining: 3.5s\n",
            "859:\tlearn: 0.2772240\ttotal: 21.3s\tremaining: 3.47s\n",
            "860:\tlearn: 0.2772023\ttotal: 21.3s\tremaining: 3.44s\n",
            "861:\tlearn: 0.2770447\ttotal: 21.4s\tremaining: 3.42s\n",
            "862:\tlearn: 0.2768981\ttotal: 21.4s\tremaining: 3.39s\n",
            "863:\tlearn: 0.2767790\ttotal: 21.4s\tremaining: 3.37s\n",
            "864:\tlearn: 0.2766805\ttotal: 21.4s\tremaining: 3.35s\n",
            "865:\tlearn: 0.2765946\ttotal: 21.5s\tremaining: 3.32s\n",
            "866:\tlearn: 0.2764881\ttotal: 21.5s\tremaining: 3.29s\n",
            "867:\tlearn: 0.2762208\ttotal: 21.5s\tremaining: 3.27s\n",
            "868:\tlearn: 0.2760435\ttotal: 21.5s\tremaining: 3.24s\n",
            "869:\tlearn: 0.2759128\ttotal: 21.5s\tremaining: 3.22s\n",
            "870:\tlearn: 0.2758488\ttotal: 21.6s\tremaining: 3.19s\n",
            "871:\tlearn: 0.2757215\ttotal: 21.6s\tremaining: 3.17s\n",
            "872:\tlearn: 0.2755723\ttotal: 21.6s\tremaining: 3.14s\n",
            "873:\tlearn: 0.2754208\ttotal: 21.6s\tremaining: 3.12s\n",
            "874:\tlearn: 0.2752427\ttotal: 21.7s\tremaining: 3.09s\n",
            "875:\tlearn: 0.2751234\ttotal: 21.7s\tremaining: 3.07s\n",
            "876:\tlearn: 0.2751088\ttotal: 21.7s\tremaining: 3.04s\n",
            "877:\tlearn: 0.2750360\ttotal: 21.7s\tremaining: 3.02s\n",
            "878:\tlearn: 0.2748756\ttotal: 21.8s\tremaining: 2.99s\n",
            "879:\tlearn: 0.2747799\ttotal: 21.8s\tremaining: 2.97s\n",
            "880:\tlearn: 0.2746574\ttotal: 21.8s\tremaining: 2.94s\n",
            "881:\tlearn: 0.2744655\ttotal: 21.8s\tremaining: 2.92s\n",
            "882:\tlearn: 0.2743501\ttotal: 21.8s\tremaining: 2.89s\n",
            "883:\tlearn: 0.2742102\ttotal: 21.9s\tremaining: 2.87s\n",
            "884:\tlearn: 0.2740981\ttotal: 21.9s\tremaining: 2.85s\n",
            "885:\tlearn: 0.2739229\ttotal: 21.9s\tremaining: 2.82s\n",
            "886:\tlearn: 0.2737401\ttotal: 22s\tremaining: 2.8s\n",
            "887:\tlearn: 0.2736419\ttotal: 22s\tremaining: 2.78s\n",
            "888:\tlearn: 0.2734857\ttotal: 22.1s\tremaining: 2.75s\n",
            "889:\tlearn: 0.2733719\ttotal: 22.1s\tremaining: 2.73s\n",
            "890:\tlearn: 0.2732822\ttotal: 22.1s\tremaining: 2.71s\n",
            "891:\tlearn: 0.2731608\ttotal: 22.2s\tremaining: 2.69s\n",
            "892:\tlearn: 0.2730894\ttotal: 22.2s\tremaining: 2.66s\n",
            "893:\tlearn: 0.2730272\ttotal: 22.3s\tremaining: 2.64s\n",
            "894:\tlearn: 0.2729575\ttotal: 22.3s\tremaining: 2.62s\n",
            "895:\tlearn: 0.2728584\ttotal: 22.4s\tremaining: 2.59s\n",
            "896:\tlearn: 0.2727176\ttotal: 22.4s\tremaining: 2.57s\n",
            "897:\tlearn: 0.2725003\ttotal: 22.4s\tremaining: 2.55s\n",
            "898:\tlearn: 0.2723314\ttotal: 22.5s\tremaining: 2.53s\n",
            "899:\tlearn: 0.2722316\ttotal: 22.5s\tremaining: 2.5s\n",
            "900:\tlearn: 0.2721144\ttotal: 22.6s\tremaining: 2.48s\n",
            "901:\tlearn: 0.2720473\ttotal: 22.6s\tremaining: 2.46s\n",
            "902:\tlearn: 0.2719063\ttotal: 22.7s\tremaining: 2.43s\n",
            "903:\tlearn: 0.2718413\ttotal: 22.7s\tremaining: 2.41s\n",
            "904:\tlearn: 0.2717117\ttotal: 22.8s\tremaining: 2.39s\n",
            "905:\tlearn: 0.2716015\ttotal: 22.8s\tremaining: 2.37s\n",
            "906:\tlearn: 0.2714574\ttotal: 22.9s\tremaining: 2.34s\n",
            "907:\tlearn: 0.2714441\ttotal: 22.9s\tremaining: 2.32s\n",
            "908:\tlearn: 0.2713596\ttotal: 22.9s\tremaining: 2.29s\n",
            "909:\tlearn: 0.2712522\ttotal: 23s\tremaining: 2.27s\n",
            "910:\tlearn: 0.2710645\ttotal: 23s\tremaining: 2.25s\n",
            "911:\tlearn: 0.2709987\ttotal: 23.1s\tremaining: 2.22s\n",
            "912:\tlearn: 0.2709171\ttotal: 23.1s\tremaining: 2.2s\n",
            "913:\tlearn: 0.2708052\ttotal: 23.1s\tremaining: 2.18s\n",
            "914:\tlearn: 0.2707468\ttotal: 23.2s\tremaining: 2.15s\n",
            "915:\tlearn: 0.2706878\ttotal: 23.2s\tremaining: 2.13s\n",
            "916:\tlearn: 0.2705435\ttotal: 23.2s\tremaining: 2.1s\n",
            "917:\tlearn: 0.2704831\ttotal: 23.3s\tremaining: 2.08s\n",
            "918:\tlearn: 0.2704236\ttotal: 23.3s\tremaining: 2.06s\n",
            "919:\tlearn: 0.2703786\ttotal: 23.4s\tremaining: 2.03s\n",
            "920:\tlearn: 0.2703457\ttotal: 23.4s\tremaining: 2.01s\n",
            "921:\tlearn: 0.2701529\ttotal: 23.5s\tremaining: 1.98s\n",
            "922:\tlearn: 0.2700631\ttotal: 23.5s\tremaining: 1.96s\n",
            "923:\tlearn: 0.2699643\ttotal: 23.5s\tremaining: 1.94s\n",
            "924:\tlearn: 0.2698295\ttotal: 23.6s\tremaining: 1.91s\n",
            "925:\tlearn: 0.2696978\ttotal: 23.6s\tremaining: 1.89s\n",
            "926:\tlearn: 0.2696497\ttotal: 23.7s\tremaining: 1.86s\n",
            "927:\tlearn: 0.2695415\ttotal: 23.7s\tremaining: 1.84s\n",
            "928:\tlearn: 0.2693891\ttotal: 23.8s\tremaining: 1.81s\n",
            "929:\tlearn: 0.2692527\ttotal: 23.8s\tremaining: 1.79s\n",
            "930:\tlearn: 0.2691382\ttotal: 23.9s\tremaining: 1.77s\n",
            "931:\tlearn: 0.2689874\ttotal: 23.9s\tremaining: 1.74s\n",
            "932:\tlearn: 0.2688912\ttotal: 23.9s\tremaining: 1.72s\n",
            "933:\tlearn: 0.2687536\ttotal: 24s\tremaining: 1.7s\n",
            "934:\tlearn: 0.2686188\ttotal: 24s\tremaining: 1.67s\n",
            "935:\tlearn: 0.2685554\ttotal: 24s\tremaining: 1.64s\n",
            "936:\tlearn: 0.2683441\ttotal: 24.1s\tremaining: 1.62s\n",
            "937:\tlearn: 0.2681373\ttotal: 24.1s\tremaining: 1.59s\n",
            "938:\tlearn: 0.2680166\ttotal: 24.2s\tremaining: 1.57s\n",
            "939:\tlearn: 0.2679374\ttotal: 24.2s\tremaining: 1.54s\n",
            "940:\tlearn: 0.2678635\ttotal: 24.3s\tremaining: 1.52s\n",
            "941:\tlearn: 0.2676686\ttotal: 24.3s\tremaining: 1.5s\n",
            "942:\tlearn: 0.2675924\ttotal: 24.4s\tremaining: 1.47s\n",
            "943:\tlearn: 0.2674190\ttotal: 24.4s\tremaining: 1.45s\n",
            "944:\tlearn: 0.2674061\ttotal: 24.4s\tremaining: 1.42s\n",
            "945:\tlearn: 0.2672576\ttotal: 24.5s\tremaining: 1.4s\n",
            "946:\tlearn: 0.2670810\ttotal: 24.5s\tremaining: 1.37s\n",
            "947:\tlearn: 0.2669960\ttotal: 24.6s\tremaining: 1.35s\n",
            "948:\tlearn: 0.2668959\ttotal: 24.6s\tremaining: 1.32s\n",
            "949:\tlearn: 0.2667182\ttotal: 24.6s\tremaining: 1.3s\n",
            "950:\tlearn: 0.2666224\ttotal: 24.7s\tremaining: 1.27s\n",
            "951:\tlearn: 0.2664536\ttotal: 24.7s\tremaining: 1.25s\n",
            "952:\tlearn: 0.2663151\ttotal: 24.8s\tremaining: 1.22s\n",
            "953:\tlearn: 0.2661938\ttotal: 24.8s\tremaining: 1.2s\n",
            "954:\tlearn: 0.2660319\ttotal: 24.8s\tremaining: 1.17s\n",
            "955:\tlearn: 0.2658979\ttotal: 24.9s\tremaining: 1.15s\n",
            "956:\tlearn: 0.2657925\ttotal: 24.9s\tremaining: 1.12s\n",
            "957:\tlearn: 0.2657817\ttotal: 25s\tremaining: 1.09s\n",
            "958:\tlearn: 0.2656665\ttotal: 25s\tremaining: 1.07s\n",
            "959:\tlearn: 0.2655236\ttotal: 25.1s\tremaining: 1.04s\n",
            "960:\tlearn: 0.2654426\ttotal: 25.1s\tremaining: 1.02s\n",
            "961:\tlearn: 0.2653227\ttotal: 25.2s\tremaining: 994ms\n",
            "962:\tlearn: 0.2651823\ttotal: 25.2s\tremaining: 968ms\n",
            "963:\tlearn: 0.2650851\ttotal: 25.3s\tremaining: 943ms\n",
            "964:\tlearn: 0.2649949\ttotal: 25.3s\tremaining: 917ms\n",
            "965:\tlearn: 0.2649091\ttotal: 25.3s\tremaining: 892ms\n",
            "966:\tlearn: 0.2647861\ttotal: 25.4s\tremaining: 866ms\n",
            "967:\tlearn: 0.2646785\ttotal: 25.4s\tremaining: 841ms\n",
            "968:\tlearn: 0.2646287\ttotal: 25.5s\tremaining: 815ms\n",
            "969:\tlearn: 0.2644180\ttotal: 25.5s\tremaining: 789ms\n",
            "970:\tlearn: 0.2642955\ttotal: 25.5s\tremaining: 762ms\n",
            "971:\tlearn: 0.2641395\ttotal: 25.5s\tremaining: 736ms\n",
            "972:\tlearn: 0.2640025\ttotal: 25.6s\tremaining: 709ms\n",
            "973:\tlearn: 0.2638837\ttotal: 25.6s\tremaining: 683ms\n",
            "974:\tlearn: 0.2637169\ttotal: 25.6s\tremaining: 657ms\n",
            "975:\tlearn: 0.2635913\ttotal: 25.6s\tremaining: 630ms\n",
            "976:\tlearn: 0.2634104\ttotal: 25.7s\tremaining: 604ms\n",
            "977:\tlearn: 0.2632588\ttotal: 25.7s\tremaining: 578ms\n",
            "978:\tlearn: 0.2631930\ttotal: 25.7s\tremaining: 552ms\n",
            "979:\tlearn: 0.2631750\ttotal: 25.7s\tremaining: 525ms\n",
            "980:\tlearn: 0.2630789\ttotal: 25.8s\tremaining: 499ms\n",
            "981:\tlearn: 0.2629797\ttotal: 25.8s\tremaining: 472ms\n",
            "982:\tlearn: 0.2629367\ttotal: 25.8s\tremaining: 446ms\n",
            "983:\tlearn: 0.2628546\ttotal: 25.8s\tremaining: 420ms\n",
            "984:\tlearn: 0.2626953\ttotal: 25.8s\tremaining: 393ms\n",
            "985:\tlearn: 0.2626132\ttotal: 25.9s\tremaining: 367ms\n",
            "986:\tlearn: 0.2625985\ttotal: 25.9s\tremaining: 341ms\n",
            "987:\tlearn: 0.2625431\ttotal: 25.9s\tremaining: 315ms\n",
            "988:\tlearn: 0.2623801\ttotal: 25.9s\tremaining: 289ms\n",
            "989:\tlearn: 0.2622889\ttotal: 26s\tremaining: 262ms\n",
            "990:\tlearn: 0.2621992\ttotal: 26s\tremaining: 236ms\n",
            "991:\tlearn: 0.2621491\ttotal: 26s\tremaining: 210ms\n",
            "992:\tlearn: 0.2620289\ttotal: 26s\tremaining: 184ms\n",
            "993:\tlearn: 0.2618992\ttotal: 26.1s\tremaining: 157ms\n",
            "994:\tlearn: 0.2618136\ttotal: 26.1s\tremaining: 131ms\n",
            "995:\tlearn: 0.2616314\ttotal: 26.1s\tremaining: 105ms\n",
            "996:\tlearn: 0.2614291\ttotal: 26.1s\tremaining: 78.6ms\n",
            "997:\tlearn: 0.2612655\ttotal: 26.2s\tremaining: 52.4ms\n",
            "998:\tlearn: 0.2611359\ttotal: 26.2s\tremaining: 26.2ms\n",
            "999:\tlearn: 0.2610266\ttotal: 26.2s\tremaining: 0us\n",
            "0:\tlearn: 0.6815508\ttotal: 22.9ms\tremaining: 22.8s\n",
            "1:\tlearn: 0.6690033\ttotal: 44.9ms\tremaining: 22.4s\n",
            "2:\tlearn: 0.6544416\ttotal: 65.6ms\tremaining: 21.8s\n",
            "3:\tlearn: 0.6451679\ttotal: 84.3ms\tremaining: 21s\n",
            "4:\tlearn: 0.6352457\ttotal: 107ms\tremaining: 21.3s\n",
            "5:\tlearn: 0.6256638\ttotal: 126ms\tremaining: 20.9s\n",
            "6:\tlearn: 0.6177108\ttotal: 147ms\tremaining: 20.8s\n",
            "7:\tlearn: 0.6114562\ttotal: 166ms\tremaining: 20.6s\n",
            "8:\tlearn: 0.6037977\ttotal: 188ms\tremaining: 20.7s\n",
            "9:\tlearn: 0.5975522\ttotal: 210ms\tremaining: 20.8s\n",
            "10:\tlearn: 0.5907673\ttotal: 240ms\tremaining: 21.6s\n",
            "11:\tlearn: 0.5852216\ttotal: 259ms\tremaining: 21.4s\n",
            "12:\tlearn: 0.5804443\ttotal: 282ms\tremaining: 21.4s\n",
            "13:\tlearn: 0.5759028\ttotal: 301ms\tremaining: 21.2s\n",
            "14:\tlearn: 0.5696128\ttotal: 323ms\tremaining: 21.2s\n",
            "15:\tlearn: 0.5648179\ttotal: 341ms\tremaining: 21s\n",
            "16:\tlearn: 0.5614477\ttotal: 365ms\tremaining: 21.1s\n",
            "17:\tlearn: 0.5576819\ttotal: 383ms\tremaining: 20.9s\n",
            "18:\tlearn: 0.5438164\ttotal: 407ms\tremaining: 21s\n",
            "19:\tlearn: 0.5404371\ttotal: 427ms\tremaining: 20.9s\n",
            "20:\tlearn: 0.5369469\ttotal: 451ms\tremaining: 21s\n",
            "21:\tlearn: 0.5337842\ttotal: 473ms\tremaining: 21s\n",
            "22:\tlearn: 0.5282245\ttotal: 494ms\tremaining: 21s\n",
            "23:\tlearn: 0.5251603\ttotal: 516ms\tremaining: 21s\n",
            "24:\tlearn: 0.5234243\ttotal: 535ms\tremaining: 20.9s\n",
            "25:\tlearn: 0.5210610\ttotal: 557ms\tremaining: 20.9s\n",
            "26:\tlearn: 0.5190119\ttotal: 576ms\tremaining: 20.8s\n",
            "27:\tlearn: 0.5174418\ttotal: 597ms\tremaining: 20.7s\n",
            "28:\tlearn: 0.5148580\ttotal: 616ms\tremaining: 20.6s\n",
            "29:\tlearn: 0.5120663\ttotal: 644ms\tremaining: 20.8s\n",
            "30:\tlearn: 0.5099091\ttotal: 683ms\tremaining: 21.4s\n",
            "31:\tlearn: 0.5086443\ttotal: 706ms\tremaining: 21.4s\n",
            "32:\tlearn: 0.5071117\ttotal: 727ms\tremaining: 21.3s\n",
            "33:\tlearn: 0.5047973\ttotal: 749ms\tremaining: 21.3s\n",
            "34:\tlearn: 0.5030209\ttotal: 772ms\tremaining: 21.3s\n",
            "35:\tlearn: 0.5000405\ttotal: 795ms\tremaining: 21.3s\n",
            "36:\tlearn: 0.4987039\ttotal: 814ms\tremaining: 21.2s\n",
            "37:\tlearn: 0.4976346\ttotal: 838ms\tremaining: 21.2s\n",
            "38:\tlearn: 0.4966183\ttotal: 859ms\tremaining: 21.2s\n",
            "39:\tlearn: 0.4946466\ttotal: 885ms\tremaining: 21.2s\n",
            "40:\tlearn: 0.4925966\ttotal: 913ms\tremaining: 21.4s\n",
            "41:\tlearn: 0.4913898\ttotal: 935ms\tremaining: 21.3s\n",
            "42:\tlearn: 0.4889052\ttotal: 957ms\tremaining: 21.3s\n",
            "43:\tlearn: 0.4865709\ttotal: 976ms\tremaining: 21.2s\n",
            "44:\tlearn: 0.4851848\ttotal: 1s\tremaining: 21.2s\n",
            "45:\tlearn: 0.4834139\ttotal: 1.02s\tremaining: 21.1s\n",
            "46:\tlearn: 0.4824939\ttotal: 1.04s\tremaining: 21.1s\n",
            "47:\tlearn: 0.4813829\ttotal: 1.06s\tremaining: 21.1s\n",
            "48:\tlearn: 0.4804844\ttotal: 1.09s\tremaining: 21.1s\n",
            "49:\tlearn: 0.4791418\ttotal: 1.11s\tremaining: 21.1s\n",
            "50:\tlearn: 0.4779662\ttotal: 1.13s\tremaining: 21.1s\n",
            "51:\tlearn: 0.4770891\ttotal: 1.16s\tremaining: 21.1s\n",
            "52:\tlearn: 0.4758901\ttotal: 1.17s\tremaining: 21s\n",
            "53:\tlearn: 0.4746771\ttotal: 1.2s\tremaining: 21s\n",
            "54:\tlearn: 0.4739094\ttotal: 1.22s\tremaining: 21s\n",
            "55:\tlearn: 0.4729320\ttotal: 1.24s\tremaining: 20.9s\n",
            "56:\tlearn: 0.4720377\ttotal: 1.26s\tremaining: 20.9s\n",
            "57:\tlearn: 0.4710418\ttotal: 1.28s\tremaining: 20.8s\n",
            "58:\tlearn: 0.4691090\ttotal: 1.31s\tremaining: 20.9s\n",
            "59:\tlearn: 0.4679640\ttotal: 1.33s\tremaining: 20.8s\n",
            "60:\tlearn: 0.4670893\ttotal: 1.35s\tremaining: 20.9s\n",
            "61:\tlearn: 0.4663677\ttotal: 1.38s\tremaining: 20.9s\n",
            "62:\tlearn: 0.4655200\ttotal: 1.4s\tremaining: 20.8s\n",
            "63:\tlearn: 0.4646922\ttotal: 1.42s\tremaining: 20.8s\n",
            "64:\tlearn: 0.4638189\ttotal: 1.44s\tremaining: 20.7s\n",
            "65:\tlearn: 0.4631020\ttotal: 1.46s\tremaining: 20.7s\n",
            "66:\tlearn: 0.4627186\ttotal: 1.48s\tremaining: 20.6s\n",
            "67:\tlearn: 0.4619904\ttotal: 1.51s\tremaining: 20.7s\n",
            "68:\tlearn: 0.4615095\ttotal: 1.53s\tremaining: 20.7s\n",
            "69:\tlearn: 0.4607077\ttotal: 1.55s\tremaining: 20.7s\n",
            "70:\tlearn: 0.4597292\ttotal: 1.58s\tremaining: 20.6s\n",
            "71:\tlearn: 0.4590348\ttotal: 1.6s\tremaining: 20.6s\n",
            "72:\tlearn: 0.4584519\ttotal: 1.62s\tremaining: 20.6s\n",
            "73:\tlearn: 0.4527643\ttotal: 1.64s\tremaining: 20.5s\n",
            "74:\tlearn: 0.4524578\ttotal: 1.67s\tremaining: 20.6s\n",
            "75:\tlearn: 0.4518936\ttotal: 1.69s\tremaining: 20.6s\n",
            "76:\tlearn: 0.4513580\ttotal: 1.73s\tremaining: 20.7s\n",
            "77:\tlearn: 0.4508427\ttotal: 1.75s\tremaining: 20.7s\n",
            "78:\tlearn: 0.4502604\ttotal: 1.77s\tremaining: 20.6s\n",
            "79:\tlearn: 0.4495909\ttotal: 1.79s\tremaining: 20.6s\n",
            "80:\tlearn: 0.4491566\ttotal: 1.81s\tremaining: 20.6s\n",
            "81:\tlearn: 0.4487068\ttotal: 1.83s\tremaining: 20.5s\n",
            "82:\tlearn: 0.4482521\ttotal: 1.85s\tremaining: 20.5s\n",
            "83:\tlearn: 0.4477420\ttotal: 1.87s\tremaining: 20.4s\n",
            "84:\tlearn: 0.4471980\ttotal: 1.9s\tremaining: 20.4s\n",
            "85:\tlearn: 0.4464189\ttotal: 1.92s\tremaining: 20.4s\n",
            "86:\tlearn: 0.4458066\ttotal: 1.95s\tremaining: 20.5s\n",
            "87:\tlearn: 0.4453484\ttotal: 1.97s\tremaining: 20.5s\n",
            "88:\tlearn: 0.4447387\ttotal: 2s\tremaining: 20.4s\n",
            "89:\tlearn: 0.4441947\ttotal: 2.02s\tremaining: 20.4s\n",
            "90:\tlearn: 0.4437784\ttotal: 2.04s\tremaining: 20.4s\n",
            "91:\tlearn: 0.4430634\ttotal: 2.06s\tremaining: 20.3s\n",
            "92:\tlearn: 0.4426717\ttotal: 2.08s\tremaining: 20.3s\n",
            "93:\tlearn: 0.4421777\ttotal: 2.1s\tremaining: 20.3s\n",
            "94:\tlearn: 0.4415834\ttotal: 2.12s\tremaining: 20.2s\n",
            "95:\tlearn: 0.4411371\ttotal: 2.14s\tremaining: 20.2s\n",
            "96:\tlearn: 0.4406801\ttotal: 2.17s\tremaining: 20.2s\n",
            "97:\tlearn: 0.4400732\ttotal: 2.19s\tremaining: 20.2s\n",
            "98:\tlearn: 0.4395575\ttotal: 2.22s\tremaining: 20.2s\n",
            "99:\tlearn: 0.4390851\ttotal: 2.24s\tremaining: 20.1s\n",
            "100:\tlearn: 0.4387001\ttotal: 2.25s\tremaining: 20.1s\n",
            "101:\tlearn: 0.4383310\ttotal: 2.28s\tremaining: 20.1s\n",
            "102:\tlearn: 0.4379399\ttotal: 2.3s\tremaining: 20s\n",
            "103:\tlearn: 0.4375062\ttotal: 2.32s\tremaining: 20s\n",
            "104:\tlearn: 0.4371004\ttotal: 2.34s\tremaining: 20s\n",
            "105:\tlearn: 0.4367080\ttotal: 2.36s\tremaining: 19.9s\n",
            "106:\tlearn: 0.4363316\ttotal: 2.4s\tremaining: 20s\n",
            "107:\tlearn: 0.4359590\ttotal: 2.42s\tremaining: 20s\n",
            "108:\tlearn: 0.4355826\ttotal: 2.44s\tremaining: 19.9s\n",
            "109:\tlearn: 0.4351722\ttotal: 2.46s\tremaining: 19.9s\n",
            "110:\tlearn: 0.4346509\ttotal: 2.48s\tremaining: 19.9s\n",
            "111:\tlearn: 0.4342568\ttotal: 2.5s\tremaining: 19.8s\n",
            "112:\tlearn: 0.4338289\ttotal: 2.53s\tremaining: 19.8s\n",
            "113:\tlearn: 0.4334125\ttotal: 2.54s\tremaining: 19.8s\n",
            "114:\tlearn: 0.4329045\ttotal: 2.57s\tremaining: 19.8s\n",
            "115:\tlearn: 0.4324884\ttotal: 2.59s\tremaining: 19.7s\n",
            "116:\tlearn: 0.4320402\ttotal: 2.62s\tremaining: 19.7s\n",
            "117:\tlearn: 0.4317209\ttotal: 2.64s\tremaining: 19.7s\n",
            "118:\tlearn: 0.4313084\ttotal: 2.66s\tremaining: 19.7s\n",
            "119:\tlearn: 0.4310158\ttotal: 2.69s\tremaining: 19.8s\n",
            "120:\tlearn: 0.4305252\ttotal: 2.73s\tremaining: 19.9s\n",
            "121:\tlearn: 0.4300710\ttotal: 2.76s\tremaining: 19.9s\n",
            "122:\tlearn: 0.4295899\ttotal: 2.78s\tremaining: 19.8s\n",
            "123:\tlearn: 0.4290972\ttotal: 2.8s\tremaining: 19.8s\n",
            "124:\tlearn: 0.4286118\ttotal: 2.83s\tremaining: 19.8s\n",
            "125:\tlearn: 0.4282887\ttotal: 2.85s\tremaining: 19.8s\n",
            "126:\tlearn: 0.4278202\ttotal: 2.88s\tremaining: 19.8s\n",
            "127:\tlearn: 0.4273459\ttotal: 2.9s\tremaining: 19.7s\n",
            "128:\tlearn: 0.4269218\ttotal: 2.92s\tremaining: 19.7s\n",
            "129:\tlearn: 0.4264715\ttotal: 2.94s\tremaining: 19.7s\n",
            "130:\tlearn: 0.4262205\ttotal: 2.97s\tremaining: 19.7s\n",
            "131:\tlearn: 0.4258765\ttotal: 2.99s\tremaining: 19.6s\n",
            "132:\tlearn: 0.4255056\ttotal: 3.01s\tremaining: 19.6s\n",
            "133:\tlearn: 0.4251983\ttotal: 3.03s\tremaining: 19.6s\n",
            "134:\tlearn: 0.4247051\ttotal: 3.05s\tremaining: 19.6s\n",
            "135:\tlearn: 0.4244411\ttotal: 3.08s\tremaining: 19.5s\n",
            "136:\tlearn: 0.4239371\ttotal: 3.09s\tremaining: 19.5s\n",
            "137:\tlearn: 0.4234941\ttotal: 3.12s\tremaining: 19.5s\n",
            "138:\tlearn: 0.4230913\ttotal: 3.13s\tremaining: 19.4s\n",
            "139:\tlearn: 0.4227291\ttotal: 3.16s\tremaining: 19.4s\n",
            "140:\tlearn: 0.4224289\ttotal: 3.18s\tremaining: 19.4s\n",
            "141:\tlearn: 0.4220186\ttotal: 3.2s\tremaining: 19.3s\n",
            "142:\tlearn: 0.4216692\ttotal: 3.22s\tremaining: 19.3s\n",
            "143:\tlearn: 0.4212831\ttotal: 3.25s\tremaining: 19.3s\n",
            "144:\tlearn: 0.4209132\ttotal: 3.27s\tremaining: 19.3s\n",
            "145:\tlearn: 0.4205973\ttotal: 3.29s\tremaining: 19.2s\n",
            "146:\tlearn: 0.4202777\ttotal: 3.31s\tremaining: 19.2s\n",
            "147:\tlearn: 0.4198900\ttotal: 3.33s\tremaining: 19.2s\n",
            "148:\tlearn: 0.4196810\ttotal: 3.35s\tremaining: 19.1s\n",
            "149:\tlearn: 0.4193050\ttotal: 3.37s\tremaining: 19.1s\n",
            "150:\tlearn: 0.4189745\ttotal: 3.39s\tremaining: 19.1s\n",
            "151:\tlearn: 0.4186177\ttotal: 3.41s\tremaining: 19s\n",
            "152:\tlearn: 0.4183656\ttotal: 3.43s\tremaining: 19s\n",
            "153:\tlearn: 0.4179681\ttotal: 3.46s\tremaining: 19s\n",
            "154:\tlearn: 0.4175572\ttotal: 3.49s\tremaining: 19s\n",
            "155:\tlearn: 0.4172754\ttotal: 3.51s\tremaining: 19s\n",
            "156:\tlearn: 0.4169836\ttotal: 3.53s\tremaining: 19s\n",
            "157:\tlearn: 0.4168120\ttotal: 3.55s\tremaining: 18.9s\n",
            "158:\tlearn: 0.4165067\ttotal: 3.57s\tremaining: 18.9s\n",
            "159:\tlearn: 0.4160482\ttotal: 3.59s\tremaining: 18.9s\n",
            "160:\tlearn: 0.4157823\ttotal: 3.62s\tremaining: 18.8s\n",
            "161:\tlearn: 0.4154505\ttotal: 3.63s\tremaining: 18.8s\n",
            "162:\tlearn: 0.4151046\ttotal: 3.66s\tremaining: 18.8s\n",
            "163:\tlearn: 0.4148292\ttotal: 3.69s\tremaining: 18.8s\n",
            "164:\tlearn: 0.4143662\ttotal: 3.71s\tremaining: 18.8s\n",
            "165:\tlearn: 0.4141011\ttotal: 3.75s\tremaining: 18.8s\n",
            "166:\tlearn: 0.4137799\ttotal: 3.77s\tremaining: 18.8s\n",
            "167:\tlearn: 0.4132570\ttotal: 3.79s\tremaining: 18.8s\n",
            "168:\tlearn: 0.4129342\ttotal: 3.81s\tremaining: 18.8s\n",
            "169:\tlearn: 0.4126962\ttotal: 3.84s\tremaining: 18.7s\n",
            "170:\tlearn: 0.4123518\ttotal: 3.86s\tremaining: 18.7s\n",
            "171:\tlearn: 0.4118910\ttotal: 3.88s\tremaining: 18.7s\n",
            "172:\tlearn: 0.4113479\ttotal: 3.91s\tremaining: 18.7s\n",
            "173:\tlearn: 0.4109375\ttotal: 3.94s\tremaining: 18.7s\n",
            "174:\tlearn: 0.4106395\ttotal: 3.96s\tremaining: 18.7s\n",
            "175:\tlearn: 0.4104274\ttotal: 3.98s\tremaining: 18.6s\n",
            "176:\tlearn: 0.4100249\ttotal: 4s\tremaining: 18.6s\n",
            "177:\tlearn: 0.4095469\ttotal: 4.02s\tremaining: 18.6s\n",
            "178:\tlearn: 0.4092805\ttotal: 4.04s\tremaining: 18.5s\n",
            "179:\tlearn: 0.4089840\ttotal: 4.07s\tremaining: 18.5s\n",
            "180:\tlearn: 0.4085676\ttotal: 4.08s\tremaining: 18.5s\n",
            "181:\tlearn: 0.4081206\ttotal: 4.11s\tremaining: 18.5s\n",
            "182:\tlearn: 0.4077840\ttotal: 4.13s\tremaining: 18.5s\n",
            "183:\tlearn: 0.4075262\ttotal: 4.16s\tremaining: 18.4s\n",
            "184:\tlearn: 0.4071891\ttotal: 4.18s\tremaining: 18.4s\n",
            "185:\tlearn: 0.4068340\ttotal: 4.2s\tremaining: 18.4s\n",
            "186:\tlearn: 0.4066137\ttotal: 4.22s\tremaining: 18.3s\n",
            "187:\tlearn: 0.4063295\ttotal: 4.24s\tremaining: 18.3s\n",
            "188:\tlearn: 0.4060078\ttotal: 4.26s\tremaining: 18.3s\n",
            "189:\tlearn: 0.4057027\ttotal: 4.29s\tremaining: 18.3s\n",
            "190:\tlearn: 0.4054137\ttotal: 4.31s\tremaining: 18.3s\n",
            "191:\tlearn: 0.4052068\ttotal: 4.33s\tremaining: 18.2s\n",
            "192:\tlearn: 0.4048529\ttotal: 4.36s\tremaining: 18.2s\n",
            "193:\tlearn: 0.4045888\ttotal: 4.38s\tremaining: 18.2s\n",
            "194:\tlearn: 0.4044505\ttotal: 4.4s\tremaining: 18.2s\n",
            "195:\tlearn: 0.4041391\ttotal: 4.42s\tremaining: 18.1s\n",
            "196:\tlearn: 0.4037397\ttotal: 4.45s\tremaining: 18.1s\n",
            "197:\tlearn: 0.4034389\ttotal: 4.46s\tremaining: 18.1s\n",
            "198:\tlearn: 0.4029998\ttotal: 4.49s\tremaining: 18.1s\n",
            "199:\tlearn: 0.4026864\ttotal: 4.51s\tremaining: 18s\n",
            "200:\tlearn: 0.4024489\ttotal: 4.53s\tremaining: 18s\n",
            "201:\tlearn: 0.4021371\ttotal: 4.56s\tremaining: 18s\n",
            "202:\tlearn: 0.4018714\ttotal: 4.58s\tremaining: 18s\n",
            "203:\tlearn: 0.4015951\ttotal: 4.6s\tremaining: 18s\n",
            "204:\tlearn: 0.4011754\ttotal: 4.63s\tremaining: 17.9s\n",
            "205:\tlearn: 0.4007848\ttotal: 4.65s\tremaining: 17.9s\n",
            "206:\tlearn: 0.4005526\ttotal: 4.67s\tremaining: 17.9s\n",
            "207:\tlearn: 0.4003185\ttotal: 4.69s\tremaining: 17.9s\n",
            "208:\tlearn: 0.4000686\ttotal: 4.71s\tremaining: 17.8s\n",
            "209:\tlearn: 0.3998965\ttotal: 4.74s\tremaining: 17.8s\n",
            "210:\tlearn: 0.3995278\ttotal: 4.77s\tremaining: 17.8s\n",
            "211:\tlearn: 0.3993027\ttotal: 4.8s\tremaining: 17.8s\n",
            "212:\tlearn: 0.3990706\ttotal: 4.82s\tremaining: 17.8s\n",
            "213:\tlearn: 0.3987099\ttotal: 4.84s\tremaining: 17.8s\n",
            "214:\tlearn: 0.3983877\ttotal: 4.86s\tremaining: 17.8s\n",
            "215:\tlearn: 0.3981140\ttotal: 4.88s\tremaining: 17.7s\n",
            "216:\tlearn: 0.3977459\ttotal: 4.91s\tremaining: 17.7s\n",
            "217:\tlearn: 0.3974482\ttotal: 4.93s\tremaining: 17.7s\n",
            "218:\tlearn: 0.3971932\ttotal: 4.95s\tremaining: 17.7s\n",
            "219:\tlearn: 0.3967604\ttotal: 4.97s\tremaining: 17.6s\n",
            "220:\tlearn: 0.3965040\ttotal: 5s\tremaining: 17.6s\n",
            "221:\tlearn: 0.3962374\ttotal: 5.02s\tremaining: 17.6s\n",
            "222:\tlearn: 0.3960171\ttotal: 5.04s\tremaining: 17.6s\n",
            "223:\tlearn: 0.3957197\ttotal: 5.06s\tremaining: 17.5s\n",
            "224:\tlearn: 0.3953929\ttotal: 5.08s\tremaining: 17.5s\n",
            "225:\tlearn: 0.3950960\ttotal: 5.11s\tremaining: 17.5s\n",
            "226:\tlearn: 0.3947514\ttotal: 5.13s\tremaining: 17.5s\n",
            "227:\tlearn: 0.3943554\ttotal: 5.15s\tremaining: 17.4s\n",
            "228:\tlearn: 0.3941043\ttotal: 5.17s\tremaining: 17.4s\n",
            "229:\tlearn: 0.3938278\ttotal: 5.2s\tremaining: 17.4s\n",
            "230:\tlearn: 0.3935825\ttotal: 5.22s\tremaining: 17.4s\n",
            "231:\tlearn: 0.3932148\ttotal: 5.24s\tremaining: 17.4s\n",
            "232:\tlearn: 0.3930214\ttotal: 5.26s\tremaining: 17.3s\n",
            "233:\tlearn: 0.3927970\ttotal: 5.29s\tremaining: 17.3s\n",
            "234:\tlearn: 0.3923438\ttotal: 5.31s\tremaining: 17.3s\n",
            "235:\tlearn: 0.3919952\ttotal: 5.33s\tremaining: 17.3s\n",
            "236:\tlearn: 0.3916837\ttotal: 5.35s\tremaining: 17.2s\n",
            "237:\tlearn: 0.3914303\ttotal: 5.37s\tremaining: 17.2s\n",
            "238:\tlearn: 0.3911004\ttotal: 5.39s\tremaining: 17.2s\n",
            "239:\tlearn: 0.3905236\ttotal: 5.42s\tremaining: 17.2s\n",
            "240:\tlearn: 0.3902687\ttotal: 5.44s\tremaining: 17.1s\n",
            "241:\tlearn: 0.3898853\ttotal: 5.46s\tremaining: 17.1s\n",
            "242:\tlearn: 0.3895503\ttotal: 5.49s\tremaining: 17.1s\n",
            "243:\tlearn: 0.3892702\ttotal: 5.51s\tremaining: 17.1s\n",
            "244:\tlearn: 0.3890031\ttotal: 5.53s\tremaining: 17s\n",
            "245:\tlearn: 0.3886255\ttotal: 5.55s\tremaining: 17s\n",
            "246:\tlearn: 0.3883701\ttotal: 5.57s\tremaining: 17s\n",
            "247:\tlearn: 0.3881413\ttotal: 5.59s\tremaining: 17s\n",
            "248:\tlearn: 0.3878818\ttotal: 5.61s\tremaining: 16.9s\n",
            "249:\tlearn: 0.3876449\ttotal: 5.64s\tremaining: 16.9s\n",
            "250:\tlearn: 0.3873324\ttotal: 5.67s\tremaining: 16.9s\n",
            "251:\tlearn: 0.3870764\ttotal: 5.69s\tremaining: 16.9s\n",
            "252:\tlearn: 0.3867980\ttotal: 5.71s\tremaining: 16.9s\n",
            "253:\tlearn: 0.3864193\ttotal: 5.73s\tremaining: 16.8s\n",
            "254:\tlearn: 0.3861496\ttotal: 5.76s\tremaining: 16.8s\n",
            "255:\tlearn: 0.3859111\ttotal: 5.78s\tremaining: 16.8s\n",
            "256:\tlearn: 0.3856069\ttotal: 5.8s\tremaining: 16.8s\n",
            "257:\tlearn: 0.3853627\ttotal: 5.83s\tremaining: 16.8s\n",
            "258:\tlearn: 0.3850566\ttotal: 5.85s\tremaining: 16.7s\n",
            "259:\tlearn: 0.3846922\ttotal: 5.88s\tremaining: 16.7s\n",
            "260:\tlearn: 0.3844118\ttotal: 5.9s\tremaining: 16.7s\n",
            "261:\tlearn: 0.3840988\ttotal: 5.92s\tremaining: 16.7s\n",
            "262:\tlearn: 0.3837993\ttotal: 5.94s\tremaining: 16.6s\n",
            "263:\tlearn: 0.3834041\ttotal: 5.96s\tremaining: 16.6s\n",
            "264:\tlearn: 0.3831684\ttotal: 5.98s\tremaining: 16.6s\n",
            "265:\tlearn: 0.3829407\ttotal: 6s\tremaining: 16.5s\n",
            "266:\tlearn: 0.3826939\ttotal: 6.02s\tremaining: 16.5s\n",
            "267:\tlearn: 0.3825148\ttotal: 6.04s\tremaining: 16.5s\n",
            "268:\tlearn: 0.3821240\ttotal: 6.07s\tremaining: 16.5s\n",
            "269:\tlearn: 0.3818676\ttotal: 6.09s\tremaining: 16.5s\n",
            "270:\tlearn: 0.3815815\ttotal: 6.11s\tremaining: 16.4s\n",
            "271:\tlearn: 0.3812356\ttotal: 6.13s\tremaining: 16.4s\n",
            "272:\tlearn: 0.3810416\ttotal: 6.15s\tremaining: 16.4s\n",
            "273:\tlearn: 0.3808300\ttotal: 6.17s\tremaining: 16.4s\n",
            "274:\tlearn: 0.3806316\ttotal: 6.19s\tremaining: 16.3s\n",
            "275:\tlearn: 0.3803101\ttotal: 6.21s\tremaining: 16.3s\n",
            "276:\tlearn: 0.3799117\ttotal: 6.23s\tremaining: 16.3s\n",
            "277:\tlearn: 0.3796415\ttotal: 6.26s\tremaining: 16.2s\n",
            "278:\tlearn: 0.3793023\ttotal: 6.28s\tremaining: 16.2s\n",
            "279:\tlearn: 0.3789756\ttotal: 6.3s\tremaining: 16.2s\n",
            "280:\tlearn: 0.3787442\ttotal: 6.32s\tremaining: 16.2s\n",
            "281:\tlearn: 0.3784945\ttotal: 6.34s\tremaining: 16.2s\n",
            "282:\tlearn: 0.3781709\ttotal: 6.36s\tremaining: 16.1s\n",
            "283:\tlearn: 0.3779181\ttotal: 6.39s\tremaining: 16.1s\n",
            "284:\tlearn: 0.3776670\ttotal: 6.41s\tremaining: 16.1s\n",
            "285:\tlearn: 0.3774264\ttotal: 6.43s\tremaining: 16.1s\n",
            "286:\tlearn: 0.3771618\ttotal: 6.46s\tremaining: 16s\n",
            "287:\tlearn: 0.3769679\ttotal: 6.48s\tremaining: 16s\n",
            "288:\tlearn: 0.3766629\ttotal: 6.51s\tremaining: 16s\n",
            "289:\tlearn: 0.3764744\ttotal: 6.53s\tremaining: 16s\n",
            "290:\tlearn: 0.3761602\ttotal: 6.54s\tremaining: 15.9s\n",
            "291:\tlearn: 0.3759250\ttotal: 6.57s\tremaining: 15.9s\n",
            "292:\tlearn: 0.3756776\ttotal: 6.59s\tremaining: 15.9s\n",
            "293:\tlearn: 0.3754649\ttotal: 6.61s\tremaining: 15.9s\n",
            "294:\tlearn: 0.3752087\ttotal: 6.63s\tremaining: 15.8s\n",
            "295:\tlearn: 0.3749850\ttotal: 6.65s\tremaining: 15.8s\n",
            "296:\tlearn: 0.3746914\ttotal: 6.67s\tremaining: 15.8s\n",
            "297:\tlearn: 0.3743841\ttotal: 6.69s\tremaining: 15.8s\n",
            "298:\tlearn: 0.3741294\ttotal: 6.72s\tremaining: 15.8s\n",
            "299:\tlearn: 0.3739632\ttotal: 6.75s\tremaining: 15.7s\n",
            "300:\tlearn: 0.3737709\ttotal: 6.78s\tremaining: 15.8s\n",
            "301:\tlearn: 0.3734759\ttotal: 6.8s\tremaining: 15.7s\n",
            "302:\tlearn: 0.3732432\ttotal: 6.83s\tremaining: 15.7s\n",
            "303:\tlearn: 0.3730287\ttotal: 6.84s\tremaining: 15.7s\n",
            "304:\tlearn: 0.3727970\ttotal: 6.87s\tremaining: 15.7s\n",
            "305:\tlearn: 0.3724631\ttotal: 6.89s\tremaining: 15.6s\n",
            "306:\tlearn: 0.3722397\ttotal: 6.91s\tremaining: 15.6s\n",
            "307:\tlearn: 0.3720692\ttotal: 6.94s\tremaining: 15.6s\n",
            "308:\tlearn: 0.3717869\ttotal: 6.96s\tremaining: 15.6s\n",
            "309:\tlearn: 0.3715984\ttotal: 6.98s\tremaining: 15.5s\n",
            "310:\tlearn: 0.3714033\ttotal: 7s\tremaining: 15.5s\n",
            "311:\tlearn: 0.3711485\ttotal: 7.03s\tremaining: 15.5s\n",
            "312:\tlearn: 0.3709618\ttotal: 7.05s\tremaining: 15.5s\n",
            "313:\tlearn: 0.3707355\ttotal: 7.07s\tremaining: 15.4s\n",
            "314:\tlearn: 0.3704483\ttotal: 7.09s\tremaining: 15.4s\n",
            "315:\tlearn: 0.3701824\ttotal: 7.12s\tremaining: 15.4s\n",
            "316:\tlearn: 0.3698061\ttotal: 7.13s\tremaining: 15.4s\n",
            "317:\tlearn: 0.3696026\ttotal: 7.16s\tremaining: 15.4s\n",
            "318:\tlearn: 0.3693324\ttotal: 7.18s\tremaining: 15.3s\n",
            "319:\tlearn: 0.3690225\ttotal: 7.2s\tremaining: 15.3s\n",
            "320:\tlearn: 0.3688023\ttotal: 7.23s\tremaining: 15.3s\n",
            "321:\tlearn: 0.3685978\ttotal: 7.25s\tremaining: 15.3s\n",
            "322:\tlearn: 0.3683757\ttotal: 7.27s\tremaining: 15.2s\n",
            "323:\tlearn: 0.3680632\ttotal: 7.29s\tremaining: 15.2s\n",
            "324:\tlearn: 0.3677716\ttotal: 7.32s\tremaining: 15.2s\n",
            "325:\tlearn: 0.3675152\ttotal: 7.34s\tremaining: 15.2s\n",
            "326:\tlearn: 0.3672247\ttotal: 7.36s\tremaining: 15.1s\n",
            "327:\tlearn: 0.3669305\ttotal: 7.39s\tremaining: 15.1s\n",
            "328:\tlearn: 0.3665726\ttotal: 7.41s\tremaining: 15.1s\n",
            "329:\tlearn: 0.3663892\ttotal: 7.43s\tremaining: 15.1s\n",
            "330:\tlearn: 0.3661992\ttotal: 7.45s\tremaining: 15.1s\n",
            "331:\tlearn: 0.3659641\ttotal: 7.47s\tremaining: 15s\n",
            "332:\tlearn: 0.3657540\ttotal: 7.49s\tremaining: 15s\n",
            "333:\tlearn: 0.3654498\ttotal: 7.51s\tremaining: 15s\n",
            "334:\tlearn: 0.3652160\ttotal: 7.53s\tremaining: 15s\n",
            "335:\tlearn: 0.3649993\ttotal: 7.56s\tremaining: 14.9s\n",
            "336:\tlearn: 0.3646567\ttotal: 7.58s\tremaining: 14.9s\n",
            "337:\tlearn: 0.3644256\ttotal: 7.61s\tremaining: 14.9s\n",
            "338:\tlearn: 0.3642167\ttotal: 7.63s\tremaining: 14.9s\n",
            "339:\tlearn: 0.3639971\ttotal: 7.65s\tremaining: 14.9s\n",
            "340:\tlearn: 0.3637382\ttotal: 7.67s\tremaining: 14.8s\n",
            "341:\tlearn: 0.3635577\ttotal: 7.69s\tremaining: 14.8s\n",
            "342:\tlearn: 0.3633328\ttotal: 7.71s\tremaining: 14.8s\n",
            "343:\tlearn: 0.3630883\ttotal: 7.74s\tremaining: 14.8s\n",
            "344:\tlearn: 0.3629552\ttotal: 7.77s\tremaining: 14.7s\n",
            "345:\tlearn: 0.3627208\ttotal: 7.8s\tremaining: 14.7s\n",
            "346:\tlearn: 0.3624849\ttotal: 7.83s\tremaining: 14.7s\n",
            "347:\tlearn: 0.3623065\ttotal: 7.85s\tremaining: 14.7s\n",
            "348:\tlearn: 0.3620813\ttotal: 7.87s\tremaining: 14.7s\n",
            "349:\tlearn: 0.3618353\ttotal: 7.89s\tremaining: 14.7s\n",
            "350:\tlearn: 0.3616322\ttotal: 7.92s\tremaining: 14.6s\n",
            "351:\tlearn: 0.3613286\ttotal: 7.93s\tremaining: 14.6s\n",
            "352:\tlearn: 0.3611335\ttotal: 7.96s\tremaining: 14.6s\n",
            "353:\tlearn: 0.3609410\ttotal: 7.98s\tremaining: 14.6s\n",
            "354:\tlearn: 0.3606971\ttotal: 8s\tremaining: 14.5s\n",
            "355:\tlearn: 0.3605288\ttotal: 8.02s\tremaining: 14.5s\n",
            "356:\tlearn: 0.3602649\ttotal: 8.05s\tremaining: 14.5s\n",
            "357:\tlearn: 0.3599552\ttotal: 8.09s\tremaining: 14.5s\n",
            "358:\tlearn: 0.3597491\ttotal: 8.13s\tremaining: 14.5s\n",
            "359:\tlearn: 0.3594451\ttotal: 8.16s\tremaining: 14.5s\n",
            "360:\tlearn: 0.3591819\ttotal: 8.2s\tremaining: 14.5s\n",
            "361:\tlearn: 0.3589315\ttotal: 8.24s\tremaining: 14.5s\n",
            "362:\tlearn: 0.3585925\ttotal: 8.29s\tremaining: 14.5s\n",
            "363:\tlearn: 0.3583594\ttotal: 8.31s\tremaining: 14.5s\n",
            "364:\tlearn: 0.3580106\ttotal: 8.34s\tremaining: 14.5s\n",
            "365:\tlearn: 0.3578677\ttotal: 8.37s\tremaining: 14.5s\n",
            "366:\tlearn: 0.3576270\ttotal: 8.41s\tremaining: 14.5s\n",
            "367:\tlearn: 0.3574325\ttotal: 8.45s\tremaining: 14.5s\n",
            "368:\tlearn: 0.3572087\ttotal: 8.49s\tremaining: 14.5s\n",
            "369:\tlearn: 0.3569675\ttotal: 8.53s\tremaining: 14.5s\n",
            "370:\tlearn: 0.3567355\ttotal: 8.57s\tremaining: 14.5s\n",
            "371:\tlearn: 0.3565112\ttotal: 8.61s\tremaining: 14.5s\n",
            "372:\tlearn: 0.3562551\ttotal: 8.65s\tremaining: 14.6s\n",
            "373:\tlearn: 0.3561334\ttotal: 8.7s\tremaining: 14.6s\n",
            "374:\tlearn: 0.3559200\ttotal: 8.74s\tremaining: 14.6s\n",
            "375:\tlearn: 0.3556876\ttotal: 8.79s\tremaining: 14.6s\n",
            "376:\tlearn: 0.3554310\ttotal: 8.84s\tremaining: 14.6s\n",
            "377:\tlearn: 0.3552412\ttotal: 8.88s\tremaining: 14.6s\n",
            "378:\tlearn: 0.3550306\ttotal: 8.93s\tremaining: 14.6s\n",
            "379:\tlearn: 0.3547666\ttotal: 8.97s\tremaining: 14.6s\n",
            "380:\tlearn: 0.3545257\ttotal: 9.01s\tremaining: 14.6s\n",
            "381:\tlearn: 0.3543891\ttotal: 9.06s\tremaining: 14.7s\n",
            "382:\tlearn: 0.3541972\ttotal: 9.1s\tremaining: 14.7s\n",
            "383:\tlearn: 0.3539337\ttotal: 9.14s\tremaining: 14.7s\n",
            "384:\tlearn: 0.3536184\ttotal: 9.19s\tremaining: 14.7s\n",
            "385:\tlearn: 0.3533734\ttotal: 9.23s\tremaining: 14.7s\n",
            "386:\tlearn: 0.3531414\ttotal: 9.28s\tremaining: 14.7s\n",
            "387:\tlearn: 0.3529437\ttotal: 9.32s\tremaining: 14.7s\n",
            "388:\tlearn: 0.3527058\ttotal: 9.37s\tremaining: 14.7s\n",
            "389:\tlearn: 0.3524218\ttotal: 9.41s\tremaining: 14.7s\n",
            "390:\tlearn: 0.3521434\ttotal: 9.46s\tremaining: 14.7s\n",
            "391:\tlearn: 0.3519323\ttotal: 9.49s\tremaining: 14.7s\n",
            "392:\tlearn: 0.3517093\ttotal: 9.53s\tremaining: 14.7s\n",
            "393:\tlearn: 0.3515286\ttotal: 9.57s\tremaining: 14.7s\n",
            "394:\tlearn: 0.3513010\ttotal: 9.62s\tremaining: 14.7s\n",
            "395:\tlearn: 0.3511685\ttotal: 9.64s\tremaining: 14.7s\n",
            "396:\tlearn: 0.3507914\ttotal: 9.67s\tremaining: 14.7s\n",
            "397:\tlearn: 0.3506060\ttotal: 9.7s\tremaining: 14.7s\n",
            "398:\tlearn: 0.3503505\ttotal: 9.73s\tremaining: 14.7s\n",
            "399:\tlearn: 0.3501433\ttotal: 9.77s\tremaining: 14.7s\n",
            "400:\tlearn: 0.3498923\ttotal: 9.83s\tremaining: 14.7s\n",
            "401:\tlearn: 0.3497275\ttotal: 9.89s\tremaining: 14.7s\n",
            "402:\tlearn: 0.3495504\ttotal: 9.94s\tremaining: 14.7s\n",
            "403:\tlearn: 0.3493972\ttotal: 9.98s\tremaining: 14.7s\n",
            "404:\tlearn: 0.3491811\ttotal: 10s\tremaining: 14.7s\n",
            "405:\tlearn: 0.3490127\ttotal: 10.1s\tremaining: 14.7s\n",
            "406:\tlearn: 0.3488128\ttotal: 10.1s\tremaining: 14.7s\n",
            "407:\tlearn: 0.3485014\ttotal: 10.2s\tremaining: 14.7s\n",
            "408:\tlearn: 0.3483001\ttotal: 10.2s\tremaining: 14.8s\n",
            "409:\tlearn: 0.3480818\ttotal: 10.3s\tremaining: 14.8s\n",
            "410:\tlearn: 0.3479168\ttotal: 10.3s\tremaining: 14.8s\n",
            "411:\tlearn: 0.3476517\ttotal: 10.3s\tremaining: 14.8s\n",
            "412:\tlearn: 0.3474727\ttotal: 10.4s\tremaining: 14.8s\n",
            "413:\tlearn: 0.3473094\ttotal: 10.4s\tremaining: 14.8s\n",
            "414:\tlearn: 0.3471522\ttotal: 10.5s\tremaining: 14.8s\n",
            "415:\tlearn: 0.3470175\ttotal: 10.5s\tremaining: 14.7s\n",
            "416:\tlearn: 0.3468052\ttotal: 10.5s\tremaining: 14.7s\n",
            "417:\tlearn: 0.3466076\ttotal: 10.6s\tremaining: 14.7s\n",
            "418:\tlearn: 0.3463465\ttotal: 10.6s\tremaining: 14.7s\n",
            "419:\tlearn: 0.3460511\ttotal: 10.7s\tremaining: 14.7s\n",
            "420:\tlearn: 0.3458754\ttotal: 10.7s\tremaining: 14.7s\n",
            "421:\tlearn: 0.3456175\ttotal: 10.8s\tremaining: 14.7s\n",
            "422:\tlearn: 0.3454466\ttotal: 10.8s\tremaining: 14.7s\n",
            "423:\tlearn: 0.3452941\ttotal: 10.8s\tremaining: 14.7s\n",
            "424:\tlearn: 0.3450905\ttotal: 10.9s\tremaining: 14.7s\n",
            "425:\tlearn: 0.3449244\ttotal: 10.9s\tremaining: 14.7s\n",
            "426:\tlearn: 0.3446771\ttotal: 11s\tremaining: 14.7s\n",
            "427:\tlearn: 0.3445357\ttotal: 11s\tremaining: 14.7s\n",
            "428:\tlearn: 0.3442863\ttotal: 11.1s\tremaining: 14.7s\n",
            "429:\tlearn: 0.3440809\ttotal: 11.1s\tremaining: 14.7s\n",
            "430:\tlearn: 0.3438674\ttotal: 11.2s\tremaining: 14.7s\n",
            "431:\tlearn: 0.3436870\ttotal: 11.2s\tremaining: 14.7s\n",
            "432:\tlearn: 0.3433951\ttotal: 11.2s\tremaining: 14.7s\n",
            "433:\tlearn: 0.3432344\ttotal: 11.3s\tremaining: 14.7s\n",
            "434:\tlearn: 0.3430181\ttotal: 11.3s\tremaining: 14.7s\n",
            "435:\tlearn: 0.3426279\ttotal: 11.3s\tremaining: 14.7s\n",
            "436:\tlearn: 0.3424243\ttotal: 11.4s\tremaining: 14.6s\n",
            "437:\tlearn: 0.3422695\ttotal: 11.4s\tremaining: 14.6s\n",
            "438:\tlearn: 0.3420433\ttotal: 11.5s\tremaining: 14.7s\n",
            "439:\tlearn: 0.3418972\ttotal: 11.5s\tremaining: 14.6s\n",
            "440:\tlearn: 0.3416354\ttotal: 11.6s\tremaining: 14.6s\n",
            "441:\tlearn: 0.3413664\ttotal: 11.6s\tremaining: 14.6s\n",
            "442:\tlearn: 0.3412400\ttotal: 11.6s\tremaining: 14.6s\n",
            "443:\tlearn: 0.3410315\ttotal: 11.7s\tremaining: 14.6s\n",
            "444:\tlearn: 0.3408687\ttotal: 11.7s\tremaining: 14.6s\n",
            "445:\tlearn: 0.3406518\ttotal: 11.8s\tremaining: 14.6s\n",
            "446:\tlearn: 0.3404747\ttotal: 11.8s\tremaining: 14.6s\n",
            "447:\tlearn: 0.3401971\ttotal: 11.8s\tremaining: 14.6s\n",
            "448:\tlearn: 0.3400559\ttotal: 11.8s\tremaining: 14.5s\n",
            "449:\tlearn: 0.3398378\ttotal: 11.9s\tremaining: 14.5s\n",
            "450:\tlearn: 0.3396391\ttotal: 11.9s\tremaining: 14.5s\n",
            "451:\tlearn: 0.3394585\ttotal: 11.9s\tremaining: 14.4s\n",
            "452:\tlearn: 0.3393841\ttotal: 11.9s\tremaining: 14.4s\n",
            "453:\tlearn: 0.3391664\ttotal: 12s\tremaining: 14.4s\n",
            "454:\tlearn: 0.3389843\ttotal: 12s\tremaining: 14.4s\n",
            "455:\tlearn: 0.3388122\ttotal: 12s\tremaining: 14.3s\n",
            "456:\tlearn: 0.3386072\ttotal: 12s\tremaining: 14.3s\n",
            "457:\tlearn: 0.3383784\ttotal: 12s\tremaining: 14.3s\n",
            "458:\tlearn: 0.3381343\ttotal: 12.1s\tremaining: 14.2s\n",
            "459:\tlearn: 0.3379308\ttotal: 12.1s\tremaining: 14.2s\n",
            "460:\tlearn: 0.3378442\ttotal: 12.1s\tremaining: 14.2s\n",
            "461:\tlearn: 0.3376240\ttotal: 12.1s\tremaining: 14.1s\n",
            "462:\tlearn: 0.3374635\ttotal: 12.2s\tremaining: 14.1s\n",
            "463:\tlearn: 0.3370582\ttotal: 12.2s\tremaining: 14.1s\n",
            "464:\tlearn: 0.3368179\ttotal: 12.2s\tremaining: 14s\n",
            "465:\tlearn: 0.3366513\ttotal: 12.2s\tremaining: 14s\n",
            "466:\tlearn: 0.3364353\ttotal: 12.2s\tremaining: 14s\n",
            "467:\tlearn: 0.3361816\ttotal: 12.3s\tremaining: 13.9s\n",
            "468:\tlearn: 0.3359768\ttotal: 12.3s\tremaining: 13.9s\n",
            "469:\tlearn: 0.3357451\ttotal: 12.3s\tremaining: 13.9s\n",
            "470:\tlearn: 0.3355379\ttotal: 12.3s\tremaining: 13.9s\n",
            "471:\tlearn: 0.3353749\ttotal: 12.4s\tremaining: 13.8s\n",
            "472:\tlearn: 0.3352236\ttotal: 12.4s\tremaining: 13.8s\n",
            "473:\tlearn: 0.3350745\ttotal: 12.4s\tremaining: 13.8s\n",
            "474:\tlearn: 0.3348895\ttotal: 12.4s\tremaining: 13.7s\n",
            "475:\tlearn: 0.3347180\ttotal: 12.4s\tremaining: 13.7s\n",
            "476:\tlearn: 0.3344776\ttotal: 12.5s\tremaining: 13.7s\n",
            "477:\tlearn: 0.3342939\ttotal: 12.5s\tremaining: 13.6s\n",
            "478:\tlearn: 0.3341095\ttotal: 12.5s\tremaining: 13.6s\n",
            "479:\tlearn: 0.3339569\ttotal: 12.5s\tremaining: 13.6s\n",
            "480:\tlearn: 0.3336878\ttotal: 12.6s\tremaining: 13.5s\n",
            "481:\tlearn: 0.3334485\ttotal: 12.6s\tremaining: 13.5s\n",
            "482:\tlearn: 0.3333420\ttotal: 12.6s\tremaining: 13.5s\n",
            "483:\tlearn: 0.3331874\ttotal: 12.6s\tremaining: 13.4s\n",
            "484:\tlearn: 0.3329551\ttotal: 12.6s\tremaining: 13.4s\n",
            "485:\tlearn: 0.3328283\ttotal: 12.7s\tremaining: 13.4s\n",
            "486:\tlearn: 0.3326268\ttotal: 12.7s\tremaining: 13.4s\n",
            "487:\tlearn: 0.3324410\ttotal: 12.7s\tremaining: 13.3s\n",
            "488:\tlearn: 0.3321627\ttotal: 12.7s\tremaining: 13.3s\n",
            "489:\tlearn: 0.3319894\ttotal: 12.7s\tremaining: 13.3s\n",
            "490:\tlearn: 0.3317854\ttotal: 12.8s\tremaining: 13.2s\n",
            "491:\tlearn: 0.3315907\ttotal: 12.8s\tremaining: 13.2s\n",
            "492:\tlearn: 0.3314979\ttotal: 12.8s\tremaining: 13.2s\n",
            "493:\tlearn: 0.3312810\ttotal: 12.8s\tremaining: 13.1s\n",
            "494:\tlearn: 0.3310186\ttotal: 12.9s\tremaining: 13.1s\n",
            "495:\tlearn: 0.3308400\ttotal: 12.9s\tremaining: 13.1s\n",
            "496:\tlearn: 0.3306502\ttotal: 12.9s\tremaining: 13.1s\n",
            "497:\tlearn: 0.3304454\ttotal: 12.9s\tremaining: 13s\n",
            "498:\tlearn: 0.3302687\ttotal: 13s\tremaining: 13s\n",
            "499:\tlearn: 0.3300921\ttotal: 13s\tremaining: 13s\n",
            "500:\tlearn: 0.3298885\ttotal: 13s\tremaining: 13s\n",
            "501:\tlearn: 0.3297299\ttotal: 13s\tremaining: 12.9s\n",
            "502:\tlearn: 0.3295684\ttotal: 13.1s\tremaining: 12.9s\n",
            "503:\tlearn: 0.3293710\ttotal: 13.1s\tremaining: 12.9s\n",
            "504:\tlearn: 0.3291861\ttotal: 13.1s\tremaining: 12.8s\n",
            "505:\tlearn: 0.3290450\ttotal: 13.1s\tremaining: 12.8s\n",
            "506:\tlearn: 0.3288332\ttotal: 13.1s\tremaining: 12.8s\n",
            "507:\tlearn: 0.3285701\ttotal: 13.2s\tremaining: 12.8s\n",
            "508:\tlearn: 0.3283576\ttotal: 13.2s\tremaining: 12.7s\n",
            "509:\tlearn: 0.3281300\ttotal: 13.2s\tremaining: 12.7s\n",
            "510:\tlearn: 0.3279743\ttotal: 13.2s\tremaining: 12.7s\n",
            "511:\tlearn: 0.3278444\ttotal: 13.3s\tremaining: 12.6s\n",
            "512:\tlearn: 0.3277331\ttotal: 13.3s\tremaining: 12.6s\n",
            "513:\tlearn: 0.3275210\ttotal: 13.3s\tremaining: 12.6s\n",
            "514:\tlearn: 0.3273325\ttotal: 13.3s\tremaining: 12.6s\n",
            "515:\tlearn: 0.3270317\ttotal: 13.3s\tremaining: 12.5s\n",
            "516:\tlearn: 0.3269179\ttotal: 13.4s\tremaining: 12.5s\n",
            "517:\tlearn: 0.3268235\ttotal: 13.4s\tremaining: 12.5s\n",
            "518:\tlearn: 0.3267103\ttotal: 13.4s\tremaining: 12.4s\n",
            "519:\tlearn: 0.3264833\ttotal: 13.4s\tremaining: 12.4s\n",
            "520:\tlearn: 0.3263688\ttotal: 13.5s\tremaining: 12.4s\n",
            "521:\tlearn: 0.3261813\ttotal: 13.5s\tremaining: 12.3s\n",
            "522:\tlearn: 0.3260180\ttotal: 13.5s\tremaining: 12.3s\n",
            "523:\tlearn: 0.3258731\ttotal: 13.5s\tremaining: 12.3s\n",
            "524:\tlearn: 0.3256146\ttotal: 13.5s\tremaining: 12.3s\n",
            "525:\tlearn: 0.3253794\ttotal: 13.6s\tremaining: 12.2s\n",
            "526:\tlearn: 0.3251511\ttotal: 13.6s\tremaining: 12.2s\n",
            "527:\tlearn: 0.3250404\ttotal: 13.6s\tremaining: 12.2s\n",
            "528:\tlearn: 0.3249604\ttotal: 13.6s\tremaining: 12.2s\n",
            "529:\tlearn: 0.3247211\ttotal: 13.7s\tremaining: 12.1s\n",
            "530:\tlearn: 0.3245020\ttotal: 13.7s\tremaining: 12.1s\n",
            "531:\tlearn: 0.3243630\ttotal: 13.7s\tremaining: 12.1s\n",
            "532:\tlearn: 0.3241865\ttotal: 13.7s\tremaining: 12s\n",
            "533:\tlearn: 0.3240051\ttotal: 13.8s\tremaining: 12s\n",
            "534:\tlearn: 0.3238802\ttotal: 13.8s\tremaining: 12s\n",
            "535:\tlearn: 0.3236922\ttotal: 13.8s\tremaining: 12s\n",
            "536:\tlearn: 0.3234954\ttotal: 13.8s\tremaining: 11.9s\n",
            "537:\tlearn: 0.3233377\ttotal: 13.9s\tremaining: 11.9s\n",
            "538:\tlearn: 0.3232416\ttotal: 13.9s\tremaining: 11.9s\n",
            "539:\tlearn: 0.3230833\ttotal: 13.9s\tremaining: 11.8s\n",
            "540:\tlearn: 0.3229388\ttotal: 13.9s\tremaining: 11.8s\n",
            "541:\tlearn: 0.3228243\ttotal: 13.9s\tremaining: 11.8s\n",
            "542:\tlearn: 0.3227360\ttotal: 14s\tremaining: 11.7s\n",
            "543:\tlearn: 0.3225541\ttotal: 14s\tremaining: 11.7s\n",
            "544:\tlearn: 0.3223638\ttotal: 14s\tremaining: 11.7s\n",
            "545:\tlearn: 0.3221383\ttotal: 14s\tremaining: 11.7s\n",
            "546:\tlearn: 0.3219722\ttotal: 14.1s\tremaining: 11.6s\n",
            "547:\tlearn: 0.3218241\ttotal: 14.1s\tremaining: 11.6s\n",
            "548:\tlearn: 0.3216830\ttotal: 14.1s\tremaining: 11.6s\n",
            "549:\tlearn: 0.3214842\ttotal: 14.1s\tremaining: 11.6s\n",
            "550:\tlearn: 0.3212616\ttotal: 14.1s\tremaining: 11.5s\n",
            "551:\tlearn: 0.3211447\ttotal: 14.2s\tremaining: 11.5s\n",
            "552:\tlearn: 0.3209147\ttotal: 14.2s\tremaining: 11.5s\n",
            "553:\tlearn: 0.3207019\ttotal: 14.2s\tremaining: 11.4s\n",
            "554:\tlearn: 0.3205002\ttotal: 14.2s\tremaining: 11.4s\n",
            "555:\tlearn: 0.3203510\ttotal: 14.3s\tremaining: 11.4s\n",
            "556:\tlearn: 0.3201542\ttotal: 14.3s\tremaining: 11.4s\n",
            "557:\tlearn: 0.3200073\ttotal: 14.3s\tremaining: 11.3s\n",
            "558:\tlearn: 0.3198090\ttotal: 14.3s\tremaining: 11.3s\n",
            "559:\tlearn: 0.3196074\ttotal: 14.3s\tremaining: 11.3s\n",
            "560:\tlearn: 0.3194980\ttotal: 14.4s\tremaining: 11.2s\n",
            "561:\tlearn: 0.3192873\ttotal: 14.4s\tremaining: 11.2s\n",
            "562:\tlearn: 0.3191370\ttotal: 14.4s\tremaining: 11.2s\n",
            "563:\tlearn: 0.3189864\ttotal: 14.4s\tremaining: 11.2s\n",
            "564:\tlearn: 0.3187674\ttotal: 14.5s\tremaining: 11.1s\n",
            "565:\tlearn: 0.3186029\ttotal: 14.5s\tremaining: 11.1s\n",
            "566:\tlearn: 0.3184135\ttotal: 14.5s\tremaining: 11.1s\n",
            "567:\tlearn: 0.3182505\ttotal: 14.5s\tremaining: 11s\n",
            "568:\tlearn: 0.3180316\ttotal: 14.5s\tremaining: 11s\n",
            "569:\tlearn: 0.3178791\ttotal: 14.6s\tremaining: 11s\n",
            "570:\tlearn: 0.3177239\ttotal: 14.6s\tremaining: 11s\n",
            "571:\tlearn: 0.3174879\ttotal: 14.6s\tremaining: 10.9s\n",
            "572:\tlearn: 0.3173719\ttotal: 14.6s\tremaining: 10.9s\n",
            "573:\tlearn: 0.3172121\ttotal: 14.6s\tremaining: 10.9s\n",
            "574:\tlearn: 0.3170235\ttotal: 14.7s\tremaining: 10.8s\n",
            "575:\tlearn: 0.3168242\ttotal: 14.7s\tremaining: 10.8s\n",
            "576:\tlearn: 0.3167897\ttotal: 14.7s\tremaining: 10.8s\n",
            "577:\tlearn: 0.3166394\ttotal: 14.7s\tremaining: 10.8s\n",
            "578:\tlearn: 0.3164661\ttotal: 14.8s\tremaining: 10.7s\n",
            "579:\tlearn: 0.3162566\ttotal: 14.8s\tremaining: 10.7s\n",
            "580:\tlearn: 0.3162274\ttotal: 14.8s\tremaining: 10.7s\n",
            "581:\tlearn: 0.3160337\ttotal: 14.8s\tremaining: 10.6s\n",
            "582:\tlearn: 0.3159144\ttotal: 14.8s\tremaining: 10.6s\n",
            "583:\tlearn: 0.3157810\ttotal: 14.9s\tremaining: 10.6s\n",
            "584:\tlearn: 0.3156488\ttotal: 14.9s\tremaining: 10.6s\n",
            "585:\tlearn: 0.3153754\ttotal: 14.9s\tremaining: 10.5s\n",
            "586:\tlearn: 0.3151272\ttotal: 14.9s\tremaining: 10.5s\n",
            "587:\tlearn: 0.3149231\ttotal: 15s\tremaining: 10.5s\n",
            "588:\tlearn: 0.3147989\ttotal: 15s\tremaining: 10.5s\n",
            "589:\tlearn: 0.3147713\ttotal: 15s\tremaining: 10.4s\n",
            "590:\tlearn: 0.3146250\ttotal: 15s\tremaining: 10.4s\n",
            "591:\tlearn: 0.3144768\ttotal: 15.1s\tremaining: 10.4s\n",
            "592:\tlearn: 0.3143633\ttotal: 15.1s\tremaining: 10.4s\n",
            "593:\tlearn: 0.3141551\ttotal: 15.1s\tremaining: 10.3s\n",
            "594:\tlearn: 0.3140429\ttotal: 15.1s\tremaining: 10.3s\n",
            "595:\tlearn: 0.3139954\ttotal: 15.2s\tremaining: 10.3s\n",
            "596:\tlearn: 0.3137910\ttotal: 15.2s\tremaining: 10.2s\n",
            "597:\tlearn: 0.3136455\ttotal: 15.2s\tremaining: 10.2s\n",
            "598:\tlearn: 0.3135356\ttotal: 15.2s\tremaining: 10.2s\n",
            "599:\tlearn: 0.3132865\ttotal: 15.2s\tremaining: 10.2s\n",
            "600:\tlearn: 0.3131585\ttotal: 15.3s\tremaining: 10.1s\n",
            "601:\tlearn: 0.3131306\ttotal: 15.3s\tremaining: 10.1s\n",
            "602:\tlearn: 0.3130359\ttotal: 15.3s\tremaining: 10.1s\n",
            "603:\tlearn: 0.3129403\ttotal: 15.3s\tremaining: 10.1s\n",
            "604:\tlearn: 0.3128054\ttotal: 15.4s\tremaining: 10s\n",
            "605:\tlearn: 0.3126485\ttotal: 15.4s\tremaining: 10s\n",
            "606:\tlearn: 0.3124756\ttotal: 15.4s\tremaining: 9.97s\n",
            "607:\tlearn: 0.3122731\ttotal: 15.4s\tremaining: 9.94s\n",
            "608:\tlearn: 0.3121134\ttotal: 15.4s\tremaining: 9.91s\n",
            "609:\tlearn: 0.3119904\ttotal: 15.5s\tremaining: 9.88s\n",
            "610:\tlearn: 0.3118364\ttotal: 15.5s\tremaining: 9.86s\n",
            "611:\tlearn: 0.3116584\ttotal: 15.5s\tremaining: 9.83s\n",
            "612:\tlearn: 0.3114403\ttotal: 15.5s\tremaining: 9.8s\n",
            "613:\tlearn: 0.3112443\ttotal: 15.6s\tremaining: 9.78s\n",
            "614:\tlearn: 0.3111717\ttotal: 15.6s\tremaining: 9.75s\n",
            "615:\tlearn: 0.3109889\ttotal: 15.6s\tremaining: 9.72s\n",
            "616:\tlearn: 0.3107854\ttotal: 15.6s\tremaining: 9.7s\n",
            "617:\tlearn: 0.3106011\ttotal: 15.6s\tremaining: 9.67s\n",
            "618:\tlearn: 0.3104376\ttotal: 15.7s\tremaining: 9.64s\n",
            "619:\tlearn: 0.3102683\ttotal: 15.7s\tremaining: 9.61s\n",
            "620:\tlearn: 0.3100794\ttotal: 15.7s\tremaining: 9.58s\n",
            "621:\tlearn: 0.3099311\ttotal: 15.7s\tremaining: 9.56s\n",
            "622:\tlearn: 0.3097210\ttotal: 15.7s\tremaining: 9.53s\n",
            "623:\tlearn: 0.3095932\ttotal: 15.8s\tremaining: 9.51s\n",
            "624:\tlearn: 0.3094630\ttotal: 15.8s\tremaining: 9.48s\n",
            "625:\tlearn: 0.3092588\ttotal: 15.8s\tremaining: 9.45s\n",
            "626:\tlearn: 0.3090861\ttotal: 15.8s\tremaining: 9.42s\n",
            "627:\tlearn: 0.3089646\ttotal: 15.9s\tremaining: 9.4s\n",
            "628:\tlearn: 0.3088567\ttotal: 15.9s\tremaining: 9.37s\n",
            "629:\tlearn: 0.3086709\ttotal: 15.9s\tremaining: 9.34s\n",
            "630:\tlearn: 0.3085113\ttotal: 15.9s\tremaining: 9.31s\n",
            "631:\tlearn: 0.3083814\ttotal: 15.9s\tremaining: 9.28s\n",
            "632:\tlearn: 0.3082044\ttotal: 16s\tremaining: 9.25s\n",
            "633:\tlearn: 0.3080117\ttotal: 16s\tremaining: 9.23s\n",
            "634:\tlearn: 0.3078994\ttotal: 16s\tremaining: 9.21s\n",
            "635:\tlearn: 0.3076870\ttotal: 16.1s\tremaining: 9.19s\n",
            "636:\tlearn: 0.3075151\ttotal: 16.1s\tremaining: 9.16s\n",
            "637:\tlearn: 0.3074938\ttotal: 16.1s\tremaining: 9.13s\n",
            "638:\tlearn: 0.3073908\ttotal: 16.1s\tremaining: 9.1s\n",
            "639:\tlearn: 0.3072204\ttotal: 16.1s\tremaining: 9.08s\n",
            "640:\tlearn: 0.3070885\ttotal: 16.2s\tremaining: 9.05s\n",
            "641:\tlearn: 0.3069193\ttotal: 16.2s\tremaining: 9.02s\n",
            "642:\tlearn: 0.3067635\ttotal: 16.2s\tremaining: 8.99s\n",
            "643:\tlearn: 0.3066442\ttotal: 16.2s\tremaining: 8.97s\n",
            "644:\tlearn: 0.3065438\ttotal: 16.3s\tremaining: 8.94s\n",
            "645:\tlearn: 0.3063605\ttotal: 16.3s\tremaining: 8.92s\n",
            "646:\tlearn: 0.3062340\ttotal: 16.3s\tremaining: 8.89s\n",
            "647:\tlearn: 0.3060680\ttotal: 16.3s\tremaining: 8.86s\n",
            "648:\tlearn: 0.3058766\ttotal: 16.3s\tremaining: 8.83s\n",
            "649:\tlearn: 0.3056481\ttotal: 16.4s\tremaining: 8.81s\n",
            "650:\tlearn: 0.3055120\ttotal: 16.4s\tremaining: 8.78s\n",
            "651:\tlearn: 0.3053836\ttotal: 16.4s\tremaining: 8.75s\n",
            "652:\tlearn: 0.3052290\ttotal: 16.4s\tremaining: 8.73s\n",
            "653:\tlearn: 0.3050734\ttotal: 16.5s\tremaining: 8.7s\n",
            "654:\tlearn: 0.3049149\ttotal: 16.5s\tremaining: 8.68s\n",
            "655:\tlearn: 0.3048129\ttotal: 16.5s\tremaining: 8.65s\n",
            "656:\tlearn: 0.3046494\ttotal: 16.5s\tremaining: 8.62s\n",
            "657:\tlearn: 0.3044909\ttotal: 16.5s\tremaining: 8.6s\n",
            "658:\tlearn: 0.3042971\ttotal: 16.6s\tremaining: 8.57s\n",
            "659:\tlearn: 0.3041722\ttotal: 16.6s\tremaining: 8.54s\n",
            "660:\tlearn: 0.3039727\ttotal: 16.6s\tremaining: 8.52s\n",
            "661:\tlearn: 0.3038257\ttotal: 16.6s\tremaining: 8.49s\n",
            "662:\tlearn: 0.3036910\ttotal: 16.7s\tremaining: 8.47s\n",
            "663:\tlearn: 0.3035981\ttotal: 16.7s\tremaining: 8.44s\n",
            "664:\tlearn: 0.3034677\ttotal: 16.7s\tremaining: 8.41s\n",
            "665:\tlearn: 0.3032500\ttotal: 16.7s\tremaining: 8.39s\n",
            "666:\tlearn: 0.3031074\ttotal: 16.7s\tremaining: 8.36s\n",
            "667:\tlearn: 0.3030245\ttotal: 16.8s\tremaining: 8.34s\n",
            "668:\tlearn: 0.3028936\ttotal: 16.8s\tremaining: 8.31s\n",
            "669:\tlearn: 0.3027994\ttotal: 16.8s\tremaining: 8.28s\n",
            "670:\tlearn: 0.3026215\ttotal: 16.8s\tremaining: 8.26s\n",
            "671:\tlearn: 0.3024397\ttotal: 16.9s\tremaining: 8.23s\n",
            "672:\tlearn: 0.3022756\ttotal: 16.9s\tremaining: 8.2s\n",
            "673:\tlearn: 0.3021646\ttotal: 16.9s\tremaining: 8.18s\n",
            "674:\tlearn: 0.3019857\ttotal: 16.9s\tremaining: 8.15s\n",
            "675:\tlearn: 0.3017983\ttotal: 16.9s\tremaining: 8.12s\n",
            "676:\tlearn: 0.3016603\ttotal: 17s\tremaining: 8.1s\n",
            "677:\tlearn: 0.3014933\ttotal: 17s\tremaining: 8.07s\n",
            "678:\tlearn: 0.3013206\ttotal: 17s\tremaining: 8.05s\n",
            "679:\tlearn: 0.3010685\ttotal: 17s\tremaining: 8.02s\n",
            "680:\tlearn: 0.3009277\ttotal: 17.1s\tremaining: 8s\n",
            "681:\tlearn: 0.3008564\ttotal: 17.1s\tremaining: 7.97s\n",
            "682:\tlearn: 0.3005716\ttotal: 17.1s\tremaining: 7.95s\n",
            "683:\tlearn: 0.3004471\ttotal: 17.1s\tremaining: 7.92s\n",
            "684:\tlearn: 0.3003198\ttotal: 17.2s\tremaining: 7.89s\n",
            "685:\tlearn: 0.3001562\ttotal: 17.2s\tremaining: 7.87s\n",
            "686:\tlearn: 0.3001036\ttotal: 17.2s\tremaining: 7.84s\n",
            "687:\tlearn: 0.2998908\ttotal: 17.2s\tremaining: 7.81s\n",
            "688:\tlearn: 0.2997349\ttotal: 17.3s\tremaining: 7.79s\n",
            "689:\tlearn: 0.2996429\ttotal: 17.3s\tremaining: 7.76s\n",
            "690:\tlearn: 0.2995232\ttotal: 17.3s\tremaining: 7.73s\n",
            "691:\tlearn: 0.2993957\ttotal: 17.3s\tremaining: 7.71s\n",
            "692:\tlearn: 0.2992690\ttotal: 17.3s\tremaining: 7.68s\n",
            "693:\tlearn: 0.2991391\ttotal: 17.4s\tremaining: 7.66s\n",
            "694:\tlearn: 0.2989780\ttotal: 17.4s\tremaining: 7.63s\n",
            "695:\tlearn: 0.2988910\ttotal: 17.4s\tremaining: 7.61s\n",
            "696:\tlearn: 0.2987959\ttotal: 17.4s\tremaining: 7.58s\n",
            "697:\tlearn: 0.2986106\ttotal: 17.5s\tremaining: 7.55s\n",
            "698:\tlearn: 0.2984731\ttotal: 17.5s\tremaining: 7.52s\n",
            "699:\tlearn: 0.2983477\ttotal: 17.5s\tremaining: 7.5s\n",
            "700:\tlearn: 0.2981948\ttotal: 17.5s\tremaining: 7.47s\n",
            "701:\tlearn: 0.2981025\ttotal: 17.5s\tremaining: 7.44s\n",
            "702:\tlearn: 0.2979776\ttotal: 17.6s\tremaining: 7.42s\n",
            "703:\tlearn: 0.2978447\ttotal: 17.6s\tremaining: 7.39s\n",
            "704:\tlearn: 0.2977845\ttotal: 17.6s\tremaining: 7.37s\n",
            "705:\tlearn: 0.2976640\ttotal: 17.6s\tremaining: 7.34s\n",
            "706:\tlearn: 0.2974992\ttotal: 17.6s\tremaining: 7.31s\n",
            "707:\tlearn: 0.2973481\ttotal: 17.7s\tremaining: 7.29s\n",
            "708:\tlearn: 0.2972007\ttotal: 17.7s\tremaining: 7.26s\n",
            "709:\tlearn: 0.2970365\ttotal: 17.7s\tremaining: 7.23s\n",
            "710:\tlearn: 0.2967967\ttotal: 17.7s\tremaining: 7.21s\n",
            "711:\tlearn: 0.2967128\ttotal: 17.8s\tremaining: 7.19s\n",
            "712:\tlearn: 0.2965286\ttotal: 17.8s\tremaining: 7.16s\n",
            "713:\tlearn: 0.2964337\ttotal: 17.8s\tremaining: 7.13s\n",
            "714:\tlearn: 0.2963072\ttotal: 17.8s\tremaining: 7.11s\n",
            "715:\tlearn: 0.2962130\ttotal: 17.9s\tremaining: 7.08s\n",
            "716:\tlearn: 0.2959711\ttotal: 17.9s\tremaining: 7.05s\n",
            "717:\tlearn: 0.2957826\ttotal: 17.9s\tremaining: 7.03s\n",
            "718:\tlearn: 0.2956205\ttotal: 17.9s\tremaining: 7s\n",
            "719:\tlearn: 0.2954470\ttotal: 17.9s\tremaining: 6.97s\n",
            "720:\tlearn: 0.2953004\ttotal: 17.9s\tremaining: 6.95s\n",
            "721:\tlearn: 0.2951640\ttotal: 18s\tremaining: 6.92s\n",
            "722:\tlearn: 0.2950019\ttotal: 18s\tremaining: 6.9s\n",
            "723:\tlearn: 0.2948626\ttotal: 18s\tremaining: 6.88s\n",
            "724:\tlearn: 0.2948398\ttotal: 18.1s\tremaining: 6.85s\n",
            "725:\tlearn: 0.2946585\ttotal: 18.1s\tremaining: 6.83s\n",
            "726:\tlearn: 0.2945007\ttotal: 18.1s\tremaining: 6.8s\n",
            "727:\tlearn: 0.2943939\ttotal: 18.1s\tremaining: 6.77s\n",
            "728:\tlearn: 0.2942751\ttotal: 18.1s\tremaining: 6.75s\n",
            "729:\tlearn: 0.2941479\ttotal: 18.2s\tremaining: 6.72s\n",
            "730:\tlearn: 0.2940446\ttotal: 18.2s\tremaining: 6.7s\n",
            "731:\tlearn: 0.2938884\ttotal: 18.2s\tremaining: 6.67s\n",
            "732:\tlearn: 0.2937917\ttotal: 18.2s\tremaining: 6.64s\n",
            "733:\tlearn: 0.2936639\ttotal: 18.3s\tremaining: 6.62s\n",
            "734:\tlearn: 0.2935328\ttotal: 18.3s\tremaining: 6.59s\n",
            "735:\tlearn: 0.2933444\ttotal: 18.3s\tremaining: 6.57s\n",
            "736:\tlearn: 0.2931607\ttotal: 18.3s\tremaining: 6.54s\n",
            "737:\tlearn: 0.2929821\ttotal: 18.4s\tremaining: 6.51s\n",
            "738:\tlearn: 0.2928720\ttotal: 18.4s\tremaining: 6.49s\n",
            "739:\tlearn: 0.2926042\ttotal: 18.4s\tremaining: 6.46s\n",
            "740:\tlearn: 0.2924418\ttotal: 18.4s\tremaining: 6.44s\n",
            "741:\tlearn: 0.2923475\ttotal: 18.4s\tremaining: 6.41s\n",
            "742:\tlearn: 0.2920966\ttotal: 18.5s\tremaining: 6.39s\n",
            "743:\tlearn: 0.2918875\ttotal: 18.5s\tremaining: 6.36s\n",
            "744:\tlearn: 0.2917546\ttotal: 18.5s\tremaining: 6.33s\n",
            "745:\tlearn: 0.2916913\ttotal: 18.5s\tremaining: 6.31s\n",
            "746:\tlearn: 0.2915722\ttotal: 18.5s\tremaining: 6.28s\n",
            "747:\tlearn: 0.2914014\ttotal: 18.6s\tremaining: 6.25s\n",
            "748:\tlearn: 0.2912676\ttotal: 18.6s\tremaining: 6.23s\n",
            "749:\tlearn: 0.2911361\ttotal: 18.6s\tremaining: 6.2s\n",
            "750:\tlearn: 0.2909765\ttotal: 18.6s\tremaining: 6.18s\n",
            "751:\tlearn: 0.2907907\ttotal: 18.7s\tremaining: 6.15s\n",
            "752:\tlearn: 0.2907696\ttotal: 18.7s\tremaining: 6.13s\n",
            "753:\tlearn: 0.2906308\ttotal: 18.7s\tremaining: 6.1s\n",
            "754:\tlearn: 0.2906093\ttotal: 18.7s\tremaining: 6.08s\n",
            "755:\tlearn: 0.2904717\ttotal: 18.7s\tremaining: 6.05s\n",
            "756:\tlearn: 0.2902950\ttotal: 18.8s\tremaining: 6.02s\n",
            "757:\tlearn: 0.2902024\ttotal: 18.8s\tremaining: 6s\n",
            "758:\tlearn: 0.2900972\ttotal: 18.8s\tremaining: 5.97s\n",
            "759:\tlearn: 0.2899768\ttotal: 18.8s\tremaining: 5.95s\n",
            "760:\tlearn: 0.2897650\ttotal: 18.9s\tremaining: 5.92s\n",
            "761:\tlearn: 0.2896581\ttotal: 18.9s\tremaining: 5.9s\n",
            "762:\tlearn: 0.2894035\ttotal: 18.9s\tremaining: 5.87s\n",
            "763:\tlearn: 0.2892976\ttotal: 18.9s\tremaining: 5.84s\n",
            "764:\tlearn: 0.2891269\ttotal: 18.9s\tremaining: 5.82s\n",
            "765:\tlearn: 0.2890053\ttotal: 19s\tremaining: 5.79s\n",
            "766:\tlearn: 0.2888632\ttotal: 19s\tremaining: 5.77s\n",
            "767:\tlearn: 0.2887241\ttotal: 19s\tremaining: 5.74s\n",
            "768:\tlearn: 0.2885846\ttotal: 19s\tremaining: 5.72s\n",
            "769:\tlearn: 0.2884790\ttotal: 19.1s\tremaining: 5.7s\n",
            "770:\tlearn: 0.2883730\ttotal: 19.1s\tremaining: 5.67s\n",
            "771:\tlearn: 0.2882491\ttotal: 19.1s\tremaining: 5.65s\n",
            "772:\tlearn: 0.2881120\ttotal: 19.1s\tremaining: 5.62s\n",
            "773:\tlearn: 0.2879586\ttotal: 19.2s\tremaining: 5.59s\n",
            "774:\tlearn: 0.2878146\ttotal: 19.2s\tremaining: 5.57s\n",
            "775:\tlearn: 0.2876577\ttotal: 19.2s\tremaining: 5.54s\n",
            "776:\tlearn: 0.2875190\ttotal: 19.2s\tremaining: 5.52s\n",
            "777:\tlearn: 0.2874111\ttotal: 19.2s\tremaining: 5.49s\n",
            "778:\tlearn: 0.2873112\ttotal: 19.3s\tremaining: 5.47s\n",
            "779:\tlearn: 0.2871946\ttotal: 19.3s\tremaining: 5.44s\n",
            "780:\tlearn: 0.2870388\ttotal: 19.3s\tremaining: 5.42s\n",
            "781:\tlearn: 0.2868628\ttotal: 19.3s\tremaining: 5.39s\n",
            "782:\tlearn: 0.2867529\ttotal: 19.4s\tremaining: 5.37s\n",
            "783:\tlearn: 0.2865536\ttotal: 19.4s\tremaining: 5.34s\n",
            "784:\tlearn: 0.2864405\ttotal: 19.4s\tremaining: 5.31s\n",
            "785:\tlearn: 0.2862757\ttotal: 19.4s\tremaining: 5.29s\n",
            "786:\tlearn: 0.2862235\ttotal: 19.5s\tremaining: 5.26s\n",
            "787:\tlearn: 0.2861172\ttotal: 19.5s\tremaining: 5.24s\n",
            "788:\tlearn: 0.2859934\ttotal: 19.5s\tremaining: 5.21s\n",
            "789:\tlearn: 0.2859210\ttotal: 19.5s\tremaining: 5.19s\n",
            "790:\tlearn: 0.2858075\ttotal: 19.6s\tremaining: 5.17s\n",
            "791:\tlearn: 0.2856485\ttotal: 19.6s\tremaining: 5.14s\n",
            "792:\tlearn: 0.2855563\ttotal: 19.6s\tremaining: 5.11s\n",
            "793:\tlearn: 0.2853761\ttotal: 19.6s\tremaining: 5.09s\n",
            "794:\tlearn: 0.2851318\ttotal: 19.6s\tremaining: 5.06s\n",
            "795:\tlearn: 0.2849989\ttotal: 19.7s\tremaining: 5.04s\n",
            "796:\tlearn: 0.2848421\ttotal: 19.7s\tremaining: 5.01s\n",
            "797:\tlearn: 0.2847637\ttotal: 19.7s\tremaining: 4.99s\n",
            "798:\tlearn: 0.2846285\ttotal: 19.7s\tremaining: 4.96s\n",
            "799:\tlearn: 0.2845015\ttotal: 19.8s\tremaining: 4.94s\n",
            "800:\tlearn: 0.2844073\ttotal: 19.8s\tremaining: 4.91s\n",
            "801:\tlearn: 0.2842018\ttotal: 19.8s\tremaining: 4.89s\n",
            "802:\tlearn: 0.2840268\ttotal: 19.8s\tremaining: 4.86s\n",
            "803:\tlearn: 0.2838830\ttotal: 19.8s\tremaining: 4.84s\n",
            "804:\tlearn: 0.2837573\ttotal: 19.9s\tremaining: 4.81s\n",
            "805:\tlearn: 0.2836449\ttotal: 19.9s\tremaining: 4.78s\n",
            "806:\tlearn: 0.2835154\ttotal: 19.9s\tremaining: 4.76s\n",
            "807:\tlearn: 0.2834003\ttotal: 19.9s\tremaining: 4.74s\n",
            "808:\tlearn: 0.2832243\ttotal: 20s\tremaining: 4.71s\n",
            "809:\tlearn: 0.2830083\ttotal: 20s\tremaining: 4.68s\n",
            "810:\tlearn: 0.2828693\ttotal: 20s\tremaining: 4.66s\n",
            "811:\tlearn: 0.2828016\ttotal: 20s\tremaining: 4.63s\n",
            "812:\tlearn: 0.2827235\ttotal: 20s\tremaining: 4.61s\n",
            "813:\tlearn: 0.2825702\ttotal: 20.1s\tremaining: 4.59s\n",
            "814:\tlearn: 0.2824620\ttotal: 20.1s\tremaining: 4.56s\n",
            "815:\tlearn: 0.2822804\ttotal: 20.1s\tremaining: 4.54s\n",
            "816:\tlearn: 0.2821790\ttotal: 20.1s\tremaining: 4.51s\n",
            "817:\tlearn: 0.2820438\ttotal: 20.2s\tremaining: 4.49s\n",
            "818:\tlearn: 0.2819603\ttotal: 20.2s\tremaining: 4.46s\n",
            "819:\tlearn: 0.2817982\ttotal: 20.2s\tremaining: 4.44s\n",
            "820:\tlearn: 0.2816830\ttotal: 20.2s\tremaining: 4.41s\n",
            "821:\tlearn: 0.2815168\ttotal: 20.3s\tremaining: 4.38s\n",
            "822:\tlearn: 0.2813779\ttotal: 20.3s\tremaining: 4.36s\n",
            "823:\tlearn: 0.2812592\ttotal: 20.3s\tremaining: 4.33s\n",
            "824:\tlearn: 0.2810569\ttotal: 20.3s\tremaining: 4.31s\n",
            "825:\tlearn: 0.2808494\ttotal: 20.3s\tremaining: 4.28s\n",
            "826:\tlearn: 0.2807623\ttotal: 20.4s\tremaining: 4.26s\n",
            "827:\tlearn: 0.2806980\ttotal: 20.4s\tremaining: 4.24s\n",
            "828:\tlearn: 0.2805624\ttotal: 20.4s\tremaining: 4.21s\n",
            "829:\tlearn: 0.2804668\ttotal: 20.4s\tremaining: 4.18s\n",
            "830:\tlearn: 0.2803372\ttotal: 20.5s\tremaining: 4.16s\n",
            "831:\tlearn: 0.2801255\ttotal: 20.5s\tremaining: 4.13s\n",
            "832:\tlearn: 0.2800557\ttotal: 20.5s\tremaining: 4.11s\n",
            "833:\tlearn: 0.2799604\ttotal: 20.5s\tremaining: 4.08s\n",
            "834:\tlearn: 0.2798135\ttotal: 20.5s\tremaining: 4.06s\n",
            "835:\tlearn: 0.2796919\ttotal: 20.6s\tremaining: 4.03s\n",
            "836:\tlearn: 0.2796197\ttotal: 20.6s\tremaining: 4.01s\n",
            "837:\tlearn: 0.2795425\ttotal: 20.6s\tremaining: 3.98s\n",
            "838:\tlearn: 0.2794162\ttotal: 20.6s\tremaining: 3.96s\n",
            "839:\tlearn: 0.2792794\ttotal: 20.7s\tremaining: 3.94s\n",
            "840:\tlearn: 0.2791386\ttotal: 20.7s\tremaining: 3.91s\n",
            "841:\tlearn: 0.2790310\ttotal: 20.7s\tremaining: 3.88s\n",
            "842:\tlearn: 0.2790169\ttotal: 20.7s\tremaining: 3.86s\n",
            "843:\tlearn: 0.2789105\ttotal: 20.7s\tremaining: 3.83s\n",
            "844:\tlearn: 0.2787621\ttotal: 20.8s\tremaining: 3.81s\n",
            "845:\tlearn: 0.2785959\ttotal: 20.8s\tremaining: 3.79s\n",
            "846:\tlearn: 0.2784222\ttotal: 20.8s\tremaining: 3.76s\n",
            "847:\tlearn: 0.2782960\ttotal: 20.8s\tremaining: 3.74s\n",
            "848:\tlearn: 0.2781427\ttotal: 20.9s\tremaining: 3.71s\n",
            "849:\tlearn: 0.2780741\ttotal: 20.9s\tremaining: 3.69s\n",
            "850:\tlearn: 0.2779656\ttotal: 20.9s\tremaining: 3.66s\n",
            "851:\tlearn: 0.2778620\ttotal: 20.9s\tremaining: 3.63s\n",
            "852:\tlearn: 0.2777162\ttotal: 21s\tremaining: 3.61s\n",
            "853:\tlearn: 0.2776108\ttotal: 21s\tremaining: 3.58s\n",
            "854:\tlearn: 0.2774317\ttotal: 21s\tremaining: 3.56s\n",
            "855:\tlearn: 0.2772988\ttotal: 21s\tremaining: 3.54s\n",
            "856:\tlearn: 0.2771316\ttotal: 21s\tremaining: 3.51s\n",
            "857:\tlearn: 0.2770254\ttotal: 21.1s\tremaining: 3.49s\n",
            "858:\tlearn: 0.2768711\ttotal: 21.1s\tremaining: 3.46s\n",
            "859:\tlearn: 0.2767660\ttotal: 21.1s\tremaining: 3.44s\n",
            "860:\tlearn: 0.2766218\ttotal: 21.1s\tremaining: 3.41s\n",
            "861:\tlearn: 0.2764858\ttotal: 21.2s\tremaining: 3.39s\n",
            "862:\tlearn: 0.2763162\ttotal: 21.2s\tremaining: 3.36s\n",
            "863:\tlearn: 0.2760882\ttotal: 21.2s\tremaining: 3.34s\n",
            "864:\tlearn: 0.2758740\ttotal: 21.2s\tremaining: 3.31s\n",
            "865:\tlearn: 0.2758605\ttotal: 21.3s\tremaining: 3.29s\n",
            "866:\tlearn: 0.2757170\ttotal: 21.3s\tremaining: 3.27s\n",
            "867:\tlearn: 0.2755711\ttotal: 21.3s\tremaining: 3.24s\n",
            "868:\tlearn: 0.2754355\ttotal: 21.3s\tremaining: 3.21s\n",
            "869:\tlearn: 0.2753465\ttotal: 21.3s\tremaining: 3.19s\n",
            "870:\tlearn: 0.2752151\ttotal: 21.4s\tremaining: 3.16s\n",
            "871:\tlearn: 0.2751488\ttotal: 21.4s\tremaining: 3.14s\n",
            "872:\tlearn: 0.2750604\ttotal: 21.4s\tremaining: 3.11s\n",
            "873:\tlearn: 0.2749629\ttotal: 21.4s\tremaining: 3.09s\n",
            "874:\tlearn: 0.2748505\ttotal: 21.5s\tremaining: 3.06s\n",
            "875:\tlearn: 0.2747611\ttotal: 21.5s\tremaining: 3.04s\n",
            "876:\tlearn: 0.2746406\ttotal: 21.5s\tremaining: 3.02s\n",
            "877:\tlearn: 0.2745154\ttotal: 21.5s\tremaining: 2.99s\n",
            "878:\tlearn: 0.2744052\ttotal: 21.5s\tremaining: 2.96s\n",
            "879:\tlearn: 0.2742935\ttotal: 21.6s\tremaining: 2.94s\n",
            "880:\tlearn: 0.2741723\ttotal: 21.6s\tremaining: 2.92s\n",
            "881:\tlearn: 0.2741554\ttotal: 21.6s\tremaining: 2.89s\n",
            "882:\tlearn: 0.2739957\ttotal: 21.7s\tremaining: 2.87s\n",
            "883:\tlearn: 0.2738401\ttotal: 21.7s\tremaining: 2.85s\n",
            "884:\tlearn: 0.2736933\ttotal: 21.7s\tremaining: 2.83s\n",
            "885:\tlearn: 0.2735906\ttotal: 21.8s\tremaining: 2.8s\n",
            "886:\tlearn: 0.2734791\ttotal: 21.8s\tremaining: 2.78s\n",
            "887:\tlearn: 0.2733490\ttotal: 21.9s\tremaining: 2.76s\n",
            "888:\tlearn: 0.2733355\ttotal: 21.9s\tremaining: 2.73s\n",
            "889:\tlearn: 0.2731429\ttotal: 21.9s\tremaining: 2.71s\n",
            "890:\tlearn: 0.2730443\ttotal: 22s\tremaining: 2.69s\n",
            "891:\tlearn: 0.2728342\ttotal: 22s\tremaining: 2.67s\n",
            "892:\tlearn: 0.2727410\ttotal: 22.1s\tremaining: 2.64s\n",
            "893:\tlearn: 0.2727291\ttotal: 22.1s\tremaining: 2.62s\n",
            "894:\tlearn: 0.2725745\ttotal: 22.2s\tremaining: 2.6s\n",
            "895:\tlearn: 0.2724356\ttotal: 22.2s\tremaining: 2.58s\n",
            "896:\tlearn: 0.2723196\ttotal: 22.3s\tremaining: 2.56s\n",
            "897:\tlearn: 0.2722473\ttotal: 22.3s\tremaining: 2.53s\n",
            "898:\tlearn: 0.2721478\ttotal: 22.4s\tremaining: 2.51s\n",
            "899:\tlearn: 0.2720507\ttotal: 22.4s\tremaining: 2.49s\n",
            "900:\tlearn: 0.2719659\ttotal: 22.4s\tremaining: 2.47s\n",
            "901:\tlearn: 0.2717984\ttotal: 22.5s\tremaining: 2.44s\n",
            "902:\tlearn: 0.2717860\ttotal: 22.5s\tremaining: 2.42s\n",
            "903:\tlearn: 0.2716662\ttotal: 22.6s\tremaining: 2.4s\n",
            "904:\tlearn: 0.2715769\ttotal: 22.6s\tremaining: 2.37s\n",
            "905:\tlearn: 0.2714624\ttotal: 22.7s\tremaining: 2.35s\n",
            "906:\tlearn: 0.2712501\ttotal: 22.7s\tremaining: 2.33s\n",
            "907:\tlearn: 0.2711302\ttotal: 22.7s\tremaining: 2.3s\n",
            "908:\tlearn: 0.2710531\ttotal: 22.8s\tremaining: 2.28s\n",
            "909:\tlearn: 0.2709386\ttotal: 22.8s\tremaining: 2.26s\n",
            "910:\tlearn: 0.2707945\ttotal: 22.9s\tremaining: 2.23s\n",
            "911:\tlearn: 0.2706764\ttotal: 22.9s\tremaining: 2.21s\n",
            "912:\tlearn: 0.2705022\ttotal: 23s\tremaining: 2.19s\n",
            "913:\tlearn: 0.2703896\ttotal: 23s\tremaining: 2.16s\n",
            "914:\tlearn: 0.2703115\ttotal: 23s\tremaining: 2.14s\n",
            "915:\tlearn: 0.2702219\ttotal: 23.1s\tremaining: 2.12s\n",
            "916:\tlearn: 0.2700823\ttotal: 23.1s\tremaining: 2.09s\n",
            "917:\tlearn: 0.2699319\ttotal: 23.2s\tremaining: 2.07s\n",
            "918:\tlearn: 0.2697847\ttotal: 23.2s\tremaining: 2.05s\n",
            "919:\tlearn: 0.2696636\ttotal: 23.2s\tremaining: 2.02s\n",
            "920:\tlearn: 0.2695584\ttotal: 23.3s\tremaining: 2s\n",
            "921:\tlearn: 0.2694466\ttotal: 23.3s\tremaining: 1.97s\n",
            "922:\tlearn: 0.2692857\ttotal: 23.4s\tremaining: 1.95s\n",
            "923:\tlearn: 0.2690563\ttotal: 23.4s\tremaining: 1.93s\n",
            "924:\tlearn: 0.2689197\ttotal: 23.5s\tremaining: 1.9s\n",
            "925:\tlearn: 0.2687787\ttotal: 23.5s\tremaining: 1.88s\n",
            "926:\tlearn: 0.2686059\ttotal: 23.6s\tremaining: 1.85s\n",
            "927:\tlearn: 0.2685392\ttotal: 23.6s\tremaining: 1.83s\n",
            "928:\tlearn: 0.2684366\ttotal: 23.7s\tremaining: 1.81s\n",
            "929:\tlearn: 0.2683186\ttotal: 23.7s\tremaining: 1.78s\n",
            "930:\tlearn: 0.2681902\ttotal: 23.7s\tremaining: 1.76s\n",
            "931:\tlearn: 0.2681134\ttotal: 23.8s\tremaining: 1.74s\n",
            "932:\tlearn: 0.2679792\ttotal: 23.8s\tremaining: 1.71s\n",
            "933:\tlearn: 0.2678473\ttotal: 23.8s\tremaining: 1.68s\n",
            "934:\tlearn: 0.2677420\ttotal: 23.9s\tremaining: 1.66s\n",
            "935:\tlearn: 0.2676515\ttotal: 23.9s\tremaining: 1.64s\n",
            "936:\tlearn: 0.2675907\ttotal: 24s\tremaining: 1.61s\n",
            "937:\tlearn: 0.2674940\ttotal: 24s\tremaining: 1.59s\n",
            "938:\tlearn: 0.2673895\ttotal: 24.1s\tremaining: 1.56s\n",
            "939:\tlearn: 0.2672511\ttotal: 24.1s\tremaining: 1.54s\n",
            "940:\tlearn: 0.2671113\ttotal: 24.1s\tremaining: 1.51s\n",
            "941:\tlearn: 0.2670141\ttotal: 24.2s\tremaining: 1.49s\n",
            "942:\tlearn: 0.2668696\ttotal: 24.2s\tremaining: 1.46s\n",
            "943:\tlearn: 0.2667218\ttotal: 24.3s\tremaining: 1.44s\n",
            "944:\tlearn: 0.2666157\ttotal: 24.3s\tremaining: 1.41s\n",
            "945:\tlearn: 0.2664872\ttotal: 24.3s\tremaining: 1.39s\n",
            "946:\tlearn: 0.2664303\ttotal: 24.4s\tremaining: 1.36s\n",
            "947:\tlearn: 0.2662982\ttotal: 24.4s\tremaining: 1.34s\n",
            "948:\tlearn: 0.2661721\ttotal: 24.5s\tremaining: 1.31s\n",
            "949:\tlearn: 0.2660396\ttotal: 24.5s\tremaining: 1.29s\n",
            "950:\tlearn: 0.2658988\ttotal: 24.6s\tremaining: 1.26s\n",
            "951:\tlearn: 0.2657951\ttotal: 24.6s\tremaining: 1.24s\n",
            "952:\tlearn: 0.2656637\ttotal: 24.7s\tremaining: 1.22s\n",
            "953:\tlearn: 0.2655197\ttotal: 24.7s\tremaining: 1.19s\n",
            "954:\tlearn: 0.2653825\ttotal: 24.7s\tremaining: 1.17s\n",
            "955:\tlearn: 0.2652659\ttotal: 24.8s\tremaining: 1.14s\n",
            "956:\tlearn: 0.2651403\ttotal: 24.8s\tremaining: 1.11s\n",
            "957:\tlearn: 0.2649854\ttotal: 24.9s\tremaining: 1.09s\n",
            "958:\tlearn: 0.2648878\ttotal: 24.9s\tremaining: 1.06s\n",
            "959:\tlearn: 0.2648270\ttotal: 25s\tremaining: 1.04s\n",
            "960:\tlearn: 0.2646884\ttotal: 25s\tremaining: 1.01s\n",
            "961:\tlearn: 0.2645775\ttotal: 25s\tremaining: 989ms\n",
            "962:\tlearn: 0.2645213\ttotal: 25.1s\tremaining: 964ms\n",
            "963:\tlearn: 0.2643810\ttotal: 25.1s\tremaining: 939ms\n",
            "964:\tlearn: 0.2642241\ttotal: 25.2s\tremaining: 913ms\n",
            "965:\tlearn: 0.2640805\ttotal: 25.2s\tremaining: 888ms\n",
            "966:\tlearn: 0.2639913\ttotal: 25.3s\tremaining: 863ms\n",
            "967:\tlearn: 0.2637885\ttotal: 25.3s\tremaining: 837ms\n",
            "968:\tlearn: 0.2636817\ttotal: 25.3s\tremaining: 810ms\n",
            "969:\tlearn: 0.2635735\ttotal: 25.4s\tremaining: 784ms\n",
            "970:\tlearn: 0.2634803\ttotal: 25.4s\tremaining: 758ms\n",
            "971:\tlearn: 0.2633667\ttotal: 25.4s\tremaining: 732ms\n",
            "972:\tlearn: 0.2631887\ttotal: 25.4s\tremaining: 705ms\n",
            "973:\tlearn: 0.2630626\ttotal: 25.4s\tremaining: 679ms\n",
            "974:\tlearn: 0.2630011\ttotal: 25.5s\tremaining: 653ms\n",
            "975:\tlearn: 0.2628808\ttotal: 25.5s\tremaining: 627ms\n",
            "976:\tlearn: 0.2627709\ttotal: 25.5s\tremaining: 600ms\n",
            "977:\tlearn: 0.2626819\ttotal: 25.5s\tremaining: 574ms\n",
            "978:\tlearn: 0.2625707\ttotal: 25.6s\tremaining: 548ms\n",
            "979:\tlearn: 0.2624302\ttotal: 25.6s\tremaining: 522ms\n",
            "980:\tlearn: 0.2622891\ttotal: 25.6s\tremaining: 496ms\n",
            "981:\tlearn: 0.2621762\ttotal: 25.6s\tremaining: 470ms\n",
            "982:\tlearn: 0.2621078\ttotal: 25.6s\tremaining: 443ms\n",
            "983:\tlearn: 0.2619771\ttotal: 25.7s\tremaining: 417ms\n",
            "984:\tlearn: 0.2618397\ttotal: 25.7s\tremaining: 391ms\n",
            "985:\tlearn: 0.2617033\ttotal: 25.7s\tremaining: 365ms\n",
            "986:\tlearn: 0.2615895\ttotal: 25.7s\tremaining: 339ms\n",
            "987:\tlearn: 0.2614332\ttotal: 25.8s\tremaining: 313ms\n",
            "988:\tlearn: 0.2612506\ttotal: 25.8s\tremaining: 287ms\n",
            "989:\tlearn: 0.2610951\ttotal: 25.8s\tremaining: 261ms\n",
            "990:\tlearn: 0.2610354\ttotal: 25.8s\tremaining: 234ms\n",
            "991:\tlearn: 0.2609360\ttotal: 25.8s\tremaining: 208ms\n",
            "992:\tlearn: 0.2608670\ttotal: 25.9s\tremaining: 182ms\n",
            "993:\tlearn: 0.2607406\ttotal: 25.9s\tremaining: 156ms\n",
            "994:\tlearn: 0.2606315\ttotal: 25.9s\tremaining: 130ms\n",
            "995:\tlearn: 0.2604831\ttotal: 25.9s\tremaining: 104ms\n",
            "996:\tlearn: 0.2603069\ttotal: 26s\tremaining: 78.1ms\n",
            "997:\tlearn: 0.2602206\ttotal: 26s\tremaining: 52ms\n",
            "998:\tlearn: 0.2601002\ttotal: 26s\tremaining: 26ms\n",
            "999:\tlearn: 0.2599758\ttotal: 26s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8474494736080517"
            ]
          },
          "metadata": {},
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#autogluon"
      ],
      "metadata": {
        "id": "PPhipcUDx3ZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autogluon\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mxfd6CUtx15L",
        "outputId": "023e678a-63ad-4b23-875c-77581427949c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogluon\n",
            "  Downloading autogluon-1.0.0-py3-none-any.whl (9.9 kB)\n",
            "Collecting autogluon.core[all]==1.0.0 (from autogluon)\n",
            "  Downloading autogluon.core-1.0.0-py3-none-any.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.features==1.0.0 (from autogluon)\n",
            "  Downloading autogluon.features-1.0.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.tabular[all]==1.0.0 (from autogluon)\n",
            "  Downloading autogluon.tabular-1.0.0-py3-none-any.whl (306 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.0/306.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.multimodal==1.0.0 (from autogluon)\n",
            "  Downloading autogluon.multimodal-1.0.0-py3-none-any.whl (416 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.7/416.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.timeseries[all]==1.0.0 (from autogluon)\n",
            "  Downloading autogluon.timeseries-1.0.0-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.5/120.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.29,>=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.0.0->autogluon) (1.25.2)\n",
            "Requirement already satisfied: scipy<1.13,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.0.0->autogluon) (1.11.4)\n",
            "Collecting scikit-learn<1.5,>=1.3.0 (from autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading scikit_learn-1.4.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.0.0->autogluon) (3.2.1)\n",
            "Collecting pandas<2.2.0,>=2.0.0 (from autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.0.0->autogluon) (4.66.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.0.0->autogluon) (2.31.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.0.0->autogluon) (3.7.1)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading boto3-1.34.53-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.common==1.0.0 (from autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading autogluon.common-1.0.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ray[default]<2.7,>=2.6.3 (from autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading ray-2.6.3-cp310-cp310-manylinux2014_x86_64.whl (56.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: async-timeout in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.0.0->autogluon) (4.0.3)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.0.0->autogluon) (0.2.7)\n",
            "Collecting Pillow<11,>=10.0.1 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch<2.1,>=2.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning<2.1,>=2.0.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading lightning-2.0.9.post0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonschema<4.18,>=4.14 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate<0.22.0,>=0.21.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers[sentencepiece]<4.32.0,>=4.31.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm<0.10.0,>=0.9.5 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision<0.16.0,>=0.14.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image<0.21.0,>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.0.0->autogluon) (0.19.3)\n",
            "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.0.0->autogluon) (1.3)\n",
            "Collecting torchmetrics<1.2.0,>=1.0.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading torchmetrics-1.1.2-py3-none-any.whl (764 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.8/764.8 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nptyping-2.4.1-py3-none-any.whl (36 kB)\n",
            "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-metric-learning<2.0,>=1.3.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading pytorch_metric_learning-1.7.3-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk<4.0.0,>=3.4.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.0.0->autogluon) (3.8.1)\n",
            "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.0.0->autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.0.0->autogluon) (3.1.3)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.0.0->autogluon) (2.15.2)\n",
            "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Collecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: xgboost<2.1,>=1.6 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.0.0->autogluon) (2.0.3)\n",
            "Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.0.0->autogluon) (2.7.14)\n",
            "Requirement already satisfied: lightgbm<4.2,>=3.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.0.0->autogluon) (4.1.0)\n",
            "Collecting catboost<1.3,>=1.1 (from autogluon.tabular[all]==1.0.0->autogluon)\n",
            "  Downloading catboost-1.2.3-cp310-cp310-manylinux2014_x86_64.whl (98.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib<2,>=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==1.0.0->autogluon) (1.3.2)\n",
            "Collecting pytorch-lightning<2.1,>=2.0.0 (from autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading pytorch_lightning-2.0.9.post0-py3-none-any.whl (727 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.7/727.7 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: statsmodels<0.15,>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==1.0.0->autogluon) (0.14.1)\n",
            "Collecting gluonts<0.15,>=0.14.0 (from autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading gluonts-0.14.4-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mlforecast<0.10.1,>=0.10.0 (from autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading mlforecast-0.10.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting utilsforecast<0.0.11,>=0.0.10 (from autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading utilsforecast-0.0.10-py3-none-any.whl (30 kB)\n",
            "Collecting orjson~=3.9 (from autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil<6,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.0.0->autogluon.core[all]==1.0.0->autogluon) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.0.0->autogluon.core[all]==1.0.0->autogluon) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.0.0->autogluon) (23.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.0.0->autogluon) (6.0.1)\n",
            "Collecting botocore<1.35.0,>=1.34.53 (from boto3<2,>=1.10->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading botocore-1.34.53-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2,>=1.10->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.0.0->autogluon) (0.20.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.0.0->autogluon) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.0.0->autogluon) (1.16.0)\n",
            "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading datasets-2.17.1-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon) (3.4.1)\n",
            "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon) (0.20.3)\n",
            "Collecting responses<0.19 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (23.1.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (1.5.29)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (1.0.3)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (3.7.4)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.15,>=0.14.0->autogluon.timeseries[all]==1.0.0->autogluon) (2.6.3)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.15,>=0.14.0->autogluon.timeseries[all]==1.0.0->autogluon) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.15,>=0.14.0->autogluon.timeseries[all]==1.0.0->autogluon) (4.10.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.0.0->autogluon) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.0.0->autogluon) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.0.0->autogluon) (0.10.9.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.0.0->autogluon) (2.1.5)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.18,>=4.14->autogluon.multimodal==1.0.0->autogluon) (23.2.0)\n",
            "Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 (from jsonschema<4.18,>=4.14->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading pyrsistent-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting arrow<3.0,>=1.2.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff<4.0,>=2.2.1 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (4.12.3)\n",
            "Requirement already satisfied: click<10.0 in /usr/local/lib/python3.10/dist-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (8.1.7)\n",
            "Collecting croniter<1.5.0,>=1.3.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading croniter-1.4.1-py2.py3-none-any.whl (19 kB)\n",
            "Collecting dateutils<2.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading dateutils-0.6.12-py2.py3-none-any.whl (5.7 kB)\n",
            "Collecting deepdiff<8.0,>=5.7.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading deepdiff-6.7.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi<2.0,>=0.92.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inquirer<5.0,>=2.10.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading inquirer-3.2.4-py3-none-any.whl (18 kB)\n",
            "Collecting lightning-cloud>=0.5.38 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading lightning_cloud-0.5.64-py3-none-any.whl (928 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m928.4/928.4 kB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning-utilities<2.0,>=0.7.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Collecting pydantic<3,>=1.7 (from gluonts<0.15,>=0.14.0->autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading pydantic-2.1.1-py3-none-any.whl (370 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m370.9/370.9 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-multipart<2.0,>=0.0.5 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: rich<15.0,>=12.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (13.7.0)\n",
            "Collecting starlette (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading starlette-0.37.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starsessions<2.0,>=1.2.1 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading starsessions-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (5.7.1)\n",
            "Requirement already satisfied: urllib3<4.0 in /usr/local/lib/python3.10/dist-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (2.0.7)\n",
            "Collecting uvicorn<2.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: websocket-client<3.0 in /usr/local/lib/python3.10/dist-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (1.7.0)\n",
            "Collecting websockets<13.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries[all]==1.0.0->autogluon) (0.58.1)\n",
            "Collecting window-ops (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading window_ops-0.0.14-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.0.0->autogluon) (4.7.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.0.0->autogluon) (2023.12.25)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon) (0.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0,>=2.0.0->autogluon.core[all]==1.0.0->autogluon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0,>=2.0.0->autogluon.core[all]==1.0.0->autogluon) (2023.4)\n",
            "Collecting tzdata>=2022.1 (from pandas<2.2.0,>=2.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon) (3.13.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon) (1.0.7)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon) (3.20.3)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon) (1.4.1)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon) (1.62.0)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon) (3.9.3)\n",
            "Collecting aiohttp-cors (from ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting colorful (from ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting py-spy>=0.2.0 (from ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gpustat>=1.0.0 (from ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading gpustat-1.1.1.tar.gz (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting opencensus (from ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<3,>=1.7 (from gluonts<0.15,>=0.14.0->autogluon.timeseries[all]==1.0.0->autogluon)\n",
            "  Downloading pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon) (0.20.0)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon) (6.4.0)\n",
            "Collecting virtualenv<20.21.1,>=20.0.24 (from ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading virtualenv-20.21.0-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboardX>=1.9 (from ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon) (14.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==1.0.0->autogluon) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==1.0.0->autogluon) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==1.0.0->autogluon) (2024.2.2)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.0.0->autogluon) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.0.0->autogluon) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.0.0->autogluon) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.5,>=1.3.0->autogluon.core[all]==1.0.0->autogluon) (3.3.0)\n",
            "Requirement already satisfied: patsy>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels<0.15,>=0.13.0->autogluon.timeseries[all]==1.0.0->autogluon) (0.5.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (3.0.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm<0.10.0,>=0.9.5->autogluon.multimodal==1.0.0->autogluon) (0.4.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon) (1.12)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon) (0.42.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading lit-17.0.6.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers[sentencepiece]<4.32.0,>=4.31.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.32.0,>=4.31.0->autogluon.multimodal==1.0.0->autogluon) (0.1.99)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==1.0.0->autogluon) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==1.0.0->autogluon) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==1.0.0->autogluon) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==1.0.0->autogluon) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==1.0.0->autogluon) (3.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon) (1.9.4)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow<3.0,>=1.2.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading types_python_dateutil-2.8.19.20240106-py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<6.0,>=4.8.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (2.5)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.0.0->autogluon) (0.6)\n",
            "Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff<8.0,>=5.7.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting starlette (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (1.3.1)\n",
            "Collecting nvidia-ml-py>=11.450.129 (from gpustat>=1.0.0->ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading nvidia_ml_py-12.535.133-py3-none-any.whl (37 kB)\n",
            "Collecting blessed>=1.17.1 (from gpustat>=1.0.0->ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow<11,>=10.0.1 (from autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading Pillow-10.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting editor>=1.6.0 (from inquirer<5.0,>=2.10.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading editor-1.6.6-py3-none-any.whl (4.0 kB)\n",
            "Collecting readchar>=3.0.6 (from inquirer<5.0,>=2.10.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from lightning-cloud>=0.5.38->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (2.3.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->mlforecast<0.10.1,>=0.10.0->autogluon.timeseries[all]==1.0.0->autogluon) (0.41.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<15.0,>=12.3.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (2.16.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (0.9.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (3.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (3.7.1)\n",
            "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from starsessions<2.0,>=1.2.1->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (2.1.2)\n",
            "Collecting h11>=0.8 (from uvicorn<2.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.6 (from virtualenv<20.21.1,>=20.0.24->ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting platformdirs<4,>=2.4 (from virtualenv<20.21.1,>=20.0.24->ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading platformdirs-3.11.0-py3-none-any.whl (17 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon) (2.11.1)\n",
            "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading openxlab-0.0.34-py3-none-any.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==1.0.0->autogluon) (8.2.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.1,>=2.0->autogluon.multimodal==1.0.0->autogluon) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (1.2.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon) (0.2.13)\n",
            "Collecting runs (from editor>=1.6.0->inquirer<5.0,>=2.10.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading runs-1.2.2-py3-none-any.whl (7.0 kB)\n",
            "Collecting xmod (from editor>=1.6.0->inquirer<5.0,>=2.10.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading xmod-1.8.1-py3-none-any.whl (4.6 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]<2.7,>=2.6.3->autogluon.core[all]==1.0.0->autogluon) (1.62.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<15.0,>=12.3.0->lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==1.0.0->autogluon) (3.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (0.1.4)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.0.0->autogluon) (0.16.0)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting requests (from autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich<15.0,>=12.3.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools (from autogluon.common==1.0.0->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm<5,>=4.38 (from autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<4.0 (from lightning<2.1,>=2.0.0->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of requests[socks] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting requests[socks] (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading requests-2.30.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading requests-2.29.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==1.0.0->autogluon) (1.7.1)\n",
            "Collecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon)\n",
            "  Downloading aliyun-python-sdk-core-2.14.0.tar.gz (443 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.0/443.0 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core[all]==1.0.0->autogluon)\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon) (42.0.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.0.0->autogluon) (2.21)\n",
            "Building wheels for collected packages: nvidia-ml-py3, antlr4-python3-runtime, seqeval, gpustat, lit, oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19171 sha256=3fa7ab384cbd86b6e2c6af3d18cf2eb2ff1afd0f876a523dee6cc377ab0da90e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/d8/c0/46899f8be7a75a2ffd197a23c8797700ea858b9b34819fbf9e\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=9da7a5e52b6b5ec205af83591a7858bf4e34a94fd41c41e1aec97c136a17e7fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=ec409c5e45b807ec74edca4ae1e12d9b1111b33c2d9b63f3de5741cc82670af7\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.1.1-py3-none-any.whl size=26535 sha256=d410ed90dcd13477c39361e33fb3116a3cb813e9d3cbef1c4e191edee509b2eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/d7/80/a71ba3540900e1f276bcae685efd8e590c810d2108b95f1e47\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=5eb2a33bf389dace5677b1631ad775ef0b0b16457e37833c2995793bf8f176eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112371 sha256=6d139e88c5075ee8fcdedd275eb9bbf7bb30c742d424bb418ed8eba1a9cc4c77\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.14.0-py3-none-any.whl size=535289 sha256=68d4a7dbf4001a86b248314756aac84bc470b807faba2509d782757d74cc27ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/3c/68/b7eab618d9f1d5e7d386296f1e07e2cf36aaa1eb5161885038\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31408 sha256=5a0326162ac2c009a900a05748ac8cc63a17a7ad5438bc2e812e9d706ff16fd7\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "Successfully built nvidia-ml-py3 antlr4-python3-runtime seqeval gpustat lit oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: tokenizers, py-spy, opencensus-context, nvidia-ml-py3, nvidia-ml-py, lit, distlib, crcmod, colorful, antlr4-python3-runtime, xmod, websockets, urllib3, tzdata, types-python-dateutil, tqdm, tensorboardX, setuptools, python-multipart, pyrsistent, pydantic, pycryptodome, platformdirs, Pillow, orjson, ordered-set, omegaconf, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, nptyping, jmespath, h11, dill, colorama, blessed, backoff, window-ops, virtualenv, uvicorn, starlette, scikit-learn, runs, rich, requests, readchar, pytesseract, pandas, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, multiprocess, model-index, lightning-utilities, jsonschema, gpustat, deepdiff, dateutils, croniter, botocore, arrow, utilsforecast, starsessions, seqeval, s3transfer, responses, ray, nvidia-cusolver-cu11, nvidia-cudnn-cu11, gluonts, fastapi, editor, catboost, aliyun-python-sdk-core, aiohttp-cors, transformers, statsforecast, opencensus, mlforecast, inquirer, datasets, boto3, aliyun-python-sdk-kms, oss2, nlpaug, lightning-cloud, evaluate, autogluon.common, openxlab, autogluon.features, autogluon.core, opendatalab, autogluon.tabular, openmim, triton, torch, torchmetrics, pytorch-lightning, torchvision, lightning, timm, pytorch-metric-learning, autogluon.timeseries, accelerate, autogluon.multimodal, autogluon\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.2\n",
            "    Uninstalling tqdm-4.66.2:\n",
            "      Successfully uninstalled tqdm-4.66.2\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.3\n",
            "    Uninstalling pydantic-2.6.3:\n",
            "      Successfully uninstalled pydantic-2.6.3\n",
            "  Attempting uninstall: platformdirs\n",
            "    Found existing installation: platformdirs 4.2.0\n",
            "    Uninstalling platformdirs-4.2.0:\n",
            "      Successfully uninstalled platformdirs-4.2.0\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.7.0\n",
            "    Uninstalling rich-13.7.0:\n",
            "      Successfully uninstalled rich-13.7.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.19.2\n",
            "    Uninstalling jsonschema-4.19.2:\n",
            "      Successfully uninstalled jsonschema-4.19.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.1\n",
            "    Uninstalling transformers-4.38.1:\n",
            "      Successfully uninstalled transformers-4.38.1\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.16.0+cu121\n",
            "    Uninstalling torchvision-0.16.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.16.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "bigframes 0.21.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.1.4 which is incompatible.\n",
            "cvxpy 1.3.3 requires setuptools>65.5.1, but you have setuptools 60.2.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.1.4 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.2 which is incompatible.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "yfinance 0.2.37 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.0.1 accelerate-0.21.0 aiohttp-cors-0.7.0 aliyun-python-sdk-core-2.14.0 aliyun-python-sdk-kms-2.16.2 antlr4-python3-runtime-4.9.3 arrow-1.3.0 autogluon-1.0.0 autogluon.common-1.0.0 autogluon.core-1.0.0 autogluon.features-1.0.0 autogluon.multimodal-1.0.0 autogluon.tabular-1.0.0 autogluon.timeseries-1.0.0 backoff-2.2.1 blessed-1.20.0 boto3-1.34.53 botocore-1.34.53 catboost-1.2.3 colorama-0.4.6 colorful-0.5.6 crcmod-1.7 croniter-1.4.1 datasets-2.17.1 dateutils-0.6.12 deepdiff-6.7.1 dill-0.3.8 distlib-0.3.8 editor-1.6.6 evaluate-0.4.1 fastapi-0.110.0 gluonts-0.14.4 gpustat-1.1.1 h11-0.14.0 inquirer-3.2.4 jmespath-0.10.0 jsonschema-4.17.3 lightning-2.0.9.post0 lightning-cloud-0.5.64 lightning-utilities-0.10.1 lit-17.0.6 mlforecast-0.10.0 model-index-0.1.11 multiprocess-0.70.16 nlpaug-1.1.11 nptyping-2.4.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-ml-py-12.535.133 nvidia-ml-py3-7.352.0 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 omegaconf-2.2.3 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.34 ordered-set-4.1.0 orjson-3.9.15 oss2-2.17.0 pandas-2.1.4 platformdirs-3.11.0 py-spy-0.3.14 pycryptodome-3.20.0 pydantic-1.10.14 pyrsistent-0.20.0 pytesseract-0.3.10 python-multipart-0.0.9 pytorch-lightning-2.0.9.post0 pytorch-metric-learning-1.7.3 ray-2.6.3 readchar-4.0.5 requests-2.28.2 responses-0.18.0 rich-13.4.2 runs-1.2.2 s3transfer-0.10.0 scikit-learn-1.4.1.post1 seqeval-1.2.2 setuptools-60.2.0 starlette-0.36.3 starsessions-1.3.0 statsforecast-1.4.0 tensorboardX-2.6.2.2 timm-0.9.16 tokenizers-0.13.3 torch-2.0.1 torchmetrics-1.1.2 torchvision-0.15.2 tqdm-4.65.2 transformers-4.31.0 triton-2.0.0 types-python-dateutil-2.8.19.20240106 tzdata-2024.1 urllib3-1.26.18 utilsforecast-0.0.10 uvicorn-0.27.1 virtualenv-20.21.0 websockets-12.0 window-ops-0.0.14 xmod-1.8.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "pkg_resources",
                  "pydevd_plugins",
                  "setuptools",
                  "sklearn",
                  "tqdm"
                ]
              },
              "id": "81fc5af2f661492a964ca6573ed7c7ba"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularDataset, TabularPredictor\n"
      ],
      "metadata": {
        "id": "w5QkygN7x-m8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train,test= train_test_split(train_data, test_size=0.2, random_state=42, shuffle=True, stratify=train_data['DiagPeriodL90D'])\n"
      ],
      "metadata": {
        "id": "-R6Zt2RtzoUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = 'DiagPeriodL90D'\n"
      ],
      "metadata": {
        "id": "VY4mbnQ94esb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = TabularPredictor(label=label,eval_metric ='roc_auc').fit(train,presets='best_quality')\n",
        "results = predictor.fit_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roIryOKz4l4B",
        "outputId": "7b272f03-e577-4afb-d227-4efdcc8b2b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20240301_072026\"\n",
            "Presets specified: ['best_quality']\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
            "Sub-fit(s) time limit is: 3600 seconds.\n",
            "Starting holdout-based sub-fit for dynamic stacking. Context path is: AutogluonModels/ag-20240301_072026/ds_sub_fit/sub_fit_ho.\n",
            "Beginning AutoGluon training ... Time limit = 900s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20240301_072026/ds_sub_fit/sub_fit_ho\"\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.0.0\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sat Nov 18 15:31:17 UTC 2023\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.95 GB / 12.67 GB (86.4%)\n",
            "Disk Space Avail:   74.13 GB / 107.72 GB (68.8%)\n",
            "===================================================\n",
            "Train Data Rows:    9176\n",
            "Train Data Columns: 224\n",
            "Label Column:       DiagPeriodL90D\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11205.09 MB\n",
            "\tTrain Data (Original)  Memory Usage: 15.31 MB (0.1% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 147 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 8): ['breast_cancer_diagnosis_desc_processed_malign neoplasm nippl areola femal', 'metastatic_cancer_category_Other or Unspecified Metastasis', 'metastatic_cancer_diagnosis_code_C7910', 'metastatic_cancer_diagnosis_code_C7919', 'metastatic_cancer_diagnosis_code_C7962', 'num_children', 'patient_state_CT', 'patient_state_NH']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 23): ['Region_Northeast', 'breast_cancer_diagnosis_desc_processed_malign neoplasm axillari tail unsp femal breast', 'breast_cancer_diagnosis_desc_processed_malign neoplasm breast', 'breast_cancer_diagnosis_desc_processed_malign neoplasm breast unspecifi site', 'breast_cancer_diagnosis_desc_processed_malign neoplasm central portion breast femal', 'breast_cancer_diagnosis_desc_processed_malign neoplasm overlap site breast femal', 'metastatic_cancer_diagnosis_code_C774', 'metastatic_cancer_diagnosis_code_C7830', 'metastatic_cancer_diagnosis_code_C7880', 'metastatic_cancer_diagnosis_code_C7911', 'metastatic_cancer_diagnosis_code_C7932', 'metastatic_cancer_diagnosis_code_C7961', 'metastatic_cancer_diagnosis_code_C7970', 'metastatic_cancer_diagnosis_code_C7971', 'metastatic_cancer_diagnosis_code_C7972', 'metastatic_first_novel_treatment_OLAPARIB', 'metastatic_first_novel_treatment_type_Antineoplastics', 'metastatic_first_novel_treatment_type_Unknown', 'patient_state_MA', 'patient_state_ND', 'patient_state_RI', 'patient_state_SD', 'patient_state_WY']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('int', []) : 23 | ['Region_Northeast', 'breast_cancer_diagnosis_desc_processed_malign neoplasm axillari tail unsp femal breast', 'breast_cancer_diagnosis_desc_processed_malign neoplasm breast', 'breast_cancer_diagnosis_desc_processed_malign neoplasm breast unspecifi site', 'breast_cancer_diagnosis_desc_processed_malign neoplasm central portion breast femal', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('bool', [])  :   6 | ['patient_race_Asian', 'patient_race_Black', 'patient_race_Hispanic', 'patient_race_Other', 'patient_race_Unknown', ...]\n",
            "\t\t('float', []) :  67 | ['Ozone', 'PM25', 'age_10_to_19', 'age_20s', 'age_30s', ...]\n",
            "\t\t('int', [])   : 120 | ['Division_East North Central', 'Division_East South Central', 'Division_Middle Atlantic', 'Division_Mountain', 'Division_New England', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     :  67 | ['Ozone', 'PM25', 'age_10_to_19', 'age_20s', 'age_30s', ...]\n",
            "\t\t('int', [])       :   2 | ['patient_age', 'patient_id']\n",
            "\t\t('int', ['bool']) : 124 | ['Division_East North Central', 'Division_East South Central', 'Division_Middle Atlantic', 'Division_Mountain', 'Division_New England', ...]\n",
            "\t9.5s = Fit runtime\n",
            "\t193 features in original data used to generate 193 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 5.92 MB (0.1% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 9.77s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 110 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 593.33s of the 890.2s of remaining time.\n",
            "\t0.5241\t = Validation score   (roc_auc)\n",
            "\t0.05s\t = Training   runtime\n",
            "\t1.41s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 586.72s of the 883.58s of remaining time.\n",
            "\t0.528\t = Validation score   (roc_auc)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t1.13s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 585.49s of the 882.35s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.67%)\n",
            "\t0.799\t = Validation score   (roc_auc)\n",
            "\t43.94s\t = Training   runtime\n",
            "\t0.28s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 529.24s of the 826.11s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.71%)\n",
            "\t0.7944\t = Validation score   (roc_auc)\n",
            "\t59.49s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 461.32s of the 758.18s of remaining time.\n",
            "\t0.7726\t = Validation score   (roc_auc)\n",
            "\t16.25s\t = Training   runtime\n",
            "\t1.09s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 443.66s of the 740.52s of remaining time.\n",
            "\t0.7751\t = Validation score   (roc_auc)\n",
            "\t16.55s\t = Training   runtime\n",
            "\t1.16s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 425.32s of the 722.18s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=1.04%)\n",
            "\t0.8005\t = Validation score   (roc_auc)\n",
            "\t126.71s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 291.8s of the 588.67s of remaining time.\n",
            "\t0.7822\t = Validation score   (roc_auc)\n",
            "\t7.49s\t = Training   runtime\n",
            "\t1.09s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 282.85s of the 579.71s of remaining time.\n",
            "\t0.7835\t = Validation score   (roc_auc)\n",
            "\t9.51s\t = Training   runtime\n",
            "\t1.11s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 271.76s of the 568.63s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.62%)\n",
            "\t0.788\t = Validation score   (roc_auc)\n",
            "\t127.25s\t = Training   runtime\n",
            "\t0.56s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 140.2s of the 437.06s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=1.24%)\n",
            "\t0.798\t = Validation score   (roc_auc)\n",
            "\t80.05s\t = Training   runtime\n",
            "\t0.32s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 54.42s of the 351.28s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.34%)\n",
            "\t0.7942\t = Validation score   (roc_auc)\n",
            "\t76.19s\t = Training   runtime\n",
            "\t0.96s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 266.26s of remaining time.\n",
            "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.291, 'XGBoost_BAG_L1': 0.273, 'LightGBMXT_BAG_L1': 0.182, 'NeuralNetFastAI_BAG_L1': 0.127, 'NeuralNetTorch_BAG_L1': 0.073, 'KNeighborsDist_BAG_L1': 0.055}\n",
            "\t0.8052\t = Validation score   (roc_auc)\n",
            "\t3.8s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting 108 L2 models ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 262.41s of the 262.24s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.78%)\n",
            "\t0.8108\t = Validation score   (roc_auc)\n",
            "\t59.05s\t = Training   runtime\n",
            "\t0.3s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 198.05s of the 197.89s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.75%)\n",
            "\t0.8101\t = Validation score   (roc_auc)\n",
            "\t75.47s\t = Training   runtime\n",
            "\t0.24s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 117.57s of the 117.41s of remaining time.\n",
            "\t0.8188\t = Validation score   (roc_auc)\n",
            "\t20.15s\t = Training   runtime\n",
            "\t1.18s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 95.98s of the 95.82s of remaining time.\n",
            "\t0.8209\t = Validation score   (roc_auc)\n",
            "\t19.48s\t = Training   runtime\n",
            "\t1.1s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 75.19s of the 75.03s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=1.11%)\n",
            "\t0.8027\t = Validation score   (roc_auc)\n",
            "\t78.16s\t = Training   runtime\n",
            "\t0.32s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -8.59s of remaining time.\n",
            "\tEnsemble Weights: {'RandomForestEntr_BAG_L2': 0.39, 'RandomForestGini_BAG_L2': 0.21, 'LightGBMXT_BAG_L2': 0.2, 'LightGBM_BAG_L2': 0.16, 'NeuralNetFastAI_BAG_L1': 0.03, 'KNeighborsDist_BAG_L1': 0.01}\n",
            "\t0.8249\t = Validation score   (roc_auc)\n",
            "\t4.4s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 913.07s ... Best model: \"WeightedEnsemble_L3\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240301_072026/ds_sub_fit/sub_fit_ho\")\n",
            "Leaderboard on holdout data from dynamic stacking:\n",
            "                      model  holdout_score  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0       WeightedEnsemble_L2       0.825756   0.805190     roc_auc        2.895189       3.553155  457.986275                 0.004697                0.007623           3.796460            2       True         13\n",
            "1           CatBoost_BAG_L2       0.821287   0.802667     roc_auc        4.781654       9.845514  641.695286                 0.131498                0.319520          78.156703            2       True         18\n",
            "2           CatBoost_BAG_L1       0.820132   0.800488     roc_auc        0.166073       0.289624  126.714179                 0.166073                0.289624         126.714179            1       True          7\n",
            "3         LightGBMXT_BAG_L2       0.819928   0.810806     roc_auc        4.891016       9.821646  622.589989                 0.240860                0.295653          59.051406            2       True         14\n",
            "4         LightGBMXT_BAG_L1       0.817932   0.798967     roc_auc        1.317545       0.279194   43.943896                 1.317545                0.279194          43.943896            1       True          3\n",
            "5           LightGBM_BAG_L2       0.815472   0.810145     roc_auc        4.831632       9.767519  639.004568                 0.181476                0.241526          75.465985            2       True         15\n",
            "6            XGBoost_BAG_L1       0.814696   0.798044     roc_auc        0.238111       0.322185   80.052164                 0.238111                0.322185          80.052164            1       True         11\n",
            "7     NeuralNetTorch_BAG_L1       0.812036   0.794250     roc_auc        0.463318       0.963327   76.187601                 0.463318                0.963327          76.187601            1       True         12\n",
            "8           LightGBM_BAG_L1       0.811680   0.794383     roc_auc        0.156578       0.123872   59.492111                 0.156578                0.123872          59.492111            1       True          4\n",
            "9    NeuralNetFastAI_BAG_L1       0.811084   0.788042     roc_auc        0.494759       0.563641  127.251732                 0.494759                0.563641         127.251732            1       True         10\n",
            "10      WeightedEnsemble_L3       0.805959   0.824926     roc_auc        5.505778      12.344649  742.085672                 0.005338                0.002850           4.404182            3       True         19\n",
            "11  RandomForestEntr_BAG_L2       0.795128   0.820863     roc_auc        4.850043      10.627589  583.017400                 0.199887                1.101596          19.478817            2       True         17\n",
            "12  RandomForestGini_BAG_L2       0.794774   0.818843     roc_auc        4.878217      10.703024  583.685282                 0.228061                1.177031          20.146698            2       True         16\n",
            "13    ExtraTreesEntr_BAG_L1       0.786161   0.783486     roc_auc        0.312361       1.111369    9.510440                 0.312361                1.111369           9.510440            1       True          9\n",
            "14    ExtraTreesGini_BAG_L1       0.782781   0.782208     roc_auc        0.312579       1.087682    7.493029                 0.312579                1.087682           7.493029            1       True          8\n",
            "15  RandomForestEntr_BAG_L1       0.779063   0.775096     roc_auc        0.290881       1.160252   16.552833                 0.290881                1.160252          16.552833            1       True          6\n",
            "16  RandomForestGini_BAG_L1       0.777361   0.772591     roc_auc        0.401016       1.088954   16.252109                 0.401016                1.088954          16.252109            1       True          5\n",
            "17    KNeighborsDist_BAG_L1       0.530093   0.527965     roc_auc        0.210686       1.127561    0.040243                 0.210686                1.127561           0.040243            1       True          2\n",
            "18    KNeighborsUnif_BAG_L1       0.524967   0.524102     roc_auc        0.286251       1.408333    0.048245                 0.286251                1.408333           0.048245            1       True          1\n",
            "Stacked overfitting occurred: True.\n",
            "Spend 920 seconds for the sub-fit(s) during dynamic stacking.\n",
            "Time left for full fit of AutoGluon: 2680 seconds.\n",
            "Starting full fit now with num_stack_levels 0.\n",
            "Beginning AutoGluon training ... Time limit = 2680s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20240301_072026\"\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.0.0\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sat Nov 18 15:31:17 UTC 2023\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.27 GB / 12.67 GB (81.1%)\n",
            "Disk Space Avail:   74.13 GB / 107.72 GB (68.8%)\n",
            "===================================================\n",
            "Train Data Rows:    10324\n",
            "Train Data Columns: 224\n",
            "Label Column:       DiagPeriodL90D\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    10537.96 MB\n",
            "\tTrain Data (Original)  Memory Usage: 17.23 MB (0.2% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 149 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUseless Original Features (Count: 6): ['breast_cancer_diagnosis_desc_processed_malign neoplasm nippl areola femal', 'metastatic_cancer_category_Other or Unspecified Metastasis', 'metastatic_cancer_diagnosis_code_C7910', 'metastatic_cancer_diagnosis_code_C7962', 'num_children', 'patient_state_CT']\n",
            "\t\tThese features carry no predictive signal and should be manually investigated.\n",
            "\t\tThis is typically a feature which has the same value for all rows.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\tUnused Original Features (Count: 21): ['Region_Northeast', 'breast_cancer_diagnosis_desc_processed_malign neoplasm breast unspecifi site', 'breast_cancer_diagnosis_desc_processed_malign neoplasm central portion unsp femal breast', 'metastatic_cancer_diagnosis_code_C774', 'metastatic_cancer_diagnosis_code_C7830', 'metastatic_cancer_diagnosis_code_C7839', 'metastatic_cancer_diagnosis_code_C7900', 'metastatic_cancer_diagnosis_code_C7901', 'metastatic_cancer_diagnosis_code_C7911', 'metastatic_cancer_diagnosis_code_C7919', 'metastatic_cancer_diagnosis_code_C7932', 'metastatic_cancer_diagnosis_code_C7940', 'metastatic_cancer_diagnosis_code_C7961', 'metastatic_cancer_diagnosis_code_C7971', 'metastatic_cancer_diagnosis_code_C7972', 'metastatic_first_novel_treatment_type_Unknown', 'patient_state_AK', 'patient_state_MA', 'patient_state_NH', 'patient_state_RI', 'patient_state_WY']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('int', []) : 21 | ['Region_Northeast', 'breast_cancer_diagnosis_desc_processed_malign neoplasm breast unspecifi site', 'breast_cancer_diagnosis_desc_processed_malign neoplasm central portion unsp femal breast', 'metastatic_cancer_diagnosis_code_C774', 'metastatic_cancer_diagnosis_code_C7830', ...]\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('bool', [])  :   6 | ['patient_race_Asian', 'patient_race_Black', 'patient_race_Hispanic', 'patient_race_Other', 'patient_race_Unknown', ...]\n",
            "\t\t('float', []) :  67 | ['Ozone', 'PM25', 'age_10_to_19', 'age_20s', 'age_30s', ...]\n",
            "\t\t('int', [])   : 124 | ['Division_East North Central', 'Division_East South Central', 'Division_Middle Atlantic', 'Division_Mountain', 'Division_New England', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     :  67 | ['Ozone', 'PM25', 'age_10_to_19', 'age_20s', 'age_30s', ...]\n",
            "\t\t('int', [])       :   2 | ['patient_age', 'patient_id']\n",
            "\t\t('int', ['bool']) : 128 | ['Division_East North Central', 'Division_East South Central', 'Division_Middle Atlantic', 'Division_Mountain', 'Division_New England', ...]\n",
            "\t3.4s = Fit runtime\n",
            "\t197 features in original data used to generate 197 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 6.70 MB (0.1% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 3.5s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 110 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 2676.5s of the 2676.49s of remaining time.\n",
            "\t0.5234\t = Validation score   (roc_auc)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t1.1s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 2675.26s of the 2675.25s of remaining time.\n",
            "\t0.5287\t = Validation score   (roc_auc)\n",
            "\t0.04s\t = Training   runtime\n",
            "\t1.06s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2674.05s of the 2674.03s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.76%)\n",
            "\t0.8013\t = Validation score   (roc_auc)\n",
            "\t48.99s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 2617.26s of the 2617.25s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.79%)\n",
            "\t0.7981\t = Validation score   (roc_auc)\n",
            "\t58.25s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 2554.23s of the 2554.22s of remaining time.\n",
            "\t0.7763\t = Validation score   (roc_auc)\n",
            "\t18.94s\t = Training   runtime\n",
            "\t1.13s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 2533.64s of the 2533.63s of remaining time.\n",
            "\t0.7749\t = Validation score   (roc_auc)\n",
            "\t19.51s\t = Training   runtime\n",
            "\t1.0s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 2512.75s of the 2512.74s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=1.12%)\n",
            "\t0.802\t = Validation score   (roc_auc)\n",
            "\t129.02s\t = Training   runtime\n",
            "\t0.19s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 2377.61s of the 2377.59s of remaining time.\n",
            "\t0.7809\t = Validation score   (roc_auc)\n",
            "\t8.07s\t = Training   runtime\n",
            "\t1.24s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 2367.8s of the 2367.78s of remaining time.\n",
            "\t0.7815\t = Validation score   (roc_auc)\n",
            "\t10.34s\t = Training   runtime\n",
            "\t1.14s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 2355.86s of the 2355.85s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.71%)\n",
            "\t0.7903\t = Validation score   (roc_auc)\n",
            "\t148.44s\t = Training   runtime\n",
            "\t2.05s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2202.56s of the 2202.55s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=1.30%)\n",
            "\t0.8\t = Validation score   (roc_auc)\n",
            "\t80.33s\t = Training   runtime\n",
            "\t0.34s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2114.52s of the 2114.5s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.40%)\n",
            "\t0.8014\t = Validation score   (roc_auc)\n",
            "\t171.15s\t = Training   runtime\n",
            "\t0.71s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1937.68s of the 1937.67s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=1.88%)\n",
            "\t0.795\t = Validation score   (roc_auc)\n",
            "\t135.96s\t = Training   runtime\n",
            "\t0.25s\t = Validation runtime\n",
            "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1793.33s of the 1793.32s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=1.14%)\n",
            "\t0.8019\t = Validation score   (roc_auc)\n",
            "\t120.02s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1667.18s of the 1667.17s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.40%)\n",
            "\t0.7968\t = Validation score   (roc_auc)\n",
            "\t210.83s\t = Training   runtime\n",
            "\t0.74s\t = Validation runtime\n",
            "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 1451.38s of the 1451.37s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=1.04%)\n",
            "\t0.799\t = Validation score   (roc_auc)\n",
            "\t92.12s\t = Training   runtime\n",
            "\t0.49s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 1353.73s of the 1353.71s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.74%)\n",
            "\t0.7878\t = Validation score   (roc_auc)\n",
            "\t249.61s\t = Training   runtime\n",
            "\t1.12s\t = Validation runtime\n",
            "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 1099.16s of the 1099.15s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=3.35%)\n",
            "\t0.7978\t = Validation score   (roc_auc)\n",
            "\t701.91s\t = Training   runtime\n",
            "\t0.34s\t = Validation runtime\n",
            "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 389.16s of the 389.15s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.58%)\n",
            "\t0.8058\t = Validation score   (roc_auc)\n",
            "\t51.91s\t = Training   runtime\n",
            "\t0.64s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 331.99s of the 331.97s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.38%)\n",
            "\t0.7996\t = Validation score   (roc_auc)\n",
            "\t254.54s\t = Training   runtime\n",
            "\t0.91s\t = Validation runtime\n",
            "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 72.3s of the 72.29s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=6.10%)\n",
            "\t0.7934\t = Validation score   (roc_auc)\n",
            "\t75.99s\t = Training   runtime\n",
            "\t1.46s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the -10.14s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM_r96_BAG_L1': 0.273, 'NeuralNetTorch_r22_BAG_L1': 0.212, 'NeuralNetTorch_BAG_L1': 0.121, 'NeuralNetTorch_r79_BAG_L1': 0.121, 'CatBoost_BAG_L1': 0.091, 'KNeighborsDist_BAG_L1': 0.061, 'CatBoost_r177_BAG_L1': 0.045, 'XGBoost_BAG_L1': 0.03, 'NeuralNetFastAI_r191_BAG_L1': 0.03, 'NeuralNetFastAI_BAG_L1': 0.015}\n",
            "\t0.8117\t = Validation score   (roc_auc)\n",
            "\t5.27s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 2695.49s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240301_072026\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                          model  score_val eval_metric  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0           WeightedEnsemble_L2   0.811697     roc_auc       7.910519  1421.165047                0.003059           5.273566            2       True         22\n",
            "1           LightGBM_r96_BAG_L1   0.805760     roc_auc       0.635419    51.909910                0.635419          51.909910            1       True         19\n",
            "2               CatBoost_BAG_L1   0.801967     roc_auc       0.185964   129.021427                0.185964         129.021427            1       True          7\n",
            "3          CatBoost_r177_BAG_L1   0.801923     roc_auc       0.148374   120.020098                0.148374         120.020098            1       True         14\n",
            "4         NeuralNetTorch_BAG_L1   0.801447     roc_auc       0.708972   171.147193                0.708972         171.147193            1       True         12\n",
            "5             LightGBMXT_BAG_L1   0.801345     roc_auc       0.171019    48.992050                0.171019          48.992050            1       True          3\n",
            "6                XGBoost_BAG_L1   0.799970     roc_auc       0.342870    80.327472                0.342870          80.327472            1       True         11\n",
            "7     NeuralNetTorch_r22_BAG_L1   0.799596     roc_auc       0.914122   254.541652                0.914122         254.541652            1       True         20\n",
            "8          LightGBM_r131_BAG_L1   0.799005     roc_auc       0.491816    92.123951                0.491816          92.123951            1       True         16\n",
            "9               LightGBM_BAG_L1   0.798064     roc_auc       0.148318    58.251971                0.148318          58.251971            1       True          4\n",
            "10           CatBoost_r9_BAG_L1   0.797768     roc_auc       0.342915   701.905660                0.342915         701.905660            1       True         18\n",
            "11    NeuralNetTorch_r79_BAG_L1   0.796800     roc_auc       0.739916   210.834342                0.739916         210.834342            1       True         15\n",
            "12         LightGBMLarge_BAG_L1   0.795025     roc_auc       0.250936   135.963794                0.250936         135.963794            1       True         13\n",
            "13           XGBoost_r33_BAG_L1   0.793428     roc_auc       1.458996    75.993613                1.458996          75.993613            1       True         21\n",
            "14       NeuralNetFastAI_BAG_L1   0.790305     roc_auc       2.051354   148.440747                2.051354         148.440747            1       True         10\n",
            "15  NeuralNetFastAI_r191_BAG_L1   0.787834     roc_auc       1.117882   249.610945                1.117882         249.610945            1       True         17\n",
            "16        ExtraTreesEntr_BAG_L1   0.781522     roc_auc       1.140873    10.336342                1.140873          10.336342            1       True          9\n",
            "17        ExtraTreesGini_BAG_L1   0.780922     roc_auc       1.236930     8.069018                1.236930           8.069018            1       True          8\n",
            "18      RandomForestGini_BAG_L1   0.776305     roc_auc       1.132142    18.942669                1.132142          18.942669            1       True          5\n",
            "19      RandomForestEntr_BAG_L1   0.774883     roc_auc       0.996175    19.513249                0.996175          19.513249            1       True          6\n",
            "20        KNeighborsDist_BAG_L1   0.528695     roc_auc       1.062587     0.037696                1.062587           0.037696            1       True          2\n",
            "21        KNeighborsUnif_BAG_L1   0.523431     roc_auc       1.095721     0.040743                1.095721           0.040743            1       True          1\n",
            "Number of models trained: 22\n",
            "Types of models trained:\n",
            "{'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_TabularNeuralNetTorch', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_NNFastAiTabular', 'WeightedEnsembleModel', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_KNN'}\n",
            "Bagging used: True  (with 8 folds)\n",
            "Multi-layer stack-ensembling used: False \n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('float', [])     :  67 | ['Ozone', 'PM25', 'age_10_to_19', 'age_20s', 'age_30s', ...]\n",
            "('int', [])       :   2 | ['patient_age', 'patient_id']\n",
            "('int', ['bool']) : 128 | ['Division_East North Central', 'Division_East South Central', 'Division_Middle Atlantic', 'Division_Mountain', 'Division_New England', ...]\n",
            "Plot summary of models saved to file: AutogluonModels/ag-20240301_072026SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.leaderboard()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "jt9APxRUHR-2",
        "outputId": "92c0c431-fac0-49b0-d121-d56618b9308d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          model  score_val eval_metric  pred_time_val  \\\n",
              "0           WeightedEnsemble_L2   0.811697     roc_auc       7.910519   \n",
              "1           LightGBM_r96_BAG_L1   0.805760     roc_auc       0.635419   \n",
              "2               CatBoost_BAG_L1   0.801967     roc_auc       0.185964   \n",
              "3          CatBoost_r177_BAG_L1   0.801923     roc_auc       0.148374   \n",
              "4         NeuralNetTorch_BAG_L1   0.801447     roc_auc       0.708972   \n",
              "5             LightGBMXT_BAG_L1   0.801345     roc_auc       0.171019   \n",
              "6                XGBoost_BAG_L1   0.799970     roc_auc       0.342870   \n",
              "7     NeuralNetTorch_r22_BAG_L1   0.799596     roc_auc       0.914122   \n",
              "8          LightGBM_r131_BAG_L1   0.799005     roc_auc       0.491816   \n",
              "9               LightGBM_BAG_L1   0.798064     roc_auc       0.148318   \n",
              "10           CatBoost_r9_BAG_L1   0.797768     roc_auc       0.342915   \n",
              "11    NeuralNetTorch_r79_BAG_L1   0.796800     roc_auc       0.739916   \n",
              "12         LightGBMLarge_BAG_L1   0.795025     roc_auc       0.250936   \n",
              "13           XGBoost_r33_BAG_L1   0.793428     roc_auc       1.458996   \n",
              "14       NeuralNetFastAI_BAG_L1   0.790305     roc_auc       2.051354   \n",
              "15  NeuralNetFastAI_r191_BAG_L1   0.787834     roc_auc       1.117882   \n",
              "16        ExtraTreesEntr_BAG_L1   0.781522     roc_auc       1.140873   \n",
              "17        ExtraTreesGini_BAG_L1   0.780922     roc_auc       1.236930   \n",
              "18      RandomForestGini_BAG_L1   0.776305     roc_auc       1.132142   \n",
              "19      RandomForestEntr_BAG_L1   0.774883     roc_auc       0.996175   \n",
              "20        KNeighborsDist_BAG_L1   0.528695     roc_auc       1.062587   \n",
              "21        KNeighborsUnif_BAG_L1   0.523431     roc_auc       1.095721   \n",
              "\n",
              "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
              "0   1421.165047                0.003059           5.273566            2   \n",
              "1     51.909910                0.635419          51.909910            1   \n",
              "2    129.021427                0.185964         129.021427            1   \n",
              "3    120.020098                0.148374         120.020098            1   \n",
              "4    171.147193                0.708972         171.147193            1   \n",
              "5     48.992050                0.171019          48.992050            1   \n",
              "6     80.327472                0.342870          80.327472            1   \n",
              "7    254.541652                0.914122         254.541652            1   \n",
              "8     92.123951                0.491816          92.123951            1   \n",
              "9     58.251971                0.148318          58.251971            1   \n",
              "10   701.905660                0.342915         701.905660            1   \n",
              "11   210.834342                0.739916         210.834342            1   \n",
              "12   135.963794                0.250936         135.963794            1   \n",
              "13    75.993613                1.458996          75.993613            1   \n",
              "14   148.440747                2.051354         148.440747            1   \n",
              "15   249.610945                1.117882         249.610945            1   \n",
              "16    10.336342                1.140873          10.336342            1   \n",
              "17     8.069018                1.236930           8.069018            1   \n",
              "18    18.942669                1.132142          18.942669            1   \n",
              "19    19.513249                0.996175          19.513249            1   \n",
              "20     0.037696                1.062587           0.037696            1   \n",
              "21     0.040743                1.095721           0.040743            1   \n",
              "\n",
              "    can_infer  fit_order  \n",
              "0        True         22  \n",
              "1        True         19  \n",
              "2        True          7  \n",
              "3        True         14  \n",
              "4        True         12  \n",
              "5        True          3  \n",
              "6        True         11  \n",
              "7        True         20  \n",
              "8        True         16  \n",
              "9        True          4  \n",
              "10       True         18  \n",
              "11       True         15  \n",
              "12       True         13  \n",
              "13       True         21  \n",
              "14       True         10  \n",
              "15       True         17  \n",
              "16       True          9  \n",
              "17       True          8  \n",
              "18       True          5  \n",
              "19       True          6  \n",
              "20       True          2  \n",
              "21       True          1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1383199-7b52-46ac-b5e4-78f3f548f6b6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.811697</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>7.910519</td>\n",
              "      <td>1421.165047</td>\n",
              "      <td>0.003059</td>\n",
              "      <td>5.273566</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LightGBM_r96_BAG_L1</td>\n",
              "      <td>0.805760</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>0.635419</td>\n",
              "      <td>51.909910</td>\n",
              "      <td>0.635419</td>\n",
              "      <td>51.909910</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CatBoost_BAG_L1</td>\n",
              "      <td>0.801967</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>0.185964</td>\n",
              "      <td>129.021427</td>\n",
              "      <td>0.185964</td>\n",
              "      <td>129.021427</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CatBoost_r177_BAG_L1</td>\n",
              "      <td>0.801923</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>0.148374</td>\n",
              "      <td>120.020098</td>\n",
              "      <td>0.148374</td>\n",
              "      <td>120.020098</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NeuralNetTorch_BAG_L1</td>\n",
              "      <td>0.801447</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>0.708972</td>\n",
              "      <td>171.147193</td>\n",
              "      <td>0.708972</td>\n",
              "      <td>171.147193</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LightGBMXT_BAG_L1</td>\n",
              "      <td>0.801345</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>0.171019</td>\n",
              "      <td>48.992050</td>\n",
              "      <td>0.171019</td>\n",
              "      <td>48.992050</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>XGBoost_BAG_L1</td>\n",
              "      <td>0.799970</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>0.342870</td>\n",
              "      <td>80.327472</td>\n",
              "      <td>0.342870</td>\n",
              "      <td>80.327472</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NeuralNetTorch_r22_BAG_L1</td>\n",
              "      <td>0.799596</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>0.914122</td>\n",
              "      <td>254.541652</td>\n",
              "      <td>0.914122</td>\n",
              "      <td>254.541652</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LightGBM_r131_BAG_L1</td>\n",
              "      <td>0.799005</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>0.491816</td>\n",
              "      <td>92.123951</td>\n",
              "      <td>0.491816</td>\n",
              "      <td>92.123951</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>LightGBM_BAG_L1</td>\n",
              "      <td>0.798064</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>0.148318</td>\n",
              "      <td>58.251971</td>\n",
              "      <td>0.148318</td>\n",
              "      <td>58.251971</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CatBoost_r9_BAG_L1</td>\n",
              "      <td>0.797768</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>0.342915</td>\n",
              "      <td>701.905660</td>\n",
              "      <td>0.342915</td>\n",
              "      <td>701.905660</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NeuralNetTorch_r79_BAG_L1</td>\n",
              "      <td>0.796800</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>0.739916</td>\n",
              "      <td>210.834342</td>\n",
              "      <td>0.739916</td>\n",
              "      <td>210.834342</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>LightGBMLarge_BAG_L1</td>\n",
              "      <td>0.795025</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>0.250936</td>\n",
              "      <td>135.963794</td>\n",
              "      <td>0.250936</td>\n",
              "      <td>135.963794</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>XGBoost_r33_BAG_L1</td>\n",
              "      <td>0.793428</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.458996</td>\n",
              "      <td>75.993613</td>\n",
              "      <td>1.458996</td>\n",
              "      <td>75.993613</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NeuralNetFastAI_BAG_L1</td>\n",
              "      <td>0.790305</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>2.051354</td>\n",
              "      <td>148.440747</td>\n",
              "      <td>2.051354</td>\n",
              "      <td>148.440747</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NeuralNetFastAI_r191_BAG_L1</td>\n",
              "      <td>0.787834</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.117882</td>\n",
              "      <td>249.610945</td>\n",
              "      <td>1.117882</td>\n",
              "      <td>249.610945</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>ExtraTreesEntr_BAG_L1</td>\n",
              "      <td>0.781522</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.140873</td>\n",
              "      <td>10.336342</td>\n",
              "      <td>1.140873</td>\n",
              "      <td>10.336342</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>ExtraTreesGini_BAG_L1</td>\n",
              "      <td>0.780922</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.236930</td>\n",
              "      <td>8.069018</td>\n",
              "      <td>1.236930</td>\n",
              "      <td>8.069018</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>RandomForestGini_BAG_L1</td>\n",
              "      <td>0.776305</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.132142</td>\n",
              "      <td>18.942669</td>\n",
              "      <td>1.132142</td>\n",
              "      <td>18.942669</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>RandomForestEntr_BAG_L1</td>\n",
              "      <td>0.774883</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>0.996175</td>\n",
              "      <td>19.513249</td>\n",
              "      <td>0.996175</td>\n",
              "      <td>19.513249</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>KNeighborsDist_BAG_L1</td>\n",
              "      <td>0.528695</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.062587</td>\n",
              "      <td>0.037696</td>\n",
              "      <td>1.062587</td>\n",
              "      <td>0.037696</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>KNeighborsUnif_BAG_L1</td>\n",
              "      <td>0.523431</td>\n",
              "      <td>roc_auc</td>\n",
              "      <td>1.095721</td>\n",
              "      <td>0.040743</td>\n",
              "      <td>1.095721</td>\n",
              "      <td>0.040743</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1383199-7b52-46ac-b5e4-78f3f548f6b6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e1383199-7b52-46ac-b5e4-78f3f548f6b6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e1383199-7b52-46ac-b5e4-78f3f548f6b6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-912dee6f-8b31-4796-97c5-7fe709bedca1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-912dee6f-8b31-4796-97c5-7fe709bedca1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-912dee6f-8b31-4796-97c5-7fe709bedca1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 22,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"WeightedEnsemble_L2\",\n          \"XGBoost_r33_BAG_L1\",\n          \"LightGBM_r131_BAG_L1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07963149285490435,\n        \"min\": 0.5234314581748855,\n        \"max\": 0.811697497580069,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.811697497580069,\n          0.7934283988507248,\n          0.7990046833347417\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"roc_auc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5995639705766744,\n        \"min\": 0.14831781387329102,\n        \"max\": 7.910519123077393,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          7.910519123077393\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 315.09771294212857,\n        \"min\": 0.037695884704589844,\n        \"max\": 1421.1650474071503,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          1421.1650474071503\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5241267823674133,\n        \"min\": 0.00305938720703125,\n        \"max\": 2.051353693008423,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.00305938720703125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 152.7534234718091,\n        \"min\": 0.037695884704589844,\n        \"max\": 701.9056596755981,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          5.273565769195557\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 1,\n        \"max\": 22,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "a72LlRtDHbTk",
        "outputId": "71de4f23-1902-4eb2-86f3-f85ad08ff604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'WeightedEnsemble_L2' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-647a552dc917>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mWeightedEnsemble_L2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'WeightedEnsemble_L2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = predictor.predict_proba(test_data)\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "V_Seg7aMHidR",
        "outputId": "487a01a0-a48c-46bc-88e8-f6fa9cfe9ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1\n",
              "0  0.201597  0.798403\n",
              "1  0.264608  0.735392\n",
              "2  0.269376  0.730624\n",
              "3  0.268922  0.731078\n",
              "4  0.199024  0.800976"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d7a7dab8-62a5-4a71-82c2-b2de424d6ef3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.201597</td>\n",
              "      <td>0.798403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.264608</td>\n",
              "      <td>0.735392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.269376</td>\n",
              "      <td>0.730624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.268922</td>\n",
              "      <td>0.731078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.199024</td>\n",
              "      <td>0.800976</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7a7dab8-62a5-4a71-82c2-b2de424d6ef3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d7a7dab8-62a5-4a71-82c2-b2de424d6ef3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d7a7dab8-62a5-4a71-82c2-b2de424d6ef3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-685ae742-db31-4ed4-8d0f-89fb0f57f832\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-685ae742-db31-4ed4-8d0f-89fb0f57f832')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-685ae742-db31-4ed4-8d0f-89fb0f57f832 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5792,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2731194555018484,\n        \"min\": 0.09023457765579224,\n        \"max\": 0.9409571290016174,\n        \"num_unique_values\": 5787,\n        \"samples\": [\n          0.27043724060058594,\n          0.32589685916900635,\n          0.8897894620895386\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27311945547732114,\n        \"min\": 0.05904286354780197,\n        \"max\": 0.9097654223442078,\n        \"num_unique_values\": 5788,\n        \"samples\": [\n          0.7783832550048828,\n          0.7627888917922974,\n          0.11021054536104202\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn1PHXZEItFp",
        "outputId": "179012aa-9ddb-4a2a-dba0-a00003b94a19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5792, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data[]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "fB_DHzPiIiuo",
        "outputId": "c4ad6118-eae0-4665-d5bf-827c507ed91f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidIndexError",
          "evalue": "(slice(None, None, None), 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3791\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3792\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), 1)' is an invalid key",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-338b488065ee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DiagPeriodL90D'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msubmission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'patient_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DiagPeriodL90D'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3892\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3893\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3894\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3895\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;31m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3802\u001b[0m             \u001b[0;31m#  the TypeError.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3803\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3804\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5973\u001b[0m             \u001b[0;31m# if key is not a scalar, directly raise an error (the code below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5974\u001b[0m             \u001b[0;31m# would convert to numpy arrays and raise later any way) - GH29926\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5975\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5977\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Submission"
      ],
      "metadata": {
        "id": "1SEFKncIAMc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['patient_id']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUJYX0xFJgFf",
        "outputId": "9e6ec11f-a039-49cd-a080-ef76ce0c1fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       573710\n",
              "1       593679\n",
              "2       184532\n",
              "3       447383\n",
              "4       687972\n",
              "5       281312\n",
              "6       492714\n",
              "7       378266\n",
              "8       291550\n",
              "9       612272\n",
              "10      240105\n",
              "11      277939\n",
              "12      504153\n",
              "13      287269\n",
              "14      108727\n",
              "15      598629\n",
              "16      805201\n",
              "17      565624\n",
              "18      689369\n",
              "19      252028\n",
              "20      830503\n",
              "21      777454\n",
              "22      931410\n",
              "23      894910\n",
              "24      257477\n",
              "25      373935\n",
              "26      929645\n",
              "27      164064\n",
              "28      558677\n",
              "29      707003\n",
              "30      289528\n",
              "31      340932\n",
              "32      182933\n",
              "33      887761\n",
              "34      249345\n",
              "35      750357\n",
              "36      162816\n",
              "37      346740\n",
              "38      496264\n",
              "39      900330\n",
              "40      630418\n",
              "41      582166\n",
              "42      397291\n",
              "43      617035\n",
              "44      903270\n",
              "45      628977\n",
              "46      664844\n",
              "47      571761\n",
              "48      284488\n",
              "49      573502\n",
              "50      914179\n",
              "51      533295\n",
              "52      673470\n",
              "53      394209\n",
              "54      165379\n",
              "55      335343\n",
              "56      521842\n",
              "57      513091\n",
              "58      144195\n",
              "59      114345\n",
              "60      611289\n",
              "61      430995\n",
              "62      755430\n",
              "63      170191\n",
              "64      739107\n",
              "65      760626\n",
              "66      999890\n",
              "67      432271\n",
              "68      908248\n",
              "69      843808\n",
              "70      830973\n",
              "71      821535\n",
              "72      129401\n",
              "73      945227\n",
              "74      907148\n",
              "75      333105\n",
              "76      597610\n",
              "77      656576\n",
              "78      572936\n",
              "79      791246\n",
              "80      539117\n",
              "81      846332\n",
              "82      773311\n",
              "83      390700\n",
              "84      245861\n",
              "85      117200\n",
              "86      910365\n",
              "87      889359\n",
              "88      356730\n",
              "89      582721\n",
              "90      264810\n",
              "91      404647\n",
              "92      984242\n",
              "93      489913\n",
              "94      278092\n",
              "95      722543\n",
              "96      450269\n",
              "97      159696\n",
              "98      939772\n",
              "99      859963\n",
              "100     546293\n",
              "101     370096\n",
              "102     199460\n",
              "103     389409\n",
              "104     621491\n",
              "105     741740\n",
              "106     647251\n",
              "107     621415\n",
              "108     890667\n",
              "109     550001\n",
              "110     304847\n",
              "111     452103\n",
              "112     893146\n",
              "113     418688\n",
              "114     800121\n",
              "115     584986\n",
              "116     905101\n",
              "117     749893\n",
              "118     716844\n",
              "119     905428\n",
              "120     935993\n",
              "121     140144\n",
              "122     881549\n",
              "123     196104\n",
              "124     344874\n",
              "125     819944\n",
              "126     509637\n",
              "127     898595\n",
              "128     704924\n",
              "129     690345\n",
              "130     159329\n",
              "131     391239\n",
              "132     815166\n",
              "133     439346\n",
              "134     194281\n",
              "135     923054\n",
              "136     341458\n",
              "137     794949\n",
              "138     697292\n",
              "139     174377\n",
              "140     333090\n",
              "141     548516\n",
              "142     183136\n",
              "143     163024\n",
              "144     556826\n",
              "145     242884\n",
              "146     293877\n",
              "147     228022\n",
              "148     192394\n",
              "149     736880\n",
              "150     463738\n",
              "151     285355\n",
              "152     829856\n",
              "153     181057\n",
              "154     663297\n",
              "155     683154\n",
              "156     618395\n",
              "157     389506\n",
              "158     414665\n",
              "159     760719\n",
              "160     607969\n",
              "161     654560\n",
              "162     896522\n",
              "163     368283\n",
              "164     358159\n",
              "165     545787\n",
              "166     499717\n",
              "167     178237\n",
              "168     360804\n",
              "169     226657\n",
              "170     857385\n",
              "171     745310\n",
              "172     861737\n",
              "173     301647\n",
              "174     882124\n",
              "175     442582\n",
              "176     335826\n",
              "177     693715\n",
              "178     590261\n",
              "179     803586\n",
              "180     701432\n",
              "181     936699\n",
              "182     945991\n",
              "183     607557\n",
              "184     217652\n",
              "185     513924\n",
              "186     492557\n",
              "187     981041\n",
              "188     623610\n",
              "189     933659\n",
              "190     668374\n",
              "191     629977\n",
              "192     107948\n",
              "193     912357\n",
              "194     899955\n",
              "195     311072\n",
              "196     912986\n",
              "197     192517\n",
              "198     709239\n",
              "199     732236\n",
              "200     906000\n",
              "201     956357\n",
              "202     510884\n",
              "203     792098\n",
              "204     207826\n",
              "205     863432\n",
              "206     952556\n",
              "207     714411\n",
              "208     791052\n",
              "209     296062\n",
              "210     782440\n",
              "211     294559\n",
              "212     691722\n",
              "213     423757\n",
              "214     578668\n",
              "215     958723\n",
              "216     390134\n",
              "217     384768\n",
              "218     228092\n",
              "219     144823\n",
              "220     482011\n",
              "221     777373\n",
              "222     472005\n",
              "223     320833\n",
              "224     172845\n",
              "225     119468\n",
              "226     726600\n",
              "227     270864\n",
              "228     383008\n",
              "229     337705\n",
              "230     735950\n",
              "231     127122\n",
              "232     772450\n",
              "233     459016\n",
              "234     903231\n",
              "235     575442\n",
              "236     379055\n",
              "237     782622\n",
              "238     388791\n",
              "239     751886\n",
              "240     870353\n",
              "241     964874\n",
              "242     344627\n",
              "243     998707\n",
              "244     575280\n",
              "245     643958\n",
              "246     592454\n",
              "247     445422\n",
              "248     562542\n",
              "249     384019\n",
              "250     567222\n",
              "251     147542\n",
              "252     634369\n",
              "253     609584\n",
              "254     179795\n",
              "255     956348\n",
              "256     780943\n",
              "257     291831\n",
              "258     979758\n",
              "259     695828\n",
              "260     209909\n",
              "261     553580\n",
              "262     178239\n",
              "263     826433\n",
              "264     868839\n",
              "265     336046\n",
              "266     444549\n",
              "267     487833\n",
              "268     489805\n",
              "269     284563\n",
              "270     121728\n",
              "271     294393\n",
              "272     718727\n",
              "273     178823\n",
              "274     627522\n",
              "275     468390\n",
              "276     100497\n",
              "277     965060\n",
              "278     611579\n",
              "279     718302\n",
              "280     131506\n",
              "281     315616\n",
              "282     977555\n",
              "283     682937\n",
              "284     633729\n",
              "285     973961\n",
              "286     226250\n",
              "287     338940\n",
              "288     720427\n",
              "289     390459\n",
              "290     816410\n",
              "291     717436\n",
              "292     266993\n",
              "293     172505\n",
              "294     502155\n",
              "295     704624\n",
              "296     588485\n",
              "297     588195\n",
              "298     914207\n",
              "299     853565\n",
              "300     395710\n",
              "301     969305\n",
              "302     173028\n",
              "303     306525\n",
              "304     558108\n",
              "305     948892\n",
              "306     825528\n",
              "307     853585\n",
              "308     785262\n",
              "309     328135\n",
              "310     196061\n",
              "311     837859\n",
              "312     708517\n",
              "313     204729\n",
              "314     720667\n",
              "315     853954\n",
              "316     925846\n",
              "317     971653\n",
              "318     915251\n",
              "319     294713\n",
              "320     439086\n",
              "321     257395\n",
              "322     447586\n",
              "323     409216\n",
              "324     121801\n",
              "325     996348\n",
              "326     352183\n",
              "327     412323\n",
              "328     197516\n",
              "329     958656\n",
              "330     421599\n",
              "331     254907\n",
              "332     932494\n",
              "333     602427\n",
              "334     283565\n",
              "335     826043\n",
              "336     837896\n",
              "337     887078\n",
              "338     509999\n",
              "339     257314\n",
              "340     736590\n",
              "341     342233\n",
              "342     900996\n",
              "343     870987\n",
              "344     197279\n",
              "345     893569\n",
              "346     689467\n",
              "347     476266\n",
              "348     498613\n",
              "349     412086\n",
              "350     136926\n",
              "351     706286\n",
              "352     578050\n",
              "353     986339\n",
              "354     180002\n",
              "355     603073\n",
              "356     331199\n",
              "357     350740\n",
              "358     624825\n",
              "359     403977\n",
              "360     670059\n",
              "361     141169\n",
              "362     175279\n",
              "363     429725\n",
              "364     235641\n",
              "365     730523\n",
              "366     118404\n",
              "367     441893\n",
              "368     420533\n",
              "369     429009\n",
              "370     720396\n",
              "371     271433\n",
              "372     476393\n",
              "373     828857\n",
              "374     100925\n",
              "375     390780\n",
              "376     977312\n",
              "377     310110\n",
              "378     644082\n",
              "379     499157\n",
              "380     745648\n",
              "381     777637\n",
              "382     879798\n",
              "383     477660\n",
              "384     532387\n",
              "385     889529\n",
              "386     171196\n",
              "387     380261\n",
              "388     546542\n",
              "389     161795\n",
              "390     161770\n",
              "391     436885\n",
              "392     499013\n",
              "393     589852\n",
              "394     453054\n",
              "395     396878\n",
              "396     838625\n",
              "397     225426\n",
              "398     663740\n",
              "399     432680\n",
              "400     916655\n",
              "401     152918\n",
              "402     237573\n",
              "403     669330\n",
              "404     505141\n",
              "405     877408\n",
              "406     216508\n",
              "407     274662\n",
              "408     235463\n",
              "409     627880\n",
              "410     726901\n",
              "411     902557\n",
              "412     386410\n",
              "413     410135\n",
              "414     775806\n",
              "415     712939\n",
              "416     560808\n",
              "417     490190\n",
              "418     876335\n",
              "419     897188\n",
              "420     932857\n",
              "421     239829\n",
              "422     337922\n",
              "423     543911\n",
              "424     186626\n",
              "425     172543\n",
              "426     473529\n",
              "427     414229\n",
              "428     638019\n",
              "429     299686\n",
              "430     468551\n",
              "431     408762\n",
              "432     378832\n",
              "433     475157\n",
              "434     976728\n",
              "435     440817\n",
              "436     768075\n",
              "437     687927\n",
              "438     869098\n",
              "439     554033\n",
              "440     961553\n",
              "441     368843\n",
              "442     476213\n",
              "443     880673\n",
              "444     924444\n",
              "445     612823\n",
              "446     310020\n",
              "447     450801\n",
              "448     476722\n",
              "449     906308\n",
              "450     525700\n",
              "451     260024\n",
              "452     269245\n",
              "453     855181\n",
              "454     329959\n",
              "455     261983\n",
              "456     816790\n",
              "457     349007\n",
              "458     289545\n",
              "459     137857\n",
              "460     430868\n",
              "461     586496\n",
              "462     298865\n",
              "463     572463\n",
              "464     261804\n",
              "465     659112\n",
              "466     308794\n",
              "467     476170\n",
              "468     833523\n",
              "469     647463\n",
              "470     351422\n",
              "471     751142\n",
              "472     955768\n",
              "473     290355\n",
              "474     127452\n",
              "475     522842\n",
              "476     240482\n",
              "477     710353\n",
              "478     229437\n",
              "479     770901\n",
              "480     884495\n",
              "481     837180\n",
              "482     285182\n",
              "483     519045\n",
              "484     940114\n",
              "485     907458\n",
              "486     447074\n",
              "487     621318\n",
              "488     901204\n",
              "489     635830\n",
              "490     115224\n",
              "491     228655\n",
              "492     173706\n",
              "493     285463\n",
              "494     326473\n",
              "495     350180\n",
              "496     760533\n",
              "497     830918\n",
              "498     513358\n",
              "499     124051\n",
              "500     512848\n",
              "501     332249\n",
              "502     216701\n",
              "503     905016\n",
              "504     348995\n",
              "505     839215\n",
              "506     559043\n",
              "507     465097\n",
              "508     578255\n",
              "509     688318\n",
              "510     561314\n",
              "511     641723\n",
              "512     817795\n",
              "513     865297\n",
              "514     391910\n",
              "515     435896\n",
              "516     331157\n",
              "517     349490\n",
              "518     873571\n",
              "519     164109\n",
              "520     488609\n",
              "521     148260\n",
              "522     298403\n",
              "523     640476\n",
              "524     288946\n",
              "525     848280\n",
              "526     490585\n",
              "527     472104\n",
              "528     292927\n",
              "529     399307\n",
              "530     129607\n",
              "531     841160\n",
              "532     517262\n",
              "533     540850\n",
              "534     392127\n",
              "535     679795\n",
              "536     245144\n",
              "537     701966\n",
              "538     322021\n",
              "539     629922\n",
              "540     393445\n",
              "541     390657\n",
              "542     911933\n",
              "543     913187\n",
              "544     272584\n",
              "545     441777\n",
              "546     801841\n",
              "547     441955\n",
              "548     403798\n",
              "549     159980\n",
              "550     856720\n",
              "551     251066\n",
              "552     508083\n",
              "553     822097\n",
              "554     526824\n",
              "555     729301\n",
              "556     604289\n",
              "557     755924\n",
              "558     308487\n",
              "559     853934\n",
              "560     615106\n",
              "561     502071\n",
              "562     288165\n",
              "563     255935\n",
              "564     187600\n",
              "565     695093\n",
              "566     265735\n",
              "567     883811\n",
              "568     163043\n",
              "569     267433\n",
              "570     611687\n",
              "571     933906\n",
              "572     115256\n",
              "573     256580\n",
              "574     251012\n",
              "575     615735\n",
              "576     145367\n",
              "577     261173\n",
              "578     233620\n",
              "579     700745\n",
              "580     942458\n",
              "581     555901\n",
              "582     505357\n",
              "583     395867\n",
              "584     350433\n",
              "585     282331\n",
              "586     618582\n",
              "587     668590\n",
              "588     980192\n",
              "589     551492\n",
              "590     702296\n",
              "591     166251\n",
              "592     417550\n",
              "593     621270\n",
              "594     448062\n",
              "595     402164\n",
              "596     800222\n",
              "597     576673\n",
              "598     117074\n",
              "599     283495\n",
              "600     567923\n",
              "601     782592\n",
              "602     381028\n",
              "603     232956\n",
              "604     582716\n",
              "605     805183\n",
              "606     312830\n",
              "607     799703\n",
              "608     833868\n",
              "609     140424\n",
              "610     797608\n",
              "611     592507\n",
              "612     317755\n",
              "613     715198\n",
              "614     604089\n",
              "615     894083\n",
              "616     810551\n",
              "617     577948\n",
              "618     585343\n",
              "619     492104\n",
              "620     316678\n",
              "621     750521\n",
              "622     740527\n",
              "623     792379\n",
              "624     976412\n",
              "625     567138\n",
              "626     889826\n",
              "627     183939\n",
              "628     689215\n",
              "629     691139\n",
              "630     569650\n",
              "631     279800\n",
              "632     108005\n",
              "633     349062\n",
              "634     725825\n",
              "635     742040\n",
              "636     787540\n",
              "637     990715\n",
              "638     892179\n",
              "639     194577\n",
              "640     988732\n",
              "641     925311\n",
              "642     168620\n",
              "643     561094\n",
              "644     497739\n",
              "645     999134\n",
              "646     644167\n",
              "647     824211\n",
              "648     305790\n",
              "649     555690\n",
              "650     745810\n",
              "651     999443\n",
              "652     872223\n",
              "653     353776\n",
              "654     995834\n",
              "655     591665\n",
              "656     873173\n",
              "657     757034\n",
              "658     141116\n",
              "659     697467\n",
              "660     985387\n",
              "661     864345\n",
              "662     190889\n",
              "663     789646\n",
              "664     325154\n",
              "665     921888\n",
              "666     561435\n",
              "667     551462\n",
              "668     701293\n",
              "669     806746\n",
              "670     534682\n",
              "671     724963\n",
              "672     845348\n",
              "673     384744\n",
              "674     616542\n",
              "675     539469\n",
              "676     423735\n",
              "677     179254\n",
              "678     964733\n",
              "679     171795\n",
              "680     641212\n",
              "681     869902\n",
              "682     532444\n",
              "683     171457\n",
              "684     953228\n",
              "685     118339\n",
              "686     494683\n",
              "687     822166\n",
              "688     262333\n",
              "689     542466\n",
              "690     202336\n",
              "691     837915\n",
              "692     141271\n",
              "693     686314\n",
              "694     871493\n",
              "695     708870\n",
              "696     565816\n",
              "697     572673\n",
              "698     994817\n",
              "699     657003\n",
              "700     207629\n",
              "701     126132\n",
              "702     790757\n",
              "703     136610\n",
              "704     424401\n",
              "705     151748\n",
              "706     662568\n",
              "707     826361\n",
              "708     106579\n",
              "709     424742\n",
              "710     645789\n",
              "711     802038\n",
              "712     984299\n",
              "713     487207\n",
              "714     518425\n",
              "715     964477\n",
              "716     420489\n",
              "717     526742\n",
              "718     687981\n",
              "719     326037\n",
              "720     558137\n",
              "721     816306\n",
              "722     357087\n",
              "723     725885\n",
              "724     484443\n",
              "725     229712\n",
              "726     873528\n",
              "727     875865\n",
              "728     448337\n",
              "729     878580\n",
              "730     974934\n",
              "731     722887\n",
              "732     600953\n",
              "733     201864\n",
              "734     988504\n",
              "735     776907\n",
              "736     970063\n",
              "737     543716\n",
              "738     225412\n",
              "739     250328\n",
              "740     581483\n",
              "741     588171\n",
              "742     591054\n",
              "743     530438\n",
              "744     915963\n",
              "745     152990\n",
              "746     662011\n",
              "747     533075\n",
              "748     686979\n",
              "749     225836\n",
              "750     151812\n",
              "751     966552\n",
              "752     209119\n",
              "753     812648\n",
              "754     870046\n",
              "755     967802\n",
              "756     462861\n",
              "757     452539\n",
              "758     994460\n",
              "759     115623\n",
              "760     416935\n",
              "761     984561\n",
              "762     834165\n",
              "763     641252\n",
              "764     318124\n",
              "765     501659\n",
              "766     586644\n",
              "767     648413\n",
              "768     114662\n",
              "769     444737\n",
              "770     558229\n",
              "771     292491\n",
              "772     558856\n",
              "773     358191\n",
              "774     974325\n",
              "775     580779\n",
              "776     560680\n",
              "777     292638\n",
              "778     808001\n",
              "779     161525\n",
              "780     924014\n",
              "781     503800\n",
              "782     787136\n",
              "783     239167\n",
              "784     857686\n",
              "785     106339\n",
              "786     520816\n",
              "787     389933\n",
              "788     605816\n",
              "789     513090\n",
              "790     956603\n",
              "791     724886\n",
              "792     680311\n",
              "793     576431\n",
              "794     591191\n",
              "795     205777\n",
              "796     431898\n",
              "797     465135\n",
              "798     687868\n",
              "799     445218\n",
              "800     613436\n",
              "801     919890\n",
              "802     423134\n",
              "803     290439\n",
              "804     753878\n",
              "805     674218\n",
              "806     752143\n",
              "807     360191\n",
              "808     940758\n",
              "809     728956\n",
              "810     611492\n",
              "811     792422\n",
              "812     381825\n",
              "813     663366\n",
              "814     379486\n",
              "815     744732\n",
              "816     239235\n",
              "817     764236\n",
              "818     212467\n",
              "819     830603\n",
              "820     444100\n",
              "821     895114\n",
              "822     990522\n",
              "823     340521\n",
              "824     961430\n",
              "825     912100\n",
              "826     812924\n",
              "827     227782\n",
              "828     195851\n",
              "829     372453\n",
              "830     107367\n",
              "831     511733\n",
              "832     567454\n",
              "833     597830\n",
              "834     543315\n",
              "835     624883\n",
              "836     988735\n",
              "837     311121\n",
              "838     664695\n",
              "839     582250\n",
              "840     549079\n",
              "841     297160\n",
              "842     963584\n",
              "843     314155\n",
              "844     455120\n",
              "845     459752\n",
              "846     957105\n",
              "847     816933\n",
              "848     621145\n",
              "849     418164\n",
              "850     283560\n",
              "851     193131\n",
              "852     698116\n",
              "853     703234\n",
              "854     233639\n",
              "855     462039\n",
              "856     251198\n",
              "857     325694\n",
              "858     308223\n",
              "859     183464\n",
              "860     939495\n",
              "861     587874\n",
              "862     818684\n",
              "863     732174\n",
              "864     664092\n",
              "865     604411\n",
              "866     367348\n",
              "867     526466\n",
              "868     538906\n",
              "869     538479\n",
              "870     236782\n",
              "871     674923\n",
              "872     626611\n",
              "873     866541\n",
              "874     619918\n",
              "875     756817\n",
              "876     131928\n",
              "877     157040\n",
              "878     875176\n",
              "879     606779\n",
              "880     315580\n",
              "881     835287\n",
              "882     131890\n",
              "883     963121\n",
              "884     843094\n",
              "885     499401\n",
              "886     401767\n",
              "887     802316\n",
              "888     426107\n",
              "889     919814\n",
              "890     519664\n",
              "891     616547\n",
              "892     199318\n",
              "893     305859\n",
              "894     908183\n",
              "895     500458\n",
              "896     961543\n",
              "897     821913\n",
              "898     852647\n",
              "899     402090\n",
              "900     480064\n",
              "901     462760\n",
              "902     488530\n",
              "903     566942\n",
              "904     544829\n",
              "905     649281\n",
              "906     482878\n",
              "907     159693\n",
              "908     106788\n",
              "909     145082\n",
              "910     428504\n",
              "911     111997\n",
              "912     258166\n",
              "913     988325\n",
              "914     714531\n",
              "915     704486\n",
              "916     960922\n",
              "917     537180\n",
              "918     545107\n",
              "919     871177\n",
              "920     539145\n",
              "921     968027\n",
              "922     630999\n",
              "923     427720\n",
              "924     317065\n",
              "925     398811\n",
              "926     354449\n",
              "927     689496\n",
              "928     576522\n",
              "929     809803\n",
              "930     538332\n",
              "931     464623\n",
              "932     617837\n",
              "933     195985\n",
              "934     266542\n",
              "935     454384\n",
              "936     904643\n",
              "937     300090\n",
              "938     967953\n",
              "939     326820\n",
              "940     754211\n",
              "941     640598\n",
              "942     366548\n",
              "943     309532\n",
              "944     525257\n",
              "945     861804\n",
              "946     671557\n",
              "947     198291\n",
              "948     992706\n",
              "949     832133\n",
              "950     546489\n",
              "951     944237\n",
              "952     821755\n",
              "953     930822\n",
              "954     387588\n",
              "955     708020\n",
              "956     793705\n",
              "957     392759\n",
              "958     739840\n",
              "959     210991\n",
              "960     674067\n",
              "961     284126\n",
              "962     843456\n",
              "963     937937\n",
              "964     158523\n",
              "965     954204\n",
              "966     622729\n",
              "967     980144\n",
              "968     400395\n",
              "969     981863\n",
              "970     964596\n",
              "971     271135\n",
              "972     105632\n",
              "973     371037\n",
              "974     463734\n",
              "975     381943\n",
              "976     146031\n",
              "977     129258\n",
              "978     507899\n",
              "979     671381\n",
              "980     581924\n",
              "981     404565\n",
              "982     110435\n",
              "983     267408\n",
              "984     227577\n",
              "985     754105\n",
              "986     880826\n",
              "987     311462\n",
              "988     213729\n",
              "989     192464\n",
              "990     810472\n",
              "991     782552\n",
              "992     615246\n",
              "993     556670\n",
              "994     428779\n",
              "995     243322\n",
              "996     862927\n",
              "997     380891\n",
              "998     796144\n",
              "999     332319\n",
              "1000    855385\n",
              "1001    550063\n",
              "1002    200098\n",
              "1003    533117\n",
              "1004    612749\n",
              "1005    248874\n",
              "1006    514141\n",
              "1007    210183\n",
              "1008    934781\n",
              "1009    839265\n",
              "1010    352036\n",
              "1011    440785\n",
              "1012    627854\n",
              "1013    698724\n",
              "1014    294676\n",
              "1015    151818\n",
              "1016    896586\n",
              "1017    722114\n",
              "1018    400788\n",
              "1019    660643\n",
              "1020    793346\n",
              "1021    985843\n",
              "1022    712577\n",
              "1023    580160\n",
              "1024    855122\n",
              "1025    472152\n",
              "1026    362912\n",
              "1027    969752\n",
              "1028    993542\n",
              "1029    195056\n",
              "1030    552471\n",
              "1031    808112\n",
              "1032    428474\n",
              "1033    893359\n",
              "1034    259326\n",
              "1035    943924\n",
              "1036    819703\n",
              "1037    806560\n",
              "1038    638443\n",
              "1039    823695\n",
              "1040    606702\n",
              "1041    390274\n",
              "1042    990132\n",
              "1043    709479\n",
              "1044    869494\n",
              "1045    929283\n",
              "1046    940648\n",
              "1047    874726\n",
              "1048    530449\n",
              "1049    777202\n",
              "1050    998202\n",
              "1051    656126\n",
              "1052    942078\n",
              "1053    134721\n",
              "1054    776938\n",
              "1055    493075\n",
              "1056    545718\n",
              "1057    644733\n",
              "1058    774485\n",
              "1059    515220\n",
              "1060    981905\n",
              "1061    965067\n",
              "1062    518893\n",
              "1063    511022\n",
              "1064    388945\n",
              "1065    831886\n",
              "1066    748692\n",
              "1067    859114\n",
              "1068    734682\n",
              "1069    879096\n",
              "1070    851678\n",
              "1071    525853\n",
              "1072    857313\n",
              "1073    227745\n",
              "1074    648282\n",
              "1075    300278\n",
              "1076    393302\n",
              "1077    157910\n",
              "1078    107997\n",
              "1079    135548\n",
              "1080    103619\n",
              "1081    362946\n",
              "1082    938003\n",
              "1083    807433\n",
              "1084    300764\n",
              "1085    486914\n",
              "1086    686911\n",
              "1087    238928\n",
              "1088    646016\n",
              "1089    610013\n",
              "1090    341006\n",
              "1091    415225\n",
              "1092    709409\n",
              "1093    819511\n",
              "1094    606025\n",
              "1095    222563\n",
              "1096    170882\n",
              "1097    683053\n",
              "1098    689133\n",
              "1099    147074\n",
              "1100    266496\n",
              "1101    932145\n",
              "1102    865732\n",
              "1103    790417\n",
              "1104    770077\n",
              "1105    155669\n",
              "1106    843197\n",
              "1107    145907\n",
              "1108    394289\n",
              "1109    716611\n",
              "1110    577953\n",
              "1111    564684\n",
              "1112    243856\n",
              "1113    822801\n",
              "1114    467649\n",
              "1115    668503\n",
              "1116    723525\n",
              "1117    801348\n",
              "1118    104639\n",
              "1119    250108\n",
              "1120    258236\n",
              "1121    286342\n",
              "1122    519494\n",
              "1123    909175\n",
              "1124    315112\n",
              "1125    326967\n",
              "1126    206159\n",
              "1127    294747\n",
              "1128    277519\n",
              "1129    852696\n",
              "1130    803374\n",
              "1131    953468\n",
              "1132    640410\n",
              "1133    559763\n",
              "1134    408304\n",
              "1135    890561\n",
              "1136    674435\n",
              "1137    519053\n",
              "1138    944571\n",
              "1139    615967\n",
              "1140    470982\n",
              "1141    266210\n",
              "1142    213653\n",
              "1143    205886\n",
              "1144    668876\n",
              "1145    854753\n",
              "1146    975985\n",
              "1147    144636\n",
              "1148    373702\n",
              "1149    751057\n",
              "1150    988179\n",
              "1151    836151\n",
              "1152    199551\n",
              "1153    230403\n",
              "1154    508803\n",
              "1155    898813\n",
              "1156    264170\n",
              "1157    472387\n",
              "1158    221377\n",
              "1159    804911\n",
              "1160    157592\n",
              "1161    366587\n",
              "1162    706969\n",
              "1163    561151\n",
              "1164    384544\n",
              "1165    451004\n",
              "1166    934193\n",
              "1167    197865\n",
              "1168    833557\n",
              "1169    383116\n",
              "1170    993358\n",
              "1171    321689\n",
              "1172    685083\n",
              "1173    666125\n",
              "1174    409023\n",
              "1175    516818\n",
              "1176    960917\n",
              "1177    812702\n",
              "1178    929897\n",
              "1179    393077\n",
              "1180    338333\n",
              "1181    150567\n",
              "1182    822257\n",
              "1183    559477\n",
              "1184    482805\n",
              "1185    834519\n",
              "1186    351760\n",
              "1187    515449\n",
              "1188    884026\n",
              "1189    863203\n",
              "1190    696402\n",
              "1191    463242\n",
              "1192    881726\n",
              "1193    692507\n",
              "1194    408807\n",
              "1195    259341\n",
              "1196    190341\n",
              "1197    814338\n",
              "1198    684859\n",
              "1199    437587\n",
              "1200    707188\n",
              "1201    995779\n",
              "1202    433999\n",
              "1203    713976\n",
              "1204    380318\n",
              "1205    781467\n",
              "1206    159511\n",
              "1207    302523\n",
              "1208    455985\n",
              "1209    545761\n",
              "1210    538585\n",
              "1211    906671\n",
              "1212    274594\n",
              "1213    100782\n",
              "1214    255542\n",
              "1215    144341\n",
              "1216    870903\n",
              "1217    107288\n",
              "1218    311864\n",
              "1219    953984\n",
              "1220    832167\n",
              "1221    935768\n",
              "1222    133555\n",
              "1223    397822\n",
              "1224    978066\n",
              "1225    581246\n",
              "1226    370593\n",
              "1227    971482\n",
              "1228    618591\n",
              "1229    676131\n",
              "1230    524368\n",
              "1231    532316\n",
              "1232    882458\n",
              "1233    544577\n",
              "1234    272639\n",
              "1235    581634\n",
              "1236    939852\n",
              "1237    475482\n",
              "1238    106241\n",
              "1239    678770\n",
              "1240    348125\n",
              "1241    365355\n",
              "1242    186302\n",
              "1243    932165\n",
              "1244    861260\n",
              "1245    489098\n",
              "1246    219669\n",
              "1247    250654\n",
              "1248    249314\n",
              "1249    208355\n",
              "1250    444958\n",
              "1251    105399\n",
              "1252    972415\n",
              "1253    633349\n",
              "1254    236320\n",
              "1255    704980\n",
              "1256    627820\n",
              "1257    732483\n",
              "1258    814485\n",
              "1259    880275\n",
              "1260    315690\n",
              "1261    913964\n",
              "1262    641456\n",
              "1263    186902\n",
              "1264    414349\n",
              "1265    426923\n",
              "1266    216298\n",
              "1267    917682\n",
              "1268    653028\n",
              "1269    732186\n",
              "1270    464644\n",
              "1271    193356\n",
              "1272    948497\n",
              "1273    714332\n",
              "1274    873897\n",
              "1275    983121\n",
              "1276    112656\n",
              "1277    627662\n",
              "1278    453219\n",
              "1279    438484\n",
              "1280    689240\n",
              "1281    325435\n",
              "1282    947010\n",
              "1283    933046\n",
              "1284    704122\n",
              "1285    263500\n",
              "1286    809802\n",
              "1287    960931\n",
              "1288    664566\n",
              "1289    811194\n",
              "1290    503951\n",
              "1291    630546\n",
              "1292    233933\n",
              "1293    127034\n",
              "1294    920725\n",
              "1295    390962\n",
              "1296    568881\n",
              "1297    421712\n",
              "1298    787180\n",
              "1299    164413\n",
              "1300    764584\n",
              "1301    318884\n",
              "1302    819570\n",
              "1303    707004\n",
              "1304    318655\n",
              "1305    919591\n",
              "1306    931900\n",
              "1307    221171\n",
              "1308    855956\n",
              "1309    738425\n",
              "1310    595827\n",
              "1311    357163\n",
              "1312    999031\n",
              "1313    820131\n",
              "1314    759478\n",
              "1315    255200\n",
              "1316    545104\n",
              "1317    160892\n",
              "1318    705093\n",
              "1319    413697\n",
              "1320    701915\n",
              "1321    894305\n",
              "1322    402009\n",
              "1323    558692\n",
              "1324    396035\n",
              "1325    446739\n",
              "1326    928640\n",
              "1327    109325\n",
              "1328    742403\n",
              "1329    249327\n",
              "1330    826976\n",
              "1331    874262\n",
              "1332    442909\n",
              "1333    821196\n",
              "1334    267272\n",
              "1335    952444\n",
              "1336    628383\n",
              "1337    557274\n",
              "1338    177041\n",
              "1339    212608\n",
              "1340    676539\n",
              "1341    876687\n",
              "1342    535976\n",
              "1343    848891\n",
              "1344    671730\n",
              "1345    179047\n",
              "1346    664463\n",
              "1347    338069\n",
              "1348    821161\n",
              "1349    791303\n",
              "1350    469087\n",
              "1351    110920\n",
              "1352    406022\n",
              "1353    566021\n",
              "1354    543780\n",
              "1355    551719\n",
              "1356    195013\n",
              "1357    907452\n",
              "1358    305313\n",
              "1359    344279\n",
              "1360    577154\n",
              "1361    667425\n",
              "1362    445362\n",
              "1363    826722\n",
              "1364    131853\n",
              "1365    286852\n",
              "1366    847322\n",
              "1367    120099\n",
              "1368    900084\n",
              "1369    581269\n",
              "1370    190988\n",
              "1371    460250\n",
              "1372    970874\n",
              "1373    964885\n",
              "1374    564556\n",
              "1375    440203\n",
              "1376    864455\n",
              "1377    104903\n",
              "1378    361511\n",
              "1379    778775\n",
              "1380    709633\n",
              "1381    677609\n",
              "1382    121268\n",
              "1383    578904\n",
              "1384    720753\n",
              "1385    162421\n",
              "1386    426656\n",
              "1387    781981\n",
              "1388    835983\n",
              "1389    285631\n",
              "1390    516603\n",
              "1391    540935\n",
              "1392    445005\n",
              "1393    880363\n",
              "1394    928620\n",
              "1395    667322\n",
              "1396    931343\n",
              "1397    761283\n",
              "1398    973764\n",
              "1399    753645\n",
              "1400    909938\n",
              "1401    200009\n",
              "1402    936543\n",
              "1403    275738\n",
              "1404    950426\n",
              "1405    426866\n",
              "1406    264728\n",
              "1407    871925\n",
              "1408    494194\n",
              "1409    715892\n",
              "1410    860740\n",
              "1411    391918\n",
              "1412    926168\n",
              "1413    721598\n",
              "1414    443074\n",
              "1415    631054\n",
              "1416    173569\n",
              "1417    509928\n",
              "1418    226406\n",
              "1419    636714\n",
              "1420    654767\n",
              "1421    899374\n",
              "1422    654915\n",
              "1423    176375\n",
              "1424    149181\n",
              "1425    846186\n",
              "1426    348079\n",
              "1427    757936\n",
              "1428    391073\n",
              "1429    147006\n",
              "1430    897454\n",
              "1431    405254\n",
              "1432    173315\n",
              "1433    511334\n",
              "1434    804051\n",
              "1435    312064\n",
              "1436    789000\n",
              "1437    511148\n",
              "1438    630576\n",
              "1439    603466\n",
              "1440    123465\n",
              "1441    114710\n",
              "1442    293934\n",
              "1443    907552\n",
              "1444    599286\n",
              "1445    627084\n",
              "1446    217317\n",
              "1447    188475\n",
              "1448    810727\n",
              "1449    412944\n",
              "1450    535253\n",
              "1451    175523\n",
              "1452    419037\n",
              "1453    286641\n",
              "1454    849570\n",
              "1455    273104\n",
              "1456    508001\n",
              "1457    757735\n",
              "1458    482007\n",
              "1459    478229\n",
              "1460    419170\n",
              "1461    223876\n",
              "1462    311321\n",
              "1463    360039\n",
              "1464    225420\n",
              "1465    376192\n",
              "1466    351556\n",
              "1467    481100\n",
              "1468    566275\n",
              "1469    815199\n",
              "1470    585553\n",
              "1471    474987\n",
              "1472    649765\n",
              "1473    823626\n",
              "1474    847341\n",
              "1475    562282\n",
              "1476    982210\n",
              "1477    469282\n",
              "1478    711473\n",
              "1479    722741\n",
              "1480    131787\n",
              "1481    241205\n",
              "1482    903720\n",
              "1483    763264\n",
              "1484    111205\n",
              "1485    243453\n",
              "1486    741024\n",
              "1487    932307\n",
              "1488    685097\n",
              "1489    273178\n",
              "1490    684312\n",
              "1491    282480\n",
              "1492    497407\n",
              "1493    494613\n",
              "1494    248712\n",
              "1495    224504\n",
              "1496    840718\n",
              "1497    400245\n",
              "1498    918560\n",
              "1499    857394\n",
              "1500    330666\n",
              "1501    229434\n",
              "1502    130472\n",
              "1503    941816\n",
              "1504    332753\n",
              "1505    197259\n",
              "1506    687200\n",
              "1507    530657\n",
              "1508    231980\n",
              "1509    503483\n",
              "1510    828114\n",
              "1511    593037\n",
              "1512    922614\n",
              "1513    609138\n",
              "1514    951397\n",
              "1515    176407\n",
              "1516    977357\n",
              "1517    130414\n",
              "1518    838898\n",
              "1519    275468\n",
              "1520    360513\n",
              "1521    663453\n",
              "1522    793511\n",
              "1523    592103\n",
              "1524    288178\n",
              "1525    800018\n",
              "1526    131126\n",
              "1527    710401\n",
              "1528    386393\n",
              "1529    859462\n",
              "1530    107248\n",
              "1531    707565\n",
              "1532    102257\n",
              "1533    343260\n",
              "1534    214345\n",
              "1535    578180\n",
              "1536    994131\n",
              "1537    390944\n",
              "1538    730269\n",
              "1539    239260\n",
              "1540    476634\n",
              "1541    897492\n",
              "1542    222216\n",
              "1543    960971\n",
              "1544    432035\n",
              "1545    886336\n",
              "1546    154702\n",
              "1547    273036\n",
              "1548    687979\n",
              "1549    967782\n",
              "1550    962978\n",
              "1551    344184\n",
              "1552    715788\n",
              "1553    705124\n",
              "1554    506675\n",
              "1555    385153\n",
              "1556    950040\n",
              "1557    448405\n",
              "1558    162615\n",
              "1559    120000\n",
              "1560    148141\n",
              "1561    707965\n",
              "1562    603017\n",
              "1563    116671\n",
              "1564    128141\n",
              "1565    636745\n",
              "1566    265912\n",
              "1567    782302\n",
              "1568    946518\n",
              "1569    519532\n",
              "1570    146436\n",
              "1571    246585\n",
              "1572    948009\n",
              "1573    217478\n",
              "1574    678349\n",
              "1575    295918\n",
              "1576    713347\n",
              "1577    550850\n",
              "1578    943300\n",
              "1579    806999\n",
              "1580    743514\n",
              "1581    701772\n",
              "1582    141029\n",
              "1583    636354\n",
              "1584    651063\n",
              "1585    990335\n",
              "1586    492490\n",
              "1587    799438\n",
              "1588    126140\n",
              "1589    970790\n",
              "1590    560322\n",
              "1591    921152\n",
              "1592    796605\n",
              "1593    596665\n",
              "1594    319619\n",
              "1595    376324\n",
              "1596    951614\n",
              "1597    547096\n",
              "1598    575449\n",
              "1599    218610\n",
              "1600    585776\n",
              "1601    826849\n",
              "1602    166117\n",
              "1603    436753\n",
              "1604    448508\n",
              "1605    604478\n",
              "1606    960613\n",
              "1607    956804\n",
              "1608    717941\n",
              "1609    172795\n",
              "1610    494639\n",
              "1611    250763\n",
              "1612    318503\n",
              "1613    266800\n",
              "1614    171013\n",
              "1615    693075\n",
              "1616    423339\n",
              "1617    772179\n",
              "1618    479034\n",
              "1619    754994\n",
              "1620    884561\n",
              "1621    445352\n",
              "1622    408585\n",
              "1623    785793\n",
              "1624    714620\n",
              "1625    483187\n",
              "1626    367738\n",
              "1627    183996\n",
              "1628    466933\n",
              "1629    959665\n",
              "1630    490778\n",
              "1631    781466\n",
              "1632    619780\n",
              "1633    437612\n",
              "1634    802280\n",
              "1635    885428\n",
              "1636    759479\n",
              "1637    596720\n",
              "1638    951372\n",
              "1639    775907\n",
              "1640    738731\n",
              "1641    250839\n",
              "1642    196251\n",
              "1643    358613\n",
              "1644    829274\n",
              "1645    145975\n",
              "1646    499629\n",
              "1647    518172\n",
              "1648    868649\n",
              "1649    831465\n",
              "1650    738780\n",
              "1651    626096\n",
              "1652    966135\n",
              "1653    830815\n",
              "1654    265386\n",
              "1655    794213\n",
              "1656    957610\n",
              "1657    869455\n",
              "1658    902179\n",
              "1659    791697\n",
              "1660    148848\n",
              "1661    552930\n",
              "1662    147627\n",
              "1663    782072\n",
              "1664    339805\n",
              "1665    868937\n",
              "1666    891058\n",
              "1667    831492\n",
              "1668    259021\n",
              "1669    523145\n",
              "1670    415688\n",
              "1671    364547\n",
              "1672    282641\n",
              "1673    264757\n",
              "1674    453703\n",
              "1675    731497\n",
              "1676    933937\n",
              "1677    223373\n",
              "1678    933418\n",
              "1679    217046\n",
              "1680    177629\n",
              "1681    753865\n",
              "1682    526732\n",
              "1683    708861\n",
              "1684    854995\n",
              "1685    556115\n",
              "1686    733440\n",
              "1687    987572\n",
              "1688    587358\n",
              "1689    466817\n",
              "1690    385582\n",
              "1691    802645\n",
              "1692    300303\n",
              "1693    219525\n",
              "1694    409128\n",
              "1695    832022\n",
              "1696    384855\n",
              "1697    547141\n",
              "1698    761578\n",
              "1699    490151\n",
              "1700    964832\n",
              "1701    945457\n",
              "1702    189557\n",
              "1703    614382\n",
              "1704    834338\n",
              "1705    198971\n",
              "1706    752635\n",
              "1707    918774\n",
              "1708    451234\n",
              "1709    875402\n",
              "1710    232223\n",
              "1711    679045\n",
              "1712    244004\n",
              "1713    733220\n",
              "1714    647081\n",
              "1715    827041\n",
              "1716    318886\n",
              "1717    127075\n",
              "1718    608152\n",
              "1719    557021\n",
              "1720    374036\n",
              "1721    686080\n",
              "1722    259541\n",
              "1723    211199\n",
              "1724    394979\n",
              "1725    831582\n",
              "1726    409384\n",
              "1727    100806\n",
              "1728    629562\n",
              "1729    846834\n",
              "1730    143478\n",
              "1731    377637\n",
              "1732    649401\n",
              "1733    906791\n",
              "1734    262672\n",
              "1735    732739\n",
              "1736    760843\n",
              "1737    136274\n",
              "1738    266153\n",
              "1739    580122\n",
              "1740    455198\n",
              "1741    782801\n",
              "1742    113357\n",
              "1743    366087\n",
              "1744    211379\n",
              "1745    714418\n",
              "1746    295515\n",
              "1747    566600\n",
              "1748    975442\n",
              "1749    552097\n",
              "1750    498359\n",
              "1751    246280\n",
              "1752    252752\n",
              "1753    226187\n",
              "1754    372938\n",
              "1755    262955\n",
              "1756    730188\n",
              "1757    255718\n",
              "1758    888143\n",
              "1759    364967\n",
              "1760    322475\n",
              "1761    811745\n",
              "1762    272129\n",
              "1763    615976\n",
              "1764    192136\n",
              "1765    893925\n",
              "1766    952523\n",
              "1767    486829\n",
              "1768    300023\n",
              "1769    709861\n",
              "1770    280950\n",
              "1771    442569\n",
              "1772    104139\n",
              "1773    762750\n",
              "1774    583890\n",
              "1775    510447\n",
              "1776    228045\n",
              "1777    556479\n",
              "1778    959875\n",
              "1779    589856\n",
              "1780    248909\n",
              "1781    991518\n",
              "1782    236173\n",
              "1783    573439\n",
              "1784    443659\n",
              "1785    998097\n",
              "1786    410477\n",
              "1787    656147\n",
              "1788    905735\n",
              "1789    632551\n",
              "1790    981460\n",
              "1791    938820\n",
              "1792    532094\n",
              "1793    299160\n",
              "1794    548887\n",
              "1795    407133\n",
              "1796    318329\n",
              "1797    857574\n",
              "1798    493214\n",
              "1799    746866\n",
              "1800    717242\n",
              "1801    107835\n",
              "1802    322908\n",
              "1803    191738\n",
              "1804    380609\n",
              "1805    437340\n",
              "1806    357622\n",
              "1807    886050\n",
              "1808    856515\n",
              "1809    448852\n",
              "1810    521774\n",
              "1811    605044\n",
              "1812    377804\n",
              "1813    750210\n",
              "1814    627277\n",
              "1815    939425\n",
              "1816    868953\n",
              "1817    928838\n",
              "1818    637428\n",
              "1819    967307\n",
              "1820    307066\n",
              "1821    696645\n",
              "1822    651700\n",
              "1823    447592\n",
              "1824    832203\n",
              "1825    115523\n",
              "1826    291105\n",
              "1827    965827\n",
              "1828    923876\n",
              "1829    473176\n",
              "1830    819374\n",
              "1831    740230\n",
              "1832    848032\n",
              "1833    137122\n",
              "1834    675584\n",
              "1835    315999\n",
              "1836    609134\n",
              "1837    848994\n",
              "1838    588715\n",
              "1839    237773\n",
              "1840    612877\n",
              "1841    739921\n",
              "1842    967169\n",
              "1843    454086\n",
              "1844    153970\n",
              "1845    297287\n",
              "1846    317052\n",
              "1847    959506\n",
              "1848    434784\n",
              "1849    827660\n",
              "1850    732649\n",
              "1851    601585\n",
              "1852    444998\n",
              "1853    412607\n",
              "1854    859320\n",
              "1855    892440\n",
              "1856    340256\n",
              "1857    649381\n",
              "1858    669744\n",
              "1859    521818\n",
              "1860    574114\n",
              "1861    479421\n",
              "1862    651772\n",
              "1863    791137\n",
              "1864    124463\n",
              "1865    299847\n",
              "1866    729045\n",
              "1867    902616\n",
              "1868    838635\n",
              "1869    755334\n",
              "1870    424865\n",
              "1871    706161\n",
              "1872    310124\n",
              "1873    407510\n",
              "1874    896386\n",
              "1875    806336\n",
              "1876    989293\n",
              "1877    520121\n",
              "1878    696333\n",
              "1879    931552\n",
              "1880    953242\n",
              "1881    723048\n",
              "1882    580972\n",
              "1883    533905\n",
              "1884    426571\n",
              "1885    167687\n",
              "1886    800637\n",
              "1887    837283\n",
              "1888    975819\n",
              "1889    207827\n",
              "1890    153316\n",
              "1891    285833\n",
              "1892    670803\n",
              "1893    365773\n",
              "1894    837404\n",
              "1895    325785\n",
              "1896    397259\n",
              "1897    373903\n",
              "1898    348149\n",
              "1899    826235\n",
              "1900    522226\n",
              "1901    702188\n",
              "1902    624905\n",
              "1903    804115\n",
              "1904    609982\n",
              "1905    793670\n",
              "1906    364352\n",
              "1907    281408\n",
              "1908    449344\n",
              "1909    984503\n",
              "1910    107006\n",
              "1911    464050\n",
              "1912    778779\n",
              "1913    758968\n",
              "1914    107355\n",
              "1915    832451\n",
              "1916    907264\n",
              "1917    177787\n",
              "1918    464869\n",
              "1919    563012\n",
              "1920    690199\n",
              "1921    992287\n",
              "1922    565842\n",
              "1923    993924\n",
              "1924    967084\n",
              "1925    313115\n",
              "1926    520128\n",
              "1927    974964\n",
              "1928    830915\n",
              "1929    333614\n",
              "1930    899249\n",
              "1931    155339\n",
              "1932    879258\n",
              "1933    925702\n",
              "1934    424165\n",
              "1935    845638\n",
              "1936    586334\n",
              "1937    135169\n",
              "1938    626778\n",
              "1939    312094\n",
              "1940    747676\n",
              "1941    434039\n",
              "1942    523759\n",
              "1943    440463\n",
              "1944    805756\n",
              "1945    950296\n",
              "1946    414443\n",
              "1947    105071\n",
              "1948    302262\n",
              "1949    586589\n",
              "1950    276778\n",
              "1951    489087\n",
              "1952    811518\n",
              "1953    287435\n",
              "1954    148518\n",
              "1955    242010\n",
              "1956    832584\n",
              "1957    349020\n",
              "1958    426291\n",
              "1959    904946\n",
              "1960    111267\n",
              "1961    979418\n",
              "1962    488570\n",
              "1963    909244\n",
              "1964    427885\n",
              "1965    226856\n",
              "1966    139756\n",
              "1967    114933\n",
              "1968    445972\n",
              "1969    327778\n",
              "1970    138034\n",
              "1971    438420\n",
              "1972    622705\n",
              "1973    578783\n",
              "1974    855041\n",
              "1975    802965\n",
              "1976    269829\n",
              "1977    789885\n",
              "1978    187443\n",
              "1979    442619\n",
              "1980    822638\n",
              "1981    827083\n",
              "1982    239061\n",
              "1983    257193\n",
              "1984    398510\n",
              "1985    681420\n",
              "1986    696886\n",
              "1987    742581\n",
              "1988    492794\n",
              "1989    146127\n",
              "1990    982202\n",
              "1991    299823\n",
              "1992    348704\n",
              "1993    675060\n",
              "1994    643799\n",
              "1995    403092\n",
              "1996    531039\n",
              "1997    303425\n",
              "1998    318556\n",
              "1999    547406\n",
              "2000    161545\n",
              "2001    424546\n",
              "2002    756870\n",
              "2003    916724\n",
              "2004    677509\n",
              "2005    701560\n",
              "2006    142868\n",
              "2007    551331\n",
              "2008    525127\n",
              "2009    146609\n",
              "2010    617451\n",
              "2011    396437\n",
              "2012    516554\n",
              "2013    665619\n",
              "2014    985872\n",
              "2015    134014\n",
              "2016    316757\n",
              "2017    730445\n",
              "2018    307378\n",
              "2019    333879\n",
              "2020    336820\n",
              "2021    845838\n",
              "2022    431277\n",
              "2023    134158\n",
              "2024    649588\n",
              "2025    170427\n",
              "2026    992834\n",
              "2027    784266\n",
              "2028    574835\n",
              "2029    915989\n",
              "2030    973550\n",
              "2031    928099\n",
              "2032    121072\n",
              "2033    934621\n",
              "2034    957213\n",
              "2035    810155\n",
              "2036    959938\n",
              "2037    270865\n",
              "2038    881087\n",
              "2039    359454\n",
              "2040    236446\n",
              "2041    522209\n",
              "2042    275499\n",
              "2043    531334\n",
              "2044    832333\n",
              "2045    637254\n",
              "2046    823113\n",
              "2047    277726\n",
              "2048    889764\n",
              "2049    236920\n",
              "2050    717150\n",
              "2051    535456\n",
              "2052    304356\n",
              "2053    277760\n",
              "2054    944030\n",
              "2055    971465\n",
              "2056    273865\n",
              "2057    547703\n",
              "2058    318071\n",
              "2059    285923\n",
              "2060    935390\n",
              "2061    565275\n",
              "2062    732603\n",
              "2063    479219\n",
              "2064    363151\n",
              "2065    963694\n",
              "2066    536052\n",
              "2067    136316\n",
              "2068    233761\n",
              "2069    333489\n",
              "2070    540257\n",
              "2071    668697\n",
              "2072    828696\n",
              "2073    857354\n",
              "2074    204429\n",
              "2075    135292\n",
              "2076    540001\n",
              "2077    832723\n",
              "2078    952020\n",
              "2079    428975\n",
              "2080    786393\n",
              "2081    755249\n",
              "2082    365163\n",
              "2083    493881\n",
              "2084    883505\n",
              "2085    311013\n",
              "2086    717460\n",
              "2087    469998\n",
              "2088    795340\n",
              "2089    272271\n",
              "2090    377428\n",
              "2091    995591\n",
              "2092    743708\n",
              "2093    564560\n",
              "2094    262921\n",
              "2095    998786\n",
              "2096    455177\n",
              "2097    807011\n",
              "2098    730200\n",
              "2099    274529\n",
              "2100    156815\n",
              "2101    226079\n",
              "2102    312881\n",
              "2103    397426\n",
              "2104    107015\n",
              "2105    328503\n",
              "2106    761222\n",
              "2107    236693\n",
              "2108    304202\n",
              "2109    783602\n",
              "2110    659325\n",
              "2111    356880\n",
              "2112    307484\n",
              "2113    882400\n",
              "2114    337901\n",
              "2115    160298\n",
              "2116    739104\n",
              "2117    766800\n",
              "2118    158651\n",
              "2119    266681\n",
              "2120    181010\n",
              "2121    737027\n",
              "2122    187129\n",
              "2123    264552\n",
              "2124    827368\n",
              "2125    373104\n",
              "2126    453326\n",
              "2127    216994\n",
              "2128    760537\n",
              "2129    669364\n",
              "2130    780492\n",
              "2131    700311\n",
              "2132    131460\n",
              "2133    830135\n",
              "2134    516644\n",
              "2135    728626\n",
              "2136    805234\n",
              "2137    302408\n",
              "2138    370575\n",
              "2139    215161\n",
              "2140    421321\n",
              "2141    774522\n",
              "2142    707574\n",
              "2143    883585\n",
              "2144    984319\n",
              "2145    217813\n",
              "2146    304533\n",
              "2147    782710\n",
              "2148    498267\n",
              "2149    814582\n",
              "2150    868484\n",
              "2151    636171\n",
              "2152    779134\n",
              "2153    424019\n",
              "2154    591105\n",
              "2155    373610\n",
              "2156    502322\n",
              "2157    953989\n",
              "2158    562137\n",
              "2159    966796\n",
              "2160    749954\n",
              "2161    374284\n",
              "2162    277080\n",
              "2163    981750\n",
              "2164    475383\n",
              "2165    749663\n",
              "2166    144122\n",
              "2167    595755\n",
              "2168    646949\n",
              "2169    583736\n",
              "2170    603948\n",
              "2171    775737\n",
              "2172    585202\n",
              "2173    895687\n",
              "2174    143668\n",
              "2175    880553\n",
              "2176    415818\n",
              "2177    925269\n",
              "2178    598423\n",
              "2179    271149\n",
              "2180    440078\n",
              "2181    663133\n",
              "2182    903207\n",
              "2183    925618\n",
              "2184    370675\n",
              "2185    534913\n",
              "2186    845481\n",
              "2187    952456\n",
              "2188    510815\n",
              "2189    335633\n",
              "2190    872268\n",
              "2191    594425\n",
              "2192    971565\n",
              "2193    142909\n",
              "2194    574840\n",
              "2195    705440\n",
              "2196    296081\n",
              "2197    175844\n",
              "2198    318375\n",
              "2199    763128\n",
              "2200    236742\n",
              "2201    651286\n",
              "2202    615544\n",
              "2203    244657\n",
              "2204    491688\n",
              "2205    257668\n",
              "2206    698312\n",
              "2207    343248\n",
              "2208    965796\n",
              "2209    859670\n",
              "2210    242475\n",
              "2211    812179\n",
              "2212    510454\n",
              "2213    937851\n",
              "2214    238978\n",
              "2215    864375\n",
              "2216    164971\n",
              "2217    808873\n",
              "2218    439992\n",
              "2219    413757\n",
              "2220    390494\n",
              "2221    989267\n",
              "2222    399209\n",
              "2223    414541\n",
              "2224    414129\n",
              "2225    255770\n",
              "2226    202434\n",
              "2227    673709\n",
              "2228    242436\n",
              "2229    886520\n",
              "2230    448742\n",
              "2231    442437\n",
              "2232    785658\n",
              "2233    631459\n",
              "2234    354475\n",
              "2235    445535\n",
              "2236    992711\n",
              "2237    875815\n",
              "2238    479670\n",
              "2239    828043\n",
              "2240    221167\n",
              "2241    557443\n",
              "2242    613918\n",
              "2243    942642\n",
              "2244    155840\n",
              "2245    670177\n",
              "2246    222062\n",
              "2247    201000\n",
              "2248    199259\n",
              "2249    582604\n",
              "2250    936920\n",
              "2251    750724\n",
              "2252    960807\n",
              "2253    244861\n",
              "2254    619740\n",
              "2255    379129\n",
              "2256    841029\n",
              "2257    869695\n",
              "2258    908888\n",
              "2259    876936\n",
              "2260    580465\n",
              "2261    139179\n",
              "2262    580237\n",
              "2263    464281\n",
              "2264    868694\n",
              "2265    554177\n",
              "2266    505770\n",
              "2267    968388\n",
              "2268    210000\n",
              "2269    197986\n",
              "2270    805620\n",
              "2271    145000\n",
              "2272    656346\n",
              "2273    798051\n",
              "2274    759693\n",
              "2275    188026\n",
              "2276    415946\n",
              "2277    640577\n",
              "2278    263409\n",
              "2279    748731\n",
              "2280    409668\n",
              "2281    862734\n",
              "2282    615169\n",
              "2283    849036\n",
              "2284    395442\n",
              "2285    342463\n",
              "2286    430056\n",
              "2287    727922\n",
              "2288    858711\n",
              "2289    464133\n",
              "2290    760769\n",
              "2291    965025\n",
              "2292    263922\n",
              "2293    981566\n",
              "2294    639488\n",
              "2295    164709\n",
              "2296    932304\n",
              "2297    146913\n",
              "2298    983255\n",
              "2299    967828\n",
              "2300    506426\n",
              "2301    675612\n",
              "2302    112955\n",
              "2303    483850\n",
              "2304    765593\n",
              "2305    621342\n",
              "2306    825347\n",
              "2307    680933\n",
              "2308    235046\n",
              "2309    153458\n",
              "2310    913327\n",
              "2311    213974\n",
              "2312    456635\n",
              "2313    841884\n",
              "2314    459806\n",
              "2315    254199\n",
              "2316    826810\n",
              "2317    145881\n",
              "2318    120118\n",
              "2319    342254\n",
              "2320    613998\n",
              "2321    160556\n",
              "2322    372827\n",
              "2323    541230\n",
              "2324    408968\n",
              "2325    276921\n",
              "2326    422408\n",
              "2327    258001\n",
              "2328    255112\n",
              "2329    146598\n",
              "2330    288369\n",
              "2331    718343\n",
              "2332    231842\n",
              "2333    177917\n",
              "2334    698200\n",
              "2335    393609\n",
              "2336    281138\n",
              "2337    880311\n",
              "2338    160461\n",
              "2339    831988\n",
              "2340    362466\n",
              "2341    668490\n",
              "2342    432246\n",
              "2343    290550\n",
              "2344    149681\n",
              "2345    482940\n",
              "2346    148811\n",
              "2347    899679\n",
              "2348    169459\n",
              "2349    592464\n",
              "2350    356423\n",
              "2351    191944\n",
              "2352    858581\n",
              "2353    114513\n",
              "2354    774225\n",
              "2355    113173\n",
              "2356    728224\n",
              "2357    884067\n",
              "2358    491583\n",
              "2359    361176\n",
              "2360    662762\n",
              "2361    756274\n",
              "2362    809590\n",
              "2363    346113\n",
              "2364    589370\n",
              "2365    441974\n",
              "2366    548616\n",
              "2367    499284\n",
              "2368    349017\n",
              "2369    622053\n",
              "2370    519661\n",
              "2371    788548\n",
              "2372    293034\n",
              "2373    839872\n",
              "2374    353670\n",
              "2375    155315\n",
              "2376    797481\n",
              "2377    971292\n",
              "2378    831939\n",
              "2379    941550\n",
              "2380    657740\n",
              "2381    326173\n",
              "2382    163738\n",
              "2383    220134\n",
              "2384    677988\n",
              "2385    852498\n",
              "2386    728854\n",
              "2387    129973\n",
              "2388    475984\n",
              "2389    783935\n",
              "2390    774050\n",
              "2391    880725\n",
              "2392    368566\n",
              "2393    497116\n",
              "2394    302863\n",
              "2395    834465\n",
              "2396    512967\n",
              "2397    577773\n",
              "2398    573046\n",
              "2399    178311\n",
              "2400    435068\n",
              "2401    464962\n",
              "2402    486282\n",
              "2403    638712\n",
              "2404    806452\n",
              "2405    543577\n",
              "2406    543338\n",
              "2407    284034\n",
              "2408    214049\n",
              "2409    907312\n",
              "2410    817765\n",
              "2411    791346\n",
              "2412    424804\n",
              "2413    960175\n",
              "2414    725066\n",
              "2415    668992\n",
              "2416    988636\n",
              "2417    838485\n",
              "2418    534956\n",
              "2419    276247\n",
              "2420    752514\n",
              "2421    786854\n",
              "2422    443338\n",
              "2423    938726\n",
              "2424    834556\n",
              "2425    569410\n",
              "2426    996040\n",
              "2427    486933\n",
              "2428    767624\n",
              "2429    764382\n",
              "2430    622656\n",
              "2431    664756\n",
              "2432    579298\n",
              "2433    113381\n",
              "2434    182553\n",
              "2435    974269\n",
              "2436    344835\n",
              "2437    792861\n",
              "2438    254333\n",
              "2439    493243\n",
              "2440    868374\n",
              "2441    672344\n",
              "2442    695004\n",
              "2443    786870\n",
              "2444    633142\n",
              "2445    284463\n",
              "2446    691058\n",
              "2447    803986\n",
              "2448    529490\n",
              "2449    304016\n",
              "2450    851197\n",
              "2451    480561\n",
              "2452    373485\n",
              "2453    816318\n",
              "2454    292661\n",
              "2455    744240\n",
              "2456    593180\n",
              "2457    847639\n",
              "2458    914593\n",
              "2459    358948\n",
              "2460    986465\n",
              "2461    804711\n",
              "2462    280459\n",
              "2463    425987\n",
              "2464    933835\n",
              "2465    287470\n",
              "2466    900574\n",
              "2467    452076\n",
              "2468    260933\n",
              "2469    276863\n",
              "2470    597811\n",
              "2471    226453\n",
              "2472    330089\n",
              "2473    662560\n",
              "2474    150871\n",
              "2475    970742\n",
              "2476    987628\n",
              "2477    431053\n",
              "2478    536875\n",
              "2479    286605\n",
              "2480    146320\n",
              "2481    716021\n",
              "2482    442769\n",
              "2483    149662\n",
              "2484    844273\n",
              "2485    702994\n",
              "2486    926709\n",
              "2487    230033\n",
              "2488    228190\n",
              "2489    959107\n",
              "2490    724065\n",
              "2491    163749\n",
              "2492    767845\n",
              "2493    180875\n",
              "2494    378382\n",
              "2495    366588\n",
              "2496    740965\n",
              "2497    878101\n",
              "2498    446573\n",
              "2499    282663\n",
              "2500    415436\n",
              "2501    955141\n",
              "2502    961747\n",
              "2503    240650\n",
              "2504    668386\n",
              "2505    698177\n",
              "2506    584380\n",
              "2507    320241\n",
              "2508    198403\n",
              "2509    392501\n",
              "2510    134842\n",
              "2511    877880\n",
              "2512    805950\n",
              "2513    974381\n",
              "2514    986969\n",
              "2515    312381\n",
              "2516    440698\n",
              "2517    495428\n",
              "2518    824901\n",
              "2519    913370\n",
              "2520    744561\n",
              "2521    129752\n",
              "2522    800291\n",
              "2523    909096\n",
              "2524    771326\n",
              "2525    752284\n",
              "2526    384313\n",
              "2527    362515\n",
              "2528    917387\n",
              "2529    108349\n",
              "2530    792010\n",
              "2531    391355\n",
              "2532    456299\n",
              "2533    201123\n",
              "2534    427413\n",
              "2535    290870\n",
              "2536    977655\n",
              "2537    909804\n",
              "2538    773393\n",
              "2539    816981\n",
              "2540    469749\n",
              "2541    592731\n",
              "2542    762959\n",
              "2543    574059\n",
              "2544    157451\n",
              "2545    622952\n",
              "2546    379948\n",
              "2547    279280\n",
              "2548    567297\n",
              "2549    931767\n",
              "2550    705670\n",
              "2551    211782\n",
              "2552    570780\n",
              "2553    976106\n",
              "2554    680986\n",
              "2555    179101\n",
              "2556    921688\n",
              "2557    394804\n",
              "2558    223722\n",
              "2559    862713\n",
              "2560    876145\n",
              "2561    981597\n",
              "2562    469545\n",
              "2563    555840\n",
              "2564    432737\n",
              "2565    664074\n",
              "2566    154236\n",
              "2567    101095\n",
              "2568    901544\n",
              "2569    814491\n",
              "2570    193348\n",
              "2571    715040\n",
              "2572    993861\n",
              "2573    272657\n",
              "2574    904336\n",
              "2575    409256\n",
              "2576    107182\n",
              "2577    547956\n",
              "2578    600858\n",
              "2579    299367\n",
              "2580    198945\n",
              "2581    416100\n",
              "2582    868392\n",
              "2583    230044\n",
              "2584    263607\n",
              "2585    434204\n",
              "2586    982785\n",
              "2587    597711\n",
              "2588    414076\n",
              "2589    866447\n",
              "2590    347688\n",
              "2591    679838\n",
              "2592    955738\n",
              "2593    991808\n",
              "2594    538346\n",
              "2595    518609\n",
              "2596    750815\n",
              "2597    865483\n",
              "2598    123601\n",
              "2599    289137\n",
              "2600    628666\n",
              "2601    563092\n",
              "2602    476557\n",
              "2603    697637\n",
              "2604    863894\n",
              "2605    289255\n",
              "2606    928179\n",
              "2607    754638\n",
              "2608    616551\n",
              "2609    132434\n",
              "2610    984031\n",
              "2611    546598\n",
              "2612    443487\n",
              "2613    250257\n",
              "2614    637587\n",
              "2615    932953\n",
              "2616    817459\n",
              "2617    466711\n",
              "2618    112287\n",
              "2619    368219\n",
              "2620    286478\n",
              "2621    527559\n",
              "2622    782819\n",
              "2623    145671\n",
              "2624    806800\n",
              "2625    693234\n",
              "2626    658641\n",
              "2627    208400\n",
              "2628    813628\n",
              "2629    127972\n",
              "2630    817556\n",
              "2631    399434\n",
              "2632    650465\n",
              "2633    227351\n",
              "2634    212184\n",
              "2635    347572\n",
              "2636    946147\n",
              "2637    645745\n",
              "2638    152261\n",
              "2639    153417\n",
              "2640    158811\n",
              "2641    950746\n",
              "2642    149026\n",
              "2643    663580\n",
              "2644    620217\n",
              "2645    780199\n",
              "2646    647943\n",
              "2647    267946\n",
              "2648    129951\n",
              "2649    517605\n",
              "2650    890217\n",
              "2651    764633\n",
              "2652    837076\n",
              "2653    922831\n",
              "2654    597706\n",
              "2655    914228\n",
              "2656    699334\n",
              "2657    693263\n",
              "2658    967982\n",
              "2659    612986\n",
              "2660    438236\n",
              "2661    462697\n",
              "2662    126815\n",
              "2663    417530\n",
              "2664    834229\n",
              "2665    788647\n",
              "2666    815293\n",
              "2667    281858\n",
              "2668    600669\n",
              "2669    538098\n",
              "2670    965961\n",
              "2671    978388\n",
              "2672    357675\n",
              "2673    204103\n",
              "2674    819073\n",
              "2675    140024\n",
              "2676    409211\n",
              "2677    289021\n",
              "2678    445467\n",
              "2679    942112\n",
              "2680    482767\n",
              "2681    485102\n",
              "2682    460303\n",
              "2683    311561\n",
              "2684    626501\n",
              "2685    142336\n",
              "2686    153048\n",
              "2687    117971\n",
              "2688    163618\n",
              "2689    617765\n",
              "2690    241244\n",
              "2691    455758\n",
              "2692    282167\n",
              "2693    384072\n",
              "2694    387928\n",
              "2695    343488\n",
              "2696    976255\n",
              "2697    224191\n",
              "2698    190640\n",
              "2699    712475\n",
              "2700    990910\n",
              "2701    193783\n",
              "2702    923625\n",
              "2703    763805\n",
              "2704    575671\n",
              "2705    647129\n",
              "2706    626331\n",
              "2707    182059\n",
              "2708    205231\n",
              "2709    855508\n",
              "2710    275530\n",
              "2711    463097\n",
              "2712    982197\n",
              "2713    321332\n",
              "2714    364431\n",
              "2715    692494\n",
              "2716    714109\n",
              "2717    795194\n",
              "2718    773013\n",
              "2719    805124\n",
              "2720    766247\n",
              "2721    965700\n",
              "2722    111571\n",
              "2723    751340\n",
              "2724    138373\n",
              "2725    321773\n",
              "2726    463845\n",
              "2727    881713\n",
              "2728    697611\n",
              "2729    716346\n",
              "2730    737195\n",
              "2731    333467\n",
              "2732    803416\n",
              "2733    362288\n",
              "2734    477269\n",
              "2735    151264\n",
              "2736    865443\n",
              "2737    253963\n",
              "2738    953167\n",
              "2739    691640\n",
              "2740    738221\n",
              "2741    168794\n",
              "2742    592636\n",
              "2743    933505\n",
              "2744    549583\n",
              "2745    304627\n",
              "2746    686443\n",
              "2747    543717\n",
              "2748    117694\n",
              "2749    672816\n",
              "2750    559741\n",
              "2751    233245\n",
              "2752    926034\n",
              "2753    392602\n",
              "2754    122290\n",
              "2755    127952\n",
              "2756    426218\n",
              "2757    130155\n",
              "2758    236379\n",
              "2759    959873\n",
              "2760    479162\n",
              "2761    705333\n",
              "2762    475745\n",
              "2763    251243\n",
              "2764    153503\n",
              "2765    916752\n",
              "2766    103352\n",
              "2767    667125\n",
              "2768    233868\n",
              "2769    449154\n",
              "2770    950576\n",
              "2771    435686\n",
              "2772    669808\n",
              "2773    519267\n",
              "2774    808186\n",
              "2775    170439\n",
              "2776    187702\n",
              "2777    847067\n",
              "2778    835424\n",
              "2779    618381\n",
              "2780    931327\n",
              "2781    793775\n",
              "2782    798315\n",
              "2783    220995\n",
              "2784    874646\n",
              "2785    898644\n",
              "2786    305525\n",
              "2787    574090\n",
              "2788    359791\n",
              "2789    677899\n",
              "2790    228810\n",
              "2791    383140\n",
              "2792    102085\n",
              "2793    261310\n",
              "2794    533314\n",
              "2795    704713\n",
              "2796    384568\n",
              "2797    323762\n",
              "2798    143840\n",
              "2799    137274\n",
              "2800    923997\n",
              "2801    129968\n",
              "2802    358291\n",
              "2803    811324\n",
              "2804    380829\n",
              "2805    199757\n",
              "2806    454376\n",
              "2807    922860\n",
              "2808    101227\n",
              "2809    829785\n",
              "2810    456332\n",
              "2811    347244\n",
              "2812    625289\n",
              "2813    898149\n",
              "2814    219712\n",
              "2815    245118\n",
              "2816    599170\n",
              "2817    151405\n",
              "2818    158359\n",
              "2819    753555\n",
              "2820    546440\n",
              "2821    947714\n",
              "2822    993493\n",
              "2823    661445\n",
              "2824    920809\n",
              "2825    471645\n",
              "2826    507559\n",
              "2827    409205\n",
              "2828    157825\n",
              "2829    763602\n",
              "2830    664408\n",
              "2831    919267\n",
              "2832    688653\n",
              "2833    528218\n",
              "2834    614487\n",
              "2835    982570\n",
              "2836    226043\n",
              "2837    777111\n",
              "2838    142545\n",
              "2839    398010\n",
              "2840    103503\n",
              "2841    106461\n",
              "2842    824869\n",
              "2843    146543\n",
              "2844    749255\n",
              "2845    177469\n",
              "2846    860290\n",
              "2847    453071\n",
              "2848    512083\n",
              "2849    596938\n",
              "2850    881676\n",
              "2851    140466\n",
              "2852    510049\n",
              "2853    619508\n",
              "2854    961704\n",
              "2855    402106\n",
              "2856    190824\n",
              "2857    305512\n",
              "2858    268355\n",
              "2859    536321\n",
              "2860    394739\n",
              "2861    138563\n",
              "2862    533812\n",
              "2863    607343\n",
              "2864    485967\n",
              "2865    685927\n",
              "2866    343521\n",
              "2867    220844\n",
              "2868    588802\n",
              "2869    408096\n",
              "2870    715117\n",
              "2871    261783\n",
              "2872    692842\n",
              "2873    979125\n",
              "2874    892297\n",
              "2875    562644\n",
              "2876    905713\n",
              "2877    370474\n",
              "2878    772371\n",
              "2879    152645\n",
              "2880    654880\n",
              "2881    536724\n",
              "2882    436408\n",
              "2883    154888\n",
              "2884    979538\n",
              "2885    695208\n",
              "2886    682273\n",
              "2887    609341\n",
              "2888    698998\n",
              "2889    148232\n",
              "2890    883575\n",
              "2891    504283\n",
              "2892    592297\n",
              "2893    555462\n",
              "2894    230896\n",
              "2895    663921\n",
              "2896    133187\n",
              "2897    587609\n",
              "2898    621751\n",
              "2899    962599\n",
              "2900    291777\n",
              "2901    731870\n",
              "2902    427955\n",
              "2903    478155\n",
              "2904    691084\n",
              "2905    618627\n",
              "2906    550321\n",
              "2907    516723\n",
              "2908    952341\n",
              "2909    996770\n",
              "2910    361876\n",
              "2911    495950\n",
              "2912    647068\n",
              "2913    970951\n",
              "2914    687689\n",
              "2915    258368\n",
              "2916    147063\n",
              "2917    697472\n",
              "2918    784638\n",
              "2919    873264\n",
              "2920    766744\n",
              "2921    770486\n",
              "2922    753373\n",
              "2923    373215\n",
              "2924    503133\n",
              "2925    953296\n",
              "2926    442877\n",
              "2927    331419\n",
              "2928    916131\n",
              "2929    663117\n",
              "2930    421061\n",
              "2931    902142\n",
              "2932    100266\n",
              "2933    156312\n",
              "2934    182596\n",
              "2935    397185\n",
              "2936    367840\n",
              "2937    138030\n",
              "2938    914324\n",
              "2939    558336\n",
              "2940    804071\n",
              "2941    743569\n",
              "2942    486878\n",
              "2943    447328\n",
              "2944    548090\n",
              "2945    360785\n",
              "2946    859641\n",
              "2947    322485\n",
              "2948    356473\n",
              "2949    217825\n",
              "2950    644723\n",
              "2951    111372\n",
              "2952    893551\n",
              "2953    859816\n",
              "2954    891564\n",
              "2955    449055\n",
              "2956    324830\n",
              "2957    176807\n",
              "2958    140158\n",
              "2959    294769\n",
              "2960    697654\n",
              "2961    329642\n",
              "2962    484851\n",
              "2963    537921\n",
              "2964    131349\n",
              "2965    384066\n",
              "2966    900119\n",
              "2967    990476\n",
              "2968    622002\n",
              "2969    632309\n",
              "2970    835710\n",
              "2971    879542\n",
              "2972    158499\n",
              "2973    333322\n",
              "2974    696199\n",
              "2975    998017\n",
              "2976    786607\n",
              "2977    331887\n",
              "2978    356602\n",
              "2979    292305\n",
              "2980    186763\n",
              "2981    168063\n",
              "2982    160446\n",
              "2983    468720\n",
              "2984    798718\n",
              "2985    615732\n",
              "2986    350792\n",
              "2987    589690\n",
              "2988    521574\n",
              "2989    534404\n",
              "2990    198307\n",
              "2991    681518\n",
              "2992    720586\n",
              "2993    344144\n",
              "2994    151198\n",
              "2995    370858\n",
              "2996    904048\n",
              "2997    725823\n",
              "2998    938414\n",
              "2999    624380\n",
              "3000    110042\n",
              "3001    763232\n",
              "3002    756672\n",
              "3003    114127\n",
              "3004    768701\n",
              "3005    741381\n",
              "3006    899363\n",
              "3007    425165\n",
              "3008    604451\n",
              "3009    727221\n",
              "3010    137930\n",
              "3011    513731\n",
              "3012    204089\n",
              "3013    712065\n",
              "3014    205702\n",
              "3015    482243\n",
              "3016    714683\n",
              "3017    390933\n",
              "3018    473453\n",
              "3019    756637\n",
              "3020    427108\n",
              "3021    474704\n",
              "3022    219546\n",
              "3023    197512\n",
              "3024    850911\n",
              "3025    904369\n",
              "3026    643149\n",
              "3027    918552\n",
              "3028    881139\n",
              "3029    653576\n",
              "3030    830654\n",
              "3031    679161\n",
              "3032    847567\n",
              "3033    961551\n",
              "3034    606387\n",
              "3035    341566\n",
              "3036    883151\n",
              "3037    764687\n",
              "3038    281637\n",
              "3039    399757\n",
              "3040    615307\n",
              "3041    370391\n",
              "3042    422866\n",
              "3043    314159\n",
              "3044    430624\n",
              "3045    563651\n",
              "3046    499215\n",
              "3047    682564\n",
              "3048    743710\n",
              "3049    174682\n",
              "3050    660954\n",
              "3051    675390\n",
              "3052    264549\n",
              "3053    694546\n",
              "3054    917164\n",
              "3055    584647\n",
              "3056    756679\n",
              "3057    399025\n",
              "3058    975842\n",
              "3059    582622\n",
              "3060    110703\n",
              "3061    479527\n",
              "3062    587239\n",
              "3063    428094\n",
              "3064    597131\n",
              "3065    660116\n",
              "3066    492748\n",
              "3067    176197\n",
              "3068    966481\n",
              "3069    176281\n",
              "3070    796637\n",
              "3071    785855\n",
              "3072    813905\n",
              "3073    402946\n",
              "3074    568615\n",
              "3075    567024\n",
              "3076    800217\n",
              "3077    967046\n",
              "3078    876081\n",
              "3079    618669\n",
              "3080    224346\n",
              "3081    204864\n",
              "3082    553769\n",
              "3083    339886\n",
              "3084    224957\n",
              "3085    757136\n",
              "3086    297312\n",
              "3087    649661\n",
              "3088    368007\n",
              "3089    639833\n",
              "3090    775371\n",
              "3091    595138\n",
              "3092    354240\n",
              "3093    855856\n",
              "3094    712517\n",
              "3095    851465\n",
              "3096    236745\n",
              "3097    868950\n",
              "3098    645712\n",
              "3099    854951\n",
              "3100    459469\n",
              "3101    387352\n",
              "3102    604738\n",
              "3103    643715\n",
              "3104    444557\n",
              "3105    658335\n",
              "3106    647980\n",
              "3107    247839\n",
              "3108    693086\n",
              "3109    673228\n",
              "3110    133248\n",
              "3111    405401\n",
              "3112    535477\n",
              "3113    484822\n",
              "3114    243951\n",
              "3115    344893\n",
              "3116    484861\n",
              "3117    548493\n",
              "3118    155692\n",
              "3119    871312\n",
              "3120    299854\n",
              "3121    309374\n",
              "3122    256368\n",
              "3123    980189\n",
              "3124    515946\n",
              "3125    531949\n",
              "3126    473027\n",
              "3127    274525\n",
              "3128    567599\n",
              "3129    885552\n",
              "3130    974647\n",
              "3131    393714\n",
              "3132    588321\n",
              "3133    484981\n",
              "3134    755651\n",
              "3135    891355\n",
              "3136    670033\n",
              "3137    156061\n",
              "3138    626310\n",
              "3139    290472\n",
              "3140    722538\n",
              "3141    714298\n",
              "3142    460435\n",
              "3143    210897\n",
              "3144    423040\n",
              "3145    745010\n",
              "3146    827068\n",
              "3147    987024\n",
              "3148    602366\n",
              "3149    245060\n",
              "3150    411215\n",
              "3151    641926\n",
              "3152    547067\n",
              "3153    163383\n",
              "3154    228267\n",
              "3155    337191\n",
              "3156    307490\n",
              "3157    407721\n",
              "3158    451070\n",
              "3159    865326\n",
              "3160    601067\n",
              "3161    471436\n",
              "3162    452811\n",
              "3163    215064\n",
              "3164    385090\n",
              "3165    238829\n",
              "3166    986498\n",
              "3167    396483\n",
              "3168    491155\n",
              "3169    691746\n",
              "3170    572003\n",
              "3171    715424\n",
              "3172    726036\n",
              "3173    243727\n",
              "3174    465716\n",
              "3175    193547\n",
              "3176    276674\n",
              "3177    785035\n",
              "3178    222671\n",
              "3179    678462\n",
              "3180    157710\n",
              "3181    655846\n",
              "3182    702936\n",
              "3183    551416\n",
              "3184    269854\n",
              "3185    718485\n",
              "3186    473845\n",
              "3187    528424\n",
              "3188    744852\n",
              "3189    110249\n",
              "3190    337691\n",
              "3191    798313\n",
              "3192    573602\n",
              "3193    498655\n",
              "3194    734309\n",
              "3195    261282\n",
              "3196    651471\n",
              "3197    862505\n",
              "3198    822028\n",
              "3199    359094\n",
              "3200    424292\n",
              "3201    352908\n",
              "3202    373203\n",
              "3203    774670\n",
              "3204    189919\n",
              "3205    542872\n",
              "3206    735646\n",
              "3207    374037\n",
              "3208    488665\n",
              "3209    482954\n",
              "3210    507980\n",
              "3211    612938\n",
              "3212    309028\n",
              "3213    642613\n",
              "3214    837618\n",
              "3215    803294\n",
              "3216    663126\n",
              "3217    507309\n",
              "3218    605604\n",
              "3219    658059\n",
              "3220    813035\n",
              "3221    309471\n",
              "3222    260908\n",
              "3223    485228\n",
              "3224    827633\n",
              "3225    106398\n",
              "3226    528142\n",
              "3227    758537\n",
              "3228    225831\n",
              "3229    499716\n",
              "3230    475506\n",
              "3231    745637\n",
              "3232    731239\n",
              "3233    353799\n",
              "3234    952541\n",
              "3235    575705\n",
              "3236    624262\n",
              "3237    453150\n",
              "3238    324714\n",
              "3239    287546\n",
              "3240    872470\n",
              "3241    852602\n",
              "3242    172441\n",
              "3243    437686\n",
              "3244    494238\n",
              "3245    305451\n",
              "3246    187371\n",
              "3247    306261\n",
              "3248    423804\n",
              "3249    473185\n",
              "3250    338093\n",
              "3251    657102\n",
              "3252    583414\n",
              "3253    917858\n",
              "3254    911940\n",
              "3255    414198\n",
              "3256    202828\n",
              "3257    371363\n",
              "3258    100460\n",
              "3259    284814\n",
              "3260    607536\n",
              "3261    703480\n",
              "3262    756811\n",
              "3263    510779\n",
              "3264    677579\n",
              "3265    894339\n",
              "3266    625255\n",
              "3267    351175\n",
              "3268    871364\n",
              "3269    652827\n",
              "3270    270163\n",
              "3271    813084\n",
              "3272    845757\n",
              "3273    812360\n",
              "3274    200702\n",
              "3275    596956\n",
              "3276    189708\n",
              "3277    488070\n",
              "3278    861996\n",
              "3279    518069\n",
              "3280    614405\n",
              "3281    232246\n",
              "3282    644812\n",
              "3283    100682\n",
              "3284    724291\n",
              "3285    899556\n",
              "3286    429151\n",
              "3287    197861\n",
              "3288    969245\n",
              "3289    992504\n",
              "3290    914330\n",
              "3291    412051\n",
              "3292    559100\n",
              "3293    256410\n",
              "3294    870558\n",
              "3295    386179\n",
              "3296    831809\n",
              "3297    319725\n",
              "3298    630769\n",
              "3299    225100\n",
              "3300    783576\n",
              "3301    154003\n",
              "3302    119333\n",
              "3303    710835\n",
              "3304    512468\n",
              "3305    426034\n",
              "3306    901007\n",
              "3307    197257\n",
              "3308    506146\n",
              "3309    280231\n",
              "3310    997586\n",
              "3311    143309\n",
              "3312    933430\n",
              "3313    279880\n",
              "3314    525953\n",
              "3315    456594\n",
              "3316    358251\n",
              "3317    122455\n",
              "3318    692226\n",
              "3319    997189\n",
              "3320    502415\n",
              "3321    325091\n",
              "3322    181583\n",
              "3323    122477\n",
              "3324    317734\n",
              "3325    391951\n",
              "3326    923415\n",
              "3327    519483\n",
              "3328    691757\n",
              "3329    593640\n",
              "3330    420444\n",
              "3331    488816\n",
              "3332    611829\n",
              "3333    706227\n",
              "3334    120356\n",
              "3335    228473\n",
              "3336    398755\n",
              "3337    701964\n",
              "3338    798828\n",
              "3339    589502\n",
              "3340    873131\n",
              "3341    626371\n",
              "3342    977068\n",
              "3343    387747\n",
              "3344    854500\n",
              "3345    854593\n",
              "3346    166939\n",
              "3347    622410\n",
              "3348    561204\n",
              "3349    220829\n",
              "3350    239058\n",
              "3351    556720\n",
              "3352    848681\n",
              "3353    473759\n",
              "3354    527738\n",
              "3355    765863\n",
              "3356    619507\n",
              "3357    776004\n",
              "3358    492757\n",
              "3359    789768\n",
              "3360    889207\n",
              "3361    836094\n",
              "3362    238078\n",
              "3363    592716\n",
              "3364    873111\n",
              "3365    640862\n",
              "3366    328361\n",
              "3367    720713\n",
              "3368    197233\n",
              "3369    259756\n",
              "3370    661080\n",
              "3371    581016\n",
              "3372    491200\n",
              "3373    715993\n",
              "3374    987621\n",
              "3375    468498\n",
              "3376    429961\n",
              "3377    970970\n",
              "3378    402279\n",
              "3379    700189\n",
              "3380    480186\n",
              "3381    673564\n",
              "3382    921936\n",
              "3383    259323\n",
              "3384    865224\n",
              "3385    497042\n",
              "3386    662922\n",
              "3387    543620\n",
              "3388    598443\n",
              "3389    379208\n",
              "3390    806644\n",
              "3391    576118\n",
              "3392    119908\n",
              "3393    503650\n",
              "3394    891427\n",
              "3395    938453\n",
              "3396    576135\n",
              "3397    890575\n",
              "3398    455614\n",
              "3399    978847\n",
              "3400    874269\n",
              "3401    257765\n",
              "3402    775583\n",
              "3403    557651\n",
              "3404    569144\n",
              "3405    714753\n",
              "3406    822472\n",
              "3407    485273\n",
              "3408    926565\n",
              "3409    839884\n",
              "3410    718205\n",
              "3411    492953\n",
              "3412    135775\n",
              "3413    824332\n",
              "3414    229171\n",
              "3415    429318\n",
              "3416    803199\n",
              "3417    332273\n",
              "3418    726571\n",
              "3419    719815\n",
              "3420    122400\n",
              "3421    859018\n",
              "3422    734810\n",
              "3423    419761\n",
              "3424    159783\n",
              "3425    978003\n",
              "3426    711730\n",
              "3427    994106\n",
              "3428    182776\n",
              "3429    743307\n",
              "3430    247772\n",
              "3431    287404\n",
              "3432    247738\n",
              "3433    151807\n",
              "3434    337137\n",
              "3435    560308\n",
              "3436    544503\n",
              "3437    509479\n",
              "3438    253184\n",
              "3439    463278\n",
              "3440    615458\n",
              "3441    189611\n",
              "3442    791934\n",
              "3443    375551\n",
              "3444    691702\n",
              "3445    734544\n",
              "3446    343882\n",
              "3447    402862\n",
              "3448    586479\n",
              "3449    753535\n",
              "3450    349307\n",
              "3451    721051\n",
              "3452    536548\n",
              "3453    753815\n",
              "3454    562464\n",
              "3455    153874\n",
              "3456    162859\n",
              "3457    575487\n",
              "3458    980694\n",
              "3459    156113\n",
              "3460    387321\n",
              "3461    877121\n",
              "3462    315272\n",
              "3463    801214\n",
              "3464    209386\n",
              "3465    815417\n",
              "3466    446899\n",
              "3467    235611\n",
              "3468    635512\n",
              "3469    836354\n",
              "3470    781445\n",
              "3471    762164\n",
              "3472    532776\n",
              "3473    903780\n",
              "3474    386589\n",
              "3475    626861\n",
              "3476    985883\n",
              "3477    748662\n",
              "3478    600626\n",
              "3479    418109\n",
              "3480    277092\n",
              "3481    264553\n",
              "3482    291896\n",
              "3483    376250\n",
              "3484    652100\n",
              "3485    681257\n",
              "3486    641474\n",
              "3487    406313\n",
              "3488    480925\n",
              "3489    644623\n",
              "3490    811321\n",
              "3491    364829\n",
              "3492    414283\n",
              "3493    645922\n",
              "3494    324479\n",
              "3495    217510\n",
              "3496    723745\n",
              "3497    125899\n",
              "3498    154674\n",
              "3499    647051\n",
              "3500    905042\n",
              "3501    607874\n",
              "3502    569848\n",
              "3503    283199\n",
              "3504    360014\n",
              "3505    998023\n",
              "3506    366944\n",
              "3507    938521\n",
              "3508    867015\n",
              "3509    903409\n",
              "3510    676716\n",
              "3511    428931\n",
              "3512    329275\n",
              "3513    764259\n",
              "3514    179143\n",
              "3515    197236\n",
              "3516    694516\n",
              "3517    977284\n",
              "3518    323110\n",
              "3519    372057\n",
              "3520    737064\n",
              "3521    429121\n",
              "3522    117513\n",
              "3523    948569\n",
              "3524    616708\n",
              "3525    798071\n",
              "3526    372929\n",
              "3527    193144\n",
              "3528    471967\n",
              "3529    909568\n",
              "3530    450865\n",
              "3531    869096\n",
              "3532    766824\n",
              "3533    198753\n",
              "3534    375272\n",
              "3535    278109\n",
              "3536    654164\n",
              "3537    567711\n",
              "3538    291456\n",
              "3539    650760\n",
              "3540    828653\n",
              "3541    581068\n",
              "3542    382394\n",
              "3543    402270\n",
              "3544    122999\n",
              "3545    774941\n",
              "3546    135518\n",
              "3547    157569\n",
              "3548    282567\n",
              "3549    448801\n",
              "3550    786873\n",
              "3551    543239\n",
              "3552    713573\n",
              "3553    748376\n",
              "3554    129030\n",
              "3555    782842\n",
              "3556    458753\n",
              "3557    591137\n",
              "3558    806061\n",
              "3559    224409\n",
              "3560    233642\n",
              "3561    298954\n",
              "3562    602351\n",
              "3563    229659\n",
              "3564    198523\n",
              "3565    688400\n",
              "3566    879210\n",
              "3567    781805\n",
              "3568    289179\n",
              "3569    578608\n",
              "3570    277541\n",
              "3571    434479\n",
              "3572    210579\n",
              "3573    432510\n",
              "3574    109790\n",
              "3575    489791\n",
              "3576    279832\n",
              "3577    769058\n",
              "3578    244505\n",
              "3579    589934\n",
              "3580    269459\n",
              "3581    109106\n",
              "3582    160769\n",
              "3583    655388\n",
              "3584    916819\n",
              "3585    348400\n",
              "3586    573372\n",
              "3587    625732\n",
              "3588    958853\n",
              "3589    264162\n",
              "3590    687040\n",
              "3591    937331\n",
              "3592    393485\n",
              "3593    818469\n",
              "3594    184797\n",
              "3595    296036\n",
              "3596    297411\n",
              "3597    291902\n",
              "3598    349203\n",
              "3599    712208\n",
              "3600    764767\n",
              "3601    347000\n",
              "3602    987055\n",
              "3603    311334\n",
              "3604    969214\n",
              "3605    498420\n",
              "3606    412413\n",
              "3607    188171\n",
              "3608    479031\n",
              "3609    546339\n",
              "3610    228486\n",
              "3611    823386\n",
              "3612    205215\n",
              "3613    249040\n",
              "3614    931863\n",
              "3615    114942\n",
              "3616    184620\n",
              "3617    510795\n",
              "3618    402199\n",
              "3619    195467\n",
              "3620    951146\n",
              "3621    679395\n",
              "3622    555794\n",
              "3623    273691\n",
              "3624    751900\n",
              "3625    783566\n",
              "3626    205360\n",
              "3627    888113\n",
              "3628    425609\n",
              "3629    893799\n",
              "3630    576724\n",
              "3631    482436\n",
              "3632    218252\n",
              "3633    996553\n",
              "3634    705611\n",
              "3635    461199\n",
              "3636    876199\n",
              "3637    401841\n",
              "3638    360365\n",
              "3639    245982\n",
              "3640    538411\n",
              "3641    797971\n",
              "3642    672700\n",
              "3643    997059\n",
              "3644    860010\n",
              "3645    904648\n",
              "3646    838653\n",
              "3647    639178\n",
              "3648    325670\n",
              "3649    516093\n",
              "3650    545502\n",
              "3651    159805\n",
              "3652    610388\n",
              "3653    555569\n",
              "3654    170437\n",
              "3655    297028\n",
              "3656    808122\n",
              "3657    875702\n",
              "3658    396350\n",
              "3659    765102\n",
              "3660    319230\n",
              "3661    587444\n",
              "3662    357673\n",
              "3663    648722\n",
              "3664    988565\n",
              "3665    662186\n",
              "3666    508555\n",
              "3667    913129\n",
              "3668    505094\n",
              "3669    262861\n",
              "3670    903789\n",
              "3671    552741\n",
              "3672    775336\n",
              "3673    629718\n",
              "3674    116797\n",
              "3675    562947\n",
              "3676    580841\n",
              "3677    429062\n",
              "3678    845945\n",
              "3679    738855\n",
              "3680    886563\n",
              "3681    964845\n",
              "3682    900282\n",
              "3683    273425\n",
              "3684    425849\n",
              "3685    996788\n",
              "3686    421049\n",
              "3687    892253\n",
              "3688    839139\n",
              "3689    943811\n",
              "3690    116579\n",
              "3691    546524\n",
              "3692    872667\n",
              "3693    712558\n",
              "3694    278779\n",
              "3695    567029\n",
              "3696    280792\n",
              "3697    642833\n",
              "3698    414151\n",
              "3699    924912\n",
              "3700    812503\n",
              "3701    426633\n",
              "3702    851380\n",
              "3703    916126\n",
              "3704    352569\n",
              "3705    966094\n",
              "3706    389077\n",
              "3707    636970\n",
              "3708    911028\n",
              "3709    523575\n",
              "3710    565211\n",
              "3711    537855\n",
              "3712    528905\n",
              "3713    550924\n",
              "3714    245259\n",
              "3715    795103\n",
              "3716    434351\n",
              "3717    946644\n",
              "3718    696553\n",
              "3719    687565\n",
              "3720    839116\n",
              "3721    165217\n",
              "3722    163660\n",
              "3723    159392\n",
              "3724    905024\n",
              "3725    125003\n",
              "3726    944436\n",
              "3727    203004\n",
              "3728    338151\n",
              "3729    686918\n",
              "3730    666578\n",
              "3731    927809\n",
              "3732    860044\n",
              "3733    356929\n",
              "3734    712907\n",
              "3735    270960\n",
              "3736    202554\n",
              "3737    415742\n",
              "3738    953540\n",
              "3739    730285\n",
              "3740    564619\n",
              "3741    100819\n",
              "3742    765159\n",
              "3743    489157\n",
              "3744    304468\n",
              "3745    730301\n",
              "3746    299957\n",
              "3747    971917\n",
              "3748    562168\n",
              "3749    108194\n",
              "3750    590532\n",
              "3751    268099\n",
              "3752    405003\n",
              "3753    344206\n",
              "3754    302138\n",
              "3755    517437\n",
              "3756    203738\n",
              "3757    253030\n",
              "3758    632315\n",
              "3759    464010\n",
              "3760    816872\n",
              "3761    874507\n",
              "3762    823147\n",
              "3763    752293\n",
              "3764    662296\n",
              "3765    399449\n",
              "3766    686052\n",
              "3767    895660\n",
              "3768    326371\n",
              "3769    421158\n",
              "3770    776093\n",
              "3771    410772\n",
              "3772    508718\n",
              "3773    488083\n",
              "3774    984080\n",
              "3775    862307\n",
              "3776    256164\n",
              "3777    448544\n",
              "3778    340171\n",
              "3779    614502\n",
              "3780    812909\n",
              "3781    418797\n",
              "3782    518482\n",
              "3783    979148\n",
              "3784    665281\n",
              "3785    310144\n",
              "3786    838178\n",
              "3787    991727\n",
              "3788    482587\n",
              "3789    616655\n",
              "3790    133361\n",
              "3791    658694\n",
              "3792    401202\n",
              "3793    569357\n",
              "3794    976146\n",
              "3795    291392\n",
              "3796    729150\n",
              "3797    622424\n",
              "3798    603115\n",
              "3799    388241\n",
              "3800    182621\n",
              "3801    813634\n",
              "3802    430882\n",
              "3803    348330\n",
              "3804    109066\n",
              "3805    906638\n",
              "3806    515424\n",
              "3807    484226\n",
              "3808    879702\n",
              "3809    260224\n",
              "3810    813191\n",
              "3811    597957\n",
              "3812    382560\n",
              "3813    926492\n",
              "3814    105011\n",
              "3815    540715\n",
              "3816    162974\n",
              "3817    521791\n",
              "3818    656555\n",
              "3819    389285\n",
              "3820    153290\n",
              "3821    248351\n",
              "3822    664322\n",
              "3823    399609\n",
              "3824    360097\n",
              "3825    654558\n",
              "3826    776987\n",
              "3827    878154\n",
              "3828    644367\n",
              "3829    532263\n",
              "3830    200240\n",
              "3831    153673\n",
              "3832    394304\n",
              "3833    527484\n",
              "3834    124482\n",
              "3835    223431\n",
              "3836    303697\n",
              "3837    706966\n",
              "3838    608316\n",
              "3839    549481\n",
              "3840    653119\n",
              "3841    973245\n",
              "3842    353836\n",
              "3843    185194\n",
              "3844    657855\n",
              "3845    888704\n",
              "3846    509077\n",
              "3847    689615\n",
              "3848    241763\n",
              "3849    484875\n",
              "3850    783363\n",
              "3851    874313\n",
              "3852    611856\n",
              "3853    601844\n",
              "3854    967455\n",
              "3855    549429\n",
              "3856    290035\n",
              "3857    319424\n",
              "3858    219944\n",
              "3859    911664\n",
              "3860    528327\n",
              "3861    628776\n",
              "3862    752730\n",
              "3863    762167\n",
              "3864    262449\n",
              "3865    690030\n",
              "3866    568841\n",
              "3867    199375\n",
              "3868    912742\n",
              "3869    465701\n",
              "3870    519506\n",
              "3871    980463\n",
              "3872    505936\n",
              "3873    663219\n",
              "3874    612840\n",
              "3875    680038\n",
              "3876    511142\n",
              "3877    855380\n",
              "3878    987752\n",
              "3879    898241\n",
              "3880    735178\n",
              "3881    438116\n",
              "3882    642929\n",
              "3883    563010\n",
              "3884    780438\n",
              "3885    814962\n",
              "3886    681078\n",
              "3887    241457\n",
              "3888    756320\n",
              "3889    650523\n",
              "3890    794678\n",
              "3891    500548\n",
              "3892    405830\n",
              "3893    822061\n",
              "3894    980692\n",
              "3895    447060\n",
              "3896    341707\n",
              "3897    381018\n",
              "3898    842776\n",
              "3899    110726\n",
              "3900    928491\n",
              "3901    666899\n",
              "3902    134305\n",
              "3903    106104\n",
              "3904    701149\n",
              "3905    570631\n",
              "3906    704869\n",
              "3907    456305\n",
              "3908    936716\n",
              "3909    596802\n",
              "3910    724898\n",
              "3911    578580\n",
              "3912    909754\n",
              "3913    892716\n",
              "3914    225868\n",
              "3915    626598\n",
              "3916    819379\n",
              "3917    192522\n",
              "3918    652104\n",
              "3919    924966\n",
              "3920    301073\n",
              "3921    602470\n",
              "3922    848271\n",
              "3923    586817\n",
              "3924    594231\n",
              "3925    837400\n",
              "3926    392760\n",
              "3927    772253\n",
              "3928    995432\n",
              "3929    908634\n",
              "3930    663662\n",
              "3931    885378\n",
              "3932    355922\n",
              "3933    268120\n",
              "3934    722134\n",
              "3935    928217\n",
              "3936    457026\n",
              "3937    317130\n",
              "3938    431958\n",
              "3939    248702\n",
              "3940    907437\n",
              "3941    775433\n",
              "3942    138157\n",
              "3943    397615\n",
              "3944    650346\n",
              "3945    401661\n",
              "3946    835509\n",
              "3947    873319\n",
              "3948    580675\n",
              "3949    602224\n",
              "3950    915719\n",
              "3951    272864\n",
              "3952    813349\n",
              "3953    205906\n",
              "3954    696094\n",
              "3955    235459\n",
              "3956    615945\n",
              "3957    258576\n",
              "3958    920184\n",
              "3959    670976\n",
              "3960    701527\n",
              "3961    848086\n",
              "3962    528208\n",
              "3963    999834\n",
              "3964    897197\n",
              "3965    684361\n",
              "3966    368334\n",
              "3967    755369\n",
              "3968    259384\n",
              "3969    201438\n",
              "3970    799192\n",
              "3971    920190\n",
              "3972    766789\n",
              "3973    911351\n",
              "3974    175409\n",
              "3975    172027\n",
              "3976    439238\n",
              "3977    719292\n",
              "3978    894646\n",
              "3979    868360\n",
              "3980    335571\n",
              "3981    226846\n",
              "3982    202893\n",
              "3983    710762\n",
              "3984    673441\n",
              "3985    564584\n",
              "3986    187489\n",
              "3987    570244\n",
              "3988    730294\n",
              "3989    113906\n",
              "3990    787693\n",
              "3991    824914\n",
              "3992    934952\n",
              "3993    138504\n",
              "3994    881145\n",
              "3995    730306\n",
              "3996    560078\n",
              "3997    239134\n",
              "3998    656189\n",
              "3999    379812\n",
              "4000    151265\n",
              "4001    710513\n",
              "4002    518561\n",
              "4003    229825\n",
              "4004    799561\n",
              "4005    903718\n",
              "4006    785542\n",
              "4007    795338\n",
              "4008    205130\n",
              "4009    490840\n",
              "4010    230520\n",
              "4011    256414\n",
              "4012    935772\n",
              "4013    707039\n",
              "4014    605704\n",
              "4015    829124\n",
              "4016    196030\n",
              "4017    471579\n",
              "4018    109193\n",
              "4019    828069\n",
              "4020    502470\n",
              "4021    396556\n",
              "4022    679799\n",
              "4023    273788\n",
              "4024    403447\n",
              "4025    569137\n",
              "4026    982466\n",
              "4027    500538\n",
              "4028    617106\n",
              "4029    612159\n",
              "4030    206874\n",
              "4031    813293\n",
              "4032    640677\n",
              "4033    507048\n",
              "4034    974950\n",
              "4035    201654\n",
              "4036    885755\n",
              "4037    779323\n",
              "4038    952825\n",
              "4039    816211\n",
              "4040    929041\n",
              "4041    619334\n",
              "4042    307506\n",
              "4043    556452\n",
              "4044    963690\n",
              "4045    546746\n",
              "4046    823598\n",
              "4047    828025\n",
              "4048    428724\n",
              "4049    166903\n",
              "4050    464851\n",
              "4051    283362\n",
              "4052    390451\n",
              "4053    447812\n",
              "4054    260583\n",
              "4055    889783\n",
              "4056    138960\n",
              "4057    774658\n",
              "4058    116926\n",
              "4059    325138\n",
              "4060    730123\n",
              "4061    563162\n",
              "4062    597625\n",
              "4063    454242\n",
              "4064    832685\n",
              "4065    828561\n",
              "4066    567163\n",
              "4067    326991\n",
              "4068    938375\n",
              "4069    158758\n",
              "4070    618747\n",
              "4071    968696\n",
              "4072    270322\n",
              "4073    704117\n",
              "4074    560138\n",
              "4075    862679\n",
              "4076    287770\n",
              "4077    285371\n",
              "4078    206765\n",
              "4079    590265\n",
              "4080    850450\n",
              "4081    214708\n",
              "4082    893286\n",
              "4083    592149\n",
              "4084    875198\n",
              "4085    848276\n",
              "4086    498070\n",
              "4087    151008\n",
              "4088    286032\n",
              "4089    284421\n",
              "4090    888392\n",
              "4091    740040\n",
              "4092    190973\n",
              "4093    481819\n",
              "4094    571675\n",
              "4095    307489\n",
              "4096    466501\n",
              "4097    852335\n",
              "4098    715047\n",
              "4099    879842\n",
              "4100    527224\n",
              "4101    961528\n",
              "4102    703146\n",
              "4103    783476\n",
              "4104    138351\n",
              "4105    589699\n",
              "4106    506060\n",
              "4107    829017\n",
              "4108    929708\n",
              "4109    980817\n",
              "4110    832505\n",
              "4111    603124\n",
              "4112    143932\n",
              "4113    661383\n",
              "4114    131364\n",
              "4115    673319\n",
              "4116    320698\n",
              "4117    825782\n",
              "4118    554794\n",
              "4119    701914\n",
              "4120    852776\n",
              "4121    478773\n",
              "4122    357538\n",
              "4123    139434\n",
              "4124    405224\n",
              "4125    967437\n",
              "4126    299197\n",
              "4127    932202\n",
              "4128    846342\n",
              "4129    727142\n",
              "4130    804895\n",
              "4131    914144\n",
              "4132    507302\n",
              "4133    628813\n",
              "4134    249663\n",
              "4135    793548\n",
              "4136    333310\n",
              "4137    588211\n",
              "4138    610471\n",
              "4139    601783\n",
              "4140    629993\n",
              "4141    223225\n",
              "4142    240210\n",
              "4143    729783\n",
              "4144    832246\n",
              "4145    152118\n",
              "4146    594301\n",
              "4147    139956\n",
              "4148    270389\n",
              "4149    607631\n",
              "4150    407991\n",
              "4151    793496\n",
              "4152    350896\n",
              "4153    155174\n",
              "4154    720817\n",
              "4155    638341\n",
              "4156    889262\n",
              "4157    459554\n",
              "4158    212193\n",
              "4159    819850\n",
              "4160    332785\n",
              "4161    446840\n",
              "4162    472956\n",
              "4163    875986\n",
              "4164    722736\n",
              "4165    100909\n",
              "4166    825910\n",
              "4167    125504\n",
              "4168    199333\n",
              "4169    519282\n",
              "4170    879207\n",
              "4171    539599\n",
              "4172    977370\n",
              "4173    580998\n",
              "4174    932252\n",
              "4175    968600\n",
              "4176    657202\n",
              "4177    548467\n",
              "4178    574118\n",
              "4179    209216\n",
              "4180    525583\n",
              "4181    921105\n",
              "4182    201724\n",
              "4183    643430\n",
              "4184    816523\n",
              "4185    631944\n",
              "4186    691383\n",
              "4187    459322\n",
              "4188    241669\n",
              "4189    777177\n",
              "4190    273008\n",
              "4191    587098\n",
              "4192    494681\n",
              "4193    373866\n",
              "4194    523801\n",
              "4195    341436\n",
              "4196    707703\n",
              "4197    935669\n",
              "4198    809282\n",
              "4199    445787\n",
              "4200    830324\n",
              "4201    201053\n",
              "4202    727007\n",
              "4203    135774\n",
              "4204    433380\n",
              "4205    474826\n",
              "4206    799908\n",
              "4207    107608\n",
              "4208    333546\n",
              "4209    210695\n",
              "4210    189242\n",
              "4211    315488\n",
              "4212    121172\n",
              "4213    108148\n",
              "4214    287302\n",
              "4215    497434\n",
              "4216    951296\n",
              "4217    517021\n",
              "4218    805660\n",
              "4219    780524\n",
              "4220    233921\n",
              "4221    250428\n",
              "4222    422764\n",
              "4223    593853\n",
              "4224    642096\n",
              "4225    785771\n",
              "4226    315425\n",
              "4227    866932\n",
              "4228    343554\n",
              "4229    455486\n",
              "4230    529458\n",
              "4231    513322\n",
              "4232    692543\n",
              "4233    463996\n",
              "4234    802918\n",
              "4235    621514\n",
              "4236    395546\n",
              "4237    574198\n",
              "4238    479896\n",
              "4239    984085\n",
              "4240    742603\n",
              "4241    748017\n",
              "4242    427422\n",
              "4243    374485\n",
              "4244    359666\n",
              "4245    718851\n",
              "4246    598486\n",
              "4247    996955\n",
              "4248    350944\n",
              "4249    344696\n",
              "4250    548604\n",
              "4251    542358\n",
              "4252    160872\n",
              "4253    156826\n",
              "4254    411801\n",
              "4255    689464\n",
              "4256    676052\n",
              "4257    671746\n",
              "4258    824287\n",
              "4259    355949\n",
              "4260    886387\n",
              "4261    432039\n",
              "4262    791770\n",
              "4263    139759\n",
              "4264    663681\n",
              "4265    221732\n",
              "4266    351472\n",
              "4267    238795\n",
              "4268    359269\n",
              "4269    964285\n",
              "4270    972000\n",
              "4271    291669\n",
              "4272    802834\n",
              "4273    557078\n",
              "4274    155800\n",
              "4275    704450\n",
              "4276    654381\n",
              "4277    569454\n",
              "4278    908319\n",
              "4279    422107\n",
              "4280    477911\n",
              "4281    304132\n",
              "4282    545018\n",
              "4283    663383\n",
              "4284    791708\n",
              "4285    686466\n",
              "4286    828637\n",
              "4287    994449\n",
              "4288    426752\n",
              "4289    707907\n",
              "4290    973314\n",
              "4291    958532\n",
              "4292    822847\n",
              "4293    687022\n",
              "4294    345588\n",
              "4295    424396\n",
              "4296    291279\n",
              "4297    462907\n",
              "4298    205348\n",
              "4299    428407\n",
              "4300    405277\n",
              "4301    183628\n",
              "4302    294000\n",
              "4303    809280\n",
              "4304    653350\n",
              "4305    549978\n",
              "4306    988258\n",
              "4307    186704\n",
              "4308    442773\n",
              "4309    210172\n",
              "4310    876305\n",
              "4311    746479\n",
              "4312    782161\n",
              "4313    927166\n",
              "4314    190496\n",
              "4315    448624\n",
              "4316    202914\n",
              "4317    401337\n",
              "4318    385332\n",
              "4319    924556\n",
              "4320    656228\n",
              "4321    109647\n",
              "4322    346583\n",
              "4323    659706\n",
              "4324    113368\n",
              "4325    597414\n",
              "4326    269076\n",
              "4327    151128\n",
              "4328    358459\n",
              "4329    340167\n",
              "4330    766696\n",
              "4331    175669\n",
              "4332    878689\n",
              "4333    738887\n",
              "4334    620465\n",
              "4335    451681\n",
              "4336    379225\n",
              "4337    209635\n",
              "4338    265239\n",
              "4339    176099\n",
              "4340    336377\n",
              "4341    114359\n",
              "4342    623947\n",
              "4343    383332\n",
              "4344    269810\n",
              "4345    896139\n",
              "4346    760376\n",
              "4347    133368\n",
              "4348    942586\n",
              "4349    828907\n",
              "4350    367217\n",
              "4351    634573\n",
              "4352    426523\n",
              "4353    875874\n",
              "4354    783872\n",
              "4355    256570\n",
              "4356    809241\n",
              "4357    742977\n",
              "4358    232517\n",
              "4359    352433\n",
              "4360    215988\n",
              "4361    505233\n",
              "4362    799256\n",
              "4363    544989\n",
              "4364    667873\n",
              "4365    262142\n",
              "4366    574126\n",
              "4367    234525\n",
              "4368    727665\n",
              "4369    738268\n",
              "4370    275922\n",
              "4371    182804\n",
              "4372    730816\n",
              "4373    271847\n",
              "4374    935549\n",
              "4375    103330\n",
              "4376    217205\n",
              "4377    609223\n",
              "4378    625174\n",
              "4379    403328\n",
              "4380    860773\n",
              "4381    568101\n",
              "4382    279169\n",
              "4383    831771\n",
              "4384    809170\n",
              "4385    991966\n",
              "4386    979899\n",
              "4387    655105\n",
              "4388    950098\n",
              "4389    223362\n",
              "4390    116742\n",
              "4391    285588\n",
              "4392    368326\n",
              "4393    455091\n",
              "4394    945622\n",
              "4395    335869\n",
              "4396    558218\n",
              "4397    709017\n",
              "4398    116824\n",
              "4399    813676\n",
              "4400    304412\n",
              "4401    297882\n",
              "4402    817625\n",
              "4403    761270\n",
              "4404    706641\n",
              "4405    368762\n",
              "4406    324769\n",
              "4407    625229\n",
              "4408    813241\n",
              "4409    174309\n",
              "4410    902048\n",
              "4411    368178\n",
              "4412    680291\n",
              "4413    647904\n",
              "4414    377451\n",
              "4415    482134\n",
              "4416    837891\n",
              "4417    664674\n",
              "4418    143533\n",
              "4419    716329\n",
              "4420    156821\n",
              "4421    672133\n",
              "4422    253957\n",
              "4423    992919\n",
              "4424    168190\n",
              "4425    615813\n",
              "4426    481021\n",
              "4427    817371\n",
              "4428    726940\n",
              "4429    826754\n",
              "4430    578935\n",
              "4431    526577\n",
              "4432    170059\n",
              "4433    219893\n",
              "4434    495140\n",
              "4435    699644\n",
              "4436    264609\n",
              "4437    901294\n",
              "4438    272454\n",
              "4439    788412\n",
              "4440    797930\n",
              "4441    916588\n",
              "4442    590999\n",
              "4443    224771\n",
              "4444    291984\n",
              "4445    305799\n",
              "4446    833133\n",
              "4447    738814\n",
              "4448    320621\n",
              "4449    749637\n",
              "4450    694091\n",
              "4451    800423\n",
              "4452    242760\n",
              "4453    449192\n",
              "4454    652225\n",
              "4455    192541\n",
              "4456    137899\n",
              "4457    986260\n",
              "4458    989321\n",
              "4459    209103\n",
              "4460    817465\n",
              "4461    839722\n",
              "4462    340965\n",
              "4463    244893\n",
              "4464    448665\n",
              "4465    803025\n",
              "4466    916332\n",
              "4467    872630\n",
              "4468    146112\n",
              "4469    112377\n",
              "4470    320996\n",
              "4471    932973\n",
              "4472    343035\n",
              "4473    759506\n",
              "4474    221761\n",
              "4475    592769\n",
              "4476    599571\n",
              "4477    466172\n",
              "4478    685541\n",
              "4479    329598\n",
              "4480    959550\n",
              "4481    337323\n",
              "4482    175723\n",
              "4483    644075\n",
              "4484    626462\n",
              "4485    940547\n",
              "4486    284047\n",
              "4487    993994\n",
              "4488    286763\n",
              "4489    122126\n",
              "4490    181027\n",
              "4491    277911\n",
              "4492    497265\n",
              "4493    537950\n",
              "4494    972413\n",
              "4495    508205\n",
              "4496    168298\n",
              "4497    547894\n",
              "4498    198137\n",
              "4499    781909\n",
              "4500    151845\n",
              "4501    867147\n",
              "4502    944998\n",
              "4503    797074\n",
              "4504    902715\n",
              "4505    694605\n",
              "4506    768087\n",
              "4507    856641\n",
              "4508    784004\n",
              "4509    446187\n",
              "4510    167516\n",
              "4511    967179\n",
              "4512    798174\n",
              "4513    553607\n",
              "4514    510991\n",
              "4515    184636\n",
              "4516    455537\n",
              "4517    936858\n",
              "4518    953843\n",
              "4519    286021\n",
              "4520    810168\n",
              "4521    392147\n",
              "4522    564341\n",
              "4523    204866\n",
              "4524    396041\n",
              "4525    269870\n",
              "4526    717382\n",
              "4527    220243\n",
              "4528    591560\n",
              "4529    353082\n",
              "4530    370077\n",
              "4531    924646\n",
              "4532    484682\n",
              "4533    747651\n",
              "4534    772702\n",
              "4535    716340\n",
              "4536    730931\n",
              "4537    202301\n",
              "4538    207699\n",
              "4539    203599\n",
              "4540    922780\n",
              "4541    510600\n",
              "4542    174662\n",
              "4543    903402\n",
              "4544    682990\n",
              "4545    608496\n",
              "4546    846526\n",
              "4547    753000\n",
              "4548    389016\n",
              "4549    611313\n",
              "4550    289525\n",
              "4551    498899\n",
              "4552    222685\n",
              "4553    373120\n",
              "4554    330640\n",
              "4555    764646\n",
              "4556    670944\n",
              "4557    805932\n",
              "4558    896134\n",
              "4559    121392\n",
              "4560    585159\n",
              "4561    259410\n",
              "4562    744698\n",
              "4563    860256\n",
              "4564    283520\n",
              "4565    352978\n",
              "4566    425971\n",
              "4567    133105\n",
              "4568    926674\n",
              "4569    528384\n",
              "4570    609848\n",
              "4571    391520\n",
              "4572    189040\n",
              "4573    603540\n",
              "4574    291222\n",
              "4575    531993\n",
              "4576    383252\n",
              "4577    520900\n",
              "4578    321713\n",
              "4579    512573\n",
              "4580    124947\n",
              "4581    250181\n",
              "4582    318880\n",
              "4583    462389\n",
              "4584    709095\n",
              "4585    661043\n",
              "4586    650871\n",
              "4587    173828\n",
              "4588    121550\n",
              "4589    301094\n",
              "4590    224588\n",
              "4591    102061\n",
              "4592    971770\n",
              "4593    148028\n",
              "4594    974505\n",
              "4595    319280\n",
              "4596    131178\n",
              "4597    950464\n",
              "4598    221830\n",
              "4599    866557\n",
              "4600    478652\n",
              "4601    666128\n",
              "4602    455196\n",
              "4603    257974\n",
              "4604    845183\n",
              "4605    364426\n",
              "4606    217187\n",
              "4607    260625\n",
              "4608    543065\n",
              "4609    251002\n",
              "4610    665420\n",
              "4611    963085\n",
              "4612    500141\n",
              "4613    173701\n",
              "4614    357814\n",
              "4615    320299\n",
              "4616    914729\n",
              "4617    522849\n",
              "4618    719088\n",
              "4619    340837\n",
              "4620    800295\n",
              "4621    563620\n",
              "4622    535560\n",
              "4623    640237\n",
              "4624    248099\n",
              "4625    831971\n",
              "4626    633827\n",
              "4627    498823\n",
              "4628    237172\n",
              "4629    598284\n",
              "4630    142572\n",
              "4631    795503\n",
              "4632    355655\n",
              "4633    816141\n",
              "4634    878987\n",
              "4635    581551\n",
              "4636    683400\n",
              "4637    758994\n",
              "4638    896567\n",
              "4639    807408\n",
              "4640    294261\n",
              "4641    576419\n",
              "4642    875370\n",
              "4643    750023\n",
              "4644    392715\n",
              "4645    332124\n",
              "4646    974999\n",
              "4647    357303\n",
              "4648    603027\n",
              "4649    311551\n",
              "4650    708866\n",
              "4651    744443\n",
              "4652    334528\n",
              "4653    622394\n",
              "4654    794623\n",
              "4655    169345\n",
              "4656    234495\n",
              "4657    773106\n",
              "4658    511924\n",
              "4659    123851\n",
              "4660    608693\n",
              "4661    100504\n",
              "4662    155186\n",
              "4663    601282\n",
              "4664    524562\n",
              "4665    456137\n",
              "4666    942629\n",
              "4667    478760\n",
              "4668    434528\n",
              "4669    870226\n",
              "4670    914134\n",
              "4671    750468\n",
              "4672    209847\n",
              "4673    559630\n",
              "4674    690856\n",
              "4675    189858\n",
              "4676    946670\n",
              "4677    900902\n",
              "4678    696320\n",
              "4679    331651\n",
              "4680    709291\n",
              "4681    348616\n",
              "4682    126116\n",
              "4683    753193\n",
              "4684    959070\n",
              "4685    912291\n",
              "4686    355609\n",
              "4687    642552\n",
              "4688    555038\n",
              "4689    595760\n",
              "4690    503517\n",
              "4691    446905\n",
              "4692    798079\n",
              "4693    466279\n",
              "4694    379638\n",
              "4695    175073\n",
              "4696    455535\n",
              "4697    767169\n",
              "4698    601725\n",
              "4699    631605\n",
              "4700    529745\n",
              "4701    681758\n",
              "4702    408443\n",
              "4703    745465\n",
              "4704    195038\n",
              "4705    590935\n",
              "4706    348048\n",
              "4707    134953\n",
              "4708    423526\n",
              "4709    759969\n",
              "4710    572812\n",
              "4711    851177\n",
              "4712    803768\n",
              "4713    672640\n",
              "4714    789636\n",
              "4715    309768\n",
              "4716    747918\n",
              "4717    731060\n",
              "4718    638400\n",
              "4719    990938\n",
              "4720    832642\n",
              "4721    182496\n",
              "4722    406579\n",
              "4723    968977\n",
              "4724    113646\n",
              "4725    155161\n",
              "4726    614691\n",
              "4727    878635\n",
              "4728    746959\n",
              "4729    319085\n",
              "4730    693293\n",
              "4731    370116\n",
              "4732    946408\n",
              "4733    938247\n",
              "4734    488201\n",
              "4735    675426\n",
              "4736    193880\n",
              "4737    782780\n",
              "4738    874821\n",
              "4739    448383\n",
              "4740    888443\n",
              "4741    676668\n",
              "4742    459680\n",
              "4743    298249\n",
              "4744    256713\n",
              "4745    946133\n",
              "4746    110886\n",
              "4747    677757\n",
              "4748    484731\n",
              "4749    283096\n",
              "4750    939833\n",
              "4751    333781\n",
              "4752    713246\n",
              "4753    991649\n",
              "4754    672068\n",
              "4755    506820\n",
              "4756    389549\n",
              "4757    260066\n",
              "4758    341147\n",
              "4759    288736\n",
              "4760    432977\n",
              "4761    160177\n",
              "4762    925198\n",
              "4763    544679\n",
              "4764    572265\n",
              "4765    198883\n",
              "4766    797473\n",
              "4767    727980\n",
              "4768    673312\n",
              "4769    143530\n",
              "4770    599124\n",
              "4771    690188\n",
              "4772    714869\n",
              "4773    739814\n",
              "4774    427030\n",
              "4775    847568\n",
              "4776    322865\n",
              "4777    234317\n",
              "4778    999007\n",
              "4779    744433\n",
              "4780    929370\n",
              "4781    778478\n",
              "4782    339660\n",
              "4783    546131\n",
              "4784    202146\n",
              "4785    972112\n",
              "4786    186609\n",
              "4787    529584\n",
              "4788    694444\n",
              "4789    171745\n",
              "4790    201770\n",
              "4791    465317\n",
              "4792    906198\n",
              "4793    720961\n",
              "4794    275385\n",
              "4795    570143\n",
              "4796    306634\n",
              "4797    737071\n",
              "4798    506699\n",
              "4799    342831\n",
              "4800    796659\n",
              "4801    677205\n",
              "4802    751637\n",
              "4803    221143\n",
              "4804    804140\n",
              "4805    575535\n",
              "4806    999515\n",
              "4807    602240\n",
              "4808    453230\n",
              "4809    168404\n",
              "4810    434585\n",
              "4811    763193\n",
              "4812    521439\n",
              "4813    206987\n",
              "4814    819609\n",
              "4815    285552\n",
              "4816    758205\n",
              "4817    984167\n",
              "4818    520515\n",
              "4819    415595\n",
              "4820    667779\n",
              "4821    909108\n",
              "4822    450984\n",
              "4823    236435\n",
              "4824    888270\n",
              "4825    739783\n",
              "4826    456726\n",
              "4827    402100\n",
              "4828    792961\n",
              "4829    835054\n",
              "4830    248620\n",
              "4831    875916\n",
              "4832    553944\n",
              "4833    906537\n",
              "4834    675556\n",
              "4835    950608\n",
              "4836    456878\n",
              "4837    858396\n",
              "4838    929010\n",
              "4839    930085\n",
              "4840    190273\n",
              "4841    572124\n",
              "4842    441061\n",
              "4843    570411\n",
              "4844    293129\n",
              "4845    726304\n",
              "4846    162727\n",
              "4847    238310\n",
              "4848    410759\n",
              "4849    111016\n",
              "4850    187376\n",
              "4851    728238\n",
              "4852    563396\n",
              "4853    480775\n",
              "4854    960532\n",
              "4855    929136\n",
              "4856    439024\n",
              "4857    296437\n",
              "4858    870626\n",
              "4859    722437\n",
              "4860    591559\n",
              "4861    898236\n",
              "4862    270897\n",
              "4863    272788\n",
              "4864    269693\n",
              "4865    968852\n",
              "4866    278055\n",
              "4867    440011\n",
              "4868    812513\n",
              "4869    480857\n",
              "4870    769682\n",
              "4871    358426\n",
              "4872    615954\n",
              "4873    384332\n",
              "4874    878790\n",
              "4875    305572\n",
              "4876    167967\n",
              "4877    302634\n",
              "4878    382989\n",
              "4879    368449\n",
              "4880    523474\n",
              "4881    399537\n",
              "4882    916395\n",
              "4883    272215\n",
              "4884    922633\n",
              "4885    963597\n",
              "4886    294886\n",
              "4887    283133\n",
              "4888    108967\n",
              "4889    511256\n",
              "4890    631657\n",
              "4891    607278\n",
              "4892    649353\n",
              "4893    121050\n",
              "4894    989902\n",
              "4895    471121\n",
              "4896    464464\n",
              "4897    579990\n",
              "4898    468156\n",
              "4899    529873\n",
              "4900    271228\n",
              "4901    682288\n",
              "4902    702347\n",
              "4903    776351\n",
              "4904    901701\n",
              "4905    355474\n",
              "4906    711436\n",
              "4907    504911\n",
              "4908    255568\n",
              "4909    695340\n",
              "4910    336513\n",
              "4911    604788\n",
              "4912    175753\n",
              "4913    752282\n",
              "4914    655330\n",
              "4915    652937\n",
              "4916    777054\n",
              "4917    216496\n",
              "4918    386501\n",
              "4919    265572\n",
              "4920    190891\n",
              "4921    789859\n",
              "4922    656839\n",
              "4923    925368\n",
              "4924    626040\n",
              "4925    796480\n",
              "4926    347304\n",
              "4927    678482\n",
              "4928    745334\n",
              "4929    833111\n",
              "4930    292906\n",
              "4931    503886\n",
              "4932    441711\n",
              "4933    824966\n",
              "4934    645851\n",
              "4935    937400\n",
              "4936    485534\n",
              "4937    944619\n",
              "4938    787218\n",
              "4939    551955\n",
              "4940    678947\n",
              "4941    876831\n",
              "4942    846773\n",
              "4943    705604\n",
              "4944    642124\n",
              "4945    263980\n",
              "4946    785590\n",
              "4947    500197\n",
              "4948    351659\n",
              "4949    207614\n",
              "4950    972145\n",
              "4951    419096\n",
              "4952    404476\n",
              "4953    622131\n",
              "4954    539175\n",
              "4955    348961\n",
              "4956    862571\n",
              "4957    770896\n",
              "4958    418808\n",
              "4959    799646\n",
              "4960    142613\n",
              "4961    171765\n",
              "4962    722193\n",
              "4963    122466\n",
              "4964    870760\n",
              "4965    761236\n",
              "4966    867328\n",
              "4967    777072\n",
              "4968    882589\n",
              "4969    794569\n",
              "4970    755533\n",
              "4971    341445\n",
              "4972    208817\n",
              "4973    612136\n",
              "4974    105978\n",
              "4975    792182\n",
              "4976    468076\n",
              "4977    476687\n",
              "4978    280990\n",
              "4979    958455\n",
              "4980    353698\n",
              "4981    690720\n",
              "4982    551582\n",
              "4983    194650\n",
              "4984    867503\n",
              "4985    393448\n",
              "4986    421512\n",
              "4987    632420\n",
              "4988    961372\n",
              "4989    746564\n",
              "4990    616086\n",
              "4991    324681\n",
              "4992    738921\n",
              "4993    857193\n",
              "4994    736313\n",
              "4995    628549\n",
              "4996    286944\n",
              "4997    285227\n",
              "4998    276058\n",
              "4999    453301\n",
              "5000    369796\n",
              "5001    352759\n",
              "5002    250643\n",
              "5003    230107\n",
              "5004    459340\n",
              "5005    961648\n",
              "5006    750639\n",
              "5007    151965\n",
              "5008    279597\n",
              "5009    814767\n",
              "5010    591739\n",
              "5011    793042\n",
              "5012    409350\n",
              "5013    224442\n",
              "5014    998103\n",
              "5015    895910\n",
              "5016    125575\n",
              "5017    945721\n",
              "5018    300546\n",
              "5019    815512\n",
              "5020    510583\n",
              "5021    158038\n",
              "5022    412125\n",
              "5023    385337\n",
              "5024    696781\n",
              "5025    260715\n",
              "5026    562124\n",
              "5027    163589\n",
              "5028    477221\n",
              "5029    360622\n",
              "5030    303346\n",
              "5031    438373\n",
              "5032    741272\n",
              "5033    500338\n",
              "5034    118791\n",
              "5035    425321\n",
              "5036    683915\n",
              "5037    686464\n",
              "5038    181526\n",
              "5039    871730\n",
              "5040    763619\n",
              "5041    258209\n",
              "5042    687530\n",
              "5043    605649\n",
              "5044    670342\n",
              "5045    548611\n",
              "5046    223698\n",
              "5047    274942\n",
              "5048    543733\n",
              "5049    460125\n",
              "5050    164089\n",
              "5051    198488\n",
              "5052    213724\n",
              "5053    460159\n",
              "5054    555952\n",
              "5055    357171\n",
              "5056    282534\n",
              "5057    734670\n",
              "5058    653906\n",
              "5059    918186\n",
              "5060    356073\n",
              "5061    797921\n",
              "5062    407888\n",
              "5063    690356\n",
              "5064    139935\n",
              "5065    886640\n",
              "5066    790602\n",
              "5067    584581\n",
              "5068    189783\n",
              "5069    176507\n",
              "5070    275837\n",
              "5071    270886\n",
              "5072    167609\n",
              "5073    317234\n",
              "5074    184503\n",
              "5075    273200\n",
              "5076    303430\n",
              "5077    487188\n",
              "5078    894921\n",
              "5079    665940\n",
              "5080    533950\n",
              "5081    158366\n",
              "5082    551305\n",
              "5083    960708\n",
              "5084    749293\n",
              "5085    687551\n",
              "5086    286547\n",
              "5087    620416\n",
              "5088    730080\n",
              "5089    201290\n",
              "5090    618016\n",
              "5091    416145\n",
              "5092    771743\n",
              "5093    187835\n",
              "5094    676922\n",
              "5095    351121\n",
              "5096    611912\n",
              "5097    549370\n",
              "5098    812901\n",
              "5099    466371\n",
              "5100    172076\n",
              "5101    936461\n",
              "5102    318229\n",
              "5103    668256\n",
              "5104    634074\n",
              "5105    861115\n",
              "5106    432110\n",
              "5107    506449\n",
              "5108    141014\n",
              "5109    647138\n",
              "5110    935354\n",
              "5111    117069\n",
              "5112    644710\n",
              "5113    443478\n",
              "5114    904300\n",
              "5115    433561\n",
              "5116    744131\n",
              "5117    213473\n",
              "5118    174209\n",
              "5119    691339\n",
              "5120    565268\n",
              "5121    869543\n",
              "5122    777626\n",
              "5123    305001\n",
              "5124    691327\n",
              "5125    197775\n",
              "5126    982042\n",
              "5127    770371\n",
              "5128    906504\n",
              "5129    760879\n",
              "5130    403710\n",
              "5131    788238\n",
              "5132    287561\n",
              "5133    530962\n",
              "5134    605423\n",
              "5135    892386\n",
              "5136    949112\n",
              "5137    879986\n",
              "5138    135551\n",
              "5139    259240\n",
              "5140    403558\n",
              "5141    334249\n",
              "5142    402556\n",
              "5143    877467\n",
              "5144    166731\n",
              "5145    835640\n",
              "5146    759404\n",
              "5147    876866\n",
              "5148    919748\n",
              "5149    241146\n",
              "5150    362537\n",
              "5151    442560\n",
              "5152    724004\n",
              "5153    928512\n",
              "5154    467933\n",
              "5155    209284\n",
              "5156    519805\n",
              "5157    430298\n",
              "5158    875095\n",
              "5159    803654\n",
              "5160    666251\n",
              "5161    516931\n",
              "5162    243901\n",
              "5163    218658\n",
              "5164    330983\n",
              "5165    327933\n",
              "5166    197307\n",
              "5167    731587\n",
              "5168    262069\n",
              "5169    744818\n",
              "5170    909783\n",
              "5171    290516\n",
              "5172    120593\n",
              "5173    128840\n",
              "5174    818071\n",
              "5175    974454\n",
              "5176    354326\n",
              "5177    748226\n",
              "5178    136521\n",
              "5179    385927\n",
              "5180    976738\n",
              "5181    595420\n",
              "5182    185255\n",
              "5183    919411\n",
              "5184    142761\n",
              "5185    152946\n",
              "5186    304522\n",
              "5187    242517\n",
              "5188    487731\n",
              "5189    431204\n",
              "5190    302584\n",
              "5191    576862\n",
              "5192    185693\n",
              "5193    329381\n",
              "5194    207597\n",
              "5195    592590\n",
              "5196    856747\n",
              "5197    196325\n",
              "5198    225818\n",
              "5199    192731\n",
              "5200    118429\n",
              "5201    949069\n",
              "5202    403979\n",
              "5203    565996\n",
              "5204    616516\n",
              "5205    107325\n",
              "5206    588751\n",
              "5207    249931\n",
              "5208    890148\n",
              "5209    825115\n",
              "5210    616186\n",
              "5211    400883\n",
              "5212    381947\n",
              "5213    395155\n",
              "5214    652717\n",
              "5215    624801\n",
              "5216    528450\n",
              "5217    730114\n",
              "5218    137722\n",
              "5219    696142\n",
              "5220    924553\n",
              "5221    384619\n",
              "5222    213583\n",
              "5223    154407\n",
              "5224    178972\n",
              "5225    211872\n",
              "5226    190476\n",
              "5227    769717\n",
              "5228    428516\n",
              "5229    901351\n",
              "5230    432959\n",
              "5231    401249\n",
              "5232    936689\n",
              "5233    202644\n",
              "5234    334142\n",
              "5235    968120\n",
              "5236    997518\n",
              "5237    172051\n",
              "5238    508797\n",
              "5239    563278\n",
              "5240    737878\n",
              "5241    370008\n",
              "5242    796783\n",
              "5243    930345\n",
              "5244    617751\n",
              "5245    672879\n",
              "5246    643630\n",
              "5247    247585\n",
              "5248    701740\n",
              "5249    922761\n",
              "5250    652542\n",
              "5251    838673\n",
              "5252    557827\n",
              "5253    989394\n",
              "5254    813462\n",
              "5255    440064\n",
              "5256    732338\n",
              "5257    142339\n",
              "5258    333346\n",
              "5259    961927\n",
              "5260    788806\n",
              "5261    945083\n",
              "5262    498517\n",
              "5263    601198\n",
              "5264    126210\n",
              "5265    393940\n",
              "5266    816513\n",
              "5267    989302\n",
              "5268    690993\n",
              "5269    198511\n",
              "5270    114172\n",
              "5271    229493\n",
              "5272    288479\n",
              "5273    911415\n",
              "5274    376212\n",
              "5275    259833\n",
              "5276    593727\n",
              "5277    772932\n",
              "5278    473809\n",
              "5279    982860\n",
              "5280    521935\n",
              "5281    436438\n",
              "5282    910777\n",
              "5283    264547\n",
              "5284    601142\n",
              "5285    185603\n",
              "5286    471154\n",
              "5287    393078\n",
              "5288    653530\n",
              "5289    445779\n",
              "5290    198863\n",
              "5291    872490\n",
              "5292    553017\n",
              "5293    321745\n",
              "5294    802654\n",
              "5295    745040\n",
              "5296    102506\n",
              "5297    587560\n",
              "5298    658730\n",
              "5299    669595\n",
              "5300    964345\n",
              "5301    229768\n",
              "5302    214233\n",
              "5303    307336\n",
              "5304    305474\n",
              "5305    478536\n",
              "5306    667600\n",
              "5307    762532\n",
              "5308    534194\n",
              "5309    221925\n",
              "5310    158761\n",
              "5311    664694\n",
              "5312    653707\n",
              "5313    315943\n",
              "5314    572962\n",
              "5315    915576\n",
              "5316    187003\n",
              "5317    693915\n",
              "5318    318140\n",
              "5319    487190\n",
              "5320    716764\n",
              "5321    228762\n",
              "5322    834937\n",
              "5323    744605\n",
              "5324    184695\n",
              "5325    695624\n",
              "5326    738233\n",
              "5327    180883\n",
              "5328    565203\n",
              "5329    594576\n",
              "5330    929828\n",
              "5331    262417\n",
              "5332    788103\n",
              "5333    127362\n",
              "5334    237272\n",
              "5335    973276\n",
              "5336    377339\n",
              "5337    870561\n",
              "5338    140590\n",
              "5339    472197\n",
              "5340    506123\n",
              "5341    615110\n",
              "5342    331396\n",
              "5343    801865\n",
              "5344    700510\n",
              "5345    394087\n",
              "5346    227252\n",
              "5347    858046\n",
              "5348    234494\n",
              "5349    901407\n",
              "5350    750444\n",
              "5351    331316\n",
              "5352    359777\n",
              "5353    200132\n",
              "5354    221358\n",
              "5355    155085\n",
              "5356    905906\n",
              "5357    290342\n",
              "5358    261137\n",
              "5359    808459\n",
              "5360    609775\n",
              "5361    789958\n",
              "5362    494191\n",
              "5363    608933\n",
              "5364    594978\n",
              "5365    359252\n",
              "5366    953995\n",
              "5367    180832\n",
              "5368    540503\n",
              "5369    138661\n",
              "5370    836178\n",
              "5371    121157\n",
              "5372    343890\n",
              "5373    340512\n",
              "5374    463731\n",
              "5375    729357\n",
              "5376    403370\n",
              "5377    373493\n",
              "5378    713389\n",
              "5379    224730\n",
              "5380    634397\n",
              "5381    476114\n",
              "5382    400264\n",
              "5383    254586\n",
              "5384    639327\n",
              "5385    498491\n",
              "5386    161570\n",
              "5387    423258\n",
              "5388    943287\n",
              "5389    353765\n",
              "5390    101094\n",
              "5391    985963\n",
              "5392    114707\n",
              "5393    277068\n",
              "5394    743930\n",
              "5395    285382\n",
              "5396    401238\n",
              "5397    493958\n",
              "5398    166120\n",
              "5399    871726\n",
              "5400    942008\n",
              "5401    582536\n",
              "5402    142329\n",
              "5403    802910\n",
              "5404    846028\n",
              "5405    731296\n",
              "5406    617691\n",
              "5407    586379\n",
              "5408    320363\n",
              "5409    405886\n",
              "5410    831719\n",
              "5411    973034\n",
              "5412    482084\n",
              "5413    934581\n",
              "5414    584105\n",
              "5415    510569\n",
              "5416    623115\n",
              "5417    189098\n",
              "5418    627250\n",
              "5419    582371\n",
              "5420    621970\n",
              "5421    980846\n",
              "5422    910241\n",
              "5423    964232\n",
              "5424    860239\n",
              "5425    477612\n",
              "5426    146942\n",
              "5427    977642\n",
              "5428    913973\n",
              "5429    576674\n",
              "5430    448603\n",
              "5431    535392\n",
              "5432    688428\n",
              "5433    787951\n",
              "5434    510793\n",
              "5435    771643\n",
              "5436    185525\n",
              "5437    213260\n",
              "5438    495225\n",
              "5439    879680\n",
              "5440    729682\n",
              "5441    744193\n",
              "5442    427860\n",
              "5443    594836\n",
              "5444    521892\n",
              "5445    901217\n",
              "5446    851056\n",
              "5447    987143\n",
              "5448    179217\n",
              "5449    416421\n",
              "5450    888956\n",
              "5451    277255\n",
              "5452    844964\n",
              "5453    689487\n",
              "5454    774013\n",
              "5455    156520\n",
              "5456    631359\n",
              "5457    104195\n",
              "5458    308397\n",
              "5459    351839\n",
              "5460    779932\n",
              "5461    990542\n",
              "5462    846854\n",
              "5463    869915\n",
              "5464    141629\n",
              "5465    561130\n",
              "5466    664051\n",
              "5467    913726\n",
              "5468    993705\n",
              "5469    693133\n",
              "5470    301461\n",
              "5471    340698\n",
              "5472    162038\n",
              "5473    980235\n",
              "5474    446691\n",
              "5475    407100\n",
              "5476    522420\n",
              "5477    944948\n",
              "5478    451382\n",
              "5479    650681\n",
              "5480    887564\n",
              "5481    637495\n",
              "5482    802073\n",
              "5483    665859\n",
              "5484    689933\n",
              "5485    230364\n",
              "5486    529645\n",
              "5487    134754\n",
              "5488    973473\n",
              "5489    395402\n",
              "5490    139307\n",
              "5491    420699\n",
              "5492    589125\n",
              "5493    777162\n",
              "5494    525271\n",
              "5495    593475\n",
              "5496    887835\n",
              "5497    715902\n",
              "5498    925051\n",
              "5499    666698\n",
              "5500    857050\n",
              "5501    426206\n",
              "5502    612903\n",
              "5503    349236\n",
              "5504    420743\n",
              "5505    188479\n",
              "5506    261946\n",
              "5507    232919\n",
              "5508    187233\n",
              "5509    110305\n",
              "5510    138697\n",
              "5511    532564\n",
              "5512    264895\n",
              "5513    136552\n",
              "5514    255671\n",
              "5515    540209\n",
              "5516    365727\n",
              "5517    151477\n",
              "5518    826760\n",
              "5519    473936\n",
              "5520    573856\n",
              "5521    699528\n",
              "5522    517510\n",
              "5523    609204\n",
              "5524    555465\n",
              "5525    929743\n",
              "5526    932803\n",
              "5527    133473\n",
              "5528    511240\n",
              "5529    483878\n",
              "5530    853674\n",
              "5531    506500\n",
              "5532    299589\n",
              "5533    329370\n",
              "5534    910667\n",
              "5535    485278\n",
              "5536    520624\n",
              "5537    817661\n",
              "5538    740104\n",
              "5539    116558\n",
              "5540    446037\n",
              "5541    418451\n",
              "5542    376559\n",
              "5543    834580\n",
              "5544    965410\n",
              "5545    740172\n",
              "5546    982896\n",
              "5547    522121\n",
              "5548    827176\n",
              "5549    309797\n",
              "5550    837096\n",
              "5551    881464\n",
              "5552    189580\n",
              "5553    309861\n",
              "5554    976875\n",
              "5555    836764\n",
              "5556    957449\n",
              "5557    835062\n",
              "5558    760744\n",
              "5559    534675\n",
              "5560    409606\n",
              "5561    636169\n",
              "5562    222139\n",
              "5563    411573\n",
              "5564    104036\n",
              "5565    575646\n",
              "5566    141017\n",
              "5567    870375\n",
              "5568    285084\n",
              "5569    146493\n",
              "5570    436583\n",
              "5571    761463\n",
              "5572    292655\n",
              "5573    157838\n",
              "5574    194720\n",
              "5575    757226\n",
              "5576    424437\n",
              "5577    244368\n",
              "5578    226297\n",
              "5579    171621\n",
              "5580    481258\n",
              "5581    688566\n",
              "5582    935693\n",
              "5583    264642\n",
              "5584    697001\n",
              "5585    433400\n",
              "5586    881258\n",
              "5587    553067\n",
              "5588    970213\n",
              "5589    931123\n",
              "5590    577898\n",
              "5591    462050\n",
              "5592    884456\n",
              "5593    872624\n",
              "5594    929403\n",
              "5595    950289\n",
              "5596    383234\n",
              "5597    804746\n",
              "5598    235781\n",
              "5599    401925\n",
              "5600    898893\n",
              "5601    123700\n",
              "5602    464835\n",
              "5603    586929\n",
              "5604    208562\n",
              "5605    112283\n",
              "5606    515471\n",
              "5607    789190\n",
              "5608    325592\n",
              "5609    532933\n",
              "5610    970758\n",
              "5611    294662\n",
              "5612    697613\n",
              "5613    707278\n",
              "5614    723757\n",
              "5615    110647\n",
              "5616    433988\n",
              "5617    135627\n",
              "5618    486961\n",
              "5619    349628\n",
              "5620    883609\n",
              "5621    156131\n",
              "5622    471799\n",
              "5623    839634\n",
              "5624    785577\n",
              "5625    762466\n",
              "5626    515234\n",
              "5627    335549\n",
              "5628    202027\n",
              "5629    500178\n",
              "5630    561173\n",
              "5631    114659\n",
              "5632    241621\n",
              "5633    172665\n",
              "5634    186932\n",
              "5635    531991\n",
              "5636    750346\n",
              "5637    595861\n",
              "5638    429076\n",
              "5639    705026\n",
              "5640    117212\n",
              "5641    146999\n",
              "5642    574349\n",
              "5643    781595\n",
              "5644    452467\n",
              "5645    413341\n",
              "5646    573265\n",
              "5647    139567\n",
              "5648    485930\n",
              "5649    462639\n",
              "5650    447209\n",
              "5651    161463\n",
              "5652    446034\n",
              "5653    405564\n",
              "5654    523102\n",
              "5655    193758\n",
              "5656    979010\n",
              "5657    619624\n",
              "5658    105251\n",
              "5659    890654\n",
              "5660    456099\n",
              "5661    796844\n",
              "5662    281510\n",
              "5663    220009\n",
              "5664    485354\n",
              "5665    512331\n",
              "5666    974966\n",
              "5667    250777\n",
              "5668    601764\n",
              "5669    387834\n",
              "5670    981618\n",
              "5671    544080\n",
              "5672    142031\n",
              "5673    867707\n",
              "5674    535032\n",
              "5675    741329\n",
              "5676    711499\n",
              "5677    511730\n",
              "5678    126058\n",
              "5679    641356\n",
              "5680    997836\n",
              "5681    420307\n",
              "5682    218695\n",
              "5683    664159\n",
              "5684    155486\n",
              "5685    367426\n",
              "5686    174783\n",
              "5687    145209\n",
              "5688    440445\n",
              "5689    393987\n",
              "5690    876167\n",
              "5691    276455\n",
              "5692    579561\n",
              "5693    851358\n",
              "5694    129125\n",
              "5695    923035\n",
              "5696    271447\n",
              "5697    369648\n",
              "5698    685123\n",
              "5699    498023\n",
              "5700    963780\n",
              "5701    923452\n",
              "5702    896792\n",
              "5703    678469\n",
              "5704    409070\n",
              "5705    111766\n",
              "5706    771184\n",
              "5707    671253\n",
              "5708    692846\n",
              "5709    647302\n",
              "5710    570758\n",
              "5711    148600\n",
              "5712    612527\n",
              "5713    812299\n",
              "5714    714025\n",
              "5715    975956\n",
              "5716    814064\n",
              "5717    305422\n",
              "5718    478743\n",
              "5719    218664\n",
              "5720    998119\n",
              "5721    773839\n",
              "5722    753071\n",
              "5723    595324\n",
              "5724    615532\n",
              "5725    476653\n",
              "5726    919206\n",
              "5727    146919\n",
              "5728    539932\n",
              "5729    487401\n",
              "5730    226655\n",
              "5731    396603\n",
              "5732    317967\n",
              "5733    438916\n",
              "5734    416770\n",
              "5735    409406\n",
              "5736    781097\n",
              "5737    809684\n",
              "5738    568541\n",
              "5739    198027\n",
              "5740    709956\n",
              "5741    704218\n",
              "5742    102372\n",
              "5743    577629\n",
              "5744    121846\n",
              "5745    198870\n",
              "5746    362579\n",
              "5747    136548\n",
              "5748    323814\n",
              "5749    301557\n",
              "5750    270303\n",
              "5751    158540\n",
              "5752    819926\n",
              "5753    948735\n",
              "5754    476794\n",
              "5755    742136\n",
              "5756    891892\n",
              "5757    458442\n",
              "5758    955891\n",
              "5759    843209\n",
              "5760    578817\n",
              "5761    784322\n",
              "5762    973144\n",
              "5763    673501\n",
              "5764    957619\n",
              "5765    953851\n",
              "5766    660506\n",
              "5767    108438\n",
              "5768    936678\n",
              "5769    821353\n",
              "5770    895063\n",
              "5771    825780\n",
              "5772    125416\n",
              "5773    452914\n",
              "5774    930066\n",
              "5775    439653\n",
              "5776    708315\n",
              "5777    595824\n",
              "5778    548169\n",
              "5779    212511\n",
              "5780    854508\n",
              "5781    896004\n",
              "5782    721119\n",
              "5783    835246\n",
              "5784    163783\n",
              "5785    758057\n",
              "5786    383965\n",
              "5787    977076\n",
              "5788    922960\n",
              "5789    759690\n",
              "5790    911717\n",
              "5791    327597\n",
              "Name: patient_id, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['DiagPeriodL90D'] = df[1]\n",
        "submission = test_data[['patient_id','DiagPeriodL90D']]\n",
        "submission.to_csv('/content/drive/MyDrive/WinDS/submission_ana_27.csv', index=False)\n"
      ],
      "metadata": {
        "id": "yS-fN9lfgWyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = se.transform(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPLRAa3Tcew6",
        "outputId": "0195d981-2739-4d95-fe88-1c7707e4f198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub_proba = xgb_model_tuned.predict_proba(test_data.drop(columns=['patient_id']))\n",
        "test_data['DiagPeriodL90D'] = sub_proba[:, 1]\n",
        "submission = test_data[['patient_id','DiagPeriodL90D']]\n",
        "submission.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qOYiraug84G_",
        "outputId": "d994e01a-65dd-4bde-e5c8-eb603f5e12b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   patient_id  DiagPeriodL90D\n",
              "0      573710        0.801780\n",
              "1      593679        0.633238\n",
              "2      184532        0.706015\n",
              "3      447383        0.576189\n",
              "4      687972        0.824491"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-335ae52c-a7e8-447f-a7ec-d0cff5f74cf6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patient_id</th>\n",
              "      <th>DiagPeriodL90D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>573710</td>\n",
              "      <td>0.801780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>593679</td>\n",
              "      <td>0.633238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>184532</td>\n",
              "      <td>0.706015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>447383</td>\n",
              "      <td>0.576189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>687972</td>\n",
              "      <td>0.824491</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-335ae52c-a7e8-447f-a7ec-d0cff5f74cf6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-335ae52c-a7e8-447f-a7ec-d0cff5f74cf6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-335ae52c-a7e8-447f-a7ec-d0cff5f74cf6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c99eac4b-cf6f-4af1-81f7-98dfe74079ad\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c99eac4b-cf6f-4af1-81f7-98dfe74079ad')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c99eac4b-cf6f-4af1-81f7-98dfe74079ad button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "submission",
              "summary": "{\n  \"name\": \"submission\",\n  \"rows\": 5792,\n  \"fields\": [\n    {\n      \"column\": \"patient_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 260988,\n        \"min\": 100266,\n        \"max\": 999890,\n        \"num_unique_values\": 5792,\n        \"samples\": [\n          285833,\n          962978,\n          777202\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DiagPeriodL90D\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5673,\n        \"samples\": [\n          0.7974824905395508,\n          0.06546947360038757,\n          0.17602160573005676\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SuHksSHjbUN",
        "outputId": "25b3a640-0e8a-4a77-cd47-9cd5938036c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5792, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv('/content/drive/MyDrive/WinDS/submission_ana_27.csv', index=False)"
      ],
      "metadata": {
        "id": "9Bee-N4X9EgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zKfQAWjLAHnA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}